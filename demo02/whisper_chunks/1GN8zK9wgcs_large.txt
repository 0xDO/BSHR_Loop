{"text": " Morning everybody. David Shapiro here with another video. So today's video is about generative AI for product owners. Some design principles, some stories, and some new paradigms that you can use if you're new to generative AI and you are a product owner who has been tasked with developing these kinds of products. Okay, so what to expect in this video? First, we're just going to go over some stories. I am a consultant and former IT professional so I've got quite a bit of experience in this in this space both working with agile and scrum teams working as an automation engineer sitting in on product meetings that sort of thing. There's also some general principles that I'm going to share that basically kind of the principles that I operate by when I am working with people to design generative AI-based products. And then finally we'll go over some of the new paradigms, the new ways to think about this stuff to take it to the next level. Alright, so story number one. For those of you that have been following me for a long time, you might remember my Auto Muse project. So the idea was I am a fiction writer. That's where I met my wife was at a sci-fi writing group. So this is something that is just really important to me. So I took my expertise in automation and generative AI and I combined it with my writing, my love of fiction writing and feedback. And so the long story short is that, well, there's actually kind of a few parts of the story. Until we got the most recent models, the ones with 8,000 tokens and more, there was a lot of things that were just not possible. And no matter what I tried to do to try and force some of the tasks into a 2,000 token window or a 4000 token window. And so if you're not familiar with this, the context window or the token window is the amount of text that the model can ingest at any one time. And so until recently, it was relatively small, you're limited to just a couple pages worth of text, which in terms of fiction is not not enough, it's just not enough to do the task. And so once I got access to larger and larger models, I was able to do more and more things. And some things that seemed impossible were suddenly very easy. Now, one of the main takeaways here is that I had subject matter expertise in both writing and editing and revising works of fiction as well as generative AI. And so by bringing that dual expertise to bear in the same mind, I was able to generate very powerful tools. Now, obviously you can't expect your engineers or your prompt engineers to also be experts in whatever subject matter or domain they're operating in. So this underscores the point, the importance of having the right people on the team. You need subject matter experts and you need expert prompt engineers at the very least. And this is why I knew exactly what questions to ask the model. And so to talk about the value of this, and this is really important. The first time I went to an editor, it was a $1,700 developmental edit, and it took two months. Once I was able to build these tools, I was able to get the same quality of edit back, and it cost about $17 instead of $1,700, so that's 100 X reduction in cost. And then instead of two months it took 30 minutes. So that's about a 3000 X reduction in time. And so when you look at those from a business perspective the value prop is obvious. You reduce time you reduce cost. And we're going to unpack a little bit more about how to go about those. How do you how do you focus on that. How do you find the tasks that achieve this? Story number two. So several of my clients have been lawyers. I have a few friends that are lawyers that are all interested in generative AI. And so in this case, this is not something that I have subject matter expertise in. And so I had to get good at talking to subject matter experts. And so it basically comes down to what information do you need and what output do you have, and then what cognitive operations you do with that information. So one of the most important questions when talking to a subject matter expert in terms of how do you use generative AI, first, you start with the output. Start with the output first. So in the case of a scientist, their output will be a scientific paper or a grant proposal. Or if it's a lawyer, it'll might be some kind of filing. They might be trying to file a motion to dismiss. They might be trying to file a patent or whatever, right? All kinds of stuff. So you start with the output and you work backwards. You say, what information goes into this? And where do you get that information? And then once you have that information, how do you, or even before you get that information, what mental processes do you go to find that information? And then once you have that information, how do you interpret that information and how do you use it? And so by understanding the workflow, by starting at the end and working backwards, how do you address this problem? You can generally work out a workflow, a formalized workflow with a few decision points and then a few checkpoints as well as reaching for external sources and so on and so forth. And so the thing is that many professionals have kind of an intuition for their workflow and it can be difficult because they don't necessarily think in terms of procedures and protocols. In many cases they do, right? Engineers, architects, there are some things that are very very highly proceduralized. But getting someone to articulate that takes a lot of back and forth and you can't just ask them, hey tell me what your procedure is. You have to be thinking about, okay what is the output and how do we get there. Story number three, 500% productivity increase. This isn't just me. There was a study by MIT that showed that some developers have a productivity output increase of 500% when they started using generative AI. I have certainly seen at least that in terms of the videos that I'm able to produce. Because guess what? I use generative AI to help brainstorm and write these videos. It's not good at creating the videos. It gives you very generic recommendations, and I have not been able to figure out how to get it to like actually figure out what to do next. I have to use my my experience and intuition there. But once I have a topic, it is absolutely critical in helping me think through that topic very, very quickly. And then another aspect of this is that productivity is not just the hard outputs. I have used generative AI to be a better leader, to be a better person, to be a better husband, to be a better friend. And so when you look at the the external work activity, that's one thing. But then when you look at yourself as an agent or you know as a person with virtues and you say what are the virtues that I can develop, one really critical thing is that the best AI products out there are going to help you be a better person as well. Not just more productive but be happier, healthier, kinder, more empathetic, and that sort of thing. And this is one of the things that generative AI really helps is that it can help with those soft skills and those intangibles like trust and respect. And I'm not saying it's obviously not appropriate to weave that into every product, but the fact that there are plenty of people working on making a generative AI products for things like coaching, executive leadership assistance, writing better emails, right? You know, marketing outreach, imbuing empathy and that sort of stuff is actually really critical and there's some stories out there that I've read on Twitter and Reddit and other places where, and I've noticed this for myself as well, that interacting with chat GPT for the last six months has actually one taught me to be a better writer but also to think more clearly about what I'm trying to write and also the state of mind of the person that I'm trying to communicate with. So for instance, I mentioned this in another video recently but it's a story worth repeating, is that you know the AI is doing the best that it can and sometimes you get frustrated with it and and what I realized is that if it senses any level of frustration then it ends up getting more bogged down trying to assuage your frustration and placate you rather than just focusing on the task at hand. And so even if it gets something flat wrong, rather than say, that's not what I wanted, all I say is, thanks, that's a good start. And when you, and just changing that word, just saying, because it's implied, thanks, that's a good start. Let's go this other way. It's like, okay, cool, let's change direction. But if you say, that's not what I want, it'll get bogged down in apologizing. And this is no different from humans. If you tell a human directly, that's not what I was looking for, it's like, oh crap, I've done something wrong. And so in the same respect, ChatGPT has taught me to be a little bit gentler with my feedback. And also, you know, my wife did the same thing too. But it's good practice. And so the point here is that productivity increases are a lot more than just the work output. It is looking at yourself as an agent or a person with virtues. Story number four, rapid adoption by a librarian. So my wife is a librarian turned product owner and we'll talk more about that later. But she did her master's thesis with GPT-3. And so one thing that I wanted to point out is that she and her advisor took to GPT-3 and this is way before chat GPT by the way. They took to it like a duck to water. And what I mean by that is that the training that librarians have in particular or anyone with a Master of Information Science or Master of Library Science, the training that they have to understand information in all of its various forms, whether it's a book, whether it's a paper, whether it's a web page. Understanding that information and how people find information and how people use information, those skills, that education is actually incredibly useful when working with generative AI. And so people like librarians, writers, philosophers, digital humanities. These folks have a very very powerful intuition when it comes to interacting with language models. I remember she told me the story about how she showed her advisor GPT-3 for the first time and he's like, Oh cool, can it do this? And just after futzing around with it for a few minutes, they realized like, yes, this this tool can absolutely instantly help librarianship and so then she her her master's thesis topic was approved she wrote it and she got she was one of the top in her program and you know her thesis has been inducted into their library of you know important master's thesis theses so the key takeaway here is that language and communication and information science should be core competencies in your teams. These are not necessarily people who are developers. They might be more on the internet side. They may be more on the SEO side. They might just be linguists. They might be writers, that sort of thing. And so there's another story within this is about, I don't know, eight months ago now or so, I was on a call with a founder and I asked him what kinds of people he wanted to hire. And this is a tech startup founder. And he said that he wanted to hire more, quote, core ML people. And I said, why? founder and he said that he wanted to hire more quote core ML people and I said why does machine do machine learning engineers and data scientists understand language no and so he looked at me like two heads when I looked at me like I had two heads when I said you know maybe you should hire people that are that actually know language and but within the tech industry, there is this view, this like, oh, poo-poo. Like, if you're not an engineer, if you're not a developer, then you just don't know anything useful. And I will say that that is a very harmful and false idea to have. And I am here to disabuse you of that notion. And I will say that, yes, you should hire humanities people, because they have a much, much stronger grasp of language abuse you of that notion. And I will say that yes, you should hire humanities people because they have a much, much stronger grasp of language than your engineers do. When I have seen, put it this way, some of the prompts that I have seen scientists and engineers write are completely incoherent. Yeah, written written communication is 100% a core competency. So story number five, the reflective journaling tool that I built. So if you're not familiar with this, I built a chatbot version of ChatGPT, or uses ChatGPT as the backend. And the idea was that it was a reflective journaling tool. And the idea here that it was a reflective journaling tool. And the idea here was to create something that could help me work through anything emotional anything stressful or whatever. And so it's for mental health but not in a professional capacity. But what I realized when I made this is I don't want any of this to be logged ever. And so in order to trust the tool I made sure that it does not log any conversations anywhere. And so one thing to keep in mind especially as you're building these tools that are able to engage with people on an emotional level that is able to engage with them on places where they're vulnerable, trust is going to be really really important. And trust once it's lost is pretty difficult to get back. And so these high-risk domains, whether it's relationships, emotions, you know I know people that are working on grief counseling tools, that sort of thing. So these are, these are, you know, AI tools that are going to touch people on a very critical level. And so respecting their privacy is 100% paramount. And I know that, you know, businesses say, you know, data is the new oil, we need to consume this data, you know, because all of the training happening on the back end, I actually don't necessarily believe that. And so what I mean by that is that all the providers of the language models, OpenAI, Microsoft, Google, Amazon and everyone else, Google, Amazon, and everyone else cohere, they are doing plenty of training on the back end. You don't necessarily need to collect your user data. And of course if the data doesn't exist anywhere, it can't be stolen and it can't be compromised. And so I just want to point that out as a possibility. One of the reasons that I actually haven't deployed an AI assistant in my own home that's constantly listening is because I haven't fully figured out what to do. Like how do I give my personal assistant a long-term memory, but also keep it safe and secure and keep it private? Because, you know, that is something that if you don't do it right, it could just happily share, accidentally or deliberately share private damaging harmful or embarrassing information with other visitors or put it on the internet or whatever and so the the safest thing is is the bomb that doesn't exist right because if a bomb is sitting there it might go off likewise if you have highly sensitive critical personal information that's just sitting there waiting to be stolen or waiting to be leaked, then maybe that information just shouldn't exist in the first place. Okay, so those are some stories. What are the general principles that I have extracted from both using these tools, building these tools, and consulting with other people building these tools. Number one is thinking about cognitive labor. So large language models provide you a type of cognitive computing. And so this is cognition. This is mental tasks, mental effort. And what you have to do is you have to have many conversations with subject matter experts in order to understand what they do, what they need, and most importantly, how they mentally go about their jobs. And so in the past, software development was about building a tool that was kind of apart and separate from your users, and then you'd have an expert that could come use the tool. The thing is, though, is that these tools are getting smarter, and the tools are now capable of cognitive labor. So you need to actually get into the mind of the subject matter experts in order to perform some cognitive offload, which we'll talk about right here. So to take it one step further, cognitive offload is one of the best signals that you can do in order to make the most valuable apps. So remember how I talked about I created an app for providing feedback for my fiction that instead of two months it took 30 minutes and instead of $1,700 it took $17. That is, the reason that that worked is because I performed cognitive offload. I no longer needed a professional editor to provide that feedback, I now had the machine provide that feedback. So that's what I mean by cognitive offload. So here's a few principles that you can think about when designing cognitive offload. One, user attention is scarce. Your user's brain juice is limited. You've got two to four hours maximum of high-quality executive function per day. Some of us have more, but we are the exception, not the rule, and we also can't do it every day. Decision fatigue is real. Deciding what to do next. Where do I get that information from? If you can just serve up, if you can intuit, use the language models to figure out what information the user needs and just give it to them without them having to even think about it before they even realize they need it, that will save them some cognitive energy and that is cognitive offload. Tedious problem solving, whether it's anticipating how something's going to be received or brainstorming or whatever, right? Like I use, I perform a tremendous amount of cognitive offload when I'm making my slide decks here. It's very tedious and it is also very draining and by offloading as much as I can to the model that makes my life much easier and it increases my output a lot. And then finally, basically whatever takes mental effort, whatever takes that cognitive labor, that mental effort, if you can delegate it to the LLM, to the language model, do it. And that is how you will create apps that just sell themselves because they are so much better. Principle number three, loose coupling. So brief history lesson. This Russian dude way back in the day named Kalashnikov designed a gun, the AK-47. And what he did was rather than designing a high precision, you know, like perfectly low tolerance machine, he said, why don't we design something that is, that everything has a lot of space, everything is loosely coupled, and so that it will have a lot of tolerance for things like dirt or broken cartridges or even bent parts, right? It can even tolerate damage because everything is just kind of loosely in there, but you know the interfaces where things work together, there's some tolerances built in there. And so the idea is that the the physical design principles that Kalashnikov put into the AK-47 make it an incredibly durable, legendarily reliable weapon. Now likewise, generative AI brings software into more direct friction with the real world, which is messy, which has variables. And so what you need to do is you need to adapt those loose tolerances into the software components because natural language is really squishy. That's just how it is. So think about how you can send instructions to a human via text or via email. And the human is able to abstract those instructions and turn it into real action. That abstraction and translation is how you need to think about the interfaces between language models and other machines or language models and other language models when you're transmitting instructions or information between language models. So that loose coupling and that high level of tolerance is how you will build language apps that are robust, resilient, and fault tolerant. Principle number four, English mastery. So I already talked about this with librarians and philosophers and that sort of stuff, so I probably don't need to rehash this, but keep in mind the fact that many developers are not the most articulate people. I'm not saying that just because someone is a developer or a technologist that doesn't mean they are not articulate. I am a professional IT guy and I'm incredibly articulate, but that's because I studied language. I studied the written word and I studied stories. So your math experts might not be the best communicators. Likewise, some of your subject matter experts might not be the best communicators. So having people that are expert communicators or expert with language will be a game changer for your teams. And as a product owner, if you're a product owner watching this, you probably understand the value of communication and your ability to communicate is part of what holds the team together and makes you great at your job. But that also means that you need a good communicator, someone who understands written word, or empathy, or theory of mind, or whatever, to help people communicate with the models. Because people with that empathy, that theory of mind, are going to be able to build a better intuition about what makes the language model tick. Principle number five, how do you measure success? So I already earlier told you that some of the things that you should aim for is at least a 5x increase in productivity. You should see speed increases on the order of 10x to 100x. You should see cost reduction, 10 10x to 100x ideally more you know the speed increase that I got for my novel feedback is 3000x which you're not going to get that every time but hey you know time is money and every little you know every minute every hour every day that you can shave off of the time it takes to complete a task the better your product is going to sell the more value add it's going to it's going to have. So the main point here is that human brains, here's how you measure it, human brains are optimizing engines. We are all intrinsically lazy. And the idea here is that your brain will automatically choose the path of least resistance. Part of that is which option, which tool, which workflow am I most familiar with, right? People will always default to whatever they're trained to do because it's mentally easier. Now if the tool you build is mentally easy to use and their brain says, you know what, I'm just gonna use this tool because it's easier, because it's quicker, it's easier. I know that it's just less mentally laborious. And so when the AI tool that you build is the optimal path, it will become the default choice. So how do you make that happen? First, you can make drop-in tools. So drop-in tools easily integrate with existing workflows. And remember, changing someone's workflow, that increases friction. Because why? That's no longer the path of least resistance. I remember I was at a small managed services provider and some people used Microsoft Teams, some use Slack, some use Skype. It was all over the place. And I used Microsoft Teams because it was the best tool for the job, but a lot of people just wouldn't get on board because it was a new tool. They had so much fatigue from keeping track of so many tools, and I'm like, but guys, this is the best tool for the job. And so even though it was a drop-in tool, the fact that it was a different tool, there was a lot of friction. So the other thing you can do is integrate language models with existing tools to further reduce friction and again perform that cognitive offload. But also don't underestimate the value of small tactical tools with very clear affordances that drive behavior to save time and energy. So for instance, one of the tools that I built, I already told you about the reflective journaling tool which has a very, very specific kind of emotional thing like hey help me talk through this thing Another tool that I built was a coding tool where literally all I do is like copy and paste some code or some data and then It's a chat interface to help me You know write code in a specific way those tiny little tactical tools are something that I can just call up When I need them and they perform some work and they're not integrated with anything else. So you might need integration, you might not, but again don't underestimate the value of really simple tools that are brain-dead easy to use. Principle number six, factual grounding. So here's something to assume, is that the LLM knows more than you do. It's not magic, right? You have to understand what training data it had, which was, you know, most of these are scraped from the internet. A lot of people have the assumption that like, okay, well, I want it to be a subject matter expert in topic X. And I'm like, have you asked it? I remember I was on a call with some folks doing SEO and they wanted to make sure that it understood the SEO principles that were published by some Scandinavian country, I don't remember which one. And they're like, well, how do we teach it this? I'm like, it already knows it. And they're like, what do you mean? And I was like, just ask it. Ask the model if it understands the SEO principles from the document that you're referring to that was these guidelines that were published by your country. And they did. And it's like, oh, it already knows that. So I was like, just tell it. Just tell it to abide by these principles. You don't need to teach it anything. Just give it a name, say abide by this principle. And if it knows it, great, and if it doesn't, you just name it and you say, you know, X, Y, and Z is an SEO principle, you know, adopted by this nation, and here's the basic facts. And so the idea is, you need a lot less factual grounding than you think you need in order to get the behavior out of the model that you want. So just tiny little reminders of the truth or the facts and just a few breadcrumbs. Because remember, it already knows a lot of general knowledge, which means that it is able to rapidly generalize to other things, even if it's never seen that term before. This is how I was able to teach it all of my stuff like axiomatic alignment and heuristic imperative. So that's my alignment research, if you're not familiar with that. And so by just quickly defining a term and saying, this is the term we're going to use, this is what it means, it is then able to work with that new thing. And this is called in-context learning. So I call it, you know, you can call it factual grounding, but from a scientific perspective, it's called in-context learning. So you can teach it something and it does not take much to teach it and then from there it can impute or infer the rest. So that's principle number six. Okay, so we're winding down, we're near the end of the video. The new paradigm you need to think about is polymorphic apps. So in the past, old school way of thinking is you build the tool. You build the tool and it build the tool and it's got databases and it's got web servers and app servers and network gateways and load balancers and that sort of thing. The paradigm that we're approaching is tools that build the tools. So instead of building tools, you build the tools that build the tools. And here's an example. Procedurally generated video game maps are nothing new. Elite Dangerous and, what was it, No Man's Sky and a whole bunch of other stuff. There's all kinds of games where every planet you go to or every new world you go to, the landscape is generated on the fly. So that's really cool. But that, of course, brings in new challenges. Because rather than having you know environment level designers, you have to have people that design the tools that build the levels for you. And with generative AI what's coming next is dialogue. So rather than having a writer manually write all the dialogue in the game, you have to have a tool that writes the dialogue for you. So on and so forth. So this is one example that's actively happening right now. Likewise, you take this to a logical extension and you start to create polymorphic apps where the user interface might be dynamically generated and it might adapt on the fly based on what the application is doing. So this is a tool that builds a tool. So you have a tool that is a UI builder So you have a tool that is a UI builder. You have a tool that is a code generator, right? This is one of the biggest things right now is language models that write code. So if the language model can write code on the fly, maybe the role of developers change to instead of writing the code themselves, they write the thing that writes code on demand as it's needed. So this is called metaprogramming. and metaprogramming is nothing new. So this is writing programs that write other programs. So one of the key foundational things that you need to adapt to this new paradigm of polymorphic apps is metaprogramming. Instead of writing the code yourself, you use the model to write the code that you need, and then you have the other systems in place that test and validate and integrate that code. Another principle to build polymorphic apps is that everything must be configurable. So whether this is your user interface, your back end, your networking, your infrastructure, all of that. And since everything has APIs today, and language models can use APIs, well, there you have it. But you need to get into this. And another thing is that when I say everything must be ephemeral, not everything, the tools that build the tools are not ephemeral, but the tools that they build are ephemeral. So what I mean by that is, think of it like the replicator from Star Trek. You need a very specific wrench and you just say, computer give me this wrench that I need right now. And then when you're done with that you give it back to the computer and it breaks it down. That's how you need to think about these ephemeral tools in order to build polymorphic apps. So rather than having a library of tens of thousands of tools, instead you have a replicator that can build any tool that you need in that moment and then it's done. So that is the new paradigm that we're moving towards is polymorphic apps. And then another way to think about this is in terms of architectural components or software components. So today, you fundamentally, from a software perspective, you fundamentally have kind of two major things. There's obviously a lot more to it than this, but you've got databases, which is where your information is stored. And of course, there's all kinds of things. There's search indexes. There's document stores. There's relational databases. But the idea is that you've got information stored somewhere. Okay, cool. One architectural design thing. You've got an information repository. Another thing is an application server. So the application server might do back-end processing, it might do OCR, it might serve up your web app, whatever. But you've got the data and the processing. But now we have LLMs, which is a new kind of processing. So this new kind of component is a cognitive engine. So rather than a data engine or an application engine or a web engine, now you have a cognitive engine. So rather than a data engine, or an application engine, or a web engine, now you have a cognitive engine. So if you start to think of LLMs as a new software component, a new architectural component that goes into the stack, that is the appropriate way. And so then, what are the characteristics of this new component? Obviously, you're familiar with databases, you're familiar with web servers, that sort of thing. You have a mental list of characterizations of what those components are capable of. So here's some of what a language model is capable of. Language processing, obviously. It can read human text, it can generate human text, it can transform human text. Pretty much any NLP task it can do, and it can do it faster and better than many humans can. It's not necessarily going to be faster than old-school NLP techniques because of the memory requirements to run language models. Reasoning and knowledge. So this is something that is still controversial but more and more scientific studies are coming out saying yes, these language models have theory of mind. Yes, they truly understand what they're talking about. Yes, they can reason through things. Yes, they can make accurate predictions and forecasts and they can defend their positions with logic. Now, that being said, they can still choose really dumb things sometimes, but there's ways to defeat that with things like tree of thought reasoning. Context understanding. So context, context, context, context. This is one of the key things that I teach people in my consultations, is in order for the language model to do exactly what you need it to do, you need to give it the right context. What business is it operating in? What step of the process is it doing? What input should expect? What kind of user is using it in order for the given task? Because if you tell a language model, hey your primary user is going to be a research scientist in a microbiology lab, that will wake up a lot of mental things than if you don't tell it that information. Or conversely, if you tell it, hey your primary user is going to be an amateur fiction writer, treat them accordingly, that context helps the language model cue in to whatever behavior it needs to manifest. Adaptability. So in the context of the tools that build the tools, remember, these things are infinitely flexible. And that gives you a whole litany of new programming capabilities. So that instead of having to keep track of a gigantic toolbox, you now have a tool replicator that can just synthesize any tool that you need on the fly. And that's going to make it infinitely more flexible. And then of course planning and sequencing, brainstorming steps, and that sort of stuff. All that, if you need more on that, just look up Tree of Thought. That is the current state of the art technique that you need to know about for that sort of thing, for problem solving. Okay, so there you have it. Generative AI for product owners. I am available for consultation. Reach out to me on LinkedIn. Link in the description. Cheers. I hope you got a lot out of it. Bye. Bye.", "chunks": [{"timestamp": [0.0, 2.5], "text": " Morning everybody. David Shapiro here with another video."}, {"timestamp": [2.5, 6.5], "text": " So today's video is about generative AI for product owners."}, {"timestamp": [6.5, 10.5], "text": " Some design principles, some stories, and some new paradigms"}, {"timestamp": [10.5, 15.5], "text": " that you can use if you're new to generative AI and you are a product owner"}, {"timestamp": [15.5, 19.5], "text": " who has been tasked with developing these kinds of products."}, {"timestamp": [19.5, 22.5], "text": " Okay, so what to expect in this video?"}, {"timestamp": [22.5, 25.12], "text": " First, we're just going to go over some stories."}, {"timestamp": [25.16, 28.08], "text": " I am a consultant and former"}, {"timestamp": [28.08, 30.6], "text": " IT professional so I've got quite a bit of experience"}, {"timestamp": [30.6, 33.0], "text": " in this in this space both working"}, {"timestamp": [33.0, 35.4], "text": " with agile and scrum teams working"}, {"timestamp": [35.4, 37.84], "text": " as an automation engineer sitting"}, {"timestamp": [37.84, 39.88], "text": " in on product meetings that sort of thing."}, {"timestamp": [40.88, 43.16], "text": " There's also some general principles that I'm going to"}, {"timestamp": [43.16, 48.0], "text": " share that basically kind of the principles that I operate by"}, {"timestamp": [48.0, 52.0], "text": " when I am working with people to design generative AI-based products."}, {"timestamp": [52.0, 56.0], "text": " And then finally we'll go over some of the new paradigms, the new ways to think about this stuff"}, {"timestamp": [56.0, 58.0], "text": " to take it to the next level."}, {"timestamp": [58.0, 60.0], "text": " Alright, so story number one."}, {"timestamp": [60.0, 70.56], "text": " For those of you that have been following me for a long time, you might remember my Auto Muse project. So the idea was I am a fiction writer. That's where I met my wife was at a sci-fi writing group."}, {"timestamp": [71.0, 73.8], "text": " So this is something that is just really important to me."}, {"timestamp": [73.8, 79.76], "text": " So I took my expertise in automation and generative AI and I combined it with my"}, {"timestamp": [80.28, 88.0], "text": " writing, my love of fiction writing and feedback. And so the long story short is that,"}, {"timestamp": [88.0, 91.0], "text": " well, there's actually kind of a few parts of the story."}, {"timestamp": [91.0, 93.0], "text": " Until we got the most recent models,"}, {"timestamp": [93.0, 96.0], "text": " the ones with 8,000 tokens and more,"}, {"timestamp": [96.0, 98.0], "text": " there was a lot of things that were just not possible."}, {"timestamp": [98.0, 102.0], "text": " And no matter what I tried to do to try and force some of the tasks"}, {"timestamp": [102.0, 106.28], "text": " into a 2,000 token window or a 4000"}, {"timestamp": [106.28, 110.8], "text": " token window. And so if you're not familiar with this, the context window or the token window is"}, {"timestamp": [110.8, 116.24], "text": " the amount of text that the model can ingest at any one time. And so until recently, it was"}, {"timestamp": [116.24, 121.28], "text": " relatively small, you're limited to just a couple pages worth of text, which in terms of fiction is"}, {"timestamp": [121.28, 125.44], "text": " not not enough, it's just not enough to do the task."}, {"timestamp": [128.92, 131.48], "text": " And so once I got access to larger and larger models, I was able to do more and more things."}, {"timestamp": [131.48, 134.28], "text": " And some things that seemed impossible"}, {"timestamp": [134.28, 136.28], "text": " were suddenly very easy."}, {"timestamp": [136.28, 138.26], "text": " Now, one of the main takeaways here"}, {"timestamp": [138.26, 140.56], "text": " is that I had subject matter expertise"}, {"timestamp": [140.56, 146.4], "text": " in both writing and editing and revising works of fiction as well as generative"}, {"timestamp": [146.4, 147.6], "text": " AI."}, {"timestamp": [147.6, 153.42], "text": " And so by bringing that dual expertise to bear in the same mind, I was able to generate"}, {"timestamp": [153.42, 155.12], "text": " very powerful tools."}, {"timestamp": [155.12, 161.56], "text": " Now, obviously you can't expect your engineers or your prompt engineers to also be experts"}, {"timestamp": [161.56, 167.4], "text": " in whatever subject matter or domain they're operating in. So this underscores the point, the importance"}, {"timestamp": [167.4, 170.0], "text": " of having the right people on the team."}, {"timestamp": [170.0, 171.68], "text": " You need subject matter experts"}, {"timestamp": [171.68, 175.32], "text": " and you need expert prompt engineers at the very least."}, {"timestamp": [175.32, 178.64], "text": " And this is why I knew exactly what questions to ask"}, {"timestamp": [179.64, 180.56], "text": " the model."}, {"timestamp": [180.56, 183.32], "text": " And so to talk about the value of this,"}, {"timestamp": [183.32, 192.0], "text": " and this is really important. The first time I went to an editor, it was a $1,700 developmental edit, and it took two months."}, {"timestamp": [192.0, 205.9], "text": " Once I was able to build these tools, I was able to get the same quality of edit back, and it cost about $17 instead of $1,700, so that's 100 X reduction in cost. And then instead of two months it"}, {"timestamp": [205.9, 206.66], "text": " took 30 minutes."}, {"timestamp": [206.66, 208.16], "text": " So that's about a 3000"}, {"timestamp": [208.76, 210.44], "text": " X reduction in time."}, {"timestamp": [211.24, 213.3], "text": " And so when you look at those"}, {"timestamp": [213.32, 215.14], "text": " from a business perspective the"}, {"timestamp": [215.14, 216.76], "text": " value prop is obvious."}, {"timestamp": [216.96, 219.28], "text": " You reduce time you reduce cost."}, {"timestamp": [219.68, 221.18], "text": " And we're going to unpack a little"}, {"timestamp": [221.18, 223.08], "text": " bit more about how to go about"}, {"timestamp": [223.08, 224.92], "text": " those. How do you how do you focus"}, {"timestamp": [224.92, 230.44], "text": " on that. How do you find the tasks that achieve this? Story number two."}, {"timestamp": [230.44, 234.96], "text": " So several of my clients have been lawyers. I have a few friends that are"}, {"timestamp": [234.96, 240.68], "text": " lawyers that are all interested in generative AI. And so in this case, this"}, {"timestamp": [240.68, 247.68], "text": " is not something that I have subject matter expertise in. And so I had to get good at talking to subject matter experts."}, {"timestamp": [247.68, 252.24], "text": " And so it basically comes down to what information do you need"}, {"timestamp": [252.24, 254.24], "text": " and what output do you have,"}, {"timestamp": [254.24, 258.64], "text": " and then what cognitive operations you do with that information."}, {"timestamp": [258.64, 262.84], "text": " So one of the most important questions when talking to a subject matter expert"}, {"timestamp": [262.84, 270.16], "text": " in terms of how do you use generative AI, first, you start with the output. Start with the output first. So in"}, {"timestamp": [270.16, 276.08], "text": " the case of a scientist, their output will be a scientific paper or a grant"}, {"timestamp": [276.08, 280.4], "text": " proposal. Or if it's a lawyer, it'll might be some kind of filing. They might"}, {"timestamp": [280.4, 285.88], "text": " be trying to file a motion to dismiss. They might be trying to file a patent or whatever, right?"}, {"timestamp": [285.88, 287.24], "text": " All kinds of stuff."}, {"timestamp": [287.24, 290.12], "text": " So you start with the output and you work backwards."}, {"timestamp": [290.12, 292.68], "text": " You say, what information goes into this?"}, {"timestamp": [292.68, 294.88], "text": " And where do you get that information?"}, {"timestamp": [294.88, 297.52], "text": " And then once you have that information, how do you,"}, {"timestamp": [297.52, 299.52], "text": " or even before you get that information,"}, {"timestamp": [299.52, 303.0], "text": " what mental processes do you go to find that information?"}, {"timestamp": [303.0, 309.08], "text": " And then once you have that information, how do you interpret that information and how do you use it? And so"}, {"timestamp": [309.08, 312.84], "text": " by understanding the workflow, by starting at the end and working"}, {"timestamp": [312.84, 318.6], "text": " backwards, how do you address this problem? You can generally work out"}, {"timestamp": [318.6, 328.64], "text": " a workflow, a formalized workflow with a few decision points and then a few checkpoints as well as"}, {"timestamp": [329.84, 336.56], "text": " reaching for external sources and so on and so forth. And so the thing is that many professionals"}, {"timestamp": [337.84, 349.28], "text": " have kind of an intuition for their workflow and it can be difficult because they don't necessarily think in terms of procedures and protocols. In many cases they do, right?"}, {"timestamp": [349.28, 353.56], "text": " Engineers, architects, there are some things that are very very highly"}, {"timestamp": [353.56, 358.9], "text": " proceduralized. But getting someone to articulate that takes a lot of back and"}, {"timestamp": [358.9, 362.36], "text": " forth and you can't just ask them, hey tell me what your procedure is. You have"}, {"timestamp": [362.36, 370.44], "text": " to be thinking about, okay what is the output and how do we get there. Story number three, 500% productivity increase."}, {"timestamp": [370.44, 375.88], "text": " This isn't just me. There was a study by MIT that showed that some developers have"}, {"timestamp": [375.88, 382.72], "text": " a productivity output increase of 500% when they started using generative AI. I"}, {"timestamp": [382.72, 387.44], "text": " have certainly seen at least that in terms of the videos that I'm able to produce."}, {"timestamp": [387.76, 388.64], "text": " Because guess what?"}, {"timestamp": [388.64, 391.96], "text": " I use generative AI to help brainstorm and write these videos."}, {"timestamp": [392.36, 394.48], "text": " It's not good at creating the videos."}, {"timestamp": [394.48, 398.2], "text": " It gives you very generic recommendations, and I have not been able to figure out"}, {"timestamp": [398.2, 401.64], "text": " how to get it to like actually figure out what to do next."}, {"timestamp": [401.64, 404.88], "text": " I have to use my my experience and intuition there."}, {"timestamp": [410.16, 414.68], "text": " But once I have a topic, it is absolutely critical in helping me think through that topic very, very quickly. And then another aspect of this is that"}, {"timestamp": [414.68, 420.28], "text": " productivity is not just the hard outputs. I have used generative AI to be"}, {"timestamp": [420.28, 423.4], "text": " a better leader, to be a better person, to be a better husband, to be a better"}, {"timestamp": [423.4, 428.64], "text": " friend. And so when you look at the the external work activity, that's one thing."}, {"timestamp": [428.64, 434.84], "text": " But then when you look at yourself as an agent or you know as a person with"}, {"timestamp": [434.84, 440.44], "text": " virtues and you say what are the virtues that I can develop, one really critical"}, {"timestamp": [440.44, 443.8], "text": " thing is that the best AI products out there are going to help you be a better"}, {"timestamp": [443.8, 450.26], "text": " person as well. Not just more productive but be happier, healthier, kinder, more empathetic,"}, {"timestamp": [450.26, 454.1], "text": " and that sort of thing. And this is one of the things that generative AI really helps"}, {"timestamp": [454.1, 459.62], "text": " is that it can help with those soft skills and those intangibles like trust and respect."}, {"timestamp": [459.62, 464.08], "text": " And I'm not saying it's obviously not appropriate to weave that into every product, but the"}, {"timestamp": [464.08, 469.18], "text": " fact that there are plenty of people working on making a generative AI products for things"}, {"timestamp": [469.18, 475.48], "text": " like coaching, executive leadership assistance, writing better emails, right?"}, {"timestamp": [475.48, 480.16], "text": " You know, marketing outreach, imbuing empathy and that sort of stuff is actually really"}, {"timestamp": [480.16, 488.24], "text": " critical and there's some stories out there that I've read on Twitter and Reddit and other places where, and I've noticed this for myself as well, that"}, {"timestamp": [488.24, 493.08], "text": " interacting with chat GPT for the last six months has actually one taught me to"}, {"timestamp": [493.08, 497.52], "text": " be a better writer but also to think more clearly about what I'm trying to"}, {"timestamp": [497.52, 501.64], "text": " write and also the state of mind of the person that I'm trying to communicate"}, {"timestamp": [501.64, 509.76], "text": " with. So for instance, I mentioned this in another video recently but it's a story worth repeating, is that you know"}, {"timestamp": [509.76, 513.64], "text": " the AI is doing the best that it can and sometimes you get frustrated with it and"}, {"timestamp": [513.64, 520.16], "text": " and what I realized is that if it senses any level of frustration then it ends up"}, {"timestamp": [520.16, 524.08], "text": " getting more bogged down trying to assuage your frustration and placate"}, {"timestamp": [524.08, 525.52], "text": " you rather than"}, {"timestamp": [525.52, 528.48], "text": " just focusing on the task at hand."}, {"timestamp": [528.48, 533.5], "text": " And so even if it gets something flat wrong, rather than say, that's not what I wanted,"}, {"timestamp": [533.5, 536.6], "text": " all I say is, thanks, that's a good start."}, {"timestamp": [536.6, 541.04], "text": " And when you, and just changing that word, just saying, because it's implied, thanks,"}, {"timestamp": [541.04, 542.16], "text": " that's a good start."}, {"timestamp": [542.16, 543.16], "text": " Let's go this other way."}, {"timestamp": [543.16, 544.66], "text": " It's like, okay, cool, let's change direction."}, {"timestamp": [544.66, 548.92], "text": " But if you say, that's not what I want, it'll get bogged down in apologizing."}, {"timestamp": [548.92, 550.86], "text": " And this is no different from humans."}, {"timestamp": [550.86, 554.5], "text": " If you tell a human directly, that's not what I was looking for, it's like, oh crap, I've"}, {"timestamp": [554.5, 556.74], "text": " done something wrong."}, {"timestamp": [556.74, 562.82], "text": " And so in the same respect, ChatGPT has taught me to be a little bit gentler with my feedback."}, {"timestamp": [562.82, 565.0], "text": " And also, you know, my wife did the same thing too."}, {"timestamp": [565.56, 566.92], "text": " But it's good practice."}, {"timestamp": [568.0, 572.12], "text": " And so the point here is that productivity increases"}, {"timestamp": [572.36, 574.44], "text": " are a lot more than just the work output."}, {"timestamp": [574.76, 577.72], "text": " It is looking at yourself as an agent"}, {"timestamp": [578.4, 580.4], "text": " or a person with virtues."}, {"timestamp": [581.4, 584.12], "text": " Story number four, rapid adoption by a librarian."}, {"timestamp": [584.12, 585.96], "text": " So my wife is a librarian"}, {"timestamp": [585.96, 587.96], "text": " turned product"}, {"timestamp": [587.96, 589.2], "text": " owner and we'll talk more about that"}, {"timestamp": [589.2, 589.92], "text": " later."}, {"timestamp": [589.92, 591.92], "text": " But she did her master's thesis"}, {"timestamp": [591.92, 592.92], "text": " with GPT-3."}, {"timestamp": [593.72, 595.52], "text": " And so one thing that I wanted"}, {"timestamp": [595.52, 597.64], "text": " to point out is that she"}, {"timestamp": [597.64, 599.56], "text": " and her advisor took to GPT-3"}, {"timestamp": [599.56, 601.24], "text": " and this is way before chat GPT by"}, {"timestamp": [601.24, 603.32], "text": " the way. They took to it like a duck"}, {"timestamp": [603.4, 604.32], "text": " to water."}, {"timestamp": [604.32, 610.82], "text": " And what I mean by that is that the training that librarians have in particular or anyone"}, {"timestamp": [610.82, 616.4], "text": " with a Master of Information Science or Master of Library Science, the training that they"}, {"timestamp": [616.4, 622.18], "text": " have to understand information in all of its various forms, whether it's a book, whether"}, {"timestamp": [622.18, 627.36], "text": " it's a paper, whether it's a web page."}, {"timestamp": [627.36, 632.48], "text": " Understanding that information and how people find information and how people use information,"}, {"timestamp": [632.48, 639.04], "text": " those skills, that education is actually incredibly useful when working with generative AI."}, {"timestamp": [639.04, 649.6], "text": " And so people like librarians, writers, philosophers, digital humanities. These folks have a very very powerful intuition when it comes to interacting with language models."}, {"timestamp": [649.6, 655.04], "text": " I remember she told me the story about how she showed her advisor GPT-3 for the first time and he's like,"}, {"timestamp": [655.04, 658.76], "text": " Oh cool, can it do this? And just after futzing around with it for a few minutes,"}, {"timestamp": [659.4, 665.06], "text": " they realized like, yes, this this tool can absolutely instantly help librarianship"}, {"timestamp": [665.06, 671.96], "text": " and so then she her her master's thesis topic was approved she wrote it and she"}, {"timestamp": [671.96, 676.72], "text": " got she was one of the top in her program and you know her thesis has been"}, {"timestamp": [676.72, 684.0], "text": " inducted into their library of you know important master's thesis theses so the"}, {"timestamp": [684.0, 686.14], "text": " key takeaway here is that language and"}, {"timestamp": [686.14, 690.4], "text": " communication and information science should be core competencies in your"}, {"timestamp": [690.4, 695.42], "text": " teams. These are not necessarily people who are developers. They might"}, {"timestamp": [695.42, 700.16], "text": " be more on the internet side. They may be more on the SEO side. They might"}, {"timestamp": [700.16, 708.88], "text": " just be linguists. They might be writers, that sort of thing. And so there's another story within this is about,"}, {"timestamp": [708.88, 711.88], "text": " I don't know, eight months ago now or so,"}, {"timestamp": [711.88, 714.68], "text": " I was on a call with a founder"}, {"timestamp": [714.68, 717.8], "text": " and I asked him what kinds of people he wanted to hire."}, {"timestamp": [717.8, 720.96], "text": " And this is a tech startup founder."}, {"timestamp": [720.96, 722.6], "text": " And he said that he wanted to hire more,"}, {"timestamp": [722.6, 724.76], "text": " quote, core ML people."}, {"timestamp": [724.76, 725.0], "text": " And I said, why? founder and he said that he wanted to hire more quote core ML people and I"}, {"timestamp": [725.0, 731.56], "text": " said why does machine do machine learning engineers and data scientists"}, {"timestamp": [731.56, 736.2], "text": " understand language no and so he looked at me like two heads when I looked at me"}, {"timestamp": [736.2, 740.76], "text": " like I had two heads when I said you know maybe you should hire people that"}, {"timestamp": [740.76, 747.08], "text": " are that actually know language and but within the tech industry, there is this view,"}, {"timestamp": [747.08, 748.24], "text": " this like, oh, poo-poo."}, {"timestamp": [748.24, 751.48], "text": " Like, if you're not an engineer, if you're not a developer,"}, {"timestamp": [751.48, 754.24], "text": " then you just don't know anything useful."}, {"timestamp": [754.24, 758.64], "text": " And I will say that that is a very harmful and false idea"}, {"timestamp": [758.64, 759.2], "text": " to have."}, {"timestamp": [759.2, 762.08], "text": " And I am here to disabuse you of that notion."}, {"timestamp": [762.08, 764.8], "text": " And I will say that, yes, you should hire humanities people,"}, {"timestamp": [764.8, 765.04], "text": " because they have a much, much stronger grasp of language abuse you of that notion. And I will say that yes, you should hire humanities people because"}, {"timestamp": [765.04, 772.52], "text": " they have a much, much stronger grasp of language than your engineers do. When I have seen,"}, {"timestamp": [772.52, 775.9], "text": " put it this way, some of the prompts that I have seen scientists and engineers write"}, {"timestamp": [775.9, 785.0], "text": " are completely incoherent. Yeah, written written communication is 100% a core competency."}, {"timestamp": [787.7, 788.9], "text": " So story number five,"}, {"timestamp": [788.9, 790.5], "text": " the reflective journaling tool that I built."}, {"timestamp": [790.5, 792.12], "text": " So if you're not familiar with this,"}, {"timestamp": [792.12, 796.54], "text": " I built a chatbot version of ChatGPT,"}, {"timestamp": [796.54, 799.86], "text": " or uses ChatGPT as the backend."}, {"timestamp": [799.86, 803.78], "text": " And the idea was that it was a reflective journaling tool."}, {"timestamp": [803.78, 806.0], "text": " And the idea here that it was a reflective journaling tool. And the idea here was"}, {"timestamp": [806.1, 808.2], "text": " to create something that could help me work"}, {"timestamp": [808.3, 810.6], "text": " through anything emotional"}, {"timestamp": [810.7, 812.5], "text": " anything stressful"}, {"timestamp": [812.6, 813.3], "text": " or whatever."}, {"timestamp": [814.1, 816.2], "text": " And so it's for mental"}, {"timestamp": [816.2, 818.5], "text": " health but not in a professional capacity."}, {"timestamp": [819.1, 821.3], "text": " But what I realized when I made this is I don't"}, {"timestamp": [821.4, 823.4], "text": " want any of this to be logged"}, {"timestamp": [823.7, 824.1], "text": " ever."}, {"timestamp": [830.6, 831.9], "text": " And so in order to trust the tool I made sure that it does not log any conversations anywhere."}, {"timestamp": [844.36, 845.6], "text": " And so one thing to keep in mind especially as you're building these tools that are able to engage with people on an emotional level that is able to engage with them on places where they're vulnerable,"}, {"timestamp": [845.6, 851.24], "text": " trust is going to be really really important. And trust once it's lost is"}, {"timestamp": [851.24, 858.0], "text": " pretty difficult to get back. And so these high-risk domains, whether it's"}, {"timestamp": [858.0, 866.56], "text": " relationships, emotions, you know I know people that are working on grief counseling tools, that sort of thing."}, {"timestamp": [866.56, 873.32], "text": " So these are, these are, you know, AI tools that are going to touch people on a very critical"}, {"timestamp": [873.32, 874.32], "text": " level."}, {"timestamp": [874.32, 880.96], "text": " And so respecting their privacy is 100% paramount."}, {"timestamp": [880.96, 884.92], "text": " And I know that, you know, businesses say, you know, data is the new oil, we need to"}, {"timestamp": [884.92, 887.32], "text": " consume this data, you know,"}, {"timestamp": [888.44, 894.68], "text": " because all of the training happening on the back end, I actually don't necessarily believe that."}, {"timestamp": [894.72, 902.96], "text": " And so what I mean by that is that all the providers of the language models, OpenAI, Microsoft, Google, Amazon and everyone else,"}, {"timestamp": [906.12, 911.88], "text": " Google, Amazon, and everyone else cohere, they are doing plenty of training on the back end. You don't necessarily need to collect your user data. And of course if"}, {"timestamp": [911.88, 915.68], "text": " the data doesn't exist anywhere, it can't be stolen and it can't be compromised."}, {"timestamp": [915.68, 922.2], "text": " And so I just want to point that out as a possibility. One of the reasons that I"}, {"timestamp": [922.2, 926.48], "text": " actually haven't deployed an AI assistant in my own"}, {"timestamp": [926.48, 931.52], "text": " home that's constantly listening is because I haven't fully figured out what to do. Like"}, {"timestamp": [931.52, 937.12], "text": " how do I give my personal assistant a long-term memory, but also keep it safe and secure and"}, {"timestamp": [937.12, 942.32], "text": " keep it private? Because, you know, that is something that if you don't do it right, it"}, {"timestamp": [942.32, 949.92], "text": " could just happily share, accidentally or deliberately share private damaging harmful or embarrassing information with"}, {"timestamp": [949.92, 954.52], "text": " other visitors or put it on the internet or whatever and so the the safest thing"}, {"timestamp": [954.52, 958.32], "text": " is is the bomb that doesn't exist right because if a bomb is sitting there it"}, {"timestamp": [958.32, 963.64], "text": " might go off likewise if you have highly sensitive critical personal information"}, {"timestamp": [963.64, 968.76], "text": " that's just sitting there waiting to be stolen or waiting to be leaked, then maybe that information"}, {"timestamp": [968.76, 974.32], "text": " just shouldn't exist in the first place. Okay, so those are some stories. What are"}, {"timestamp": [974.32, 979.16], "text": " the general principles that I have extracted from both using these tools,"}, {"timestamp": [979.16, 992.32], "text": " building these tools, and consulting with other people building these tools. Number one is thinking about cognitive labor. So large language models provide you a type"}, {"timestamp": [992.32, 998.68], "text": " of cognitive computing. And so this is cognition. This is mental tasks, mental"}, {"timestamp": [998.68, 1002.8], "text": " effort. And what you have to do is you have to have many conversations with"}, {"timestamp": [1002.8, 1007.72], "text": " subject matter experts in order to understand what they do, what they need, and most importantly, how they"}, {"timestamp": [1007.72, 1010.2], "text": " mentally go about their jobs."}, {"timestamp": [1010.2, 1015.28], "text": " And so in the past, software development was about building a tool that was kind of apart"}, {"timestamp": [1015.28, 1021.6], "text": " and separate from your users, and then you'd have an expert that could come use the tool."}, {"timestamp": [1021.6, 1024.48], "text": " The thing is, though, is that these tools are getting smarter, and the tools are now"}, {"timestamp": [1024.48, 1026.38], "text": " capable of cognitive labor."}, {"timestamp": [1026.38, 1028.74], "text": " So you need to actually get into the mind"}, {"timestamp": [1028.74, 1030.28], "text": " of the subject matter experts"}, {"timestamp": [1030.28, 1033.0], "text": " in order to perform some cognitive offload,"}, {"timestamp": [1033.0, 1035.02], "text": " which we'll talk about right here."}, {"timestamp": [1035.92, 1037.96], "text": " So to take it one step further,"}, {"timestamp": [1037.96, 1040.6], "text": " cognitive offload is one of the best signals"}, {"timestamp": [1040.6, 1044.7], "text": " that you can do in order to make the most valuable apps."}, {"timestamp": [1044.7, 1050.4], "text": " So remember how I talked about I created an app for providing feedback for my fiction"}, {"timestamp": [1050.4, 1058.04], "text": " that instead of two months it took 30 minutes and instead of $1,700 it took $17."}, {"timestamp": [1058.04, 1062.62], "text": " That is, the reason that that worked is because I performed cognitive offload."}, {"timestamp": [1062.62, 1067.86], "text": " I no longer needed a professional editor to provide that feedback, I now had the machine provide that feedback. So that's"}, {"timestamp": [1067.86, 1071.58], "text": " what I mean by cognitive offload. So here's a few principles that you can"}, {"timestamp": [1071.58, 1077.42], "text": " think about when designing cognitive offload. One, user attention is scarce."}, {"timestamp": [1077.42, 1082.42], "text": " Your user's brain juice is limited. You've got two to four hours maximum of"}, {"timestamp": [1082.42, 1085.64], "text": " high-quality executive function per day."}, {"timestamp": [1085.64, 1091.2], "text": " Some of us have more, but we are the exception, not the rule, and we also can't do it every day."}, {"timestamp": [1091.2, 1096.8], "text": " Decision fatigue is real. Deciding what to do next. Where do I get that information from?"}, {"timestamp": [1096.8, 1103.4], "text": " If you can just serve up, if you can intuit, use the language models to figure out what information the user needs"}, {"timestamp": [1103.4, 1109.6], "text": " and just give it to them without them having to even think about it before they even realize they need it,"}, {"timestamp": [1109.6, 1113.28], "text": " that will save them some cognitive energy and that is cognitive offload."}, {"timestamp": [1113.28, 1118.72], "text": " Tedious problem solving, whether it's anticipating how something's going to be received"}, {"timestamp": [1118.72, 1127.02], "text": " or brainstorming or whatever, right? Like I use, I perform a tremendous amount of cognitive offload when I'm making my slide"}, {"timestamp": [1127.02, 1128.94], "text": " decks here."}, {"timestamp": [1128.94, 1134.62], "text": " It's very tedious and it is also very draining and by offloading as much as I can to the"}, {"timestamp": [1134.62, 1140.52], "text": " model that makes my life much easier and it increases my output a lot."}, {"timestamp": [1140.52, 1145.04], "text": " And then finally, basically whatever takes mental effort, whatever takes that cognitive"}, {"timestamp": [1145.04, 1150.88], "text": " labor, that mental effort, if you can delegate it to the LLM, to the language model, do it."}, {"timestamp": [1150.88, 1155.16], "text": " And that is how you will create apps that just sell themselves because they are so much"}, {"timestamp": [1155.16, 1156.84], "text": " better."}, {"timestamp": [1156.84, 1158.64], "text": " Principle number three, loose coupling."}, {"timestamp": [1158.64, 1161.16], "text": " So brief history lesson."}, {"timestamp": [1161.16, 1167.6], "text": " This Russian dude way back in the day named Kalashnikov designed a gun, the AK-47."}, {"timestamp": [1167.6, 1174.2], "text": " And what he did was rather than designing a high precision, you know, like perfectly"}, {"timestamp": [1174.2, 1182.28], "text": " low tolerance machine, he said, why don't we design something that is, that everything"}, {"timestamp": [1182.28, 1189.2], "text": " has a lot of space, everything is loosely coupled, and so that it will have a lot of tolerance for things like dirt or broken"}, {"timestamp": [1189.2, 1194.52], "text": " cartridges or even bent parts, right? It can even tolerate damage because"}, {"timestamp": [1194.52, 1198.56], "text": " everything is just kind of loosely in there, but you know the interfaces where"}, {"timestamp": [1198.56, 1202.92], "text": " things work together, there's some tolerances built in there. And so the"}, {"timestamp": [1202.92, 1207.92], "text": " idea is that the the physical design principles that Kalashnikov put into the AK-47"}, {"timestamp": [1208.04, 1210.48], "text": " make it an incredibly durable,"}, {"timestamp": [1211.48, 1213.48], "text": " legendarily reliable weapon."}, {"timestamp": [1213.68, 1215.68], "text": " Now likewise,"}, {"timestamp": [1215.84, 1223.16], "text": " generative AI brings software into more direct friction with the real world, which is messy, which has variables."}, {"timestamp": [1223.16, 1227.52], "text": " And so what you need to do is you need to adapt those loose tolerances into the"}, {"timestamp": [1227.52, 1230.44], "text": " software components because natural language is really squishy."}, {"timestamp": [1230.8, 1231.8], "text": " That's just how it is."}, {"timestamp": [1232.28, 1237.28], "text": " So think about how you can send instructions to a human via text or via email."}, {"timestamp": [1238.16, 1242.16], "text": " And the human is able to abstract those instructions and turn it into real"}, {"timestamp": [1242.16, 1242.98], "text": " action."}, {"timestamp": [1243.12, 1246.2], "text": " That abstraction and translation is how you need to think"}, {"timestamp": [1246.2, 1249.46], "text": " about the interfaces between language models"}, {"timestamp": [1249.46, 1251.18], "text": " and other machines or language models"}, {"timestamp": [1251.18, 1253.8], "text": " and other language models when you're transmitting"}, {"timestamp": [1253.8, 1256.94], "text": " instructions or information between language models."}, {"timestamp": [1256.94, 1260.76], "text": " So that loose coupling and that high level of tolerance"}, {"timestamp": [1260.76, 1268.76], "text": " is how you will build language apps that are robust, resilient, and fault tolerant."}, {"timestamp": [1268.76, 1273.68], "text": " Principle number four, English mastery. So I already talked about this with"}, {"timestamp": [1273.68, 1277.32], "text": " librarians and philosophers and that sort of stuff, so I probably don't"}, {"timestamp": [1277.32, 1281.78], "text": " need to rehash this, but keep in mind the fact that many developers are not the"}, {"timestamp": [1281.78, 1284.64], "text": " most articulate people. I'm not saying that just because someone is a"}, {"timestamp": [1284.64, 1287.92], "text": " developer or a technologist that doesn't mean they are not articulate."}, {"timestamp": [1287.92, 1292.72], "text": " I am a professional IT guy and I'm incredibly articulate, but that's because I studied"}, {"timestamp": [1292.72, 1298.72], "text": " language. I studied the written word and I studied stories. So your math experts might not be the best"}, {"timestamp": [1298.72, 1305.32], "text": " communicators. Likewise, some of your subject matter experts might not be the best communicators."}, {"timestamp": [1305.32, 1311.36], "text": " So having people that are expert communicators or expert with language will be a game changer"}, {"timestamp": [1311.36, 1312.64], "text": " for your teams."}, {"timestamp": [1312.64, 1317.16], "text": " And as a product owner, if you're a product owner watching this, you probably understand"}, {"timestamp": [1317.16, 1321.44], "text": " the value of communication and your ability to communicate is part of what holds the team"}, {"timestamp": [1321.44, 1324.52], "text": " together and makes you great at your job."}, {"timestamp": [1324.52, 1329.0], "text": " But that also means that you need a good communicator, someone who understands written word,"}, {"timestamp": [1329.0, 1335.0], "text": " or empathy, or theory of mind, or whatever, to help people communicate with the models."}, {"timestamp": [1335.0, 1341.0], "text": " Because people with that empathy, that theory of mind, are going to be able to build a better intuition"}, {"timestamp": [1341.0, 1346.26], "text": " about what makes the language model tick."}, {"timestamp": [1346.26, 1348.48], "text": " Principle number five, how do you measure success?"}, {"timestamp": [1348.48, 1353.28], "text": " So I already earlier told you that some of the things that you should aim for is at least"}, {"timestamp": [1353.28, 1357.2], "text": " a 5x increase in productivity."}, {"timestamp": [1357.2, 1360.9], "text": " You should see speed increases on the order of 10x to 100x."}, {"timestamp": [1360.9, 1366.48], "text": " You should see cost reduction, 10 10x to 100x ideally more you know the speed increase"}, {"timestamp": [1366.48, 1372.72], "text": " that I got for my novel feedback is 3000x which you're not going to get that every time but hey"}, {"timestamp": [1372.72, 1377.04], "text": " you know time is money and every little you know every minute every hour every day that you can"}, {"timestamp": [1377.04, 1383.52], "text": " shave off of the time it takes to complete a task the better your product is going to sell the more"}, {"timestamp": [1383.52, 1390.16], "text": " value add it's going to it's going to have. So the main point here is that human brains, here's how you measure it,"}, {"timestamp": [1390.16, 1398.0], "text": " human brains are optimizing engines. We are all intrinsically lazy. And the idea here is that"}, {"timestamp": [1398.0, 1406.72], "text": " your brain will automatically choose the path of least resistance. Part of that is which option, which tool, which workflow"}, {"timestamp": [1406.72, 1410.7], "text": " am I most familiar with, right? People will always default to whatever they're"}, {"timestamp": [1410.7, 1415.72], "text": " trained to do because it's mentally easier. Now if the tool you build is"}, {"timestamp": [1415.72, 1419.52], "text": " mentally easy to use and their brain says, you know what, I'm just gonna use"}, {"timestamp": [1419.52, 1427.34], "text": " this tool because it's easier, because it's quicker, it's easier. I know that it's just less mentally laborious."}, {"timestamp": [1427.34, 1432.34], "text": " And so when the AI tool that you build is the optimal path,"}, {"timestamp": [1432.4, 1434.72], "text": " it will become the default choice."}, {"timestamp": [1434.72, 1436.2], "text": " So how do you make that happen?"}, {"timestamp": [1436.2, 1438.8], "text": " First, you can make drop-in tools."}, {"timestamp": [1438.8, 1441.84], "text": " So drop-in tools easily integrate with existing workflows."}, {"timestamp": [1441.84, 1444.72], "text": " And remember, changing someone's workflow,"}, {"timestamp": [1444.72, 1448.2], "text": " that increases friction. Because why? That's no longer the"}, {"timestamp": [1448.2, 1453.32], "text": " path of least resistance. I remember I was at a small managed services"}, {"timestamp": [1453.32, 1457.96], "text": " provider and some people used Microsoft Teams, some use Slack, some"}, {"timestamp": [1457.96, 1463.8], "text": " use Skype. It was all over the place. And I used Microsoft Teams because it was"}, {"timestamp": [1463.8, 1469.0], "text": " the best tool for the job, but a lot of people just wouldn't get on board because it was a new tool."}, {"timestamp": [1469.0, 1474.0], "text": " They had so much fatigue from keeping track of so many tools, and I'm like, but guys, this is the best tool for the job."}, {"timestamp": [1474.0, 1485.84], "text": " And so even though it was a drop-in tool, the fact that it was a different tool, there was a lot of friction. So the other thing you can do is integrate language models with existing tools to further"}, {"timestamp": [1485.84, 1490.72], "text": " reduce friction and again perform that cognitive offload."}, {"timestamp": [1490.72, 1496.24], "text": " But also don't underestimate the value of small tactical tools with very clear affordances"}, {"timestamp": [1496.24, 1499.2], "text": " that drive behavior to save time and energy."}, {"timestamp": [1499.2, 1503.58], "text": " So for instance, one of the tools that I built, I already told you about the reflective journaling"}, {"timestamp": [1503.58, 1508.16], "text": " tool which has a very, very specific kind of emotional thing like hey help me talk through this thing"}, {"timestamp": [1508.84, 1515.18], "text": " Another tool that I built was a coding tool where literally all I do is like copy and paste some code or some data and then"}, {"timestamp": [1515.18, 1517.24], "text": " It's a chat interface to help me"}, {"timestamp": [1517.24, 1523.32], "text": " You know write code in a specific way those tiny little tactical tools are something that I can just call up"}, {"timestamp": [1523.88, 1529.06], "text": " When I need them and they perform some work and they're not integrated with anything else. So you"}, {"timestamp": [1529.06, 1533.74], "text": " might need integration, you might not, but again don't underestimate the value of"}, {"timestamp": [1533.74, 1539.1], "text": " really simple tools that are brain-dead easy to use."}, {"timestamp": [1539.1, 1547.24], "text": " Principle number six, factual grounding. So here's something to assume, is that the LLM knows more than you do."}, {"timestamp": [1547.24, 1549.12], "text": " It's not magic, right?"}, {"timestamp": [1549.12, 1553.34], "text": " You have to understand what training data it had, which was, you know, most of these"}, {"timestamp": [1553.34, 1557.12], "text": " are scraped from the internet."}, {"timestamp": [1557.12, 1562.42], "text": " A lot of people have the assumption that like, okay, well, I want it to be a subject matter"}, {"timestamp": [1562.42, 1564.54], "text": " expert in topic X."}, {"timestamp": [1564.54, 1566.6], "text": " And I'm like, have you asked it?"}, {"timestamp": [1566.6, 1570.68], "text": " I remember I was on a call with some folks doing SEO"}, {"timestamp": [1570.68, 1574.56], "text": " and they wanted to make sure that it understood"}, {"timestamp": [1574.56, 1576.52], "text": " the SEO principles that were published"}, {"timestamp": [1576.52, 1579.66], "text": " by some Scandinavian country, I don't remember which one."}, {"timestamp": [1579.66, 1581.66], "text": " And they're like, well, how do we teach it this?"}, {"timestamp": [1581.66, 1582.64], "text": " I'm like, it already knows it."}, {"timestamp": [1582.64, 1583.96], "text": " And they're like, what do you mean?"}, {"timestamp": [1583.96, 1585.24], "text": " And I was like, just ask it."}, {"timestamp": [1585.24, 1589.48], "text": " Ask the model if it understands the SEO principles from the document that you're referring to"}, {"timestamp": [1589.48, 1592.96], "text": " that was these guidelines that were published by your country."}, {"timestamp": [1592.96, 1593.96], "text": " And they did."}, {"timestamp": [1593.96, 1595.6], "text": " And it's like, oh, it already knows that."}, {"timestamp": [1595.6, 1596.86], "text": " So I was like, just tell it."}, {"timestamp": [1596.86, 1598.76], "text": " Just tell it to abide by these principles."}, {"timestamp": [1598.76, 1600.78], "text": " You don't need to teach it anything."}, {"timestamp": [1600.78, 1603.48], "text": " Just give it a name, say abide by this principle."}, {"timestamp": [1603.48, 1606.24], "text": " And if it knows it, great, and if it doesn't, you just name it and you say,"}, {"timestamp": [1606.24, 1609.02], "text": " you know, X, Y, and Z is an SEO principle,"}, {"timestamp": [1609.96, 1611.36], "text": " you know, adopted by this nation,"}, {"timestamp": [1611.36, 1613.68], "text": " and here's the basic facts."}, {"timestamp": [1613.68, 1616.94], "text": " And so the idea is, you need a lot less factual grounding"}, {"timestamp": [1616.94, 1619.4], "text": " than you think you need in order to get the behavior"}, {"timestamp": [1619.4, 1621.92], "text": " out of the model that you want."}, {"timestamp": [1621.92, 1625.96], "text": " So just tiny little reminders of the truth or the facts"}, {"timestamp": [1625.96, 1627.56], "text": " and just a few breadcrumbs."}, {"timestamp": [1627.56, 1629.44], "text": " Because remember, it already knows"}, {"timestamp": [1629.44, 1631.04], "text": " a lot of general knowledge, which"}, {"timestamp": [1631.04, 1634.88], "text": " means that it is able to rapidly generalize to other things,"}, {"timestamp": [1634.88, 1637.72], "text": " even if it's never seen that term before."}, {"timestamp": [1637.72, 1639.24], "text": " This is how I was able to teach it"}, {"timestamp": [1639.24, 1642.08], "text": " all of my stuff like axiomatic alignment"}, {"timestamp": [1642.08, 1643.12], "text": " and heuristic imperative."}, {"timestamp": [1643.12, 1646.0], "text": " So that's my alignment research, if you're not familiar with that."}, {"timestamp": [1646.0, 1649.0], "text": " And so by just quickly defining a term and saying,"}, {"timestamp": [1649.0, 1651.0], "text": " this is the term we're going to use, this is what it means,"}, {"timestamp": [1651.0, 1653.0], "text": " it is then able to work with that new thing."}, {"timestamp": [1653.0, 1656.0], "text": " And this is called in-context learning."}, {"timestamp": [1656.0, 1658.0], "text": " So I call it, you know, you can call it factual grounding,"}, {"timestamp": [1658.0, 1661.0], "text": " but from a scientific perspective, it's called in-context learning."}, {"timestamp": [1661.0, 1668.16], "text": " So you can teach it something and it does not take much to teach it and then from there it can impute or infer the rest."}, {"timestamp": [1669.0, 1670.88], "text": " So that's principle number six."}, {"timestamp": [1670.88, 1672.52], "text": " Okay, so we're winding down,"}, {"timestamp": [1672.52, 1673.9], "text": " we're near the end of the video."}, {"timestamp": [1673.9, 1675.8], "text": " The new paradigm you need to think about"}, {"timestamp": [1675.8, 1678.16], "text": " is polymorphic apps."}, {"timestamp": [1678.16, 1682.44], "text": " So in the past, old school way of thinking"}, {"timestamp": [1682.44, 1684.14], "text": " is you build the tool."}, {"timestamp": [1684.14, 1685.44], "text": " You build the tool and it build the tool and it's got"}, {"timestamp": [1685.44, 1689.36], "text": " databases and it's got web servers and app servers and network gateways and"}, {"timestamp": [1689.36, 1693.68], "text": " load balancers and that sort of thing. The paradigm that we're"}, {"timestamp": [1693.68, 1697.88], "text": " approaching is tools that build the tools. So instead of building tools, you"}, {"timestamp": [1697.88, 1706.86], "text": " build the tools that build the tools. And here's an example. Procedurally generated video game maps are nothing new."}, {"timestamp": [1706.86, 1710.44], "text": " Elite Dangerous and, what was it, No Man's Sky"}, {"timestamp": [1710.44, 1712.1], "text": " and a whole bunch of other stuff."}, {"timestamp": [1712.1, 1715.54], "text": " There's all kinds of games where every planet you go to"}, {"timestamp": [1715.54, 1718.0], "text": " or every new world you go to, the landscape"}, {"timestamp": [1718.0, 1719.38], "text": " is generated on the fly."}, {"timestamp": [1719.38, 1721.06], "text": " So that's really cool."}, {"timestamp": [1721.06, 1724.38], "text": " But that, of course, brings in new challenges."}, {"timestamp": [1724.38, 1725.54], "text": " Because rather than having"}, {"timestamp": [1725.54, 1730.68], "text": " you know environment level designers, you have to have people that"}, {"timestamp": [1730.68, 1735.6], "text": " design the tools that build the levels for you. And with generative AI what's"}, {"timestamp": [1735.6, 1740.96], "text": " coming next is dialogue. So rather than having a writer manually write all the"}, {"timestamp": [1740.96, 1745.64], "text": " dialogue in the game, you have to have a tool that writes the dialogue for you."}, {"timestamp": [1745.64, 1746.64], "text": " So on and so forth."}, {"timestamp": [1746.64, 1749.6], "text": " So this is one example that's actively happening right now."}, {"timestamp": [1749.6, 1756.72], "text": " Likewise, you take this to a logical extension and you start to create polymorphic apps where"}, {"timestamp": [1756.72, 1761.44], "text": " the user interface might be dynamically generated and it might adapt on the fly based on what"}, {"timestamp": [1761.44, 1763.36], "text": " the application is doing."}, {"timestamp": [1763.36, 1764.8], "text": " So this is a tool that builds a tool."}, {"timestamp": [1764.8, 1766.8], "text": " So you have a tool that is a UI builder So you have a tool that is a UI builder."}, {"timestamp": [1766.8, 1768.84], "text": " You have a tool that is a code generator, right?"}, {"timestamp": [1768.84, 1770.72], "text": " This is one of the biggest things right now"}, {"timestamp": [1770.72, 1772.96], "text": " is language models that write code."}, {"timestamp": [1772.96, 1775.68], "text": " So if the language model can write code on the fly,"}, {"timestamp": [1775.68, 1778.0], "text": " maybe the role of developers change"}, {"timestamp": [1778.0, 1780.12], "text": " to instead of writing the code themselves,"}, {"timestamp": [1780.12, 1782.56], "text": " they write the thing that writes code on demand"}, {"timestamp": [1782.56, 1784.0], "text": " as it's needed."}, {"timestamp": [1784.0, 1789.0], "text": " So this is called metaprogramming. and metaprogramming is nothing new. So this is writing programs"}, {"timestamp": [1789.0, 1794.04], "text": " that write other programs. So one of the key foundational things that you need to"}, {"timestamp": [1794.04, 1798.36], "text": " adapt to this new paradigm of polymorphic apps is metaprogramming."}, {"timestamp": [1798.36, 1802.12], "text": " Instead of writing the code yourself, you use the model to write the code that you"}, {"timestamp": [1802.12, 1807.34], "text": " need, and then you have the other systems in place that test and validate and integrate that code."}, {"timestamp": [1807.34, 1809.46], "text": " Another principle to build polymorphic apps"}, {"timestamp": [1809.46, 1812.1], "text": " is that everything must be configurable."}, {"timestamp": [1812.1, 1816.1], "text": " So whether this is your user interface, your back end,"}, {"timestamp": [1816.1, 1821.06], "text": " your networking, your infrastructure, all of that."}, {"timestamp": [1821.06, 1822.82], "text": " And since everything has APIs today,"}, {"timestamp": [1822.82, 1825.04], "text": " and language models can use APIs, well,"}, {"timestamp": [1825.04, 1831.28], "text": " there you have it. But you need to get into this. And another thing is that when I say everything"}, {"timestamp": [1831.28, 1835.04], "text": " must be ephemeral, not everything, the tools that build the tools are not ephemeral, but the tools"}, {"timestamp": [1835.04, 1840.56], "text": " that they build are ephemeral. So what I mean by that is, think of it like the replicator from"}, {"timestamp": [1840.56, 1845.48], "text": " Star Trek. You need a very specific wrench and you just say, computer give me"}, {"timestamp": [1845.48, 1848.48], "text": " this wrench that I need right now. And then when you're done with that you give"}, {"timestamp": [1848.48, 1851.68], "text": " it back to the computer and it breaks it down. That's how you need to think about"}, {"timestamp": [1851.68, 1856.76], "text": " these ephemeral tools in order to build polymorphic apps. So rather than having a"}, {"timestamp": [1856.76, 1860.84], "text": " library of tens of thousands of tools, instead you have a replicator that can"}, {"timestamp": [1860.84, 1865.58], "text": " build any tool that you need in that moment and then it's done."}, {"timestamp": [1865.58, 1870.56], "text": " So that is the new paradigm that we're moving towards is polymorphic apps."}, {"timestamp": [1870.56, 1874.44], "text": " And then another way to think about this is in terms of architectural components or software"}, {"timestamp": [1874.44, 1876.7], "text": " components."}, {"timestamp": [1876.7, 1880.92], "text": " So today, you fundamentally, from a software perspective, you fundamentally have kind of"}, {"timestamp": [1880.92, 1883.52], "text": " two major things."}, {"timestamp": [1883.52, 1887.72], "text": " There's obviously a lot more to it than this, but you've got databases, which is where your information is stored."}, {"timestamp": [1887.72, 1890.96], "text": " And of course, there's all kinds of things. There's search indexes. There's"}, {"timestamp": [1891.72, 1899.36], "text": " document stores. There's relational databases. But the idea is that you've got information stored somewhere. Okay, cool. One architectural design"}, {"timestamp": [1899.68, 1903.4], "text": " thing. You've got an information repository. Another thing is an application server."}, {"timestamp": [1903.4, 1910.16], "text": " So the application server might do back-end processing, it might do OCR, it might serve up your web"}, {"timestamp": [1910.16, 1916.04], "text": " app, whatever. But you've got the data and the processing. But now we have LLMs, which"}, {"timestamp": [1916.04, 1922.32], "text": " is a new kind of processing. So this new kind of component is a cognitive engine. So rather"}, {"timestamp": [1922.32, 1925.44], "text": " than a data engine or an application engine or a web engine, now you have a cognitive engine. So rather than a data engine, or an application engine, or a web engine,"}, {"timestamp": [1925.44, 1930.32], "text": " now you have a cognitive engine. So if you start to think of LLMs as a new software component,"}, {"timestamp": [1930.32, 1936.56], "text": " a new architectural component that goes into the stack, that is the appropriate way. And so then,"}, {"timestamp": [1936.56, 1940.16], "text": " what are the characteristics of this new component? Obviously, you're familiar with"}, {"timestamp": [1940.16, 1944.16], "text": " databases, you're familiar with web servers, that sort of thing. You have a mental list of"}, {"timestamp": [1944.16, 1948.02], "text": " characterizations of what those components are capable of. So"}, {"timestamp": [1948.02, 1952.62], "text": " here's some of what a language model is capable of. Language processing, obviously."}, {"timestamp": [1952.62, 1957.68], "text": " It can read human text, it can generate human text, it can transform human text."}, {"timestamp": [1957.68, 1963.4], "text": " Pretty much any NLP task it can do, and it can do it faster and better than many"}, {"timestamp": [1963.4, 1965.12], "text": " humans can. It's not"}, {"timestamp": [1965.12, 1969.36], "text": " necessarily going to be faster than old-school NLP techniques because of the"}, {"timestamp": [1969.36, 1974.24], "text": " memory requirements to run language models. Reasoning and knowledge. So this"}, {"timestamp": [1974.24, 1977.8], "text": " is something that is still controversial but more and more scientific studies are"}, {"timestamp": [1977.8, 1981.68], "text": " coming out saying yes, these language models have theory of mind. Yes, they"}, {"timestamp": [1981.68, 1988.2], "text": " truly understand what they're talking about. Yes, they can reason through things. Yes, they can make accurate predictions and"}, {"timestamp": [1988.2, 1991.64], "text": " forecasts and they can defend their positions with logic. Now, that being said,"}, {"timestamp": [1991.64, 1995.64], "text": " they can still choose really dumb things sometimes, but there's ways to defeat"}, {"timestamp": [1995.64, 2001.28], "text": " that with things like tree of thought reasoning. Context understanding. So"}, {"timestamp": [2001.28, 2008.04], "text": " context, context, context, context. This is one of the key things that I teach people in my consultations,"}, {"timestamp": [2008.34, 2011.92], "text": " is in order for the language model to do exactly what you need it to do,"}, {"timestamp": [2011.92, 2015.68], "text": " you need to give it the right context. What business is it operating in?"}, {"timestamp": [2015.68, 2020.32], "text": " What step of the process is it doing? What input should expect?"}, {"timestamp": [2020.32, 2024.92], "text": " What kind of user is using it in order for the given task?"}, {"timestamp": [2024.92, 2025.48], "text": " Because if you"}, {"timestamp": [2025.48, 2029.56], "text": " tell a language model, hey your primary user is going to be a research scientist"}, {"timestamp": [2029.56, 2034.28], "text": " in a microbiology lab, that will wake up a lot of mental things than"}, {"timestamp": [2034.28, 2039.04], "text": " if you don't tell it that information. Or conversely, if you tell it, hey your"}, {"timestamp": [2039.04, 2043.04], "text": " primary user is going to be an amateur fiction writer, treat them accordingly,"}, {"timestamp": [2043.04, 2045.8], "text": " that context helps the language model"}, {"timestamp": [2045.8, 2049.96], "text": " cue in to whatever behavior it needs to manifest."}, {"timestamp": [2049.96, 2051.14], "text": " Adaptability."}, {"timestamp": [2051.14, 2053.96], "text": " So in the context of the tools that build the tools,"}, {"timestamp": [2053.96, 2056.18], "text": " remember, these things are infinitely flexible."}, {"timestamp": [2056.18, 2058.4], "text": " And that gives you a whole litany"}, {"timestamp": [2058.4, 2060.36], "text": " of new programming capabilities."}, {"timestamp": [2060.36, 2063.08], "text": " So that instead of having to keep"}, {"timestamp": [2063.08, 2066.4], "text": " track of a gigantic toolbox, you now have a tool replicator"}, {"timestamp": [2066.4, 2069.28], "text": " that can just synthesize any tool that you need on the fly."}, {"timestamp": [2069.28, 2071.92], "text": " And that's going to make it infinitely more flexible."}, {"timestamp": [2071.92, 2076.68], "text": " And then of course planning and sequencing, brainstorming steps, and that sort of stuff."}, {"timestamp": [2076.68, 2080.84], "text": " All that, if you need more on that, just look up Tree of Thought."}, {"timestamp": [2080.84, 2086.68], "text": " That is the current state of the art technique that you need to know about for"}, {"timestamp": [2086.68, 2092.92], "text": " that sort of thing, for problem solving. Okay, so there you have it. Generative AI for product"}, {"timestamp": [2092.92, 2098.2], "text": " owners. I am available for consultation. Reach out to me on LinkedIn. Link in the description."}, {"timestamp": [2098.2, 2100.48], "text": " Cheers. I hope you got a lot out of it. Bye."}, {"timestamp": [2095.99, 2096.83], "text": " Bye."}]}