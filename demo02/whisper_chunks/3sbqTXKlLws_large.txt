{"text": " I think the actual anxiety that you are experiencing and that other people are experiencing has more to do with just how thin and fragile our experience of being is. And I think that that is part of why people are afraid of AI and why people have this like human exceptionalism. Like people say, oh, the machine is never going to be as smart as us. It's never going to be anything like us, because that is emotionally more comfortable than reconciling with that, like existential dread. Today I'm speaking with David Shapiro, a prominent figure in the world of AI, who I greatly admire. On his YouTube channel, David delves into the intricacies of building artificial intelligence, exploring the social, philosophical, and technical aspects of the topic. If you're curious about the world of AI, I would definitely recommend checking out his channel. The link to do that is in the description. If you're enjoying these conversations, make sure to like and subscribe. Without further delay, here's David Shapiro. I hope you enjoy the conversation. AI is coming for all of our jobs, but let's say technology creates more jobs, right? Throughout history that has happened. You often hear that line of thinking. Why is that line of thinking wrong in this case? So historically speaking, technology has not necessarily strictly created new jobs, but what it did is it created efficiencies that allowed people to further specialize. So it is kind of a misnomer or a platitude. It's an oversimplification to say technology creates new jobs. Technology creates new systems, new ways of using energy that allows for further branching and specialization, but of course, that's not as good of a catchphrase as technology creates new jobs. So first, it's just the premise is a little bit, you know, off to the side. But then when I looked at the data in terms of the idea that like, oh, hey, internet technologies, information technologies, this must intrinsically create new jobs because it's the most powerful new technology. When you look, there are certain trend lines that if you look at job creation actually started tapering off or slowing down in the mid to late 90s, just as the internet was taking off. And if this idea was true, that advanced new information technologies only and always create new jobs, you would expect that trend line to go the opposite direction, that with the rise of the internet, jobs would go up. But instead, we have total labor participation rates slowly declining since the mid-90s. We do have very low unemployment right now, but that's because a bunch of people have exited the workforce permanently. And so, you know, unemployment rate is just a proxy for some things, but total employment is actually trending back towards kind of where it was in the 60s or 70s. Whether or not that's a good thing or not, I'm not making a judgment on it, just pointing out that if the demand for human labor was going up, we would see that in rising wages, which of course wages for most workers have been largely stagnant since around 1980. And so what I suspect is happening from a functional or algorithmic standpoint is that yes, technology is increasing efficiency, but that efficiency is driving down the need for human labor, and that's only going to accelerate with artificial intelligence, especially when you look at the fact that machines are generally cheaper than humans, and as machines can do more and more cognitive labor, there's going to be less and less that you actually need a human to do. Now there are some things that humans will have that are going to stay unique for a little while. You know, we've got a gentle touch, we've got gentle voice, you know, so things like healing professions, massage therapists, doctors, nurses, those kinds of jobs will probably be pretty well insulated because nobody wants a robot doctor working on them just yet. Child care, education, there are plenty of things that really do require a human touch, but the rule of thumb that I follow is if your job can be done at a computer, you are at risk of being automated out. And it's just because, hey, you know, that's where AI lives. It lives on the computer. So if you can do it on a computer, an AI can probably do it too. Okay, so here's a prompt for you. I have a few prompts for you throughout this interview. Okay. I want you to imagine that you are my wise life coach and that I am young, ambitious, let's say in my mid-20s. I'm interested in a whole bunch of things. Maybe I have a bachelor's degree, but I don't know what I wanna do. I'm looking at all of this stuff that's happening in terms of AI, seeing what ChatGPT alone is capable of. And I see a huge opportunity here, but I'm also, you know, I want to have, let's say in the next five to 10 years, my own family and security is something that I value. I want to spend, invest my time in something that is going to be relatively safe, as safe as one's job could be. Where should I invest my time? What kind of advice would you give me? Yeah, so that's a great question. And for most people, what I would recommend is don't be afraid of the AI, learn to use it. So for now, tools like ChatGPT can be used to really accelerate whatever job it is that you're doing. And more tools like that are coming. In fact, that's kind of what my startup is working on, is rather than working on tools that will replace human labor, we're going to work on tools that accelerate it and work very closely with humans. Because in most cases, there are cases where a machine is better suited to do the job in its entirety, for example, on an assembly line. It's better to just get humans out of that situation altogether. Now, that being said, there are still plenty of situations where human creativity and ingenuity and intuition still far outstrip the capability of any AI that we've come up with. And what I have found in my own experiments and the products that I'm working on is that what we can do is if we if we build tools that form a partnership with humans, what we can do is we can get more done with less human cognitive labor by offloading some of that cognition to the machines. So the, the, the securest thing for the next five to 10 years is going to be either learning to build and deploy these tools or learn to use them. Um, now that being said, there, as I just mentioned, there's also plenty of trades that, uh, focus on, you know, that human touch, whether it's communication or anything that requires warmth or, or that sort of stuff. So those are, those are the kind of the directions that I would advocate for for your typical, you know, 20 something to go in. I would say that's probably a much better response than I would receive from chat GPT, too. So there's still hope for us, I think. OK, but going through going through your video yesterday in particular on the robot tax that you proposed, I got the sense that it's very like, you know, this is coming, whether we like it or not. AI is coming, jobs are going to be replaced at a level that we've never seen. And at the same time, some companies are going to win and experience profits like we've never seen before in human history. And we can either redistribute that wealth in some way or riot in the streets because all of us are hungry, essentially. And the fundamental point that you kept hammering home in that video was that decoupling economic growth from human labor is 100% necessary. We need to do that. Why is that so important? Yeah, so if you zoom out, I often find that it's helpful to look at these things from a historical perspective. Throughout most of history, all of everything that we built, everything that we made, was dependent on human labor to do. So, you know, you look back in ancient Greece, ancient Rome, you know, if you were a tradesman or a craftsman, you made things with your hands, right? And even before that, farming, we had to do by hand. Then we got new sources of energy with beasts of burden, ox, cows, elephants if you're in Asia. And every time we learn to use a new source of energy, we get a little bit better at, you know, deploying or producing goods and services, basically. And I apologize, I kind of lost the lost the plot you're asking about Decoupling that's right decoupling. I apologize. Apparently I need a little bit more coffee so what happened in the past was You know, we it was animal labor whether it was, you know, human muscles animal muscles and then with the Industrial Revolution we were able to decouple our expression of energy from human and animals with the invention of the steam engine, with the invention of the internal combustion engine, the use of petroleum, and so suddenly we had so much more energy and that is actually why we saw not parabolic but exponential growth of the human population in the 20th century is because suddenly the Industrial Revolution allowed us to produce exponentially more food. And so now what we can do is we can decouple, well let me take a pause for a second. So decoupling energy expenditure from human capacity, that removed one constraint, right? And so now we can move another constraint, another human limitation, which is human cognitive labor. So for knowledge workers, for people that use their brains to do their job, we only have about one to four hours of cognitive labor, of real cognitive labor that we can do per day. That's like solving problems, doing difficult tasks, because our brains are just not calibrated to think hard all day, every day. Our bodies are meant to move all day, every day. That's how we evolved. But really, we evolved in a situation where it's like, okay, you might have one big problem that you address per day, right? You know, if your tribe lives on the banks of it lives on the on the banks of a river, and all of your nets get tangled up, and it's like, Oh, crap, now we got to make some new nets, right? That's the hard problem that you're going to face that week. And since we evolved in that situation, we cannot physically apply our brains for eight hours a day, 16 hours a day, except for an extreme cases, and then we can only do it for like, you know, a day or two and then we're burned out. And so by usually with lots of coffee and or some right, you know, coffee and swearing and everything else. And also, also plenty of studies show that the longer you focus, the worse your work gets. Right. Because it takes so much executive functioning to measure the quality of your work and to keep yourself on track. And eventually, you just kind of go based on heuristics and intuition and you say, screw it, let's just do the best that we can. Now, as we build machines, not if, we are building machines that can replace some cognitive labor, that separates out, we've already separated out energy, right? We've decoupled energy from productivity. Now we can decouple cognition from productivity, and that's going to have another exponential explosion to producing goods and services. Right, right. And so the idea is that what happens at that point? I mean, this, I guess, gets to your point in the video where, you know, we don't need to expend energy anymore. I mean, we haven't had to in a lot for a long time in some sense and we don't need to think anymore because the machines are thinking for us really. I know I'm being overly simplistic and ridiculous here, but what happens at that point? Let's say that we do redistribute this wealth and we don't have to worry about making ends meet anymore. How do you think humans deal with that? I want to read you a quote in a second here, but just your... how do humans deal with that reality that we've really never had before well, so The this this is this is another misnomer or I don't say disinformation, but it's um It's it's a gap in in people's experience because throughout history. We have always had the existence of a leisure class so in ancient Greece of a leisure class. So in ancient Greece, you know, if you were a Spartan citizen, you didn't work. In fact, Spartans were not allowed to have an occupation. If you were a Spartan citizen, it was illegal for you to be a leather worker or anything other than, like if you're a man, a soldier, a hunter, and a politician. Those were the three occupations you were allowed to have. If you were a Spartan woman, you were allowed to basically be, you know, a mother and a wife. And of course, there's other aspects of Spartan culture that's very distinct from our own. But what they would do is they'd spend all day exercising, debating, hunting, you know, running the nation. And most Greek city-states had a leisure class. Athens, all of them had something like that. Ditto for Rome. Ancient Rome, if you were in the upper crust, you were a politician, you were a thinker, you were a writer. All societies that grow really great like that, and this includes in the East as well. The Mughal Empire in India also had a huge leisure class for many many like centuries. I don't know if the Mughal Empire lasted centuries, but across India the various empires had huge leisure classes and there were immense patrons of the arts, you know. Most of the... India produced, you know, many many thousands of Vedantas through philosophical debate, lots of poetry, lots of art. So even when you have a group of people effectively living with abundance, they always find something to do. And we are so based, we Americans in the West, we base our identity on labor and on work, but when you look across history it's not necessary for people to have their identity. So what I'm hoping to see is as we move towards this global leisure class, well first, one, I hope we do move towards a global leisure class where, you know, the fully automated luxury space communism model, right? That's kind of the meme version. But if we move towards that\u2026 Right. All of this\u2026 Let me just start in\u2026 Yeah, go ahead. All of this depends on us first figuring out the redistribution component of this, which is in itself just a whole can of worms that we haven't gotten into yet. But let's say that we figure that out. Yep. Yeah. So all this is predicated on the idea that we make a choice as a culture, as a species, as a planet, to say, hey, maybe we actually can redistribute and we can allow people to move towards this leisure class. If we do that, then we're going to have a very different society in some respects. We're already kind of addicted to entertainment and distractions and stuff. But, at the same time, people love challenges. So there's a framework in psychology. I can't remember who created it, but it's called self-determination theory. And in self-determination theory, there are three pillars of psychological needs. So you might be familiar with Maslow's hierarchy of needs, which forms it as a stack. But in self-determination theory, there are three primary pillars of like mental health or psychological well-being. One is autonomy. So one thing that is universal across all humanity is that we all desire to be more autonomous. And in Western society having money makes you more autonomous. Money gives you choices so on and so forth. Now if we decouple our way of life from our need to make money that makes us more autonomous so this is a very attractive way to go. The second pillar of that is competence or mastery. And this is what I have, you know, I retired from my day job to focus on AI and my startup, and people love challenges. So I was talking with an educator. He was a retired middle school teacher who taught computer science and game design. And what he pointed out to me, and he's not the only educator to notice this, but what he pointed out to me is that kids already challenge themselves. They will play games, you know, like my nephew plays Roblox and Minecraft and all that stuff and he'll find all kinds of challenges for himself. He'll learn all these complex, you know, build trees and stuff. And all these behaviors that children put into video games, and adults for that matter, are the kinds of self, are the kinds of challenges that people, you know, that educators want children to put into education. It's also the same kind of challenges that go into our occupations. We as a species, we are calibrated to be, to crave a certain level of challenge. If you put a whole bunch of people, you know, out in a field together and just like give them a box of like sports equipment, guess what? Within a few minutes they're gonna like explore the sports equipment and come up with new games. You, I mean, you, anyone who has children or has nephews or has been with children, like spontaneous play is very much part of our natural state. And part of play is to, you know, there's the body intelligence part, but there's also the skills, the competence and the mastery. And I apologize, I can't actually remember the third pillar of self-determination theory. But anyways, point being is that we have these intrinsic motivations that if we do decouple, you know, labor from life, we're going to have plenty of impulses to engage in, whether it's more play, whether it's finding new challenges for ourself, or we might even become more like these ancient societies, engage in more art, more debate, more literature, that we will, even if machines can do this stuff better than us, or a lot of stuff better than us, we will just find ways to entertain ourselves to come up with new challenges. Is that right? Oh yeah. Think about chess. It's been a decade or two since any human could beat the best chess computer. But we still play chess, right? We still play chess competitively. We just don't let the machines in, right? There is something intrinsically human about games in specific, but also that challenge. Like, you know, I have some friends who are, who are or were competitive chess players, and they still care about their ELO score. So ELO is the ranking system that is used for competitive chess for any of your audience that aren't familiar. They still care about that, even though they know that like, you know, the best machine out there could get an Elo of 2800 and they're never going to get above 2200, but that doesn't matter. Yeah. I often think about this too with like, with sports, you know, um, even once we get to a point where robots can like play basketball way better than us, let's say, I think people would still love watching NBA games and humans compete at that and be interested in competing themselves at that. Oh yeah, oh yeah, and even think about cars, something industrial, you know, like Ford can crank out, you know, 3,000 Mustangs a day and their plants, but I still know people who rebuild, you know,000 Mustangs a day in their plants, but I still know people who rebuild classic Mustangs by hand. There's no real benefit to it, but it's a hobby and it's something that they get enjoyment out of because there's a certain mastery that goes into it and there's a certain pride that we derive from developing these skills and producing these results. So really all that's gonna happen, I think, what I hope, is that we will see more of this kind of stuff. More people that take pride in their garden, or rebuilding Mustangs, or whatever, right? Like there's so much to do out there. And getting rid of our occupation, if that's what happens, like, I don't know, from my perspective where I'm at right now, it seems like a really easy transition. occupation if that's what happens. From my perspective where I'm at right now, it seems like a really easy transition. But there's so many people that have never gone through that transition that it might feel scary or uncertain. And certainly there are people, I've known plenty of people that they got to the age of retirement and then they didn't know what to do with themselves so they just went back to work. Right? and then they didn't know what to do with themselves, so they just went back to work. Right, but if you work at the same thing until you're 50 or 60 or so, there's a certain amount of inertia and it's like we do what we know. But you look at, what if subsequent generations, young people today, never grow up in an environment where they must put their labor so that they have a place to stay, so that they have food to eat. People are going to be so much more creative. There's a book, I can't remember the name of the author, but my fianc\u00e9 told me about it. It's called Cognitive Surplus. And one of the things that this book talks about is that as people gain a greater measure of physical security, so like food security, housing security, our brains, like that gives us more free time to solve harder problems. And we all give back in some ways, right? Like some people get on the internet to debate social justice, and some people think that that's a worthless thing, but I will tell you, having watched the internet for the last 20 years, there are ideas that get hashed out through internet debate that ends up in academic literature, right? So even, even if people just idly, you know, argue on Twitter, sometimes that produces really good ideas. And then some people do a higher order, let's say research, like in their free time, as I did, because most of the AI research I did, I still had a full-time job, but I had enough cognitive surplus that I was like, okay, I can do this other thing too. Not everyone's going to have AI as their primary hobby, but everyone's got to have a hobby, right? Right. Okay. I want to challenge, well, here's another prompt for you. We'll get to second but have you have you read notes from the underground by Dostoevsky? I have not Okay, so I want to read you an excerpt from that book. Have you read any Dostoevsky at all? No, I but I only know just a little bit about him very cynical watch some of your videos Yes, yes I was I was watching some of your your videos where You were talking about some of the things that we're talking about now. You should definitely dive into them. I think you'd love them. All right. So I want to read you this one excerpt from Notes from the Underground, and I should frame this by saying that the protagonist in this book and the guy who's speaking here is this bitter old man who is the most bitter, depressing person you've ever seen in your life who's, for the first half of the book, just going on these like crazy philosophical rants. Okay, so this is part of his bitter rant. And the prompt, while you're listening to this, just for you to prepare, I want you to imagine that you're on stage in a debate against this bitter old man from Notes from the Underground. And he had, well, I'll read you the quote first, then we'll come back to the prompt at the end to finish it. But here's a quote. What can be expected of man since he is a being endowed with strange qualities, shower upon him every earthly blessing, drown him in a sea of happiness so that nothing but bubbles of bliss can be seen on the surface. Give him economic prosperity, such that he should have nothing else to do but sleep, eat cakes, and busy himself with the continuation of his species. And even then, out of sheer ingratitude, sheer spite, man would play you some nasty trick. He would even risk his cakes, and would deliberately desire the most fatal rubbish, the most uneconomical absurdity, simply to introduce into all this positive good sense his fatal, fantastic element. It is just his fantastic dreams, his vulgar folly, that he will desire to retain, simply in order to prove to himself, as though that were so necessary, that men are still men and not the keys of a piano, which the laws of nature threaten to control so completely that soon one will be able to desire nothing but by the calendar. And that is not all. Even if man really were nothing but a piano key, even if this were proved to him by natural science and mathematics, even then he would not become reasonable, but would purposely do something perverse out of simple ingratitude, simply to gain his point. And if he does not find means, he will contrive destruction and chaos, will contrive sufferings of all sorts, only to gain his point. So, again, imagine you're on stage, debating this bitter old man. I was reminded of this excerpt when I was watching your video yesterday, when you were talking about and making your points for why humans will be able to thrive in an environment where AI can do a lot of the stuff that we had previously done. Why is this man wrong? I think what he's arguing, at least to me, is a part of it is that even in the best case scenario, even when we imagine the most bullish case for AI, where we have all of this time, that there's something about humans where we would still burn it all to hell out of ingratitude, out of whatever, just because we're human. Right. Well, I would say that one, nihilism started in Russia, and when you look at what Russia is doing today, nothing has changed in the last two centuries. And if you look at the history of Russia, basically that is a product of an environment. Everything that you just read, every cynical, you know, nihilistic Russian that has, you know, ever put pen to paper, is more or less a product of intergenerational trauma, just to put it as bluntly as possible, between repeated civil wars, famines, invasions, political upheaval, everything that has happened, what you're seeing is someone who is unable to escape what you could think of as a nihilistic fishbowl. He can't get out of that worldview because nihilistic fishbowl. He can't get out of that worldview because not only did he grow up with it, but he was surrounded by it. And so what I would say is that is that I'm not saying that he's wrong because within the context of his life and his experience he's absolutely right. That being said, there are other fishbowls. There are other ways of being, other ways of learning and growing. And something that is becoming more popular is the idea of healing. You know, whether it's through, you know, the resurgence of psychedelic therapy, changing the way that we orient towards each other, so on and so forth. But the short version is traumatic environments create broken people. And that's not to forgive anywhere else in the world. America certainly has our own aspects of our society that are broken and have been broken. Ditto for the East, ditto for everywhere, right? You know, pick your poison. It's just that when you look at some regions, you can say, comparatively speaking, some nations, some regions seem to have a lot more trauma. I remember a few years ago, I had joined a spiritual healing group and I became friends with a Russian woman And we were we were walking through a park one day, you know her her friend and her son were there and we were talking about spiritual healing and I mentioned that you know PTSD is really big in Russia and she's like, oh we don't have any PTSD in Russia and I was like in Russia?\" and she's like, oh, we don't have any PTSD in Russia. And I was like, how did you come to that conclusion? And it's because they're in such deep denial about the pain that they are in that they can't even recognize it. And so there's an idiom that I like, which is you may as well ask the fish if the water is wet. When you grow up and you live with nothing but the abandonment and trauma, that's all you know, and you can't even conceptualize of another way of being. You know, and I pointed out to her, I was like, how many men do you know that have died of alcoholism in Russia? And she just kind of clammed up. It's something like 30% of men in Russia are alcoholics, and more than 10% die of alcoholism or suicide, like it's incredible just how traumatized that entire society is. And again, that's not to forgive anywhere else because when you look at, you know, in America, like, what was it, depending on the statistics you look at, but like 70% of American adults have mental illness. Like we're not in much better shape. And it all comes down to intergenerational trauma and abandonment. And so what you're seeing in that quotation that you shared is someone reflecting on that and being aware of it and unable to escape from it. That's my interpretation. Yeah, yeah, nicely said. Your story of meeting that Russian woman reminded me of an experience I had in Korea. So I lived in Korea for two years, and I taught English over there. And there was a time where I went to the doctor there, and in my broken Korean, I forget exactly why I was going, but he was asking me if there was like anything else I was dealing with. And I remember trying to explain to him that I just had like kind of this like generalized anxiety and his response to that was like, well like do you have like a test coming up or something? Like what are you what are you anxious about? And we couldn't get past the fact that I was like I didn't know why I was anxious I just kind of like felt this anxiety and he's like no but you must have, like, some reason for it. And it was this weird, uh, this, this moment I'll never forget. Um, why, yeah, why, why I think you'd love Dostoevsky too, is he explores this nihilistic tendency, just nihilism in general, I guess, in, in such depth. I mean, as you can see from that passage there, but ultimately he is a person, I think, like, he gives the strongest argument he can for nihilism, but he comes up on the other side. His idea, his solution to the problem is God. This is a whole can of worms that, you know, there's so many things I want to talk to you about and I'm, I fear that I might be opening or going down another rabbit hole but I heard you talk in a video that you know people like Jordan Peterson for example Dostoevsky too I mean Jordan Peterson is a big fan of Dostoevsky but they are their heart is in the right place in terms of combating this nihilism with the idea of you know going back to more traditional routes and this idea of God, let's say. You, I think, disagree with that. What would you say your solution, if you had to sum it up, I know this is an impossibly hard question, but your solution to the problem of nihilism? So, in my work with nihilism, I discovered that there are, or rather I categorized the problems into four categories, and I call it the four abandonments. So the first abandonment is childhood abandonment, which is in the form of trauma, neglect, and abuse that goes untreated in children. That ranges from mild emotional neglect to children exposed to domestic violence or even just shouting is enough to traumatize a child, especially if their emotions are not addressed. I have friends from all over the world, Lebanon, Iran know, experienced civil strife, you know, hiding in bunkers during air raids, and, you know, even a well-meaning and loving parent that is not able to address that trauma is still a form of abandonment. And it's no one's fault. So I don't want to say abandonment like, oh, you just left a child alone. You can still have very well-meaning parents and families that just don't know what to do. They don't know how to process it. So that's the first abandonment. The second abandonment is social abandonment, which is an extension of childhood abandonment, and that is the rugged individualism that we see in both in Western and Eastern societies today to be honest. And so rugged individualism is that, you know, like, I'm a sovereign citizen, I'm going to take care of myself, I don't need any help, like, you know, get off my lawn. And where we don't trust each other and we don't help each other. And this is reflected in everything from the way that we live, we don't talk to our neighbors anymore, we don't have communities anymore. And it's also reflected all the way up into our law have communities anymore. And it's also reflected all the way up into our law and the way that we live. Some of our economic policies are intrinsically just make the assumption that we should all just kind of live in our own little houses and kind of not talk to each other. So that's the second abandonment. And then the third abandonment is cosmic abandonment. So this is what Jordan Peterson and Eugene Rose and Dostoyevsky all talk about, which is with the rise of secularism, with the rise of nihilism and and kind of the the diminishment of the centrality of religion, we haven't replaced it with anything. And not only that, we build bigger and bigger telescopes and we look further and further out into the universe and we see that we are entirely alone. Who was it, was it Arthur C. Clarke said that two possibilities exist, either we are alone in the universe or we are not and both are equally terrifying. And like you can't put it any more succinctly than that and so we feel alone in the universe and that makes us even wonder even more deeply why are we here? What's the purpose of it all? Which again, only serves to reinforce that, like maybe there is no purpose, which is the heart of nihilism. And then finally, under the weight of all three of those abandonments, we end up with self-abandonment, which is why you see all sorts of toxic echo chambers on the internet and and people people taking it out of the internet and you know, we end up with things like mass shootings And and deaths from despair even amongst young people I participated in another podcast about six or seven months ago And one of the things that I pointed out is that we have 17 18 19 20 year olds is that we have 17, 18, 19, 20 year olds that are so lonely and angry that they hurt themselves and they hurt other people when they are, when they really, physically, they're in the prime of their life. They are at the most energetic that they will ever be. They're at the most resilient that they will ever be. And instead of living it up, instead of, you know, chasing romantic partners and having fun and even, you know, even drinking at parties or whatever, instead of having fun and enjoying life, they're so angry and so lonely that they lash out. And there are plenty of people that suffer in silence too. I'm not saying that, oh, everyone who's suffering is at risk of lashing out violently, but certainly some people are. And so by naming it, by naming it this nihilistic crisis that we're in, I'm hoping that I can help start changing the conversation around the solution. So one of the solutions, the primary solution is just to create a more trauma literate society. And what I mean by that is, you know, the books, the YouTubers, you know, the blogs, and bringing the conversation about trauma and abandonment and neglect into the mainstream, which it's happening. You know, if you look at the number of books that have been published over the last 10 years alone, it's gone up exponentially. The information is there, we are becoming a more trauma-literate society, but then we still need to put a name on it, right? We still need to say, okay, this is the problem and this is the solution, and so the nihilistic crisis is the problem, that is the underpinning problem that results in trauma, that results in abandonment, and then the solution is that trauma-literate society. And unfortunately, I think that for some people, it's probably too late. You know, I look at older generations that they had to live with trauma and abandonment, you know, from World War II, Vietnam, Korea, World War I, you know, and for many people, they had to live with PTSD their entire life and never had answers. We are fortunate in that we are the first generation that really has comprehensive answers. And so Jordan Peterson did the best that he could with the information that he had. The best answer that he had is to return to traditional structures. Now, that being said, we have better answers today. And then you combine more information, trauma literacy, because you know the the best, what is, how do I say it, an ounce of prevention is worth a pound of cure. If we can prevent trauma moving forward or treat it more appropriately, in a generation or two we're gonna see a much less traumatized society, just wholesale. Now that being said, for those that are young enough or flexible enough, there are more treatments available today, ranging, you know, on the most extreme end is the rise of psychedelic-based therapy. Thinking about that as you were talking. Yep, so there's somatic experiencing, there's group-based therapies, and as our medical establishment becomes more trauma-based therapies, and as our medical establishment becomes more trauma-informed, more trauma literate, these therapies will be better. My fianc\u00e9e was a librarian. It's fascinating. Even librarians are now trained to be trauma-informed, because what often happens is that more vulnerable people in a city will end up at the library because that's the only place that they can get free resources. And in fact, some libraries start to staff social workers. And of course, social workers are gonna be more trauma-informed today too. So as we become a more trauma-informed and trauma-literate society, a lot of this is gonna kind of work, I hope, will work itself out naturally over time It is a slow process though I want to Dive into childhood a bit and ask you a personal question if I may Sure, you you have another channel in addition to all of the stuff that you do with AI Called David Shapiro life, I think yep And you released a video quite recently about autism and about your experience with autism growing up. And you told a story about this experience you had from your childhood. And this was actually one thing that I found really fascinating, that one of the signs of autism in younger children is that you score either really high or really poorly on tests. And in your case, you said that you score either really high or really poorly on tests. And in your case you said that you were 99th percentile in everything except for reading comprehension and that the reason for that was because you didn't know at which level of analysis to stop or to analyze the story at. So you'd write these like incredibly nuanced responses that were inappropriately deep for the question and What you said was you had this we'll get into education in a bit here but there was this teacher who came to you and Explained to you what you were doing wrong, and that was this big aha moment for you so before we get to education Just at a at a in a general on a general level, what has your own experience with autism taught you about the challenges of building artificial intelligence? I think there's one conversation that encapsulates this perfectly. And it was shortly after I met my now-fian fiance, we met at our writers group. And so we got together for coffee to discuss our stories. And I told her about this character that I was working on called Raven in my novel, this globe-spanning AI, and she's like, oh, you know a lot about this, you care a lot about this. And so she's like, you should lean into this character and explore it more. And of course, you know, four years later, I'm actually working on a real version. But we were talking about what it takes to model intelligence. And she stopped after I was telling her about all my theories about cognitive architecture and AI, and she said, whose brain are you trying to model anyways? And I was like, what do you mean? And she's like, you're talking about the way that your brain works. And she's like, what about other people whose minds work differently? And I was like, I hadn't thought about that. And so that's kind of a circuitous way of answering your question, but metacognition or self-awareness is a huge component of working on theory of mind, cognitive architectures, that sort of thing. And one of the most common, it's actually in several assessments to determine whether or not you have autism or where you're at on the spectrum is, if you're fascinated with personality theory you are more likely to be autistic it's just you know one little you know notch in the test but the reason that many of us are and one of my one of my absolute best friends is also she's big into more into Enneagram but she knows about MBTI too and it's like she has she has all these great stories she's like people are confusing to me so stories. She's like, people are confusing to me. So I need like a template of how to interact with people. And then we also seek out information to understand ourselves. And that's actually how I got into personality theory many years ago. I was like, I don't know how I work. Apparently I don't work the same as other people. So let me figure out why. And of course, you know, I take a MBTI test and it's like oh you know you're this personality type but of course it doesn't actually have like the the real answer which is oh you're actually autistic. Like that would have been a great thing for that to have. And you know if I had gone, here's the thing, even if I had gone to a professional psychologist back in 2008-2007 I probably still would not have been diagnosed correctly because the information is still advancing. So anyways, that was a very roundabout way of answering your question is that exploring psychology, exploring the mind, exploring philosophy, all of that is kind of part and parcel with being autistic and also all of it contributed to my understanding of artificial intelligence too and actual intelligence for that matter. Right. You have a video called billion dollar GPT-3 startup fix education with an expert tutor chatbot. As someone with a background in in education myself I am so excited about what all of this stuff means for education My girlfriend is Korean and she's still learning English over here, and she found this app where she can Have a conversation with this AI She speaks in English it responds to her in English And at the end of the conversation it shows the transcript and also how she could have sounded more natural at different points in the conversation. And I was, you know, I taught English in Korea for two years and then online for a little bit and like one of the biggest challenges as an online teacher especially was like everyone wants to speak with the teacher but you're a human and you only have, you know, so much time. This just solved that problem and it's already here and she's using it and it's an amazing app. If someone, my next prompt for you, if someone came to you and gave you the keys to the country, I'm in Canada, you're in the States, but you know, similar education systems, if someone gave you the keys to fix education, you had unlimited resources and could do whatever you want to do, what would you do? How would you fix education? So I actually had a few conversations with educators all over the world in January. So one of the platforms that my startup is working on is actually edtech, so deploying AI into education. And so obviously with the rise of chat GPT, there was a lot of consternation around AI. A lot of teachers had a lot of fear and anxiety, like, is this gonna replace this? Is this gonna break everything? And of course, after the initial panic has subsided, people are like, oh, there's actually ways to use this. So, but to answer the question more directly, what I would do, what I'm trying to do, what I'm working towards doing is adding more tools like that, like that language tutor, so that students have more individualized support. Whether it's something that is going to provide coaching and feedback, because that's absolutely one of the pillars of our work, is providing that really personalized, hands-on feedback that allows students to learn and get super high quality coaching and guidance. So deploying as many of those tools as we can, and then kind of see where the gaps are. Because obviously, learning from a computer is gonna have some limitations, right? That's why I said earlier, we will always need that human touch, but 30 students for one teacher is too much, right? And, you know, we need the human that has that emotional intelligence, that has the soothing voice, that has, you know, the physical touch to be able to work with students when they get frustrated, or when they're sad and angry and distracted because something happened at home. So much of being a teacher, being a good teacher, is paying attention to the student as a whole entity, not just thinking about the grades. And on the topic of grades, there is an ungrading movement, which I think is probably more popular in Canada than it is in America. I'm not sure though. But the idea is to get rid of grading altogether and just focus on learning. Now I talked to several educators about that and they said, we get it, you know, we get the idea, but you do need grades. The problem is that grading is misused today because grading is one of the few levers of influence and power that teachers have, right? A teacher has to be there and has to teach the students in their class, whether or not the students even want to be there, right? So the the two levers of power that teachers have is grades and disciplinary actions, and depending on the students or the classroom or the classroom or the school or the district, they might even have constraints about the discipline that they can take. Sometimes because of parents, sometimes because of legislation that's passed, so on and so forth. So teachers don't have a whole lot of power over the environment in which they teach. So you know, by automating or aiding some of this process with machines, we can, one, provide more equitable experience for children. So, for instance, one of the biggest problems, and this is just a structural problem, is that our classrooms are designed, they were designed during the rise of the of industrialization, which means that they're kind of calibrated to create, you know, like worker drones, right? Part of the of the Western school system is you sit quietly at a desk doing menial work and if you can't do that, well then you're defective, right? You know, we pathologize things like ADHD, like, you know, I'm probably somewhere on the spectrum of ADHD, but it's because my brain is too damn fast and too active and wants to solve harder problems, and so I didn't do well in, you know, sitting at a desk. I still don't. Well, I mean, I can sit at a desk and hyper focusfocus on AI for a few hours. But if we can decouple education and learning from being in lockstep with every other student so that children can move at their own pace. So another thing about me is that my first year of education was at a Montessori school. And so for anyone who's not familiar with Montessori school, it is super unstructured. It basically just looks like play. And the idea is that children will engage in self-directed learning based on what interests them. And so, like, one of my favorite things to do back at Montessori school, and I actually, I remember this, was there's this toy where you, there's parts that you stack and marbles go through it, right? The marble tracks. And then there's like little loops and pinwheels and spirals and stuff. And that was, I found that so interesting because it was a system. You create this tower and then you send marbles down it and you figure out how marbles end up where they're going and you play with the physics of it. And I was actually so excited playing with that, I'd be like screaming that eventually the teachers had to take it away from me. But anyways, the point being is we do have other models of education, but they're either too expensive or too unreliable to deploy. And what I'm hoping is that with AI and machines, we can actually, we can kind of flip the classroom again and change it so that students, so that all students, one, get their intellectual needs met, and two, can move at their own pace, and three, get the feedback and guidance that they need, whether it's from a machine or a human, as needed. So I think if we do those three things, I think that we're going to see a very, very different generation of children that have a very different relationship with education. Because learning is exciting, right? Children, like all children, do natural experiments at all times, right? My nephew, he found a scarf. We were hanging out one day at my brother's house and he was just throwing a scarf up in the air. And I recognized the behavior because it's something I would have done. He was playing with, how does this scarf move through the air? How does it fall? What are the rules that govern this thing? And I was like, oh you're doing science. And he's like, no I'm not. I'm like, yeah you are. You're figuring out how this thing works. And I had, I actually had an argument with with another friend over the definition of science I told him a story like that and I was like that's natural science and he's like no the only the only people who can do scientists work at universities and publish papers and I'm like that is such a narrow definition of science and I was like I'm not gonna talk to you right now you're you're too obt anyways, if we do those things, we will completely change our relationship with learning and education. Because it turns out, as much as I hated school, I actually love learning, and I love science, but I learned to hate it because of how broken our school system is. Right. Do you think we'll get to a point, I guess there are kind of two questions packaged in here, but I was thinking back to the experience that you had with this one teacher who was able to explain to you why your answers to these questions were inappropriately deep. And when I was watching that part of the video, you know, there was something about that experience that seemed to be, and you talked about this a little bit in the answer that you just gave, but you know, there's a component of it, of course, that's teaching you, but really the big component of it is just being able to like empathize with what you're going through. And like, I forget the exact way that you phrased it, but look at you as a full entity. I think you said, do you think that we'll get to a point anytime soon, let's say in the next five to 10 years where you're able to have that same experience that you had with this teacher, with a machine, where a machine is able to look at you in that same way and not only correct you in terms of what's wrong with your answer. I mean, we can do that right now. ChatGPT is pretty good at that, but also make you feel, um, create that change in you. That has. That was such an important moment to you that it's stuck with you all this time, right? So will a machine be able to have that same impact? And then the second part of this question is what, how do we teach kids that they are interacting with machines and about the difference between interacting with a human and interacting with a machine? What impact does that have on children? Yeah, good questions. So to the to the first question or the first part, technologies like ChatGPT are already, this is probably going to be a controversial assertion, but I've, I've, I've witnessed it firsthand and I figured out how to do it reliably. Chat GPT has an incredible ability to make inferences about our emotional reality. And so I have a couple of examples of, of how I can demonstrate this. So one, um, I was, I was, I was having a conversation with ChatGPT, I need to come up with something that rolls off the tongue better, but I was having a conversation about my novel. I was working through a chapter and I was trying to come up with ways to make the chapter more nuanced, more layered, more relevant to the theme and the character arcs and stuff. And I was telling it about these two different worlds, that they're a juxtaposition, where one world goes one way and another world goes another, and without me saying the reason for that, ChatGPT told me, like, oh, the reason that you have this contrast is to show the theme of your story and here's a better way of doing it.\" I was just like, when that happened, I said, holy crap, this goes above and beyond what, even though I'm so bullish on what large language models are capable of, this completely changed the scale of what it's already capable of today. changed the scale of what it's already capable of today. And the nuance that it detected in my story is something that it took me three years to develop. And so just through one conversation, by connecting those dots, I said, okay, we are in a new paradigm in terms of understanding the human condition, just strictly from a linguistic perspective. Then at the same time, I've had similar conversations about myself. And of course, it's really infuriating because usually when you talk to chat GPT about like personal problems or whatever, it'll just rattle off a list of things you can do. I said, no, no, no, don't, don't tell me what to do. Let's explore this. Let's unpack this. And it says, okay, let me ask you a few questions, let me give you some generalizations about what this might mean. And its ability to connect those dots is incredible. So strictly from a thought perspective or emotional perspective or linguistic perspective, the technology can already do that. It's not reliable though because it's not thinking. It's not structured in a way to do that for you. So how do we get there? Well one of the things that I'm working on is what I call a cognitive architecture. So how do we take these technologies and encapsulate them and structure them in such a way that it can reliably do that. So that it can take this miraculous ability it has to make inferences about the human condition, about emotions, about people, about theory of mind. There was actually a recent paper published that said that, that actually concluded that large language models do have, they do possess theory of mind and that it just emerged by virtue of how it's trained. So with a cognitive architecture, we can develop machines that remember all these facts about you, that play with these ideas internally, and then either come up with hypotheses, say, oh, I wonder if this is what's going on with this person, and then test that hypothesis by asking questions or make recommendations or so on and so forth. So the technology is coming. We already have visual technology and audio technology. So there's a company that I spoke with more than a year ago now. It's a French company called Humano, and they focus on creating automatic telemetry, emotional telemetry from users based on face, voice, and so on, where it's like, how engaged is the person? Are they frustrated? Are they happy? Are they excited? So on and so forth. So we combine this emotional telemetry that can read your body language and facial expressions and voice inflection. You combine that with this language technology and the appropriate cognitive architecture and we will very soon get to the point where our machines are able to have those eureka moments with you. And that's actually one of the primary inspirations I'll say for my Raven project, which one of the central mantras is the right information at the right moment changes lives. That is the whole point of that cognitive architecture is to figure out what information is needed and to deliver it in exactly the right way at exactly the right moment. Because when you make that connection, when you get the answer that you need, when your brain is ready for it, when your mind is ready for it, then that's what changes your trajectory. So it's coming. We're working on it. I'm actively working on this technology. Now, the second part of the question, which is, you know, how do we teach children about this? I suspect that the first generation of children that grow up with this high-level artificial intelligence, for them it's just going to be intuitive. You ever hand a smartphone to, you know, a toddler? The stuff they figure out on accident is just like, I didn't even know I could do it. Like, I'm a technologist. Like, I've done IT for years, and I'm a digital native, and children's brains, they get acclimated to the tools that they're using, and they just figure it out, and they can't even articulate it. Same thing when I watch my nephew and all of his friends, that they just play these games day in and day out. They have tablets, they have phones, and they just get it. So I suspect that once they know that they're interacting with an intelligent entity, and when I say intelligent entity I don't mean like human intelligence, but something that has the functional intelligence that they need, that they'll have a model of saying, oh, I know that this thing has the answers for me. I just need to interact with it in a certain way. And we already see that with children who will like interact with Alexa or voice enabled robots. And that's just going to go up. So I don't know that we need to do anything specific. I think that nature will kind of work itself out in that respect. Okay, last question for you, and I don't know exactly how I'm going to\u2014what the question is yet, but I want to frame it in a certain way. So there's one thing that has terrified me more than anything about AI, and it's terrified me for\u2014I mean, I think I saw the movie in 2015. I think I heard you talk about Ex Machina in one of your videos. Yep, okay. So it's a scene from Ex Machina that I watched it and it's just stuck with me and I'm reminded of it and it's becoming especially terrifying now to me. And it's related to what we were just, well, I'll get back to what we were just talking about with children interacting with machines. But anyways, the scene from the movie is when Caleb, who's the engineer who's brought in to interact with these AIs and test whether they're sentient or whether they pass the Turing test or whatever, it's near the end of the movie where he realizes that he's been set up and that all of this is a test and that he's been fooled so wildly by these AIs to the point where he doesn't even recognize that there were AIs that looked like humans that he thought were humans that were actually AIs around him that he didn't fall in love with. And the particular scene is one where he starts doubting whether he's a human. And he actually, the scene is he like cuts his arm open to see if he bleeds or if he'll find wires inside. And that scene has that that terrifies me more than anything, this idea that we don't know what's true anymore. You can kind of you see this already with a lot of the technologies and startups that are that are being launched where there's, you know, synthetic video that's getting it's still not perfect, but it startups that are being launched, where there's synthetic video. It's still not perfect, but it's getting closer and closer. There's no reason to think that it's not going to get to the point where we can't tell the difference. As you were speaking, I was just imagining, I want to have kids in the next couple of years. I'm almost 33 now. I was imagining my kid speaking to this AI that's like totally convincing to the point where you don't know It is an AI and the thought came to me like well What if this kid just can't tell the difference between humans and AI's does that matter? what does it mean if he like looks he or she looks at me and You know, there's no there's no there's no difference in terms of how that child perceives me as the father versus like an AI that's teaching them. I guess my last question for you is what do you my last prompt let's say I want you to make the the bullish case for why I shouldn't worry about this stuff, or just respond to my fears and tell me what you think is going to happen with this particular concern. Yeah, so this has been explored in science fiction for for decades actually. There's a there's a series on YouTube, it's called like the History of Cyberpunk or something, and it unpacks like each decade, like 1970s, 1980s, and 1990s. It's a phenomenal series. Each video is like two hours long, so it takes six hours to watch. But ever since the rise of computers, humans have had so much anxiety about virtual reality, what is reality, what does it mean to be human? There is all kinds of movies where people get sucked into the machine. Tron is the most famous one where it's like, oh, hey, if a machine can run a simulation and you get sucked into it, how do you know, right? So there's that, there's the Matrix, which also kind of was the pinnacle of what if we're all living in virtual reality, how do we know what's real, and there's been plenty of other stories in between. More recently, so there's Ex Machina, there's Ghost in the Shell which is an anime and manga where the protagonist, that's actually her primary philosophical character arc, is she has a fully robotic body so she doubts whether or not she's even human. And so the idea is, that's actually the name of the series, Ghost in the Shell, so the shell is the artificial brain case and the ghost is her soul, right? That is the key question. What does it mean to be human? And so the anxiety that you feel is one, extremely common and it's why it has been explored for literally 50 plus years in science fiction as we started creating thinking machines. And actually it probably goes back earlier. This was one of the ideas originally explored in Mary Shelley's Frankenstein. You know, the new Prometheus, the idea of if you reanimate something, what is it? Right? If you create an artificial life form, does it have rights? Is it a person? You know, these are all questions that we've been asking for, I guess, more than a century. been asking for, I guess, more than a century. And for me personally, it is no longer an unsettling question. And it kind of goes back to, who was it? Was it Sartre? Who said, I think, therefore I am? Descartes, I think. Okay, yeah. Some French philosopher. I think. Okay yeah some some French philosopher. But anyways so I know that I have a subjective experience. I know that I I feel myself looking out of my eyes at the screen talking with you right now. I also know that all of my day yesterday was totally ephemeral. From the perspective of my day yesterday was totally ephemeral. From the perspective of my brain and from the perspective of physics, the person that I was yesterday no longer exists, right? And because of that, once we become aware of and comfortable with how ephemeral our existence is, that is far more existential than whether or not we're machines, than whether or not a child can differentiate between a flesh and blood human or a facsimile of, you know, an anthropomorphic machine. I think, I think, so I guess my answer is I think the actual anxiety that you are experiencing and that other people are experiencing has more to do with just how thin and fragile our experience of being is. And I think that that is part of why people are afraid of AI and why people have this like human exceptionalism. Like people say, oh, the machine is never going to be as smart as us. It's never going to be anything like us because that is emotionally more comfortable than reconciling with that like existential dread. And this is actually, this is actually a conversation that I've been having with my fiance for like four years because this is the central theme in most of her writing, actually. She explores this quite extensively, just like, okay, like, if our existence is so fragile, so thin, so ephemeral, and we can compare ourselves to machines, what's the difference? Right? But once you fully wrangle with this this and I guess I shouldn't assume that everyone's gonna come to the same conclusion as me but at least for myself once I go through that and once I experience things like full ego death and and realize just how thin and fragile it is and learn to accept that then it's like oh it's actually not that big of a deal but it is and learn to accept that, then it's like, oh, it's actually not that big of a deal. But it is a matter of reconciling with that idea and being able to accept it, I think. And does that for you, I imagine like, well, we talked about this earlier, but I imagine for some people that could, all of these nih these nihilistic tendencies, maybe could start bubbling up as a result of that, or the opposite, where you realize that, like, you know, we're here, we're having this experience, and you just learn to embrace it and, and enjoy it more, maybe. It seems like for you, that's been the latter has, has happened. Yeah, so that's actually why I call my philosophy post-Nihilism, because you don't reject Nihilism, you have to move through it. I was having a chat with someone, I think it was on my Patreon or something, or somewhere recently, and they were talking about, like, oh, well, Nihilism is just the obvious logical conclusion. If you accept that like, you know, there are no deities and you know, materialism and science and blah, blah, blah. And it's like, sure, like you could make an argument that it is logical, but at the end of the day, who cares? Who cares about logic, right? Logic doesn't really figure into our daily experience and this is so this there's there's two philosophical paradigms one is the is-ought problem which is David Hume the Scottish philosopher it isn't basically it says that it is impossible to determine what ought to be based on what is so if you make an observation about the physical world, it is impossible to say how something should be. All we can do is make observations and then we can then take our, you know, moral sensibilities, our intellectual sensibilities, and then claim it ought to be a different way or it is how it ought to be, but they're completely orthogonal. And so orthogonality is the other more general logical or philosophical complex, which is some things are just not correlated. They're just not related and no matter how much science we apply to existence to our subjective sense of being to intelligence. It may it might never make sense as to why we are sentient. And so once you get to that point, it's just like, who cares, right? It's just like, I have a bookcase full of books trying to get to the bottom of it, and I've gone through quantum gravity and Eastern philosophy and everything else in between, and at the end of the day, it doesn't matter. And I know I can hear all the optimistic nihilists saying, oh, you figured it out. That's optimistic nihilism. But I think that optimistic nihilism is wishful thinking for people that kind of want to take a shortcut. It seems like a, what's the word I'm looking for? Cop out? No, no, no. One of those things that like like like a paradox, but there's a different word And I can't remember right now. Okay, but but like and but like I feel like optimism you can't almost Like it feels like that can't exist an optimistic nihilist in some sense, right? Well, yeah I think I think that um, I think oxymoron is the word you're looking for. Yeah. Yeah Yeah, so because I think that um, I think oxymoron is the word you're looking for. Yeah. Yeah, that was yeah Yeah. Yeah, so because if if you are Trapped in the quagmire of nihilism, then you still believe that nothing matters Right, and so then you can say oh, well nothing matters. Therefore. I'm free, but that feels really hollow whereas at least from my perspective if you move through that and It's it's not that you know, I say, who cares? That doesn't mean like nothing matters. It's like, actually, the only thing that matters is our experience. And by settling on that, by saying like, okay, logic, math, science, religion, spirituality, none of that has a satisfying answer. But at the end of the day, I still have my experience of being, and I can't get rid of that. That's what matters. And then you arrive at that tiny little nucleus of, I know that I have a subjective experience and that matters to me. And then if I make the assumption that everyone like me, you know, you, every other human, every animal with a sufficiently sophisticated brain, if I then make the assumption that they also have a subjective experience and that their experience matters to them, that's an entirely new framework of looking at existence. Say, actually what matters is that experience, whether it's individual or collective. And so that's why I say post-nihilism, because you get to that logic, that logical conclusion, I've used air quotes, that nothing matters. And it's like, but that's not true, right? If nothing matters, why do we continue to exist? You know, that ignores the biological reality that I'm here right now, and it's like, okay, that actually matters. So let's go from there. Yeah. And hopefully that subjective experience is beautiful enough and filled with enough moments of love, let's say, where you want to, you know, make sure that more people have a great experience to Anyways, I think that's a great way to Do it to end the conversation, but David, thank you so much for taking the time to be with me this morning And thank you for all the content you're putting out. I'm so grateful that I found your channel on this Otherwise, what would have been an otherwise boring flight to Korea and it's no surprise to me at all that you're that you're blowing up And just keep doing what you're doing man, because it's a pleasure to follow so I'm talking to you and thank you Yeah, no, you're quite welcome. And thanks for the great talk and yeah Good luck with everything and keep doing the good work that you're doing All right, man. See you in the next episode everyone. Bye. Bye All right, man. See you in the next episode, everyone. Bye-bye.", "chunks": [{"timestamp": [0.0, 5.56], "text": " I think the actual anxiety that you are experiencing and that other people are experiencing has"}, {"timestamp": [5.56, 12.6], "text": " more to do with just how thin and fragile our experience of being is."}, {"timestamp": [12.6, 18.48], "text": " And I think that that is part of why people are afraid of AI and why people have this"}, {"timestamp": [18.48, 21.08], "text": " like human exceptionalism."}, {"timestamp": [21.08, 23.44], "text": " Like people say, oh, the machine is never going to be as smart as us."}, {"timestamp": [23.44, 30.14], "text": " It's never going to be anything like us, because that is emotionally more comfortable than"}, {"timestamp": [30.14, 36.64], "text": " reconciling with that, like existential dread."}, {"timestamp": [36.64, 41.08], "text": " Today I'm speaking with David Shapiro, a prominent figure in the world of AI, who I"}, {"timestamp": [41.08, 50.2], "text": " greatly admire. On his YouTube channel, David delves into the intricacies of building artificial intelligence, exploring the social, philosophical, and technical aspects"}, {"timestamp": [50.2, 53.56], "text": " of the topic. If you're curious about the world of AI, I would definitely recommend"}, {"timestamp": [53.56, 57.18], "text": " checking out his channel. The link to do that is in the description. If you're enjoying"}, {"timestamp": [57.18, 61.24], "text": " these conversations, make sure to like and subscribe. Without further delay, here's David"}, {"timestamp": [61.24, 71.4], "text": " Shapiro. I hope you enjoy the conversation. AI is coming for all of our jobs, but let's say technology creates more jobs, right? Throughout"}, {"timestamp": [71.4, 76.4], "text": " history that has happened. You often hear that line of thinking. Why is that line of"}, {"timestamp": [76.4, 79.8], "text": " thinking wrong in this case?"}, {"timestamp": [79.8, 85.72], "text": " So historically speaking, technology has not necessarily strictly created new jobs,"}, {"timestamp": [85.72, 90.8], "text": " but what it did is it created efficiencies that allowed people to further specialize."}, {"timestamp": [90.8, 95.28], "text": " So it is kind of a misnomer or a platitude."}, {"timestamp": [95.28, 99.34], "text": " It's an oversimplification to say technology creates new jobs."}, {"timestamp": [99.34, 103.74], "text": " Technology creates new systems, new ways of using energy that allows for further branching"}, {"timestamp": [103.74, 109.28], "text": " and specialization, but of course, that's not as good of a catchphrase as technology creates new jobs."}, {"timestamp": [109.28, 114.96], "text": " So first, it's just the premise is a little bit, you know, off to the side."}, {"timestamp": [114.96, 121.92], "text": " But then when I looked at the data in terms of the idea that like, oh, hey, internet technologies,"}, {"timestamp": [121.92, 127.54], "text": " information technologies, this must intrinsically create new jobs because it's the most powerful new technology."}, {"timestamp": [127.54, 132.54], "text": " When you look, there are certain trend lines"}, {"timestamp": [132.54, 136.34], "text": " that if you look at job creation actually started"}, {"timestamp": [136.34, 140.14], "text": " tapering off or slowing down in the mid to late 90s,"}, {"timestamp": [140.14, 142.26], "text": " just as the internet was taking off."}, {"timestamp": [142.26, 145.0], "text": " And if this idea was true,"}, {"timestamp": [145.0, 147.0], "text": " that advanced new information technologies"}, {"timestamp": [147.0, 150.0], "text": " only and always create new jobs,"}, {"timestamp": [150.0, 152.0], "text": " you would expect that trend line to go the opposite direction,"}, {"timestamp": [152.0, 154.0], "text": " that with the rise of the internet,"}, {"timestamp": [154.0, 156.0], "text": " jobs would go up."}, {"timestamp": [156.0, 158.0], "text": " But instead, we have"}, {"timestamp": [158.0, 160.0], "text": " total labor participation rates"}, {"timestamp": [160.0, 162.0], "text": " slowly declining since the mid-90s."}, {"timestamp": [162.0, 165.2], "text": " We do have very low unemployment right now, but"}, {"timestamp": [165.2, 171.36], "text": " that's because a bunch of people have exited the workforce permanently. And so, you know,"}, {"timestamp": [171.36, 177.12], "text": " unemployment rate is just a proxy for some things, but total employment is actually trending"}, {"timestamp": [177.12, 182.48], "text": " back towards kind of where it was in the 60s or 70s. Whether or not that's a good thing"}, {"timestamp": [182.48, 186.0], "text": " or not, I'm not making a judgment on it, just pointing out that"}, {"timestamp": [186.0, 206.0], "text": " if the demand for human labor was going up, we would see that in rising wages, which of course wages for most workers have been largely stagnant since around 1980. And so what I suspect is happening from a functional or algorithmic standpoint"}, {"timestamp": [206.0, 210.0], "text": " is that yes, technology is increasing efficiency,"}, {"timestamp": [210.0, 214.0], "text": " but that efficiency is driving down the need for human labor,"}, {"timestamp": [214.0, 217.0], "text": " and that's only going to accelerate with artificial intelligence,"}, {"timestamp": [217.0, 223.0], "text": " especially when you look at the fact that machines are generally cheaper than humans,"}, {"timestamp": [223.0, 225.0], "text": " and as machines can do more and more cognitive"}, {"timestamp": [225.0, 229.36], "text": " labor, there's going to be less and less that you actually need a human to do. Now"}, {"timestamp": [229.36, 232.8], "text": " there are some things that humans will have that are going to stay"}, {"timestamp": [232.8, 236.84], "text": " unique for a little while. You know, we've got a gentle touch, we've got gentle"}, {"timestamp": [236.84, 242.08], "text": " voice, you know, so things like healing professions, massage therapists, doctors,"}, {"timestamp": [242.08, 251.16], "text": " nurses, those kinds of jobs will probably be pretty well insulated because nobody wants a robot doctor working on them just yet."}, {"timestamp": [251.16, 256.4], "text": " Child care, education, there are plenty of things that really do require a human touch,"}, {"timestamp": [256.4, 260.96], "text": " but the rule of thumb that I follow is if your job can be done at a computer, you are"}, {"timestamp": [260.96, 263.52], "text": " at risk of being automated out."}, {"timestamp": [263.52, 265.28], "text": " And it's just because, hey, you know,"}, {"timestamp": [265.28, 270.8], "text": " that's where AI lives. It lives on the computer. So if you can do it on a computer, an AI can"}, {"timestamp": [270.8, 275.16], "text": " probably do it too. Okay, so here's a prompt for you. I have"}, {"timestamp": [275.16, 278.52], "text": " a few prompts for you throughout this interview. Okay."}, {"timestamp": [278.52, 288.72], "text": " I want you to imagine that you are my wise life coach and that I am young, ambitious, let's say in my mid-20s."}, {"timestamp": [289.88, 291.62], "text": " I'm interested in a whole bunch of things."}, {"timestamp": [291.62, 293.12], "text": " Maybe I have a bachelor's degree,"}, {"timestamp": [293.12, 294.92], "text": " but I don't know what I wanna do."}, {"timestamp": [294.92, 297.4], "text": " I'm looking at all of this stuff that's happening"}, {"timestamp": [297.4, 302.4], "text": " in terms of AI, seeing what ChatGPT alone is capable of."}, {"timestamp": [302.88, 308.52], "text": " And I see a huge opportunity here, but I'm also, you know, I want to have,"}, {"timestamp": [308.52, 312.36], "text": " let's say in the next five to 10 years, my own family and security is something that"}, {"timestamp": [312.36, 318.28], "text": " I value. I want to spend, invest my time in something that is going to be relatively safe,"}, {"timestamp": [318.28, 324.8], "text": " as safe as one's job could be. Where should I invest my time? What kind of advice would"}, {"timestamp": [324.8, 325.2], "text": " you give me?"}, {"timestamp": [325.2, 333.6], "text": " Yeah, so that's a great question. And for most people, what I would recommend is don't be afraid"}, {"timestamp": [333.6, 342.88], "text": " of the AI, learn to use it. So for now, tools like ChatGPT can be used to really accelerate"}, {"timestamp": [344.88, 346.92], "text": " whatever job it is that you're doing."}, {"timestamp": [346.92, 349.08], "text": " And more tools like that are coming."}, {"timestamp": [349.08, 352.84], "text": " In fact, that's kind of what my startup is working on,"}, {"timestamp": [352.84, 354.48], "text": " is rather than working on tools"}, {"timestamp": [354.48, 356.2], "text": " that will replace human labor,"}, {"timestamp": [356.2, 358.52], "text": " we're going to work on tools that accelerate it"}, {"timestamp": [358.52, 361.0], "text": " and work very closely with humans."}, {"timestamp": [361.0, 362.8], "text": " Because in most cases,"}, {"timestamp": [362.8, 368.12], "text": " there are cases where a machine is better suited"}, {"timestamp": [368.12, 370.74], "text": " to do the job in its entirety, for example,"}, {"timestamp": [370.74, 372.24], "text": " on an assembly line."}, {"timestamp": [372.24, 374.48], "text": " It's better to just get humans out of that situation"}, {"timestamp": [374.48, 375.48], "text": " altogether."}, {"timestamp": [375.48, 377.36], "text": " Now, that being said, there are still"}, {"timestamp": [377.36, 382.12], "text": " plenty of situations where human creativity and ingenuity"}, {"timestamp": [382.12, 385.28], "text": " and intuition still far outstrip the capability of any"}, {"timestamp": [385.28, 389.72], "text": " AI that we've come up with. And what I have found in my own experiments and the"}, {"timestamp": [389.72, 393.8], "text": " products that I'm working on is that what we can do is if we if we build"}, {"timestamp": [393.8, 397.72], "text": " tools that form a partnership with humans, what we can do is we can get more"}, {"timestamp": [397.72, 401.76], "text": " done with less human cognitive labor by offloading some of that"}, {"timestamp": [401.76, 405.04], "text": " cognition to the machines. So the, the,"}, {"timestamp": [405.04, 408.52], "text": " the securest thing for the next five to 10 years is going to be either learning"}, {"timestamp": [408.52, 412.92], "text": " to build and deploy these tools or learn to use them. Um,"}, {"timestamp": [412.96, 415.36], "text": " now that being said, there, as I just mentioned,"}, {"timestamp": [415.56, 419.76], "text": " there's also plenty of trades that, uh, focus on, you know, that human touch,"}, {"timestamp": [419.76, 423.52], "text": " whether it's communication or anything that requires warmth or,"}, {"timestamp": [423.52, 427.04], "text": " or that sort of stuff. So those are, those are the kind of the directions that I would"}, {"timestamp": [427.04, 432.38], "text": " advocate for for your typical, you know, 20 something to go in."}, {"timestamp": [433.72, 435.92], "text": " I would say that's probably a much better response"}, {"timestamp": [435.92, 437.78], "text": " than I would receive from chat GPT, too."}, {"timestamp": [437.78, 440.06], "text": " So there's still hope for us, I think."}, {"timestamp": [440.06, 444.1], "text": " OK, but going through going through your video yesterday"}, {"timestamp": [444.1, 446.32], "text": " in particular on the robot tax that you proposed,"}, {"timestamp": [446.88, 453.6], "text": " I got the sense that it's very like, you know, this is coming, whether we like it or not. AI is"}, {"timestamp": [453.6, 458.56], "text": " coming, jobs are going to be replaced at a level that we've never seen. And at the same time,"}, {"timestamp": [459.68, 466.6], "text": " some companies are going to win and experience profits like we've never seen before in human"}, {"timestamp": [466.6, 468.36], "text": " history."}, {"timestamp": [468.36, 475.72], "text": " And we can either redistribute that wealth in some way or riot in the streets because"}, {"timestamp": [475.72, 478.2], "text": " all of us are hungry, essentially."}, {"timestamp": [478.2, 485.64], "text": " And the fundamental point that you kept hammering home in that video was that decoupling economic growth from"}, {"timestamp": [485.64, 491.96], "text": " human labor is 100% necessary. We need to do that. Why is that so"}, {"timestamp": [491.96, 497.88], "text": " important? Yeah, so if you zoom out, I often find that it's helpful to look at"}, {"timestamp": [497.88, 501.44], "text": " these things from a historical perspective. Throughout most of history,"}, {"timestamp": [501.44, 506.32], "text": " all of everything that we built, everything that we made,"}, {"timestamp": [506.32, 512.4], "text": " was dependent on human labor to do. So, you know, you look back in ancient Greece, ancient Rome,"}, {"timestamp": [512.4, 516.48], "text": " you know, if you were a tradesman or a craftsman, you made things with your hands,"}, {"timestamp": [516.48, 522.16], "text": " right? And even before that, farming, we had to do by hand. Then we got new sources of energy"}, {"timestamp": [522.16, 526.8], "text": " with beasts of burden, ox, cows, elephants if you're in Asia."}, {"timestamp": [527.52, 533.84], "text": " And every time we learn to use a new source of energy, we get a little bit better at, you know,"}, {"timestamp": [535.12, 538.72], "text": " deploying or producing goods and services, basically."}, {"timestamp": [540.88, 545.6], "text": " And I apologize, I kind of lost the lost the plot you're asking about"}, {"timestamp": [547.16, 552.3], "text": " Decoupling that's right decoupling. I apologize. Apparently I need a little bit more coffee"}, {"timestamp": [553.48, 555.68], "text": " so what happened in the past was"}, {"timestamp": [556.68, 563.6], "text": " You know, we it was animal labor whether it was, you know, human muscles animal muscles and then with the Industrial Revolution"}, {"timestamp": [564.24, 565.4], "text": " we were able to"}, {"timestamp": [565.4, 571.44], "text": " decouple our expression of energy from human and animals with the"}, {"timestamp": [571.44, 575.24], "text": " invention of the steam engine, with the invention of the internal combustion"}, {"timestamp": [575.24, 579.48], "text": " engine, the use of petroleum, and so suddenly we had so much more energy and"}, {"timestamp": [579.48, 587.44], "text": " that is actually why we saw not parabolic but exponential growth of the human population"}, {"timestamp": [587.44, 591.64], "text": " in the 20th century is because suddenly the Industrial Revolution allowed us to produce"}, {"timestamp": [591.64, 594.42], "text": " exponentially more food."}, {"timestamp": [594.42, 600.68], "text": " And so now what we can do is we can decouple, well let me take a pause for a second."}, {"timestamp": [600.68, 605.0], "text": " So decoupling energy expenditure from human capacity,"}, {"timestamp": [605.64, 607.64], "text": " that removed one constraint, right?"}, {"timestamp": [607.64, 609.92], "text": " And so now we can move another constraint,"}, {"timestamp": [609.92, 613.96], "text": " another human limitation, which is human cognitive labor."}, {"timestamp": [613.96, 615.5], "text": " So for knowledge workers,"}, {"timestamp": [615.5, 617.88], "text": " for people that use their brains to do their job,"}, {"timestamp": [617.88, 621.16], "text": " we only have about one to four hours of cognitive labor,"}, {"timestamp": [621.16, 624.12], "text": " of real cognitive labor that we can do per day."}, {"timestamp": [624.12, 625.6], "text": " That's like solving problems,"}, {"timestamp": [625.6, 631.28], "text": " doing difficult tasks, because our brains are just not calibrated to think hard all day, every day."}, {"timestamp": [631.28, 636.48], "text": " Our bodies are meant to move all day, every day. That's how we evolved. But really, we evolved in"}, {"timestamp": [636.48, 640.96], "text": " a situation where it's like, okay, you might have one big problem that you address per day, right?"}, {"timestamp": [640.96, 646.78], "text": " You know, if your tribe lives on the banks of it lives on the on the banks of a river, and all of your nets"}, {"timestamp": [646.78, 649.0], "text": " get tangled up, and it's like, Oh, crap, now we got to make"}, {"timestamp": [649.0, 651.04], "text": " some new nets, right? That's the hard problem that you're going"}, {"timestamp": [651.04, 655.04], "text": " to face that week. And since we evolved in that situation, we"}, {"timestamp": [655.04, 660.28], "text": " cannot physically apply our brains for eight hours a day,"}, {"timestamp": [660.28, 663.72], "text": " 16 hours a day, except for an extreme cases, and then we can"}, {"timestamp": [663.72, 667.7], "text": " only do it for like, you know, a day or two and then we're burned out."}, {"timestamp": [667.7, 672.64], "text": " And so by usually with lots of coffee and or some right, you know, coffee and swearing"}, {"timestamp": [672.64, 674.2], "text": " and everything else."}, {"timestamp": [674.2, 680.0], "text": " And also, also plenty of studies show that the longer you focus, the worse your work"}, {"timestamp": [680.0, 681.0], "text": " gets."}, {"timestamp": [681.0, 682.0], "text": " Right."}, {"timestamp": [682.0, 686.96], "text": " Because it takes so much executive functioning to measure the quality of your work"}, {"timestamp": [686.96, 691.52], "text": " and to keep yourself on track. And eventually, you just kind of go based on heuristics and"}, {"timestamp": [691.52, 698.64], "text": " intuition and you say, screw it, let's just do the best that we can. Now, as we build machines,"}, {"timestamp": [698.64, 704.16], "text": " not if, we are building machines that can replace some cognitive labor, that separates out,"}, {"timestamp": [704.16, 705.96], "text": " we've already separated out energy, right?"}, {"timestamp": [706.16, 708.08], "text": " We've decoupled energy from productivity."}, {"timestamp": [708.28, 713.12], "text": " Now we can decouple cognition from productivity, and that's going to have"}, {"timestamp": [713.32, 718.96], "text": " another exponential explosion to producing goods and services."}, {"timestamp": [719.16, 720.16], "text": " Right, right."}, {"timestamp": [720.36, 724.8], "text": " And so the idea is that what happens at that point?"}, {"timestamp": [729.28, 730.04], "text": " I mean, this, I guess, gets to your point in the video where, you know, we don't need to"}, {"timestamp": [732.68, 733.38], "text": " expend energy anymore. I mean, we haven't had to"}, {"timestamp": [735.38, 735.6], "text": " in a lot for a long time"}, {"timestamp": [737.6, 737.64], "text": " in some sense and"}, {"timestamp": [752.56, 756.04], "text": " we don't need to think anymore because the machines are thinking for us really. I know I'm being overly simplistic and ridiculous here, but what happens at that point? Let's say that we do redistribute this wealth and we don't have to worry about making ends meet anymore. How do"}, {"timestamp": [756.04, 759.44], "text": " you think humans deal with that? I want to read you a quote in a second here, but"}, {"timestamp": [759.44, 766.52], "text": " just your... how do humans deal with that reality that we've really never had before well, so"}, {"timestamp": [766.52, 772.88], "text": " The this this is this is another misnomer or I don't say disinformation, but it's um"}, {"timestamp": [773.52, 781.16], "text": " It's it's a gap in in people's experience because throughout history. We have always had the existence of a leisure class"}, {"timestamp": [781.6, 783.76], "text": " so in ancient Greece"}, {"timestamp": [787.44, 792.08], "text": " of a leisure class. So in ancient Greece, you know, if you were a Spartan citizen, you didn't work. In fact, Spartans were not allowed to have an occupation. If you were a Spartan citizen,"}, {"timestamp": [794.0, 799.76], "text": " it was illegal for you to be a leather worker or anything other than, like if you're a man,"}, {"timestamp": [799.76, 804.4], "text": " a soldier, a hunter, and a politician. Those were the three occupations you were allowed to have."}, {"timestamp": [804.4, 808.88], "text": " If you were a Spartan woman, you were allowed to basically be, you know, a mother and a wife."}, {"timestamp": [809.52, 813.44], "text": " And of course, there's other aspects of Spartan culture that's very distinct from our own."}, {"timestamp": [814.08, 819.92], "text": " But what they would do is they'd spend all day exercising, debating, hunting, you know,"}, {"timestamp": [819.92, 826.4], "text": " running the nation. And most Greek city-states had a leisure class. Athens, all of them had"}, {"timestamp": [826.4, 832.48], "text": " something like that. Ditto for Rome. Ancient Rome, if you were in the upper crust, you"}, {"timestamp": [832.48, 839.28], "text": " were a politician, you were a thinker, you were a writer. All societies that grow really"}, {"timestamp": [839.28, 847.22], "text": " great like that, and this includes in the East as well. The Mughal Empire in India also had a huge leisure class for many many"}, {"timestamp": [847.3, 851.82], "text": " like centuries. I don't know if the Mughal Empire lasted centuries, but across India"}, {"timestamp": [852.04, 857.6], "text": " the various empires had huge leisure classes and there were immense patrons of the arts, you know."}, {"timestamp": [858.16, 859.76], "text": " Most of the..."}, {"timestamp": [859.76, 867.2], "text": " India produced, you know, many many thousands of Vedantas through philosophical debate, lots of poetry,"}, {"timestamp": [867.2, 868.2], "text": " lots of art."}, {"timestamp": [868.2, 876.96], "text": " So even when you have a group of people effectively living with abundance, they always find something"}, {"timestamp": [876.96, 878.52], "text": " to do."}, {"timestamp": [878.52, 888.1], "text": " And we are so based, we Americans in the West, we base our identity on labor and on work, but when you look across"}, {"timestamp": [888.1, 892.0], "text": " history it's not necessary for people to have their identity."}, {"timestamp": [892.0, 900.16], "text": " So what I'm hoping to see is as we move towards this global leisure class, well first, one,"}, {"timestamp": [900.16, 905.12], "text": " I hope we do move towards a global leisure class where, you know, the fully automated"}, {"timestamp": [910.48, 912.16], "text": " luxury space communism model, right? That's kind of the meme version. But if we move towards that\u2026 Right. All of this\u2026 Let me just start in\u2026"}, {"timestamp": [912.16, 912.64], "text": " Yeah, go ahead."}, {"timestamp": [912.64, 917.52], "text": " All of this depends on us first figuring out the redistribution component of this, which"}, {"timestamp": [917.52, 921.44], "text": " is in itself just a whole can of worms that we haven't gotten into yet."}, {"timestamp": [921.44, 931.6], "text": " But let's say that we figure that out. Yep. Yeah. So all this is predicated on the idea that we make a choice as a culture, as a species,"}, {"timestamp": [931.6, 939.04], "text": " as a planet, to say, hey, maybe we actually can redistribute and we can allow people to move"}, {"timestamp": [939.04, 947.0], "text": " towards this leisure class. If we do that, then we're going to have a very different society"}, {"timestamp": [947.0, 954.0], "text": " in some respects. We're already kind of addicted to entertainment and distractions and stuff."}, {"timestamp": [954.0, 961.0], "text": " But, at the same time, people love challenges. So there's a framework in psychology. I can't"}, {"timestamp": [961.0, 965.46], "text": " remember who created it, but it's called self-determination theory."}, {"timestamp": [965.46, 970.58], "text": " And in self-determination theory, there are three pillars of psychological needs."}, {"timestamp": [970.58, 974.66], "text": " So you might be familiar with Maslow's hierarchy of needs, which forms it as a stack."}, {"timestamp": [974.66, 979.48], "text": " But in self-determination theory, there are three primary pillars of like mental health"}, {"timestamp": [979.48, 981.56], "text": " or psychological well-being."}, {"timestamp": [981.56, 983.0], "text": " One is autonomy."}, {"timestamp": [983.0, 985.88], "text": " So one thing that is universal across all humanity is"}, {"timestamp": [985.88, 990.4], "text": " that we all desire to be more autonomous. And in Western society having money"}, {"timestamp": [990.4, 996.6], "text": " makes you more autonomous. Money gives you choices so on and so forth. Now if we"}, {"timestamp": [996.6, 1001.68], "text": " decouple our way of life from our need to make money that makes us more"}, {"timestamp": [1001.68, 1005.44], "text": " autonomous so this is a very attractive way to go. The second pillar of"}, {"timestamp": [1005.44, 1012.8], "text": " that is competence or mastery. And this is what I have, you know, I retired from my day job to"}, {"timestamp": [1012.8, 1019.52], "text": " focus on AI and my startup, and people love challenges. So I was talking with an educator."}, {"timestamp": [1020.32, 1026.4], "text": " He was a retired middle school teacher who taught computer science and game design."}, {"timestamp": [1026.4, 1030.92], "text": " And what he pointed out to me, and he's not the only educator to notice this, but what"}, {"timestamp": [1030.92, 1035.32], "text": " he pointed out to me is that kids already challenge themselves."}, {"timestamp": [1035.32, 1041.44], "text": " They will play games, you know, like my nephew plays Roblox and Minecraft and all that stuff"}, {"timestamp": [1041.44, 1044.68], "text": " and he'll find all kinds of challenges for himself."}, {"timestamp": [1044.68, 1048.92], "text": " He'll learn all these complex, you know, build trees and stuff."}, {"timestamp": [1048.92, 1053.6], "text": " And all these behaviors that children put into video games, and adults for that matter,"}, {"timestamp": [1053.6, 1059.08], "text": " are the kinds of self, are the kinds of challenges that people, you know, that educators want"}, {"timestamp": [1059.08, 1061.0], "text": " children to put into education."}, {"timestamp": [1061.0, 1069.66], "text": " It's also the same kind of challenges that go into our occupations. We as a species, we are calibrated to be, to crave a certain"}, {"timestamp": [1069.66, 1074.14], "text": " level of challenge. If you put a whole bunch of people, you know, out in a field"}, {"timestamp": [1074.14, 1078.38], "text": " together and just like give them a box of like sports equipment, guess what?"}, {"timestamp": [1078.38, 1082.14], "text": " Within a few minutes they're gonna like explore the sports equipment and come up"}, {"timestamp": [1082.14, 1088.0], "text": " with new games. You, I mean, you, anyone who has children or has nephews or has been with children,"}, {"timestamp": [1088.0, 1092.0], "text": " like spontaneous play is very much part of our natural state."}, {"timestamp": [1092.0, 1097.0], "text": " And part of play is to, you know, there's the body intelligence part,"}, {"timestamp": [1097.0, 1100.0], "text": " but there's also the skills, the competence and the mastery."}, {"timestamp": [1100.0, 1104.0], "text": " And I apologize, I can't actually remember the third pillar of self-determination theory."}, {"timestamp": [1104.0, 1111.84], "text": " But anyways, point being is that we have these intrinsic motivations that if we do decouple,"}, {"timestamp": [1111.84, 1117.0], "text": " you know, labor from life, we're going to have plenty of impulses to engage in, whether"}, {"timestamp": [1117.0, 1121.68], "text": " it's more play, whether it's finding new challenges for ourself, or we might even become"}, {"timestamp": [1121.68, 1151.36], "text": " more like these ancient societies, engage in more art, more debate, more literature, that we will, even if machines can do this stuff better than us, or a lot of"}, {"timestamp": [1151.36, 1157.12], "text": " stuff better than us, we will just find ways to entertain ourselves to come up with new challenges."}, {"timestamp": [1157.12, 1163.6], "text": " Is that right? Oh yeah. Think about chess. It's been a decade or two since any human could beat"}, {"timestamp": [1163.6, 1167.16], "text": " the best chess computer. But we still play chess, right?"}, {"timestamp": [1167.16, 1172.0], "text": " We still play chess competitively. We just don't let the machines in, right? There is something intrinsically human about"}, {"timestamp": [1172.52, 1176.32], "text": " games in specific, but also that challenge. Like, you know,"}, {"timestamp": [1176.32, 1182.84], "text": " I have some friends who are, who are or were competitive chess players, and they still care about their ELO score."}, {"timestamp": [1182.84, 1187.04], "text": " So ELO is the ranking system that is used for competitive chess for any of your audience"}, {"timestamp": [1187.04, 1188.04], "text": " that aren't familiar."}, {"timestamp": [1188.04, 1191.54], "text": " They still care about that, even though they know that like, you know, the best machine"}, {"timestamp": [1191.54, 1196.76], "text": " out there could get an Elo of 2800 and they're never going to get above 2200, but that doesn't"}, {"timestamp": [1196.76, 1197.76], "text": " matter."}, {"timestamp": [1197.76, 1198.76], "text": " Yeah."}, {"timestamp": [1198.76, 1204.08], "text": " I often think about this too with like, with sports, you know, um, even once we get to"}, {"timestamp": [1204.08, 1205.64], "text": " a point where robots can like play"}, {"timestamp": [1205.64, 1209.48], "text": " basketball way better than us, let's say, I think people would still love watching"}, {"timestamp": [1209.48, 1214.4], "text": " NBA games and humans compete at that and be interested in competing themselves at"}, {"timestamp": [1214.4, 1219.92], "text": " that. Oh yeah, oh yeah, and even think about cars, something industrial, you"}, {"timestamp": [1219.92, 1224.16], "text": " know, like Ford can crank out, you know, 3,000 Mustangs a day and their"}, {"timestamp": [1224.16, 1225.0], "text": " plants, but I still know people who rebuild, you know,000 Mustangs a day in their plants,"}, {"timestamp": [1225.0, 1227.44], "text": " but I still know people who rebuild"}, {"timestamp": [1227.44, 1229.22], "text": " classic Mustangs by hand."}, {"timestamp": [1229.22, 1232.92], "text": " There's no real benefit to it, but it's a hobby"}, {"timestamp": [1232.92, 1235.8], "text": " and it's something that they get enjoyment out of"}, {"timestamp": [1235.8, 1238.04], "text": " because there's a certain mastery that goes into it"}, {"timestamp": [1238.04, 1240.64], "text": " and there's a certain pride that we derive"}, {"timestamp": [1240.64, 1243.62], "text": " from developing these skills and producing these results."}, {"timestamp": [1243.62, 1246.26], "text": " So really all that's gonna happen, I think,"}, {"timestamp": [1246.26, 1249.34], "text": " what I hope, is that we will see more of this kind of stuff."}, {"timestamp": [1249.34, 1252.14], "text": " More people that take pride in their garden,"}, {"timestamp": [1252.14, 1255.18], "text": " or rebuilding Mustangs, or whatever, right?"}, {"timestamp": [1255.18, 1257.46], "text": " Like there's so much to do out there."}, {"timestamp": [1258.26, 1262.34], "text": " And getting rid of our occupation, if that's what happens,"}, {"timestamp": [1262.34, 1265.2], "text": " like, I don't know, from my perspective where I'm at right now, it seems like a really easy transition. occupation if that's what happens."}, {"timestamp": [1265.2, 1269.12], "text": " From my perspective where I'm at right now, it seems like a really easy transition."}, {"timestamp": [1269.12, 1273.26], "text": " But there's so many people that have never gone through that transition that it might"}, {"timestamp": [1273.26, 1275.36], "text": " feel scary or uncertain."}, {"timestamp": [1275.36, 1279.36], "text": " And certainly there are people, I've known plenty of people that they got to the age"}, {"timestamp": [1279.36, 1283.58], "text": " of retirement and then they didn't know what to do with themselves so they just went back"}, {"timestamp": [1283.58, 1284.58], "text": " to work."}, {"timestamp": [1284.58, 1287.12], "text": " Right? and then they didn't know what to do with themselves, so they just went back to work. Right, but if you work at the same thing"}, {"timestamp": [1287.12, 1290.34], "text": " until you're 50 or 60 or so,"}, {"timestamp": [1290.34, 1291.68], "text": " there's a certain amount of inertia"}, {"timestamp": [1291.68, 1293.76], "text": " and it's like we do what we know."}, {"timestamp": [1293.76, 1298.0], "text": " But you look at, what if subsequent generations,"}, {"timestamp": [1298.0, 1301.84], "text": " young people today, never grow up in an environment"}, {"timestamp": [1301.84, 1303.96], "text": " where they must put their labor"}, {"timestamp": [1303.96, 1305.68], "text": " so that they have a place to stay, so that they"}, {"timestamp": [1305.68, 1311.04], "text": " have food to eat. People are going to be so much more creative. There's a book, I can't remember"}, {"timestamp": [1311.04, 1315.52], "text": " the name of the author, but my fianc\u00e9 told me about it. It's called Cognitive Surplus."}, {"timestamp": [1316.24, 1322.56], "text": " And one of the things that this book talks about is that as people gain a greater measure of"}, {"timestamp": [1322.56, 1326.72], "text": " physical security, so like food security, housing security,"}, {"timestamp": [1326.72, 1331.64], "text": " our brains, like that gives us more free time to solve harder problems."}, {"timestamp": [1331.64, 1333.44], "text": " And we all give back in some ways, right?"}, {"timestamp": [1333.44, 1337.56], "text": " Like some people get on the internet to debate social justice, and some people think that"}, {"timestamp": [1337.56, 1342.32], "text": " that's a worthless thing, but I will tell you, having watched the internet for the last"}, {"timestamp": [1342.32, 1349.72], "text": " 20 years, there are ideas that get hashed out through internet debate that ends up in academic literature, right?"}, {"timestamp": [1349.86, 1355.42], "text": " So even, even if people just idly, you know, argue on Twitter, sometimes that"}, {"timestamp": [1355.42, 1356.6], "text": " produces really good ideas."}, {"timestamp": [1356.6, 1361.58], "text": " And then some people do a higher order, let's say research, like in their free"}, {"timestamp": [1361.58, 1369.2], "text": " time, as I did, because most of the AI research I did, I still had a full-time job, but I had enough cognitive surplus that I was like, okay,"}, {"timestamp": [1369.2, 1374.4], "text": " I can do this other thing too. Not everyone's going to have AI as their primary hobby, but"}, {"timestamp": [1375.12, 1381.92], "text": " everyone's got to have a hobby, right? Right. Okay. I want to challenge, well,"}, {"timestamp": [1381.92, 1389.52], "text": " here's another prompt for you. We'll get to second but have you have you read notes from the underground by Dostoevsky? I have not"}, {"timestamp": [1390.24, 1394.46], "text": " Okay, so I want to read you an excerpt from that book. Have you read any Dostoevsky at all?"}, {"timestamp": [1394.84, 1399.76], "text": " No, I but I only know just a little bit about him very cynical watch some of your videos"}, {"timestamp": [1399.76, 1400.64], "text": " Yes, yes"}, {"timestamp": [1400.64, 1403.72], "text": " I was I was watching some of your your videos where"}, {"timestamp": [1404.24, 1405.52], "text": " You were talking about some of the things"}, {"timestamp": [1405.52, 1406.52], "text": " that we're talking about now."}, {"timestamp": [1406.52, 1408.2], "text": " You should definitely dive into them."}, {"timestamp": [1408.2, 1409.2], "text": " I think you'd love them."}, {"timestamp": [1409.2, 1410.2], "text": " All right."}, {"timestamp": [1410.2, 1414.18], "text": " So I want to read you this one excerpt from Notes from the Underground, and I should frame"}, {"timestamp": [1414.18, 1420.64], "text": " this by saying that the protagonist in this book and the guy who's speaking here is this"}, {"timestamp": [1420.64, 1426.08], "text": " bitter old man who is the most bitter, depressing person you've ever seen in your"}, {"timestamp": [1426.08, 1430.28], "text": " life who's, for the first half of the book, just going on these like crazy philosophical"}, {"timestamp": [1430.28, 1435.6], "text": " rants. Okay, so this is part of his bitter rant. And the prompt, while you're listening"}, {"timestamp": [1435.6, 1440.68], "text": " to this, just for you to prepare, I want you to imagine that you're on stage in a debate"}, {"timestamp": [1440.68, 1446.12], "text": " against this bitter old man from Notes from the Underground. And he had, well,"}, {"timestamp": [1446.12, 1449.28], "text": " I'll read you the quote first, then we'll come back to the prompt at the end to finish"}, {"timestamp": [1449.28, 1455.82], "text": " it. But here's a quote. What can be expected of man since he is a being endowed with strange"}, {"timestamp": [1455.82, 1462.38], "text": " qualities, shower upon him every earthly blessing, drown him in a sea of happiness so that nothing"}, {"timestamp": [1462.38, 1465.6], "text": " but bubbles of bliss can be seen on the surface."}, {"timestamp": [1470.16, 1475.84], "text": " Give him economic prosperity, such that he should have nothing else to do but sleep, eat cakes, and busy himself with the continuation of his species. And even then, out of sheer"}, {"timestamp": [1475.84, 1481.84], "text": " ingratitude, sheer spite, man would play you some nasty trick. He would even risk his cakes,"}, {"timestamp": [1481.84, 1487.0], "text": " and would deliberately desire the most fatal rubbish, the most uneconomical absurdity,"}, {"timestamp": [1487.0, 1492.0], "text": " simply to introduce into all this positive good sense his fatal, fantastic element."}, {"timestamp": [1492.0, 1497.0], "text": " It is just his fantastic dreams, his vulgar folly, that he will desire to retain,"}, {"timestamp": [1497.0, 1501.0], "text": " simply in order to prove to himself, as though that were so necessary,"}, {"timestamp": [1501.0, 1505.6], "text": " that men are still men and not the keys of a piano, which"}, {"timestamp": [1505.6, 1510.04], "text": " the laws of nature threaten to control so completely that soon one will be able to desire"}, {"timestamp": [1510.04, 1512.32], "text": " nothing but by the calendar."}, {"timestamp": [1512.32, 1513.56], "text": " And that is not all."}, {"timestamp": [1513.56, 1518.24], "text": " Even if man really were nothing but a piano key, even if this were proved to him by natural"}, {"timestamp": [1518.24, 1523.28], "text": " science and mathematics, even then he would not become reasonable, but would purposely"}, {"timestamp": [1523.28, 1528.0], "text": " do something perverse out of simple ingratitude, simply to gain his point."}, {"timestamp": [1528.0, 1538.0], "text": " And if he does not find means, he will contrive destruction and chaos, will contrive sufferings of all sorts, only to gain his point."}, {"timestamp": [1538.0, 1545.84], "text": " So, again, imagine you're on stage, debating this bitter old man. I was reminded of this excerpt when I was watching"}, {"timestamp": [1545.84, 1552.64], "text": " your video yesterday, when you were talking about and making your points for why humans will be"}, {"timestamp": [1552.64, 1558.4], "text": " able to thrive in an environment where AI can do a lot of the stuff that we had previously done."}, {"timestamp": [1559.52, 1566.24], "text": " Why is this man wrong? I think what he's arguing, at least to me, is a part of it is"}, {"timestamp": [1567.6, 1574.0], "text": " that even in the best case scenario, even when we imagine the most bullish case for AI, where we"}, {"timestamp": [1574.0, 1579.68], "text": " have all of this time, that there's something about humans where we would still burn it all"}, {"timestamp": [1579.68, 1586.38], "text": " to hell out of ingratitude, out of whatever, just because we're human. Right. Well, I would"}, {"timestamp": [1586.38, 1590.94], "text": " say that one, nihilism started in Russia, and when you look at what Russia is"}, {"timestamp": [1590.94, 1596.34], "text": " doing today, nothing has changed in the last two centuries. And if you look at"}, {"timestamp": [1596.34, 1606.56], "text": " the history of Russia, basically that is a product of an environment. Everything that you just read, every cynical, you know,"}, {"timestamp": [1609.08, 1610.96], "text": " nihilistic Russian"}, {"timestamp": [1610.96, 1615.84], "text": " that has, you know, ever put pen to paper, is more or less a product of"}, {"timestamp": [1617.4, 1620.7], "text": " intergenerational trauma, just to put it as bluntly as possible,"}, {"timestamp": [1622.04, 1628.16], "text": " between repeated civil wars, famines, invasions, political upheaval,"}, {"timestamp": [1630.48, 1637.52], "text": " everything that has happened, what you're seeing is someone who is unable to escape"}, {"timestamp": [1638.72, 1643.92], "text": " what you could think of as a nihilistic fishbowl. He can't get out of that worldview because"}, {"timestamp": [1645.84, 1652.12], "text": " nihilistic fishbowl. He can't get out of that worldview because not only did he grow up with it, but he was surrounded by it. And so what I would say is that is"}, {"timestamp": [1652.12, 1656.68], "text": " that I'm not saying that he's wrong because within the context of his life"}, {"timestamp": [1656.68, 1662.32], "text": " and his experience he's absolutely right. That being said, there are other fishbowls."}, {"timestamp": [1662.32, 1667.2], "text": " There are other ways of being, other ways of learning and growing."}, {"timestamp": [1667.2, 1673.6], "text": " And something that is becoming more popular is the idea of healing."}, {"timestamp": [1674.88, 1680.16], "text": " You know, whether it's through, you know, the resurgence of psychedelic therapy,"}, {"timestamp": [1680.96, 1685.28], "text": " changing the way that we orient towards each other, so on and so forth."}, {"timestamp": [1685.28, 1692.2], "text": " But the short version is traumatic environments create broken people."}, {"timestamp": [1692.2, 1696.6], "text": " And that's not to forgive anywhere else in the world."}, {"timestamp": [1696.6, 1702.84], "text": " America certainly has our own aspects of our society that are broken and have been broken."}, {"timestamp": [1702.84, 1705.48], "text": " Ditto for the East, ditto for everywhere, right?"}, {"timestamp": [1705.48, 1708.32], "text": " You know, pick your poison."}, {"timestamp": [1708.32, 1711.48], "text": " It's just that when you look at some regions,"}, {"timestamp": [1711.48, 1714.04], "text": " you can say, comparatively speaking,"}, {"timestamp": [1714.04, 1719.04], "text": " some nations, some regions seem to have a lot more trauma."}, {"timestamp": [1719.12, 1721.44], "text": " I remember a few years ago,"}, {"timestamp": [1721.44, 1724.72], "text": " I had joined a spiritual healing group"}, {"timestamp": [1724.72, 1727.28], "text": " and I became friends with a Russian woman"}, {"timestamp": [1727.96, 1731.34], "text": " And we were we were walking through a park one day, you know"}, {"timestamp": [1731.34, 1736.4], "text": " her her friend and her son were there and we were talking about spiritual healing and"}, {"timestamp": [1737.08, 1742.38], "text": " I mentioned that you know PTSD is really big in Russia and she's like, oh we don't have any PTSD in Russia"}, {"timestamp": [1742.38, 1744.38], "text": " and I was like"}, {"timestamp": [1745.52, 1748.0], "text": " in Russia?\" and she's like, oh, we don't have any PTSD in Russia. And I was like,"}, {"timestamp": [1753.44, 1759.52], "text": " how did you come to that conclusion? And it's because they're in such deep denial about the pain that they are in that they can't even recognize it. And so there's an idiom that I"}, {"timestamp": [1759.52, 1767.04], "text": " like, which is you may as well ask the fish if the water is wet. When you grow up and you live with nothing but the abandonment and trauma,"}, {"timestamp": [1767.68, 1771.76], "text": " that's all you know, and you can't even conceptualize of another way of being."}, {"timestamp": [1772.8, 1774.32], "text": " You know, and I pointed out to her, I was like,"}, {"timestamp": [1774.96, 1778.32], "text": " how many men do you know that have died of alcoholism in Russia?"}, {"timestamp": [1778.32, 1779.52], "text": " And she just kind of clammed up."}, {"timestamp": [1779.52, 1783.52], "text": " It's something like 30% of men in Russia are alcoholics,"}, {"timestamp": [1783.52, 1786.64], "text": " and more than 10% die of alcoholism or suicide,"}, {"timestamp": [1786.64, 1793.12], "text": " like it's incredible just how traumatized that entire society is. And again, that's not to"}, {"timestamp": [1793.12, 1798.0], "text": " forgive anywhere else because when you look at, you know, in America, like, what was it,"}, {"timestamp": [1798.0, 1802.56], "text": " depending on the statistics you look at, but like 70% of American adults have mental illness."}, {"timestamp": [1802.56, 1805.8], "text": " Like we're not in much better shape."}, {"timestamp": [1805.8, 1808.76], "text": " And it all comes down to intergenerational trauma"}, {"timestamp": [1808.76, 1809.68], "text": " and abandonment."}, {"timestamp": [1809.68, 1813.8], "text": " And so what you're seeing in that quotation that you shared"}, {"timestamp": [1813.8, 1817.0], "text": " is someone reflecting on that and being aware of it"}, {"timestamp": [1817.0, 1818.5], "text": " and unable to escape from it."}, {"timestamp": [1818.5, 1820.48], "text": " That's my interpretation."}, {"timestamp": [1820.48, 1823.16], "text": " Yeah, yeah, nicely said."}, {"timestamp": [1823.16, 1827.5], "text": " Your story of meeting that Russian woman reminded me of an experience"}, {"timestamp": [1827.5, 1832.62], "text": " I had in Korea. So I lived in Korea for two years, and I taught English over there. And"}, {"timestamp": [1832.62, 1837.86], "text": " there was a time where I went to the doctor there, and in my broken Korean, I forget exactly"}, {"timestamp": [1837.86, 1842.52], "text": " why I was going, but he was asking me if there was like anything else I was dealing with."}, {"timestamp": [1842.52, 1848.96], "text": " And I remember trying to explain to him that I just had like kind of this like generalized anxiety and his"}, {"timestamp": [1848.96, 1852.64], "text": " response to that was like, well like do you have like a test coming up or"}, {"timestamp": [1852.64, 1856.44], "text": " something? Like what are you what are you anxious about? And we couldn't get past"}, {"timestamp": [1856.44, 1860.08], "text": " the fact that I was like I didn't know why I was anxious I just kind of like"}, {"timestamp": [1860.08, 1865.16], "text": " felt this anxiety and he's like no but you must have, like, some reason for it."}, {"timestamp": [1865.16, 1868.96], "text": " And it was this weird, uh, this, this moment I'll never forget."}, {"timestamp": [1868.96, 1875.76], "text": " Um, why, yeah, why, why I think you'd love Dostoevsky too, is he explores this nihilistic"}, {"timestamp": [1875.76, 1881.0], "text": " tendency, just nihilism in general, I guess, in, in such depth."}, {"timestamp": [1881.0, 1885.68], "text": " I mean, as you can see from that passage there, but ultimately he is a"}, {"timestamp": [1885.68, 1890.36], "text": " person, I think, like, he gives the strongest argument he can for nihilism, but he comes"}, {"timestamp": [1890.36, 1891.64], "text": " up on the other side."}, {"timestamp": [1891.64, 1897.28], "text": " His idea, his solution to the problem is God."}, {"timestamp": [1897.28, 1900.08], "text": " This is a whole can of worms that, you know, there's so many things I want to talk to you"}, {"timestamp": [1900.08, 1910.32], "text": " about and I'm, I fear that I might be opening or going down another rabbit hole but I heard you talk in a video that you know people like Jordan"}, {"timestamp": [1910.32, 1914.28], "text": " Peterson for example Dostoevsky too I mean Jordan Peterson is a big fan of"}, {"timestamp": [1914.28, 1918.48], "text": " Dostoevsky but they are their heart is in the right place in terms of"}, {"timestamp": [1918.48, 1928.16], "text": " combating this nihilism with the idea of you know going back to more traditional routes and this idea of God, let's say."}, {"timestamp": [1928.16, 1932.52], "text": " You, I think, disagree with that."}, {"timestamp": [1932.52, 1936.58], "text": " What would you say your solution, if you had to sum it up, I know this is an impossibly"}, {"timestamp": [1936.58, 1940.08], "text": " hard question, but your solution to the problem of nihilism?"}, {"timestamp": [1940.08, 1948.82], "text": " So, in my work with nihilism, I discovered that there are, or rather I categorized the"}, {"timestamp": [1948.82, 1953.04], "text": " problems into four categories, and I call it the four abandonments."}, {"timestamp": [1953.04, 1959.28], "text": " So the first abandonment is childhood abandonment, which is in the form of trauma, neglect, and"}, {"timestamp": [1959.28, 1962.02], "text": " abuse that goes untreated in children."}, {"timestamp": [1962.02, 1968.56], "text": " That ranges from mild emotional neglect to children exposed to domestic"}, {"timestamp": [1968.56, 1974.2], "text": " violence or even just shouting is enough to traumatize a child, especially if their emotions"}, {"timestamp": [1974.2, 1987.4], "text": " are not addressed. I have friends from all over the world, Lebanon, Iran know, experienced civil strife, you know, hiding in bunkers during air"}, {"timestamp": [1987.4, 1994.32], "text": " raids, and, you know, even a well-meaning and loving parent that is"}, {"timestamp": [1994.32, 1998.44], "text": " not able to address that trauma is still a form of abandonment. And it's"}, {"timestamp": [1998.44, 2001.5], "text": " no one's fault. So I don't want to say abandonment like, oh, you just left a"}, {"timestamp": [2001.5, 2006.5], "text": " child alone. You can still have very well-meaning parents and families that just don't know what to do."}, {"timestamp": [2006.5, 2008.2], "text": " They don't know how to process it."}, {"timestamp": [2008.2, 2009.32], "text": " So that's the first abandonment."}, {"timestamp": [2009.32, 2013.98], "text": " The second abandonment is social abandonment, which is an extension of childhood abandonment,"}, {"timestamp": [2013.98, 2020.0], "text": " and that is the rugged individualism that we see in both in Western and Eastern societies"}, {"timestamp": [2020.0, 2021.96], "text": " today to be honest."}, {"timestamp": [2021.96, 2025.44], "text": " And so rugged individualism is that, you know, like, I'm a sovereign citizen,"}, {"timestamp": [2025.44, 2029.44], "text": " I'm going to take care of myself, I don't need any help, like, you know, get off my lawn."}, {"timestamp": [2030.32, 2034.72], "text": " And where we don't trust each other and we don't help each other. And this is reflected in"}, {"timestamp": [2035.28, 2038.4], "text": " everything from the way that we live, we don't talk to our neighbors anymore,"}, {"timestamp": [2039.28, 2044.32], "text": " we don't have communities anymore. And it's also reflected all the way up into our law"}, {"timestamp": [2042.24, 2045.36], "text": " have communities anymore. And it's also reflected all the way up into our law"}, {"timestamp": [2045.36, 2048.16], "text": " and the way that we live."}, {"timestamp": [2048.16, 2050.72], "text": " Some of our economic policies are intrinsically"}, {"timestamp": [2050.72, 2053.6], "text": " just make the assumption that we should all just kind of live"}, {"timestamp": [2053.6, 2057.04], "text": " in our own little houses and kind of not talk to each other."}, {"timestamp": [2057.04, 2058.4], "text": " So that's the second abandonment."}, {"timestamp": [2058.4, 2061.04], "text": " And then the third abandonment is cosmic abandonment."}, {"timestamp": [2061.04, 2064.72], "text": " So this is what Jordan Peterson and Eugene Rose and Dostoyevsky"}, {"timestamp": [2064.72, 2069.6], "text": " all talk about, which is with the rise of secularism, with the rise of nihilism and"}, {"timestamp": [2069.6, 2075.52], "text": " and kind of the the diminishment of the centrality of religion, we haven't"}, {"timestamp": [2075.52, 2080.12], "text": " replaced it with anything. And not only that, we build bigger and bigger"}, {"timestamp": [2080.12, 2083.28], "text": " telescopes and we look further and further out into the universe and we see"}, {"timestamp": [2083.28, 2089.58], "text": " that we are entirely alone. Who was it, was it Arthur C. Clarke said that two"}, {"timestamp": [2089.58, 2093.46], "text": " possibilities exist, either we are alone in the universe or we are not and both"}, {"timestamp": [2093.46, 2098.36], "text": " are equally terrifying. And like you can't put it any more succinctly than"}, {"timestamp": [2098.36, 2102.74], "text": " that and so we feel alone in the universe and that makes us even wonder"}, {"timestamp": [2102.74, 2105.88], "text": " even more deeply why are we here?"}, {"timestamp": [2105.88, 2111.06], "text": " What's the purpose of it all? Which again, only serves to reinforce that, like maybe"}, {"timestamp": [2111.06, 2117.44], "text": " there is no purpose, which is the heart of nihilism. And then finally, under the weight"}, {"timestamp": [2117.44, 2120.92], "text": " of all three of those abandonments, we end up with self-abandonment, which is why you"}, {"timestamp": [2120.92, 2129.32], "text": " see all sorts of toxic echo chambers on the internet and and people people taking it out of the internet and you know, we end up with things like mass shootings"}, {"timestamp": [2129.96, 2133.22], "text": " And and deaths from despair even amongst young people"}, {"timestamp": [2133.68, 2137.72], "text": " I participated in another podcast about six or seven months ago"}, {"timestamp": [2137.72, 2144.02], "text": " And one of the things that I pointed out is that we have 17 18 19 20 year olds"}, {"timestamp": [2148.08, 2152.64], "text": " is that we have 17, 18, 19, 20 year olds that are so lonely and angry that they hurt themselves and they hurt other people when they are, when they really, physically, they're in the"}, {"timestamp": [2152.64, 2154.12], "text": " prime of their life."}, {"timestamp": [2154.12, 2157.08], "text": " They are at the most energetic that they will ever be."}, {"timestamp": [2157.08, 2158.8], "text": " They're at the most resilient that they will ever be."}, {"timestamp": [2158.8, 2163.56], "text": " And instead of living it up, instead of, you know, chasing romantic partners and having"}, {"timestamp": [2163.56, 2167.6], "text": " fun and even, you know, even drinking at parties or whatever,"}, {"timestamp": [2167.6, 2169.42], "text": " instead of having fun and enjoying life,"}, {"timestamp": [2169.42, 2172.66], "text": " they're so angry and so lonely that they lash out."}, {"timestamp": [2172.66, 2175.12], "text": " And there are plenty of people that suffer in silence too."}, {"timestamp": [2175.12, 2178.08], "text": " I'm not saying that, oh, everyone who's suffering"}, {"timestamp": [2178.08, 2181.46], "text": " is at risk of lashing out violently,"}, {"timestamp": [2181.46, 2184.26], "text": " but certainly some people are."}, {"timestamp": [2184.26, 2193.2], "text": " And so by naming it, by naming it this nihilistic crisis that we're in, I'm hoping that I can"}, {"timestamp": [2193.2, 2197.46], "text": " help start changing the conversation around the solution."}, {"timestamp": [2197.46, 2208.8], "text": " So one of the solutions, the primary solution is just to create a more trauma literate society. And what I mean by that is, you know, the books, the YouTubers, you know, the blogs,"}, {"timestamp": [2208.8, 2213.38], "text": " and bringing the conversation about trauma"}, {"timestamp": [2213.38, 2216.0], "text": " and abandonment and neglect into the mainstream,"}, {"timestamp": [2216.0, 2217.68], "text": " which it's happening."}, {"timestamp": [2217.68, 2219.4], "text": " You know, if you look at the number of books"}, {"timestamp": [2219.4, 2221.74], "text": " that have been published over the last 10 years alone,"}, {"timestamp": [2221.74, 2223.32], "text": " it's gone up exponentially."}, {"timestamp": [2224.16, 2228.38], "text": " The information is there, we are becoming a more trauma-literate society, but then we"}, {"timestamp": [2228.38, 2230.26], "text": " still need to put a name on it, right?"}, {"timestamp": [2230.26, 2234.88], "text": " We still need to say, okay, this is the problem and this is the solution, and so the nihilistic"}, {"timestamp": [2234.88, 2239.76], "text": " crisis is the problem, that is the underpinning problem that results in trauma, that results"}, {"timestamp": [2239.76, 2244.04], "text": " in abandonment, and then the solution is that trauma-literate society."}, {"timestamp": [2244.04, 2247.1], "text": " And unfortunately, I think that for some people,"}, {"timestamp": [2247.1, 2248.52], "text": " it's probably too late."}, {"timestamp": [2248.52, 2251.68], "text": " You know, I look at older generations"}, {"timestamp": [2251.68, 2253.76], "text": " that they had to live with trauma and abandonment,"}, {"timestamp": [2253.76, 2258.18], "text": " you know, from World War II, Vietnam, Korea, World War I,"}, {"timestamp": [2258.18, 2259.8], "text": " you know, and for many people,"}, {"timestamp": [2259.8, 2261.82], "text": " they had to live with PTSD their entire life"}, {"timestamp": [2261.82, 2263.52], "text": " and never had answers."}, {"timestamp": [2263.52, 2266.6], "text": " We are fortunate in that we are the first generation"}, {"timestamp": [2266.6, 2269.48], "text": " that really has comprehensive answers."}, {"timestamp": [2269.48, 2272.44], "text": " And so Jordan Peterson did the best that he could"}, {"timestamp": [2272.44, 2274.26], "text": " with the information that he had."}, {"timestamp": [2274.26, 2276.52], "text": " The best answer that he had"}, {"timestamp": [2276.52, 2279.32], "text": " is to return to traditional structures."}, {"timestamp": [2279.32, 2283.56], "text": " Now, that being said, we have better answers today."}, {"timestamp": [2283.56, 2286.64], "text": " And then you combine more information, trauma"}, {"timestamp": [2286.64, 2292.36], "text": " literacy, because you know the the best, what is, how do I say it, an ounce of"}, {"timestamp": [2292.36, 2297.16], "text": " prevention is worth a pound of cure. If we can prevent trauma moving forward or"}, {"timestamp": [2297.16, 2302.76], "text": " treat it more appropriately, in a generation or two we're gonna see a much"}, {"timestamp": [2302.76, 2306.26], "text": " less traumatized society, just wholesale. Now"}, {"timestamp": [2306.26, 2310.72], "text": " that being said, for those that are young enough or flexible enough, there are more"}, {"timestamp": [2310.72, 2314.86], "text": " treatments available today, ranging, you know, on the most extreme end is the"}, {"timestamp": [2314.86, 2318.3], "text": " rise of psychedelic-based therapy. Thinking about that as you were talking."}, {"timestamp": [2318.3, 2323.56], "text": " Yep, so there's somatic experiencing, there's group-based therapies,"}, {"timestamp": [2323.56, 2326.24], "text": " and as our medical establishment becomes more trauma-based therapies, and as our"}, {"timestamp": [2326.24, 2330.16], "text": " medical establishment becomes more trauma-informed, more trauma literate,"}, {"timestamp": [2330.16, 2334.84], "text": " these therapies will be better. My fianc\u00e9e was a librarian. It's fascinating."}, {"timestamp": [2334.84, 2340.72], "text": " Even librarians are now trained to be trauma-informed, because what"}, {"timestamp": [2340.72, 2345.68], "text": " often happens is that more vulnerable people in a city will end up at the library"}, {"timestamp": [2345.68, 2346.64], "text": " because that's the only place"}, {"timestamp": [2346.64, 2348.2], "text": " that they can get free resources."}, {"timestamp": [2348.2, 2353.2], "text": " And in fact, some libraries start to staff social workers."}, {"timestamp": [2353.84, 2355.24], "text": " And of course, social workers are gonna be"}, {"timestamp": [2355.24, 2357.3], "text": " more trauma-informed today too."}, {"timestamp": [2357.3, 2359.28], "text": " So as we become a more trauma-informed"}, {"timestamp": [2359.28, 2360.74], "text": " and trauma-literate society,"}, {"timestamp": [2360.74, 2362.44], "text": " a lot of this is gonna kind of work,"}, {"timestamp": [2362.44, 2365.3], "text": " I hope, will work itself out naturally over time"}, {"timestamp": [2365.4, 2367.4], "text": " It is a slow process though"}, {"timestamp": [2369.24, 2370.82], "text": " I want to"}, {"timestamp": [2370.82, 2374.36], "text": " Dive into childhood a bit and ask you a personal question if I may"}, {"timestamp": [2374.64, 2378.68], "text": " Sure, you you have another channel in addition to all of the stuff that you do with AI"}, {"timestamp": [2379.24, 2381.4], "text": " Called David Shapiro life, I think yep"}, {"timestamp": [2381.8, 2386.04], "text": " And you released a video quite recently about autism"}, {"timestamp": [2386.04, 2389.24], "text": " and about your experience with autism growing up."}, {"timestamp": [2389.24, 2392.12], "text": " And you told a story about this experience"}, {"timestamp": [2392.12, 2394.04], "text": " you had from your childhood."}, {"timestamp": [2394.04, 2395.96], "text": " And this was actually one thing that I"}, {"timestamp": [2395.96, 2399.36], "text": " found really fascinating, that one of the signs of autism"}, {"timestamp": [2399.36, 2403.04], "text": " in younger children is that you score either really high"}, {"timestamp": [2403.04, 2411.16], "text": " or really poorly on tests. And in your case, you said that you score either really high or really poorly on tests. And in your case you said that you were 99th percentile in everything except for"}, {"timestamp": [2411.16, 2415.56], "text": " reading comprehension and that the reason for that was because you didn't"}, {"timestamp": [2415.56, 2422.32], "text": " know at which level of analysis to stop or to analyze the story at. So you'd"}, {"timestamp": [2422.32, 2425.54], "text": " write these like incredibly nuanced responses that were"}, {"timestamp": [2426.32, 2428.36], "text": " inappropriately deep for the question and"}, {"timestamp": [2429.1, 2432.56], "text": " What you said was you had this we'll get into education in a bit here"}, {"timestamp": [2432.56, 2434.56], "text": " but there was this teacher who came to you and"}, {"timestamp": [2435.16, 2440.46], "text": " Explained to you what you were doing wrong, and that was this big aha moment for you so before we get to"}, {"timestamp": [2441.48, 2443.24], "text": " education"}, {"timestamp": [2443.24, 2450.46], "text": " Just at a at a in a general on a general level, what has your own experience with autism"}, {"timestamp": [2450.46, 2456.98], "text": " taught you about the challenges of building artificial intelligence?"}, {"timestamp": [2456.98, 2461.24], "text": " I think there's one conversation that encapsulates this perfectly."}, {"timestamp": [2461.24, 2467.0], "text": " And it was shortly after I met my now-fian fiance, we met at our writers group."}, {"timestamp": [2467.0, 2472.0], "text": " And so we got together for coffee to discuss our stories."}, {"timestamp": [2472.0, 2477.0], "text": " And I told her about this character that I was working on called Raven in my novel,"}, {"timestamp": [2477.0, 2482.0], "text": " this globe-spanning AI, and she's like, oh, you know a lot about this, you care a lot about this."}, {"timestamp": [2482.0, 2485.8], "text": " And so she's like, you should lean into this character and explore it more."}, {"timestamp": [2485.8, 2487.44], "text": " And of course, you know, four years later,"}, {"timestamp": [2487.44, 2489.8], "text": " I'm actually working on a real version."}, {"timestamp": [2489.8, 2491.72], "text": " But we were talking about"}, {"timestamp": [2491.72, 2495.12], "text": " what it takes to model intelligence."}, {"timestamp": [2495.12, 2497.52], "text": " And she stopped after I was telling her"}, {"timestamp": [2497.52, 2500.44], "text": " about all my theories about cognitive architecture and AI,"}, {"timestamp": [2500.44, 2503.96], "text": " and she said, whose brain are you trying to model anyways?"}, {"timestamp": [2503.96, 2505.76], "text": " And I was like, what do you mean?"}, {"timestamp": [2505.76, 2508.5], "text": " And she's like, you're talking about the way that your brain works."}, {"timestamp": [2508.5, 2511.6], "text": " And she's like, what about other people whose minds work differently?"}, {"timestamp": [2511.6, 2515.08], "text": " And I was like, I hadn't thought about that."}, {"timestamp": [2515.08, 2528.8], "text": " And so that's kind of a circuitous way of answering your question, but metacognition or self-awareness is a huge component of working on"}, {"timestamp": [2528.8, 2534.56], "text": " theory of mind, cognitive architectures, that sort of thing. And one of the most common,"}, {"timestamp": [2534.56, 2540.72], "text": " it's actually in several assessments to determine whether or not you have autism or where you're at"}, {"timestamp": [2540.72, 2547.68], "text": " on the spectrum is, if you're fascinated with personality theory you are more likely to be autistic it's just you know one little"}, {"timestamp": [2547.68, 2554.22], "text": " you know notch in the test but the reason that many of us are and one of my"}, {"timestamp": [2554.22, 2559.86], "text": " one of my absolute best friends is also she's big into more into Enneagram but"}, {"timestamp": [2559.86, 2564.94], "text": " she knows about MBTI too and it's like she has she has all these great stories"}, {"timestamp": [2564.94, 2566.4], "text": " she's like people are confusing to me so stories. She's like, people are confusing to me."}, {"timestamp": [2566.4, 2570.16], "text": " So I need like a template of how to interact with people."}, {"timestamp": [2570.16, 2572.88], "text": " And then we also seek out information"}, {"timestamp": [2572.88, 2573.72], "text": " to understand ourselves."}, {"timestamp": [2573.72, 2576.68], "text": " And that's actually how I got into personality theory"}, {"timestamp": [2576.68, 2577.52], "text": " many years ago."}, {"timestamp": [2577.52, 2579.4], "text": " I was like, I don't know how I work."}, {"timestamp": [2579.4, 2581.16], "text": " Apparently I don't work the same as other people."}, {"timestamp": [2581.16, 2582.96], "text": " So let me figure out why."}, {"timestamp": [2582.96, 2589.2], "text": " And of course, you know, I take a MBTI test and it's like oh you know you're this personality type but of"}, {"timestamp": [2589.2, 2592.92], "text": " course it doesn't actually have like the the real answer which is oh you're"}, {"timestamp": [2592.92, 2596.84], "text": " actually autistic. Like that would have been a great thing for that to have. And"}, {"timestamp": [2596.84, 2600.84], "text": " you know if I had gone, here's the thing, even if I had gone to a professional"}, {"timestamp": [2600.84, 2607.0], "text": " psychologist back in 2008-2007 I probably still would not have been diagnosed correctly"}, {"timestamp": [2607.0, 2609.76], "text": " because the information is still advancing."}, {"timestamp": [2609.76, 2612.08], "text": " So anyways, that was a very roundabout way"}, {"timestamp": [2612.08, 2614.56], "text": " of answering your question is that exploring psychology,"}, {"timestamp": [2614.56, 2617.4], "text": " exploring the mind, exploring philosophy,"}, {"timestamp": [2617.4, 2621.68], "text": " all of that is kind of part and parcel with being autistic"}, {"timestamp": [2621.68, 2624.76], "text": " and also all of it contributed to my understanding"}, {"timestamp": [2624.76, 2625.12], "text": " of artificial"}, {"timestamp": [2625.12, 2631.28], "text": " intelligence too and actual intelligence for that matter. Right. You have a video called"}, {"timestamp": [2631.28, 2638.16], "text": " billion dollar GPT-3 startup fix education with an expert tutor chatbot. As someone with a"}, {"timestamp": [2638.16, 2645.64], "text": " background in in education myself I am so excited about what all of this stuff means for education"}, {"timestamp": [2645.64, 2650.56], "text": " My girlfriend is Korean and she's still learning English over here, and she found this app where"}, {"timestamp": [2651.8, 2653.8], "text": " she can"}, {"timestamp": [2654.0, 2656.28], "text": " Have a conversation with this AI"}, {"timestamp": [2656.84, 2659.64], "text": " She speaks in English it responds to her in English"}, {"timestamp": [2660.24, 2667.76], "text": " And at the end of the conversation it shows the transcript and also how she could have sounded more natural at different points in the conversation."}, {"timestamp": [2667.76, 2671.66], "text": " And I was, you know, I taught English in Korea for two years and then online for a little"}, {"timestamp": [2671.66, 2675.88], "text": " bit and like one of the biggest challenges as an online teacher especially was like everyone"}, {"timestamp": [2675.88, 2679.88], "text": " wants to speak with the teacher but you're a human and you only have, you know, so much"}, {"timestamp": [2679.88, 2681.2], "text": " time."}, {"timestamp": [2681.2, 2684.84], "text": " This just solved that problem and it's already here and she's using it and it's an amazing"}, {"timestamp": [2684.84, 2686.32], "text": " app."}, {"timestamp": [2686.32, 2694.96], "text": " If someone, my next prompt for you, if someone came to you and gave you the keys to the country,"}, {"timestamp": [2694.96, 2700.12], "text": " I'm in Canada, you're in the States, but you know, similar education systems, if someone"}, {"timestamp": [2700.12, 2705.48], "text": " gave you the keys to fix education, you had unlimited resources and could do whatever"}, {"timestamp": [2705.48, 2708.64], "text": " you want to do, what would you do?"}, {"timestamp": [2708.64, 2711.12], "text": " How would you fix education?"}, {"timestamp": [2711.12, 2718.22], "text": " So I actually had a few conversations with educators all over the world in January."}, {"timestamp": [2718.22, 2722.52], "text": " So one of the platforms that my startup is working on is actually edtech, so deploying"}, {"timestamp": [2722.52, 2727.24], "text": " AI into education. And so obviously with the rise of chat GPT,"}, {"timestamp": [2727.24, 2730.64], "text": " there was a lot of consternation around AI."}, {"timestamp": [2730.64, 2733.84], "text": " A lot of teachers had a lot of fear and anxiety,"}, {"timestamp": [2733.84, 2735.0], "text": " like, is this gonna replace this?"}, {"timestamp": [2735.0, 2736.16], "text": " Is this gonna break everything?"}, {"timestamp": [2736.16, 2738.72], "text": " And of course, after the initial panic has subsided,"}, {"timestamp": [2738.72, 2741.6], "text": " people are like, oh, there's actually ways to use this."}, {"timestamp": [2741.6, 2744.4], "text": " So, but to answer the question more directly,"}, {"timestamp": [2744.4, 2746.52], "text": " what I would do, what I'm trying to do, what"}, {"timestamp": [2746.52, 2753.6], "text": " I'm working towards doing is adding more tools like that, like that language tutor, so that"}, {"timestamp": [2753.6, 2758.2], "text": " students have more individualized support."}, {"timestamp": [2758.2, 2766.44], "text": " Whether it's something that is going to provide coaching and feedback, because that's absolutely one of the pillars of our work, is providing"}, {"timestamp": [2766.44, 2774.04], "text": " that really personalized, hands-on feedback that allows students to learn and get super"}, {"timestamp": [2774.04, 2777.64], "text": " high quality coaching and guidance."}, {"timestamp": [2777.64, 2782.48], "text": " So deploying as many of those tools as we can, and then kind of see where the gaps are."}, {"timestamp": [2782.48, 2785.28], "text": " Because obviously, learning from a computer"}, {"timestamp": [2785.28, 2788.02], "text": " is gonna have some limitations, right?"}, {"timestamp": [2788.02, 2789.44], "text": " That's why I said earlier,"}, {"timestamp": [2789.44, 2791.36], "text": " we will always need that human touch,"}, {"timestamp": [2791.36, 2794.88], "text": " but 30 students for one teacher is too much, right?"}, {"timestamp": [2794.88, 2797.68], "text": " And, you know, we need the human"}, {"timestamp": [2797.68, 2799.76], "text": " that has that emotional intelligence,"}, {"timestamp": [2799.76, 2801.24], "text": " that has the soothing voice,"}, {"timestamp": [2801.24, 2804.24], "text": " that has, you know, the physical touch"}, {"timestamp": [2804.24, 2807.08], "text": " to be able to work with students when they get frustrated,"}, {"timestamp": [2807.08, 2810.44], "text": " or when they're sad and angry and distracted because something"}, {"timestamp": [2810.44, 2811.94], "text": " happened at home."}, {"timestamp": [2811.94, 2815.0], "text": " So much of being a teacher, being a good teacher,"}, {"timestamp": [2815.0, 2817.8], "text": " is paying attention to the student as a whole entity,"}, {"timestamp": [2817.8, 2819.92], "text": " not just thinking about the grades."}, {"timestamp": [2819.92, 2822.8], "text": " And on the topic of grades, there"}, {"timestamp": [2822.8, 2824.52], "text": " is an ungrading movement, which I"}, {"timestamp": [2824.52, 2827.36], "text": " think is probably more popular in Canada than it is in America."}, {"timestamp": [2827.36, 2828.8], "text": " I'm not sure though."}, {"timestamp": [2828.8, 2833.08], "text": " But the idea is to get rid of grading altogether and just focus on learning."}, {"timestamp": [2833.08, 2838.28], "text": " Now I talked to several educators about that and they said, we get it, you know, we get"}, {"timestamp": [2838.28, 2840.96], "text": " the idea, but you do need grades."}, {"timestamp": [2840.96, 2845.46], "text": " The problem is that grading is misused today because grading is one"}, {"timestamp": [2845.46, 2851.14], "text": " of the few levers of influence and power that teachers have, right? A teacher has"}, {"timestamp": [2851.14, 2854.26], "text": " to be there and has to teach the students in their class, whether or not"}, {"timestamp": [2854.26, 2858.72], "text": " the students even want to be there, right? So the the two levers of power that"}, {"timestamp": [2858.72, 2864.42], "text": " teachers have is grades and disciplinary actions, and depending on the students or"}, {"timestamp": [2864.42, 2865.14], "text": " the classroom or the classroom or the"}, {"timestamp": [2865.14, 2868.48], "text": " school or the district, they might even have constraints about the discipline"}, {"timestamp": [2868.48, 2872.98], "text": " that they can take. Sometimes because of parents, sometimes because of legislation"}, {"timestamp": [2872.98, 2876.38], "text": " that's passed, so on and so forth. So teachers don't have a whole lot of power"}, {"timestamp": [2876.38, 2882.9], "text": " over the environment in which they teach. So you know, by automating or"}, {"timestamp": [2882.9, 2886.56], "text": " aiding some of this process with machines,"}, {"timestamp": [2887.12, 2892.32], "text": " we can, one, provide more equitable experience for children. So, for instance,"}, {"timestamp": [2893.12, 2896.56], "text": " one of the biggest problems, and this is just a structural problem,"}, {"timestamp": [2897.76, 2907.04], "text": " is that our classrooms are designed, they were designed during the rise of the of industrialization, which means that"}, {"timestamp": [2907.04, 2913.2], "text": " they're kind of calibrated to create, you know, like worker drones, right? Part of the"}, {"timestamp": [2913.2, 2919.28], "text": " of the Western school system is you sit quietly at a desk doing menial work and if you can't do"}, {"timestamp": [2919.28, 2925.48], "text": " that, well then you're defective, right? You know, we pathologize things like ADHD, like, you"}, {"timestamp": [2925.48, 2930.08], "text": " know, I'm probably somewhere on the spectrum of ADHD, but it's because my"}, {"timestamp": [2930.08, 2935.96], "text": " brain is too damn fast and too active and wants to solve harder problems, and"}, {"timestamp": [2935.96, 2940.36], "text": " so I didn't do well in, you know, sitting at a desk. I still don't. Well, I mean, I"}, {"timestamp": [2940.36, 2945.36], "text": " can sit at a desk and hyper focusfocus on AI for a few hours."}, {"timestamp": [2945.36, 2954.28], "text": " But if we can decouple education and learning from being in lockstep with every other student"}, {"timestamp": [2954.28, 2956.58], "text": " so that children can move at their own pace."}, {"timestamp": [2956.58, 2961.18], "text": " So another thing about me is that my first year of education was at a Montessori school."}, {"timestamp": [2961.18, 2964.62], "text": " And so for anyone who's not familiar with Montessori school, it is super unstructured."}, {"timestamp": [2964.62, 2967.0], "text": " It basically just looks like play."}, {"timestamp": [2967.0, 2974.0], "text": " And the idea is that children will engage in self-directed learning based on what interests them."}, {"timestamp": [2974.0, 2981.0], "text": " And so, like, one of my favorite things to do back at Montessori school, and I actually, I remember this, was there's this toy where you,"}, {"timestamp": [2981.0, 2988.56], "text": " there's parts that you stack and marbles go through it, right? The marble tracks. And then there's like little loops and pinwheels and spirals and stuff."}, {"timestamp": [2988.56, 2992.8], "text": " And that was, I found that so interesting because it was a system."}, {"timestamp": [2992.8, 2996.2], "text": " You create this tower and then you send marbles down it"}, {"timestamp": [2996.2, 2998.44], "text": " and you figure out how marbles end up where they're going"}, {"timestamp": [2998.44, 2999.96], "text": " and you play with the physics of it."}, {"timestamp": [2999.96, 3002.44], "text": " And I was actually so excited playing with that,"}, {"timestamp": [3002.44, 3007.16], "text": " I'd be like screaming that eventually the teachers had to take it away from me."}, {"timestamp": [3007.16, 3010.26], "text": " But anyways, the point being is we do have other models"}, {"timestamp": [3010.26, 3014.32], "text": " of education, but they're either too expensive"}, {"timestamp": [3014.32, 3017.94], "text": " or too unreliable to deploy."}, {"timestamp": [3017.94, 3021.76], "text": " And what I'm hoping is that with AI and machines,"}, {"timestamp": [3021.76, 3026.8], "text": " we can actually, we can kind of flip the classroom again and change it so that"}, {"timestamp": [3026.8, 3034.56], "text": " students, so that all students, one, get their intellectual needs met, and two, can move at"}, {"timestamp": [3034.56, 3039.6], "text": " their own pace, and three, get the feedback and guidance that they need, whether it's from a"}, {"timestamp": [3039.6, 3046.56], "text": " machine or a human, as needed. So I think if we do those three things, I think that we're going to see a"}, {"timestamp": [3046.56, 3052.56], "text": " very, very different generation of children that have a very different relationship with education."}, {"timestamp": [3053.44, 3059.68], "text": " Because learning is exciting, right? Children, like all children, do natural experiments at all"}, {"timestamp": [3059.68, 3065.04], "text": " times, right? My nephew, he found a scarf. We were hanging out one day at my brother's"}, {"timestamp": [3065.04, 3068.96], "text": " house and he was just throwing a scarf up in the air. And I recognized the"}, {"timestamp": [3068.96, 3071.56], "text": " behavior because it's something I would have done. He was playing with,"}, {"timestamp": [3071.56, 3075.8], "text": " how does this scarf move through the air? How does it fall? What are the rules that"}, {"timestamp": [3075.8, 3079.52], "text": " govern this thing? And I was like, oh you're doing science. And he's like, no"}, {"timestamp": [3079.52, 3083.1], "text": " I'm not. I'm like, yeah you are. You're figuring out how this thing works. And I"}, {"timestamp": [3083.1, 3088.28], "text": " had, I actually had an argument with with another friend over the definition of science I told"}, {"timestamp": [3088.28, 3091.48], "text": " him a story like that and I was like that's natural science and he's like no"}, {"timestamp": [3091.48, 3096.0], "text": " the only the only people who can do scientists work at universities and"}, {"timestamp": [3096.0, 3100.4], "text": " publish papers and I'm like that is such a narrow definition of science and I was"}, {"timestamp": [3100.4, 3109.32], "text": " like I'm not gonna talk to you right now you're you're too obt anyways, if we do those things, we will completely change our relationship with learning"}, {"timestamp": [3109.32, 3110.32], "text": " and education."}, {"timestamp": [3110.32, 3115.4], "text": " Because it turns out, as much as I hated school, I actually love learning, and I love science,"}, {"timestamp": [3115.4, 3118.76], "text": " but I learned to hate it because of how broken our school system is."}, {"timestamp": [3118.76, 3119.76], "text": " Right."}, {"timestamp": [3119.76, 3125.28], "text": " Do you think we'll get to a point, I guess there are kind of two questions packaged in"}, {"timestamp": [3125.28, 3130.96], "text": " here, but I was thinking back to the experience that you had with this one teacher who was"}, {"timestamp": [3130.96, 3136.56], "text": " able to explain to you why your answers to these questions were inappropriately deep."}, {"timestamp": [3136.56, 3142.28], "text": " And when I was watching that part of the video, you know, there was something about that experience"}, {"timestamp": [3142.28, 3147.48], "text": " that seemed to be, and you talked about this a little bit in the answer that you just gave, but you know, there's a component of it, of"}, {"timestamp": [3147.48, 3150.96], "text": " course, that's teaching you, but really the big component of it is just being able to"}, {"timestamp": [3150.96, 3152.72], "text": " like empathize with what you're going through."}, {"timestamp": [3152.72, 3157.92], "text": " And like, I forget the exact way that you phrased it, but look at you as a full entity."}, {"timestamp": [3157.92, 3163.44], "text": " I think you said, do you think that we'll get to a point anytime soon, let's say in"}, {"timestamp": [3163.44, 3168.12], "text": " the next five to 10 years where you're able to have that same experience that you had with"}, {"timestamp": [3168.12, 3173.44], "text": " this teacher, with a machine, where a machine is able to look at you in that"}, {"timestamp": [3173.44, 3178.64], "text": " same way and not only correct you in terms of what's wrong with your answer."}, {"timestamp": [3178.64, 3179.8], "text": " I mean, we can do that right now."}, {"timestamp": [3179.8, 3187.16], "text": " ChatGPT is pretty good at that, but also make you feel, um, create that change in you."}, {"timestamp": [3187.16, 3188.28], "text": " That has."}, {"timestamp": [3188.8, 3191.04], "text": " That was such an important moment to you that it's stuck"}, {"timestamp": [3191.04, 3192.3], "text": " with you all this time, right?"}, {"timestamp": [3192.68, 3195.0], "text": " So will a machine be able to have that same impact?"}, {"timestamp": [3195.0, 3202.6], "text": " And then the second part of this question is what, how do we teach kids that they"}, {"timestamp": [3202.6, 3205.76], "text": " are interacting with machines and about the difference"}, {"timestamp": [3205.76, 3209.28], "text": " between interacting with a human and interacting with a machine? What impact"}, {"timestamp": [3209.28, 3215.04], "text": " does that have on children? Yeah, good questions. So to the to the first"}, {"timestamp": [3215.04, 3222.36], "text": " question or the first part, technologies like ChatGPT are already, this is"}, {"timestamp": [3222.36, 3225.2], "text": " probably going to be a controversial assertion, but I've, I've,"}, {"timestamp": [3225.2, 3228.8], "text": " I've witnessed it firsthand and I figured out how to do it reliably."}, {"timestamp": [3229.24, 3234.24], "text": " Chat GPT has an incredible ability to make inferences about our emotional"}, {"timestamp": [3235.4, 3236.22], "text": " reality."}, {"timestamp": [3237.12, 3240.04], "text": " And so I have a couple of examples of,"}, {"timestamp": [3240.12, 3244.16], "text": " of how I can demonstrate this. So one,"}, {"timestamp": [3244.96, 3251.28], "text": " um, I was, I was, I was having a conversation with ChatGPT, I need to come up with something that rolls"}, {"timestamp": [3251.28, 3255.78], "text": " off the tongue better, but I was having a conversation about my novel."}, {"timestamp": [3255.78, 3260.72], "text": " I was working through a chapter and I was trying to come up with ways to make the chapter"}, {"timestamp": [3260.72, 3266.16], "text": " more nuanced, more layered, more relevant to the theme and the character arcs and stuff."}, {"timestamp": [3266.16, 3270.76], "text": " And I was telling it about these two different worlds, that they're a juxtaposition, where"}, {"timestamp": [3270.76, 3276.36], "text": " one world goes one way and another world goes another, and without me saying the reason"}, {"timestamp": [3276.36, 3282.8], "text": " for that, ChatGPT told me, like, oh, the reason that you have this contrast is to show the"}, {"timestamp": [3282.8, 3293.36], "text": " theme of your story and here's a better way of doing it.\" I was just like, when that happened, I said, holy crap, this goes above and beyond what,"}, {"timestamp": [3294.64, 3297.92], "text": " even though I'm so bullish on what large language models are capable of,"}, {"timestamp": [3298.56, 3304.08], "text": " this completely changed the scale of what it's already capable of today."}, {"timestamp": [3305.0, 3308.62], "text": " changed the scale of what it's already capable of today. And the nuance that it detected in my story"}, {"timestamp": [3308.62, 3311.62], "text": " is something that it took me three years to develop."}, {"timestamp": [3311.62, 3314.42], "text": " And so just through one conversation,"}, {"timestamp": [3314.42, 3316.46], "text": " by connecting those dots, I said,"}, {"timestamp": [3316.46, 3318.78], "text": " okay, we are in a new paradigm"}, {"timestamp": [3318.78, 3321.98], "text": " in terms of understanding the human condition,"}, {"timestamp": [3321.98, 3325.2], "text": " just strictly from a linguistic perspective."}, {"timestamp": [3325.2, 3329.64], "text": " Then at the same time, I've had similar conversations about myself."}, {"timestamp": [3329.64, 3334.38], "text": " And of course, it's really infuriating because usually when you talk to chat GPT about like"}, {"timestamp": [3334.38, 3337.64], "text": " personal problems or whatever, it'll just rattle off a list of things you can do."}, {"timestamp": [3337.64, 3341.06], "text": " I said, no, no, no, don't, don't tell me what to do."}, {"timestamp": [3341.06, 3342.06], "text": " Let's explore this."}, {"timestamp": [3342.06, 3343.06], "text": " Let's unpack this."}, {"timestamp": [3343.06, 3350.62], "text": " And it says, okay, let me ask you a few questions, let me give you some generalizations about what this might mean."}, {"timestamp": [3350.62, 3355.66], "text": " And its ability to connect those dots is incredible."}, {"timestamp": [3355.66, 3360.94], "text": " So strictly from a thought perspective or emotional perspective or linguistic perspective,"}, {"timestamp": [3360.94, 3362.82], "text": " the technology can already do that."}, {"timestamp": [3362.82, 3370.92], "text": " It's not reliable though because it's not thinking. It's not structured in a way to do that for you. So how do we"}, {"timestamp": [3370.92, 3375.56], "text": " get there? Well one of the things that I'm working on is what I"}, {"timestamp": [3375.56, 3380.72], "text": " call a cognitive architecture. So how do we take these technologies and"}, {"timestamp": [3380.72, 3385.36], "text": " encapsulate them and structure them in such a way that it can reliably do that."}, {"timestamp": [3385.36, 3391.6], "text": " So that it can take this miraculous ability it has to make inferences about the human condition,"}, {"timestamp": [3391.6, 3394.56], "text": " about emotions, about people, about theory of mind."}, {"timestamp": [3394.56, 3397.6], "text": " There was actually a recent paper published that said that,"}, {"timestamp": [3397.6, 3400.88], "text": " that actually concluded that large language models do have,"}, {"timestamp": [3400.88, 3405.68], "text": " they do possess theory of mind and that it just emerged by virtue of how it's"}, {"timestamp": [3405.68, 3407.08], "text": " trained."}, {"timestamp": [3407.08, 3416.48], "text": " So with a cognitive architecture, we can develop machines that remember all these facts about"}, {"timestamp": [3416.48, 3421.56], "text": " you, that play with these ideas internally, and then either come up with hypotheses, say,"}, {"timestamp": [3421.56, 3430.16], "text": " oh, I wonder if this is what's going on with this person, and then test that hypothesis by asking questions or make recommendations or so on and so forth."}, {"timestamp": [3430.16, 3433.16], "text": " So the technology is coming."}, {"timestamp": [3433.16, 3436.44], "text": " We already have visual technology and audio technology."}, {"timestamp": [3436.44, 3440.58], "text": " So there's a company that I spoke with more than a year ago now."}, {"timestamp": [3440.58, 3448.04], "text": " It's a French company called Humano, and they focus on creating automatic telemetry,"}, {"timestamp": [3448.04, 3454.04], "text": " emotional telemetry from users based on face, voice, and so on, where it's like, how engaged"}, {"timestamp": [3454.04, 3455.84], "text": " is the person?"}, {"timestamp": [3455.84, 3456.84], "text": " Are they frustrated?"}, {"timestamp": [3456.84, 3457.84], "text": " Are they happy?"}, {"timestamp": [3457.84, 3459.08], "text": " Are they excited?"}, {"timestamp": [3459.08, 3460.16], "text": " So on and so forth."}, {"timestamp": [3460.16, 3465.28], "text": " So we combine this emotional telemetry that can read your body language and facial expressions"}, {"timestamp": [3465.28, 3471.2], "text": " and voice inflection. You combine that with this language technology and the appropriate"}, {"timestamp": [3471.2, 3480.24], "text": " cognitive architecture and we will very soon get to the point where our machines are able to"}, {"timestamp": [3482.0, 3492.0], "text": " have those eureka moments with you. And that's actually one of the primary inspirations I'll say for my Raven project, which one of"}, {"timestamp": [3492.0, 3497.04], "text": " the central mantras is the right information at the right moment changes lives."}, {"timestamp": [3497.04, 3501.44], "text": " That is the whole point of that cognitive architecture is to figure out what information"}, {"timestamp": [3501.44, 3505.48], "text": " is needed and to deliver it in exactly the right way at"}, {"timestamp": [3505.48, 3506.68], "text": " exactly the right moment."}, {"timestamp": [3506.68, 3510.18], "text": " Because when you make that connection, when you get the answer that you need, when your"}, {"timestamp": [3510.18, 3516.04], "text": " brain is ready for it, when your mind is ready for it, then that's what changes your trajectory."}, {"timestamp": [3516.04, 3517.04], "text": " So it's coming."}, {"timestamp": [3517.04, 3518.04], "text": " We're working on it."}, {"timestamp": [3518.04, 3520.0], "text": " I'm actively working on this technology."}, {"timestamp": [3520.0, 3527.6], "text": " Now, the second part of the question, which is, you know, how do we teach children about this?"}, {"timestamp": [3527.6, 3534.2], "text": " I suspect that the first generation of children that grow up with this high-level artificial"}, {"timestamp": [3534.2, 3537.52], "text": " intelligence, for them it's just going to be intuitive."}, {"timestamp": [3537.52, 3542.8], "text": " You ever hand a smartphone to, you know, a toddler?"}, {"timestamp": [3542.8, 3547.16], "text": " The stuff they figure out on accident is just like, I didn't even know I could do it."}, {"timestamp": [3547.16, 3553.04], "text": " Like, I'm a technologist. Like, I've done IT for years, and I'm a digital native, and"}, {"timestamp": [3554.44, 3560.22], "text": " children's brains, they get acclimated to the tools that they're using, and they just figure it out, and they can't even articulate it."}, {"timestamp": [3561.04, 3567.0], "text": " Same thing when I watch my nephew and all of his friends, that they just play these games day in and day out."}, {"timestamp": [3567.0, 3571.0], "text": " They have tablets, they have phones, and they just get it."}, {"timestamp": [3571.0, 3577.0], "text": " So I suspect that once they know that they're interacting with an intelligent entity,"}, {"timestamp": [3577.0, 3581.0], "text": " and when I say intelligent entity I don't mean like human intelligence,"}, {"timestamp": [3581.0, 3589.04], "text": " but something that has the functional intelligence that they need, that they'll have a model of saying, oh, I know that this thing has"}, {"timestamp": [3589.04, 3590.04], "text": " the answers for me."}, {"timestamp": [3590.04, 3591.96], "text": " I just need to interact with it in a certain way."}, {"timestamp": [3591.96, 3596.44], "text": " And we already see that with children who will like interact with Alexa or voice enabled"}, {"timestamp": [3596.44, 3597.8], "text": " robots."}, {"timestamp": [3597.8, 3598.88], "text": " And that's just going to go up."}, {"timestamp": [3598.88, 3601.6], "text": " So I don't know that we need to do anything specific."}, {"timestamp": [3601.6, 3605.16], "text": " I think that nature will kind of work itself out in that respect."}, {"timestamp": [3605.16, 3610.52], "text": " Okay, last question for you, and I don't know exactly how I'm going to\u2014what the question"}, {"timestamp": [3610.52, 3613.92], "text": " is yet, but I want to frame it in a certain way."}, {"timestamp": [3613.92, 3621.8], "text": " So there's one thing that has terrified me more than anything about AI, and it's terrified"}, {"timestamp": [3621.8, 3625.12], "text": " me for\u2014I mean, I think I saw the movie in 2015."}, {"timestamp": [3625.12, 3628.44], "text": " I think I heard you talk about Ex Machina in one of your videos."}, {"timestamp": [3628.44, 3629.68], "text": " Yep, okay."}, {"timestamp": [3629.68, 3636.4], "text": " So it's a scene from Ex Machina that I watched it and it's just stuck with me and I'm reminded"}, {"timestamp": [3636.4, 3639.52], "text": " of it and it's becoming especially terrifying now to me."}, {"timestamp": [3639.52, 3642.76], "text": " And it's related to what we were just, well, I'll get back to what we were just talking"}, {"timestamp": [3642.76, 3651.0], "text": " about with children interacting with machines. But anyways, the scene from the movie is when Caleb, who's the engineer who's brought in"}, {"timestamp": [3651.0, 3655.84], "text": " to interact with these AIs and test whether they're sentient or whether they pass the"}, {"timestamp": [3655.84, 3660.48], "text": " Turing test or whatever, it's near the end of the movie where he realizes that he's been"}, {"timestamp": [3660.48, 3669.92], "text": " set up and that all of this is a test and that he's been fooled so wildly by these AIs to the point where he doesn't even recognize that there were AIs that looked like humans"}, {"timestamp": [3669.92, 3673.8], "text": " that he thought were humans that were actually AIs around him that he didn't fall in love"}, {"timestamp": [3673.8, 3675.04], "text": " with."}, {"timestamp": [3675.04, 3681.96], "text": " And the particular scene is one where he starts doubting whether he's a human."}, {"timestamp": [3681.96, 3689.44], "text": " And he actually, the scene is he like cuts his arm open to see if he bleeds or if he'll find wires inside. And"}, {"timestamp": [3689.68, 3693.48], "text": " that scene has that that terrifies me more than anything,"}, {"timestamp": [3693.48, 3699.24], "text": " this idea that we don't know what's true anymore. You can"}, {"timestamp": [3699.24, 3701.96], "text": " kind of you see this already with a lot of the technologies"}, {"timestamp": [3701.96, 3704.24], "text": " and startups that are that are being launched where there's,"}, {"timestamp": [3704.36, 3706.16], "text": " you know, synthetic video that's getting it's still not perfect, but it startups that are being launched, where there's synthetic video."}, {"timestamp": [3706.16, 3709.44], "text": " It's still not perfect, but it's getting closer and closer."}, {"timestamp": [3709.44, 3713.12], "text": " There's no reason to think that it's not going to get to the point where we can't tell the"}, {"timestamp": [3713.12, 3714.64], "text": " difference."}, {"timestamp": [3714.64, 3718.88], "text": " As you were speaking, I was just imagining, I want to have kids in the next couple of"}, {"timestamp": [3718.88, 3719.88], "text": " years."}, {"timestamp": [3719.88, 3722.28], "text": " I'm almost 33 now."}, {"timestamp": [3722.28, 3728.86], "text": " I was imagining my kid speaking to this AI that's like totally convincing to the point where you don't know"}, {"timestamp": [3729.12, 3732.42], "text": " It is an AI and the thought came to me like well"}, {"timestamp": [3732.42, 3736.7], "text": " What if this kid just can't tell the difference between humans and AI's does that matter?"}, {"timestamp": [3736.92, 3740.3], "text": " what does it mean if he like looks he or she looks at me and"}, {"timestamp": [3741.86, 3743.54], "text": " You know, there's no"}, {"timestamp": [3743.54, 3747.4], "text": " there's no there's no difference in terms of how that child"}, {"timestamp": [3747.4, 3753.5], "text": " perceives me as the father versus like an AI that's teaching them. I guess my"}, {"timestamp": [3753.5, 3759.82], "text": " last question for you is what do you my last prompt let's say I want you to make"}, {"timestamp": [3759.82, 3767.32], "text": " the the bullish case for why I shouldn't worry about this stuff, or just respond"}, {"timestamp": [3767.32, 3771.88], "text": " to my fears and tell me what you think is going to happen with this particular"}, {"timestamp": [3771.88, 3779.68], "text": " concern. Yeah, so this has been explored in science fiction for for decades"}, {"timestamp": [3779.68, 3786.32], "text": " actually. There's a there's a series on YouTube, it's called like the History of Cyberpunk or something,"}, {"timestamp": [3786.32, 3791.12], "text": " and it unpacks like each decade, like 1970s, 1980s, and 1990s."}, {"timestamp": [3791.12, 3792.22], "text": " It's a phenomenal series."}, {"timestamp": [3792.22, 3796.12], "text": " Each video is like two hours long, so it takes six hours to watch."}, {"timestamp": [3796.12, 3802.76], "text": " But ever since the rise of computers, humans have had so much anxiety about virtual reality,"}, {"timestamp": [3802.76, 3806.5], "text": " what is reality, what does it mean to be human?"}, {"timestamp": [3807.72, 3811.44], "text": " There is all kinds of movies where people get sucked"}, {"timestamp": [3811.44, 3813.2], "text": " into the machine."}, {"timestamp": [3813.2, 3816.2], "text": " Tron is the most famous one where it's like,"}, {"timestamp": [3816.2, 3818.44], "text": " oh, hey, if a machine can run a simulation"}, {"timestamp": [3818.44, 3821.7], "text": " and you get sucked into it, how do you know, right?"}, {"timestamp": [3821.7, 3823.24], "text": " So there's that, there's the Matrix,"}, {"timestamp": [3823.24, 3827.16], "text": " which also kind of was the pinnacle of what if we're"}, {"timestamp": [3827.16, 3832.44], "text": " all living in virtual reality, how do we know what's real, and there's been plenty of other"}, {"timestamp": [3832.44, 3835.88], "text": " stories in between."}, {"timestamp": [3835.88, 3842.28], "text": " More recently, so there's Ex Machina, there's Ghost in the Shell which is an anime and manga"}, {"timestamp": [3842.28, 3845.76], "text": " where the protagonist, that's actually her primary philosophical"}, {"timestamp": [3845.76, 3851.12], "text": " character arc, is she has a fully robotic body so she doubts whether or not she's even human."}, {"timestamp": [3852.08, 3856.16], "text": " And so the idea is, that's actually the name of the series, Ghost in the Shell,"}, {"timestamp": [3856.16, 3866.92], "text": " so the shell is the artificial brain case and the ghost is her soul, right? That is the key question. What does it mean to be human? And so the"}, {"timestamp": [3866.92, 3873.64], "text": " anxiety that you feel is one, extremely common and it's why it has been explored for literally"}, {"timestamp": [3873.64, 3879.48], "text": " 50 plus years in science fiction as we started creating thinking machines. And actually it"}, {"timestamp": [3879.48, 3886.4], "text": " probably goes back earlier. This was one of the ideas originally explored in Mary Shelley's Frankenstein."}, {"timestamp": [3887.52, 3891.76], "text": " You know, the new Prometheus, the idea of if you reanimate something, what is it?"}, {"timestamp": [3892.48, 3898.0], "text": " Right? If you create an artificial life form, does it have rights? Is it a person?"}, {"timestamp": [3898.72, 3901.6], "text": " You know, these are all questions that we've been asking for, I guess, more than a century."}, {"timestamp": [3904.12, 3912.56], "text": " been asking for, I guess, more than a century. And for me personally, it is no longer an unsettling question."}, {"timestamp": [3912.56, 3916.08], "text": " And it kind of goes back to, who was it?"}, {"timestamp": [3916.08, 3917.08], "text": " Was it Sartre?"}, {"timestamp": [3917.08, 3919.2], "text": " Who said, I think, therefore I am?"}, {"timestamp": [3919.2, 3920.96], "text": " Descartes, I think."}, {"timestamp": [3920.96, 3922.36], "text": " Okay, yeah."}, {"timestamp": [3922.36, 3923.36], "text": " Some French philosopher."}, {"timestamp": [3923.36, 3928.04], "text": " I think. Okay yeah some some French philosopher. But anyways so I know"}, {"timestamp": [3928.04, 3934.52], "text": " that I have a subjective experience. I know that I I feel myself looking out of"}, {"timestamp": [3934.52, 3942.04], "text": " my eyes at the screen talking with you right now. I also know that all of my day"}, {"timestamp": [3942.04, 3945.92], "text": " yesterday was totally ephemeral. From the perspective of my day yesterday was totally ephemeral."}, {"timestamp": [3949.0, 3951.2], "text": " From the perspective of my brain and from the perspective of physics,"}, {"timestamp": [3951.2, 3955.68], "text": " the person that I was yesterday no longer exists, right?"}, {"timestamp": [3955.68, 3960.68], "text": " And because of that, once we become aware of"}, {"timestamp": [3961.42, 3968.56], "text": " and comfortable with how ephemeral our existence is, that is far more existential than"}, {"timestamp": [3968.56, 3974.4], "text": " whether or not we're machines, than whether or not a child can differentiate between a flesh and"}, {"timestamp": [3974.4, 3982.88], "text": " blood human or a facsimile of, you know, an anthropomorphic machine. I think, I think,"}, {"timestamp": [3982.88, 3987.24], "text": " so I guess my answer is I think the actual anxiety that you are experiencing and that"}, {"timestamp": [3987.24, 3993.76], "text": " other people are experiencing has more to do with just how thin and fragile our experience"}, {"timestamp": [3993.76, 3996.52], "text": " of being is."}, {"timestamp": [3996.52, 4002.36], "text": " And I think that that is part of why people are afraid of AI and why people have this"}, {"timestamp": [4002.36, 4004.96], "text": " like human exceptionalism."}, {"timestamp": [4004.96, 4006.32], "text": " Like people say, oh, the machine is never"}, {"timestamp": [4006.32, 4007.26], "text": " going to be as smart as us."}, {"timestamp": [4007.26, 4009.08], "text": " It's never going to be anything like us"}, {"timestamp": [4009.08, 4013.88], "text": " because that is emotionally more comfortable"}, {"timestamp": [4013.88, 4018.4], "text": " than reconciling with that like existential dread."}, {"timestamp": [4018.4, 4021.52], "text": " And this is actually, this is actually a conversation"}, {"timestamp": [4021.52, 4024.04], "text": " that I've been having with my fiance for like four years"}, {"timestamp": [4024.04, 4027.0], "text": " because this is the central theme in most of her writing, actually."}, {"timestamp": [4027.0, 4040.0], "text": " She explores this quite extensively, just like, okay, like, if our existence is so fragile, so thin, so ephemeral, and we can compare ourselves to machines, what's the difference?"}, {"timestamp": [4040.0, 4041.0], "text": " Right?"}, {"timestamp": [4041.0, 4047.36], "text": " But once you fully wrangle with this this and I guess I shouldn't assume that"}, {"timestamp": [4047.36, 4051.64], "text": " everyone's gonna come to the same conclusion as me but at least for myself"}, {"timestamp": [4051.64, 4056.96], "text": " once I go through that and once I experience things like full ego death"}, {"timestamp": [4056.96, 4061.88], "text": " and and realize just how thin and fragile it is and learn to accept that"}, {"timestamp": [4061.88, 4065.36], "text": " then it's like oh it's actually not that big of a deal but it is and learn to accept that, then it's like, oh, it's actually not that big of a deal."}, {"timestamp": [4066.96, 4072.64], "text": " But it is a matter of reconciling with that idea and being able to accept it, I think."}, {"timestamp": [4073.92, 4080.32], "text": " And does that for you, I imagine like, well, we talked about this earlier, but I imagine for some"}, {"timestamp": [4080.32, 4085.92], "text": " people that could, all of these nih these nihilistic tendencies, maybe could start bubbling"}, {"timestamp": [4085.92, 4091.28], "text": " up as a result of that, or the opposite, where you realize that, like, you know, we're here,"}, {"timestamp": [4091.28, 4098.48], "text": " we're having this experience, and you just learn to embrace it and, and enjoy it more, maybe."}, {"timestamp": [4099.28, 4103.84], "text": " It seems like for you, that's been the latter has, has happened."}, {"timestamp": [4104.8, 4109.82], "text": " Yeah, so that's actually why I call my philosophy post-Nihilism, because you don't reject Nihilism,"}, {"timestamp": [4109.82, 4113.52], "text": " you have to move through it."}, {"timestamp": [4113.52, 4118.76], "text": " I was having a chat with someone, I think it was on my Patreon or something, or somewhere"}, {"timestamp": [4118.76, 4123.96], "text": " recently, and they were talking about, like, oh, well, Nihilism is just the obvious logical"}, {"timestamp": [4123.96, 4127.64], "text": " conclusion. If you accept that like, you know,"}, {"timestamp": [4127.64, 4129.76], "text": " there are no deities and you know,"}, {"timestamp": [4129.76, 4131.6], "text": " materialism and science and blah, blah, blah."}, {"timestamp": [4131.6, 4135.6], "text": " And it's like, sure, like you could make an argument"}, {"timestamp": [4135.6, 4139.12], "text": " that it is logical, but at the end of the day, who cares?"}, {"timestamp": [4139.12, 4141.68], "text": " Who cares about logic, right?"}, {"timestamp": [4141.68, 4146.16], "text": " Logic doesn't really figure into our daily experience and this is so"}, {"timestamp": [4146.16, 4150.12], "text": " this there's there's two philosophical paradigms one is the is-ought problem"}, {"timestamp": [4150.12, 4155.2], "text": " which is David Hume the Scottish philosopher it isn't basically it says"}, {"timestamp": [4155.2, 4161.0], "text": " that it is impossible to determine what ought to be based on what is so if you"}, {"timestamp": [4161.0, 4169.98], "text": " make an observation about the physical world, it is impossible to say how something should be. All we can do is make observations and then we can then"}, {"timestamp": [4169.98, 4174.3], "text": " take our, you know, moral sensibilities, our intellectual sensibilities, and then"}, {"timestamp": [4174.3, 4179.26], "text": " claim it ought to be a different way or it is how it ought to be, but they're"}, {"timestamp": [4179.26, 4185.12], "text": " completely orthogonal. And so orthogonality is the other more general"}, {"timestamp": [4185.12, 4188.56], "text": " logical or philosophical complex, which is some things"}, {"timestamp": [4188.56, 4192.88], "text": " are just not correlated. They're just not related and no"}, {"timestamp": [4192.88, 4198.8], "text": " matter how much science we apply to existence to our"}, {"timestamp": [4198.8, 4202.8], "text": " subjective sense of being to intelligence. It may it might"}, {"timestamp": [4202.8, 4206.0], "text": " never make sense as to why we are sentient."}, {"timestamp": [4206.0, 4209.76], "text": " And so once you get to that point, it's just like, who cares, right?"}, {"timestamp": [4209.76, 4214.68], "text": " It's just like, I have a bookcase full of books trying to get to the bottom of it, and"}, {"timestamp": [4214.68, 4221.76], "text": " I've gone through quantum gravity and Eastern philosophy and everything else in between,"}, {"timestamp": [4221.76, 4224.38], "text": " and at the end of the day, it doesn't matter."}, {"timestamp": [4224.38, 4225.12], "text": " And I know I can hear all"}, {"timestamp": [4225.12, 4230.72], "text": " the optimistic nihilists saying, oh, you figured it out. That's optimistic nihilism. But I think"}, {"timestamp": [4230.72, 4235.12], "text": " that optimistic nihilism is wishful thinking for people that kind of want to take a shortcut."}, {"timestamp": [4235.84, 4238.48], "text": " It seems like a, what's the word I'm looking for?"}, {"timestamp": [4239.6, 4240.1], "text": " Cop out?"}, {"timestamp": [4241.12, 4245.36], "text": " No, no, no. One of those things that like like like a paradox, but there's a different word"}, {"timestamp": [4245.92, 4252.86], "text": " And I can't remember right now. Okay, but but like and but like I feel like optimism you can't almost"}, {"timestamp": [4253.48, 4260.4], "text": " Like it feels like that can't exist an optimistic nihilist in some sense, right? Well, yeah"}, {"timestamp": [4260.4, 4264.36], "text": " I think I think that um, I think oxymoron is the word you're looking for. Yeah. Yeah"}, {"timestamp": [4265.0, 4268.54], "text": " Yeah, so because I think that um, I think oxymoron is the word you're looking for. Yeah. Yeah, that was yeah Yeah. Yeah, so because if if you are"}, {"timestamp": [4269.88, 4274.56], "text": " Trapped in the quagmire of nihilism, then you still believe that nothing matters"}, {"timestamp": [4275.02, 4280.46], "text": " Right, and so then you can say oh, well nothing matters. Therefore. I'm free, but that feels really hollow"}, {"timestamp": [4281.24, 4284.96], "text": " whereas at least from my perspective if you move through that and"}, {"timestamp": [4287.96, 4292.8], "text": " It's it's not that you know, I say, who cares? That doesn't mean like nothing matters. It's like, actually,"}, {"timestamp": [4292.8, 4300.52], "text": " the only thing that matters is our experience. And by settling on that, by saying like, okay,"}, {"timestamp": [4300.52, 4306.12], "text": " logic, math, science, religion, spirituality, none of that has a satisfying answer."}, {"timestamp": [4306.12, 4311.92], "text": " But at the end of the day, I still have my experience of being, and I can't get rid of"}, {"timestamp": [4311.92, 4313.0], "text": " that."}, {"timestamp": [4313.0, 4314.26], "text": " That's what matters."}, {"timestamp": [4314.26, 4320.46], "text": " And then you arrive at that tiny little nucleus of, I know that I have a subjective experience"}, {"timestamp": [4320.46, 4322.4], "text": " and that matters to me."}, {"timestamp": [4322.4, 4328.72], "text": " And then if I make the assumption that everyone like me, you know, you, every other human, every animal with a sufficiently"}, {"timestamp": [4328.72, 4334.04], "text": " sophisticated brain, if I then make the assumption that they also have a"}, {"timestamp": [4334.04, 4337.88], "text": " subjective experience and that their experience matters to them, that's an"}, {"timestamp": [4337.88, 4342.4], "text": " entirely new framework of looking at existence. Say, actually what matters is"}, {"timestamp": [4342.4, 4345.28], "text": " that experience, whether it's individual"}, {"timestamp": [4345.28, 4348.72], "text": " or collective. And so that's why I say post-nihilism, because you get to that"}, {"timestamp": [4348.72, 4353.24], "text": " logic, that logical conclusion, I've used air quotes, that nothing matters. And it's"}, {"timestamp": [4353.24, 4358.4], "text": " like, but that's not true, right? If nothing matters, why do we continue to"}, {"timestamp": [4358.4, 4363.0], "text": " exist? You know, that ignores the biological reality that I'm here right"}, {"timestamp": [4363.0, 4365.84], "text": " now, and it's like, okay, that actually matters."}, {"timestamp": [4365.84, 4367.0], "text": " So let's go from there."}, {"timestamp": [4368.4, 4369.32], "text": " Yeah."}, {"timestamp": [4369.32, 4371.76], "text": " And hopefully that subjective experience is"}, {"timestamp": [4373.66, 4377.88], "text": " beautiful enough and filled with enough moments of love,"}, {"timestamp": [4377.88, 4381.44], "text": " let's say, where you want to, you know,"}, {"timestamp": [4381.44, 4386.2], "text": " make sure that more people have a great experience to"}, {"timestamp": [4386.56, 4388.56], "text": " Anyways, I think that's a great way to"}, {"timestamp": [4389.32, 4394.8], "text": " Do it to end the conversation, but David, thank you so much for taking the time to be with me this morning"}, {"timestamp": [4394.8, 4399.36], "text": " And thank you for all the content you're putting out. I'm so grateful that I found your channel on this"}, {"timestamp": [4400.16, 4407.12], "text": " Otherwise, what would have been an otherwise boring flight to Korea and it's no surprise to me at all that you're that you're blowing up"}, {"timestamp": [4407.52, 4412.22], "text": " And just keep doing what you're doing man, because it's a pleasure to follow so I'm talking to you and thank you"}, {"timestamp": [4412.44, 4416.24], "text": " Yeah, no, you're quite welcome. And thanks for the great talk and yeah"}, {"timestamp": [4416.24, 4418.98], "text": " Good luck with everything and keep doing the good work that you're doing"}, {"timestamp": [4419.56, 4422.32], "text": " All right, man. See you in the next episode everyone. Bye. Bye"}, {"timestamp": [4417.59, 4418.43], "text": " All right, man."}, {"timestamp": [4418.43, 4419.75], "text": " See you in the next episode, everyone."}, {"timestamp": [4419.75, 4420.59], "text": " Bye-bye."}]}