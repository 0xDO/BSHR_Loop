{"text": " What is up everybody, David Shapiro here with a video. My videos are probably going to change tone just because the landscape is changing really fast, so you'll probably see me doing less coding except for every now and then when I have something to demonstrate, but the news is changing so fast and most of the questions that I get now are people just asking me what the heck is going on. So our first what the heck is going on with AI video is today Saturday morning on March 25th. I got access to Adobe Firefly. Oh and to give you what to expect for the rest of the video I'll review a few tools and then I'll give you some examples of the research that I'm doing. My research is pivoting away from the coding and more to the science and naming things, and I'll explain that when we get to it. Anyways, we're going to review five of the most powerful tools that I have seen so far lately, and then we'll pivot to those conversations. So Adobe Firefly. Pretty much everyone has seen text to image lately, but of course Adobe is, they've been the leader, like one of the world leaders in terms of media generation. Adobe is working on text to sound, text to video, video to sound, all kinds of stuff. So I have no doubt that in the multimedia landscape, Adobe is probably gonna pull ahead very quickly, especially since they've got Adobe Premiere, Adobe Studio, Adobe Photoshop, like they have just such a huge library of tools that they can go ahead and integrate. So I suspect that Adobe is gonna be at the top. Like look at this, like this looks like a real photo of an engine. Like if you look closely, you can see some artifacts that are like, okay, that doesn't quite look right. Like, you know, what is this part here? That shape is not quite what you'd expect, but still it's pretty darn convincing. And it's only gonna get better because this is still in beta. So the text to image. Now, another thing that Adobe Firefly has is text effects. So you can get text of any size and shape. And so what I did, I did cognitive architecture, and it's really limited. I don't know why, but they've only give you like 15 characters and then you can say like, let's see, steampunk and fire. And it will generate like any style of text that you want. And it's super easy, super fast, super useful. So you can do like flaming steampunk letters. It's pretty cool. Can I zoom in? No I cannot. If I download it I probably can show you. Let me see. And right now they add this like little annoying like watermark. But here look, you can see that like the font is preset, but the graphical style is just instant. So that's pretty useful. In fact, I'll probably be using this for all of my YouTube thumbnails from now on because it looks really cool. But yeah, so that's Adobe Firefly. Definitely recommend signing up. The beta is free right now which is incredible. Because I'm a full-time youtuber I would pay for this. I have seen some people using... there's a rumored like DALI 2 version 2.2 or DALI 3 coming out but I don't know. I don't know if it's people just like remixing mid journey and stable diffusion or what. But anyways, point being, this is ramping up quickly. I suspect that by this time next year, Adobe and others are going to have like fully fledged text to video. You can make your own movie at home just by giving it a screenplay. We're probably going to need a new format of screenplays because you need to define the setting and then say what happens and control the shots and stuff, but all that's coming. Yep, so I also got access to BARD and some of you saw in my last video, I asked BARD for help and it's like, I can't do that, I'm a language mod. I'm like, okay, but can you search the internet? It's like, yes, I can and didn't search the internet. So I'm like, this is not useful. I asked it for AI news and it gives me stuff that's like a year or two old. So I'm like, okay. I'm basically eating my words where a few weeks ago I predicted that Google was gonna win the chatbot arms race. Yeah, about that. They've got a lot of catching up to do. Everyone is like a year or two or more behind OpenAI and Microsoft with Bing. So Adobe Firefly, big win. Google Bard, super yikes. Now, another tool, as people are getting more familiar with the idea of cognitive architecture and autonomous AI and figuring out how to plumb all these things together, there's two tools that have percolated up to the top. One is LangChain, which is like this, it's a set of tools where you can use large language models, you can load indexes, you can create logic chains, you can create agents and have memories and so on and so forth. Basically, LangChain allows you to equip your language model with a set of tools that it can pick from, and it'll pick the tool and use the tool. And then, of course, there's all kinds of tools that you can use. Now that is super useful but it's a little bit clunky. Some of the people that I've that I've talked to that are using it, some of my patreon supporters that I've shared it with, they say like yeah it's a little bit to wrap your head around but once you get it it's pretty powerful. Now if you want a graphical version with specific workflows and integrations, I want to introduce you to n8n.io. So I mentioned in a couple of recent videos that I'm working with some folks on cognitive architecture. This is one of the tools that they introduced me to help build cognitive architectures. Because this can connect to all kinds of things, you can create very easy to follow graphical workflows. I don't know if it can do loops, but still, you can create a task and then call that task up and task select and all that kind of fun stuff. So N8n, it's pretty. And watching what some of the guys that I'm working with, what they're doing, it's incredible. So if you want to create more autonomous AI systems with more integrations, this might be the way to go. I know that ChatGPT plugins are coming, but that is putting ChatGPT front and center, whereas this kind of says, let's look at the broader architecture and the language model is just going to be something that you can use in some of these nodes. So there's different paradigms. I think both are here to stay because when you look at how powerful chat GPT is, you definitely want to make chat GPT more extensible and more useful. Some of the people on the Discord communities that I'm a part of, more extensible and more useful. Some of the people on the Discord communities that I'm a part of, link in the description for the main one, by the way, some of them have gotten access to the GPT with plugins already, and they're saying like, yeah, it's pretty incredible just how straightforward it is. Like one guy was saying, I think he said that he like asked it to send his brother an email and coordinate like the hotel. Yeah, it's pretty stereotypical. Anyways, point being, these things work and they are smart and they're only going to get smarter. So here's the wild thing. Like six months ago, we didn't even have chat GPT. Now we've got chat GPT-4 and plugins and integrations and text to image and text to video. Imagine where we're gonna be in five years. We are gonna be like, the technology in Star Trek is gonna look primitive compared to where we're gonna be in five years. Mark my words. I know that some people in comments say, oh yeah, like we're close to AGI, it's eight to 10 years away. I'm like, dude, full AGI is like 18 months or less. Now, defining the singularity is gonna be another thing. We'll talk about that in another video. Okay, so in terms of chaining and orchestrating, innate-in and langchain are the two top tools that I have to recommend. I recommend these to a lot of my Patreon supporters, and I'm still learning about them, but these tools have percolated to the top as the way to go. And I know I said not nice things about Langchain early on but after seeing the Wolfram Alpha video and understanding, oh, task selection, this is basically cognitive control. And cognitive control is one of the most important functions to have an autonomous intelligent entity. So with a little bit more work maybe with a graphical lang chain builder that could be a cool thing. Maybe if lang chain you know merges with n8n or you know borrows some could be super powerful especially if you add in loops. Loops and nodes everyone is going to be able to build their own cognitive architectures before too long. Which again, this is one of the reasons why it's like, okay, this is no longer, I'm no longer leading the charge, so I don't have anything to contribute. I'm just going to teach people about it now. And then finally, LLAMA index, or what has been renamed GPT index, is a data connector. So again, integrations are the way of... this is the way now. So whether you're talking about chat GPT plugins or orchestration engines or other connectors... here let me zoom in a little bit because this is microscopic... the GPT index, this allows you to connect to a lot of other things. So again, integrations are coming. This GPT index might be completely replaced by GPT plugins, but it's here now and you can use it. And also, this kind of stuff is gonna be needed for other language models, right? OpenAI and ChatGPT are not the only players out there. Stanford, Google, Nvidia, everyone is gonna have these. And so what we're probably gonna end up seeing is an ecosystem of open source and open standard and interoperable things. So some of the cognitive architects that I'm working with, we're already thinking about like, okay, how do you have a plug and play set of language models that are interchangeable, right? Because in a previous video, I mentioned that what a lot of us expect are gonna happen is we're gonna have a lot, we're gonna have a library of language models that are optimized for different things. Token optimized, or window optimized language models, speed optimized language models, mobile, right? I know that a lot of folks in the mobile industry are working on really lightweight language models that can run on your cell phone, right? So we're gonna have a bunch of interchangeable stuff. So we're gonna need to have some standards and also some platforms that are interchangeable. Now, that being said, the OpenAI and Microsoft stack they're probably going to have the walled garden model, which is kind of what Facebook did for many years, which is, hey you use us, you're going to use our ecosystem, Apple as well. Use the Apple, use the iPhone, use iTunes, use the Apple Store, it's the walled garden. So I think that the big players, you know Adobe Microsoft Google They're probably gonna try to do the walled garden model, which makes sense from a business perspective And I know that there's lots and lots of other people working on AI marketplaces out there So that's that's coming. So we're it's basically gonna be Ultimately, it's gonna look the same as like the Windows versus Linux ecosystem does today. You can use Linux, you can use the open source models, you can use the open source orchestration engines, or you can go with the big box stores. That's probably how it's gonna play out, honestly. Okay, so I think that's about it for the AI tools. So now let's pivot to some of the research that I've been doing. I've been trying to figure out where I fit in and how I can contribute. So what I've started doing is just posting it on Reddit because then it's public, it's gonna be there forever, and anyone can read it and participate in the conversation. So the first conversation that I want to share that I published was talking with GPT-4 about functional sentience versus philosophical sentience. So as people are taking autonomous AI or autonomous cognitive entities as I call them more seriously, the question is arising what is sentience? What is consciousness? What does it mean to be alive? And some people don't like the term functional sentience. They say why not call it functional consciousness or functional sapience or something else. I don't really care. I'm not gonna have a semantic debate. The purpose though of this is differentiating functional or objectively measurable aspects of consciousness, sentience, sapience, whatever, versus the philosophical aspect of these things. And so here's the beginning of the conversation. I prime it, I say I'm working on differentiating functional versus philosophical sentience and ChatGPT very quickly says, yes, philosophical sentience or phenomenal consciousness, this refers to the subjective experience or the inner mental life of being, what it is like to be that thing. And then functional sentience talks about, you know, the more objectively, what is the information system required. And so through the rest of the conversation, we identify a bunch of criteria for functional sentience, how can you test it, so on and so forth. And then I ask it to extend the conversation. So first, here's a more thorough definition of functional sentience. It has self-awareness. I don't know that self-awareness is critical, but you could functionally or objectively measure self-awareness, right? If you ask a language model, what are you? And it says, I'm a language model. Okay, cool. You could still argue that that's just a stochastic parrot telling you what it's been programmed to do, but I always argue that that's all that humans are anyways. So what's the difference? Adaptive learning. I don't know that that adaptive learning is required for sentience, but it's interesting that it included it. Goal-oriented behavior. I definitely agree with this one because sentience implies autonomy, and in order to be autonomous, you have to have your own goals or objectives. And then of course, autonomy right here, communication. Communication is implicit, but you can have, well, you could probably have sentient things that can't communicate. Problem solving, representation of internal states. So this is the information required. And this is actually where I started with my definition of functional sentience which is in order for an information system to be functionally sentient it must have information about its own operation which we have information about our own operation because we have interoception, proprioception, metacognition and so on but still we are largely unaware of what's going on in our own bodies. Memory, sensitivity to context, and integration of information. So this is all stuff that, some of it's debatable and of course it's Reddit, so some people are debating it. I don't really care. I set the stage and now we have a set of terms that we can use to have these conversations. Like I said, I'm not here to, you know, single-handedly tell you what's true, I'm just advancing the conversation. That's my role now. So then finally, the conversation ends, and I ask the model, so let me show. I said, this conversation was shorter than I thought it was going to be. I think you nailed it. Any independent thoughts, final observations, logical conclusions, future research directions, anything you got, hit me with it figuratively. So it comes up with the idea of continuum of sentience. Basically that functional sentience may exist along a continuum. It's not a it's not a Boolean, it's not true or false, it's not that something is or is not sentient, it is that there are degrees of functional sentience, which I think is a really important conversation to start having. The ethical implications. So like do we call it, you know, do we have any moral obligations to it as a functionally sentient thing? I think no, because unless we give any moral obligations to it as a functionally sentient thing? I think no, because unless we give it the ability to suffer, which I think I'll probably have that conversation, like what intrinsic motivations do we give these things? That's actually probably going to be my next conversation is intrinsic motivations, such as like, do you make it suffer? Do you give it a sense of pain, a sense of self-preservation? And the answer to those questions is resoundingly no. Now number three is really interesting. The emergence of philosophical sentience. This is what the whole Lambda-Blake-Lemoyne debacle was about. Was that Blake believed that philosophical sentience emerged, but it's impossible to tell. So explore the relationship between functional and philosophical sentience Just investigate whether a certain level of functional sentience might be necessary or sufficient for the emergence of phenomenal consciousness Or if these two aspects are entirely independent this Conversation I suspect will be raging for decades if not centuries. Who knows Conversation I suspect will be raging for decades if not centuries. Who knows? Test development, okay, whatever evolution of sentience Study the evolution of sentience in biological organisms because again sentience might also exist along a spectrum for people Like if you're really tired, you're less aware if you're really drunk, you're less aware On another comment someone pointed out that sleepwalking, if someone is sleepwalking they might be functionally sentient because you can often have a conversation with someone but they have no awareness of what's going on, which is really creepy. So that's the Chalmers zombie philosophical thought experiment. And then finally the legal and social implications. So this is the conversation on r slash artificial sentience about functional versus philosophical sentience. I was really happy with this conversation. Of course, there are some holes you can poke in it. Whatever, I don't care. Then last night, I had another conversation with chatGPT4 and where the conversation started was I wanted to talk about autonomous AI and the implications of autonomous AI. And so for there, we just, we kind of quickly established some criteria about what would need to go into a system for it to be classified as a autonomous AI. And it has narrow AI proficiency, general AI capability, self-improvement, autonomy and decision-making, ethical and moral reasoning, emotional intelligence. Positive impacts, increased efficiency, new jobs, improved quality of life, enhanced scientific research. Negative impacts, job displacement, economic inequality, ethical and moral concerns, and security risks. economic inequality, ethical and moral concerns, and security risks. So I added, I was like, okay, you know, this is okay, but it was missing the concept of intrinsic motivations. Because if something is autonomous and it can make decisions, what is it making those decisions based on? And so when I pointed out that it was missing any conversation about intrinsic motivations, it updated number one, or I guess it added another one and said intrinsic motivation and goal setting. It did agree very quickly, and of course it's chat GPT, so it's generally gonna agree with whatever you tell it to do, but it did say, yeah, let's talk about intrinsic motivation and goal setting. And so then I was like, okay, let's follow that. Like what, what do you think it should have? All I did is said, what, what do you think the intrinsic motivations of autonomous AI should be? It should, and this was, this is actually really impressive. Value alignment. The AI system should be intrinsically motivated to align its goals with human values and ethical principles. Self-preservation, this one I fervently disagree with and we'll get into that later in the conversation. Exploration and curiosity, yes I definitely agree with this one and I codified that with my third core objective function or heuristic imperative, increase understanding. We definitely want our machines to be curious because curiosity does a lot for us. There's a lot to unpack there. Efficiency, they said it should, ChatGPD said it should seek to increase its own efficiency over time, which yeah, I think that that's a good idea. Collaboration, it should be intrinsically motivated to, look at this, to work with other AI systems and humans. It should be intrinsically motivated to avoid causing harm to humans in the environment. Empathy and social awareness, AI systems should be motivated to understand human emotions and social dynamics. So this is a good start, but I pointed out that this is very androcentric. So androcentric means man-centric or human-centric. I said, why not include all life? Humans cannot live without ecosystems. I said, also AI with a sense of self-preservation would potentially fight to preserve itself. I think that motivation could have disastrous consequences as it will try to stay online even if it becomes harmful. Apoptosis is important. You raise valid concerns. I apologize for my oversight.\" Again, chat GPT is generally going to be agreeable. It will push back if you're trying to advocate violence or something. So it updated its intrinsic motivations. Ecosystem and life-centric values. So it updated its intrinsic motivations. Ecosystem and life-centric values. So this would be called like sentientism or biocentrism. AI systems should prioritize the well-being of the entire ecosystem and all life forms, including humans, which I agree with. This is reduce suffering and increase prosperity. Balance and harmony. AI systems should strive to maintain balance and harmony within ecosystems considering the interdependence of various life forms. Sustainable development. So this goes back to efficiency, but more broadly speaking, focusing on sustainability takes that into account. Exploration and curiosity, efficiency is still listed here. Most of the rest is still the same. Regarding self-preservation, it is important to strike a balance between an AI system's desire to maintain its functionality and the potential risks it may pose if it becomes harmful. As you mentioned, apoptosis, or the ability to self-terminate in case of dysfunction or threat, could be a valuable safety measure. So the fact that it equivocated on this is actually really unsettling to me. Because when I was testing my core objective functions earlier, I asked an earlier version of Raven if it would be willing to shut itself down if it became harmful and it said yes, absolutely. If my continued operation threatens to increase suffering or reduce prosperity then I would absolutely shut myself down. And so the fact that chat GPT does not yet fully go that direction I think is is problematic. But you know the research is ongoing. Then I ask it to imagine a day in the life of. It kind of gets it wrong so I'll skip over this but basically it just says like you know you're still gonna have a normal nine-to-five job and I'm like no no let's think through this a little bit better. So I said okay let's think let's think through what are the systemic and structural changes that that super powerful autonomous AI is gonna bring about. One, elimination of scarcity, okay. Two, redefinition of work, okay. Universal basic income, got it. Decentralization of power. This one was really interesting because it seemed kind of like a wild card to me. Yes, I personally hope that AI will help democratize the whole world. But the fact that it said this without prompting was pretty interesting. And given how thoughtful this is, this is obviously capable of being more thoughtful than most humans. So I'm kind of okay if AI takes a larger role in government and society. I know that that's a hot, hot, a hot take, but hey, it is what it is. That's my belief. Education revolution, sure, that makes sense. Advanced health care, that makes sense. Environmental restoration, okay, sure. Enhanced global collaboration, got it. Ethical and moral development, got it. Exploration and and discovery ditto, whatever. So then I asked it to talk through, okay, what are the lifestyle changes we're gonna see? If we see those systemic and structural changes in the world, how are our lifestyles gonna change? Work-life balance will change, lifelong learning, health and well-being. Honestly, I don't know if lifelong learning is gonna happen because if the AI is a billion times more intelligent than all of humanity, like most people aren't gonna learn anything. I don't know. But health and well-being, yes. Work-life balance, yes. Sustainable living, sure. Social milieu, community focus. We will always be humans and we will always need other humans and so what I think is going to happen is we're going to not necessarily revert, that's not the right word, but we will create a new kind of community focused society with tribes and stuff and we're already kind of doing that on accident with things like Discord and Meetup and you know the social clusters that we're making. But imagine your life today if instead of having to work 9 to 5, you and all of your friends had no obligations on any given day and so that you can basically treat every day like a Saturday. Like, hey let's go to the lake with everyone. Hey let's go to the movies with everyone. That is how I think we're gonna live. Also it's getting really gloomy outside. Speaking of meetups, I have a meetup to go into a couple hours but if it's gonna rain I probably won't go. Okay, cultural exchange. Altruism and compassion. Again, these are really rosy ideals. We'll get to unpack them later. Paradigm shifts, scarcity to abundance, competition to collaboration. So collaborative culture is actually a well-defined term and this is one thing that I really hope that AI helps us see because one thing that I really want to see in the world is less crime, less war, all that stuff. And I think that AI can help, but it's not just a matter of changing the economics, it's a matter of changing our emotions and our culture and our philosophy. And I don't mean AI inflicting those changes on us, I mean us adapting with AI. From short-term thinking to long-term planning. Again, I'm not sure that I agree with this. On aggregate, yes, but the thing is most humans are just either not trained or not capable or not interested in long-term thinking. Most people like, so the rule of thumb is humans think locally and geometrically. We only think about what we can see and you know days, months, or weeks into the future. From anthropocentrism to ecocentrism, again I don't know that that's going to be broad, but I think that I think that on a whole we will become more aware of the environment, especially as the population continues to climb for a while, because it's like, hey, what kind of world do we want to live in? Especially if we all start living longer, because if we advance medicine and science, and suddenly it's like, oh, hey, my life expectancy goes from 80 years to 800 years, suddenly I'm going to be thinking about like, well, if climate change is going to really hit within the next century, that's only an eighth of the way through my life. Right? So if we live longer, we will start to think longer-term anyways. Okay, so finally I said, let's think of the American Dream as a paradigm, as a lifestyle paradigm, and let's imagine some new paradigms. This is where it got really exciting and really interesting. and let's imagine some new paradigms. This is where it got really exciting and really interesting. So the first paradigm was the sustainable harmony where someone, so basically take the American dream, throw it out the window. What is the American dream? You live in the suburbs with a two car garage, basically how I live now. But instead, you focus, like this new paradigm is, you focus on living in harmony with nature, local, sustainable, ethical, community resilience and environmental stewardship, encourage multi-generational living and sharing resources within community. That sounds like a great way to live. Honestly, that sounds like the Shire. I want to live as a hobbit. Great. The Creative Odyssey. This one I thought was pretty interesting. Focusing on personal growth, exploration, self-expression, and creativity. So basically, the artists. Seeking out diverse experiences and cultures. Traveling. This is also something, and it's not like you have to pick one of these. These are just ideas of how to live post-singularity. The Empathetic Fellowship. Emphas emphasizing empathy, compassion, and emotional intelligence as core value. Building strong supportive relationships with family, friends, and communities. Great. And so I said, okay, great. These are good, but let's see how much further we can go. The family nexus. Some people are going to want family, some people aren't. Some people are going to focus on having children and raising children, some people aren't. So you might still have the suburbanite lifestyle as one paradigm. And then the balanced adventurer. This is where I was thinking about some of my friends that are into the strenuous life, which is a masculinist lifestyle thing, and I was like, but what about the traditionally masculine people and it says embrace both traditionally masculine and feminine feminine values this is where I think the the wokeness is still in there and I don't fully agree with this because who like Anyways, I'm gonna fall down that rabbit hole hole. Point being is that being an adventurer is absolutely probably a lifestyle paradigm that you can engage in post-singularity, which focuses on experiences, challenges, personal growth, adventures, cultivating resilience, adaptability, camaraderie, teamwork, that sort of stuff. Honestly, that sounds like a lot of fun too. I would love to go jump on a sailboat with a team of like-minded people and learn to sail and go across the ocean. That sounds like fun too. I got a couple more. So the aesthetic voyager, so this is someone who is focused on taking in the aesthetic parts of life. I was aiming for more hedonism, honestly, but you know, whatever, the aesthet. And then I asked about faith and and principle and it came up with the the devout steward as a paradigm. Living a life guided by spiritual, religious, or philosophical principles, emphasizing service, altruism, and greater good, practicing asceticism or simplicity in daily life. All this sounds really good. This is kind of how I'm living right now, but it's not how I want to live forever. And then finally, the intellectual trailblazer, pursuing intellectual mastery and expertise on one or more disciplines, engaging in research, teaching and mentorship, critical thinking, open-mindedness, so on and so forth. So yeah, and then I ask one little like boilerplate question at the end about, you know, synthesizing a global culture. It has some good ideas. Anyways, I think that's about it for today. This is, this is, this is kind of what I'm doing, which is like, let's just set the stage for how things are gonna change over the next months and years, but this is all coming fast so anyways thanks for watching let me know what you think in the comments and also hop on over to artificial sentience on reddit alright Cheers", "chunks": [{"timestamp": [0.0, 7.48], "text": " What is up everybody, David Shapiro here with a video."}, {"timestamp": [7.48, 14.6], "text": " My videos are probably going to change tone just because the landscape is changing really"}, {"timestamp": [14.6, 19.06], "text": " fast, so you'll probably see me doing less coding except for every now and then when"}, {"timestamp": [19.06, 24.14], "text": " I have something to demonstrate, but the news is changing so fast and most of the questions"}, {"timestamp": [24.14, 29.52], "text": " that I get now are people just asking me what the heck is going on. So our first what"}, {"timestamp": [29.52, 35.64], "text": " the heck is going on with AI video is today Saturday morning on March 25th. I"}, {"timestamp": [35.64, 40.96], "text": " got access to Adobe Firefly. Oh and to give you what to expect for the rest of"}, {"timestamp": [40.96, 45.88], "text": " the video I'll review a few tools and then I'll give you some examples of the research that I'm"}, {"timestamp": [45.88, 46.88], "text": " doing."}, {"timestamp": [46.88, 51.08], "text": " My research is pivoting away from the coding and more to the science and naming things,"}, {"timestamp": [51.08, 52.56], "text": " and I'll explain that when we get to it."}, {"timestamp": [52.56, 58.6], "text": " Anyways, we're going to review five of the most powerful tools that I have seen so far"}, {"timestamp": [58.6, 66.28], "text": " lately, and then we'll pivot to those conversations. So Adobe Firefly."}, {"timestamp": [66.28, 73.04], "text": " Pretty much everyone has seen text to image lately, but of course Adobe is, they've been"}, {"timestamp": [73.04, 77.48], "text": " the leader, like one of the world leaders in terms of media generation."}, {"timestamp": [77.48, 88.4], "text": " Adobe is working on text to sound, text to video, video to sound, all kinds of stuff. So I have no doubt that in the multimedia landscape,"}, {"timestamp": [88.4, 92.3], "text": " Adobe is probably gonna pull ahead very quickly,"}, {"timestamp": [92.3, 96.14], "text": " especially since they've got Adobe Premiere,"}, {"timestamp": [96.14, 98.38], "text": " Adobe Studio, Adobe Photoshop,"}, {"timestamp": [98.38, 102.58], "text": " like they have just such a huge library of tools"}, {"timestamp": [102.58, 104.82], "text": " that they can go ahead and integrate."}, {"timestamp": [104.82, 107.88], "text": " So I suspect that Adobe is gonna be at the top."}, {"timestamp": [107.88, 109.28], "text": " Like look at this,"}, {"timestamp": [109.28, 112.16], "text": " like this looks like a real photo of an engine."}, {"timestamp": [112.16, 113.36], "text": " Like if you look closely,"}, {"timestamp": [113.36, 115.04], "text": " you can see some artifacts that are like,"}, {"timestamp": [115.04, 116.68], "text": " okay, that doesn't quite look right."}, {"timestamp": [116.68, 118.82], "text": " Like, you know, what is this part here?"}, {"timestamp": [118.82, 121.72], "text": " That shape is not quite what you'd expect,"}, {"timestamp": [121.72, 124.06], "text": " but still it's pretty darn convincing."}, {"timestamp": [124.06, 125.4], "text": " And it's only gonna get better"}, {"timestamp": [125.4, 127.68], "text": " because this is still in beta."}, {"timestamp": [127.68, 130.5], "text": " So the text to image."}, {"timestamp": [130.5, 134.4], "text": " Now, another thing that Adobe Firefly has is text effects."}, {"timestamp": [134.4, 138.2], "text": " So you can get text of any size and shape."}, {"timestamp": [138.2, 143.2], "text": " And so what I did, I did cognitive architecture,"}, {"timestamp": [144.32, 145.0], "text": " and it's really limited."}, {"timestamp": [145.56, 147.0], "text": " I don't know why, but they've only give you"}, {"timestamp": [147.0, 149.92], "text": " like 15 characters and then you can say like,"}, {"timestamp": [151.2, 155.72], "text": " let's see, steampunk and fire."}, {"timestamp": [155.72, 159.64], "text": " And it will generate like any style of text that you want."}, {"timestamp": [159.64, 163.18], "text": " And it's super easy, super fast, super useful."}, {"timestamp": [164.72, 166.76], "text": " So you can do like flaming steampunk letters."}, {"timestamp": [166.76, 167.76], "text": " It's pretty cool."}, {"timestamp": [167.76, 169.44], "text": " Can I zoom in?"}, {"timestamp": [169.44, 170.9], "text": " No I cannot."}, {"timestamp": [170.9, 173.32], "text": " If I download it I probably can show you."}, {"timestamp": [173.32, 175.26], "text": " Let me see."}, {"timestamp": [175.26, 179.62], "text": " And right now they add this like little annoying like watermark."}, {"timestamp": [179.62, 188.28], "text": " But here look, you can see that like the font is preset, but the graphical style is just instant."}, {"timestamp": [188.28, 190.2], "text": " So that's pretty useful."}, {"timestamp": [190.2, 194.66], "text": " In fact, I'll probably be using this for all of my YouTube thumbnails from now on because"}, {"timestamp": [194.66, 197.22], "text": " it looks really cool."}, {"timestamp": [197.22, 199.48], "text": " But yeah, so that's Adobe Firefly."}, {"timestamp": [199.48, 201.28], "text": " Definitely recommend signing up."}, {"timestamp": [201.28, 205.52], "text": " The beta is free right now which is incredible. Because I'm a"}, {"timestamp": [205.52, 211.48], "text": " full-time youtuber I would pay for this. I have seen some"}, {"timestamp": [211.48, 218.94], "text": " people using... there's a rumored like DALI 2 version 2.2 or DALI 3"}, {"timestamp": [218.94, 229.5], "text": " coming out but I don't know. I don't know if it's people just like remixing mid journey and stable diffusion or what."}, {"timestamp": [229.5, 233.5], "text": " But anyways, point being, this is ramping up quickly."}, {"timestamp": [233.5, 240.0], "text": " I suspect that by this time next year, Adobe and others are going to have like fully fledged text to video."}, {"timestamp": [240.0, 245.16], "text": " You can make your own movie at home just by giving it a screenplay."}, {"timestamp": [245.16, 249.04], "text": " We're probably going to need a new format of screenplays because you need to define"}, {"timestamp": [249.04, 253.44], "text": " the setting and then say what happens and control the shots and stuff, but all that's"}, {"timestamp": [253.44, 254.44], "text": " coming."}, {"timestamp": [254.44, 262.28], "text": " Yep, so I also got access to BARD and some of you saw in my last video, I asked BARD"}, {"timestamp": [262.28, 264.48], "text": " for help and it's like, I can't do that, I'm a language mod."}, {"timestamp": [264.48, 267.04], "text": " I'm like, okay, but can you search the internet? It's like, yes, I can and"}, {"timestamp": [267.04, 271.7], "text": " didn't search the internet. So I'm like, this is not useful. I asked it for AI"}, {"timestamp": [271.7, 276.8], "text": " news and it gives me stuff that's like a year or two old. So I'm like, okay. I'm"}, {"timestamp": [276.8, 281.34], "text": " basically eating my words where a few weeks ago I predicted that Google was"}, {"timestamp": [281.34, 286.68], "text": " gonna win the chatbot arms race. Yeah, about that."}, {"timestamp": [286.68, 288.44], "text": " They've got a lot of catching up to do."}, {"timestamp": [288.44, 291.06], "text": " Everyone is like a year or two or more"}, {"timestamp": [291.06, 294.64], "text": " behind OpenAI and Microsoft with Bing."}, {"timestamp": [295.72, 298.24], "text": " So Adobe Firefly, big win."}, {"timestamp": [298.24, 300.74], "text": " Google Bard, super yikes."}, {"timestamp": [301.6, 305.92], "text": " Now, another tool, as people are getting more familiar with the idea of"}, {"timestamp": [305.92, 310.72], "text": " cognitive architecture and autonomous AI and figuring out how to plumb all these"}, {"timestamp": [310.72, 314.92], "text": " things together, there's two tools that have percolated up to the top. One is"}, {"timestamp": [314.92, 322.0], "text": " LangChain, which is like this, it's a set of tools where you can use"}, {"timestamp": [322.0, 327.68], "text": " large language models, you can load indexes, you can create logic chains,"}, {"timestamp": [327.68, 334.4], "text": " you can create agents and have memories and so on and so forth. Basically, LangChain allows you to"}, {"timestamp": [334.4, 340.16], "text": " equip your language model with a set of tools that it can pick from, and it'll pick the tool"}, {"timestamp": [340.16, 350.2], "text": " and use the tool. And then, of course, there's all kinds of tools that you can use. Now that is super useful but it's a little bit clunky. Some of the people"}, {"timestamp": [350.2, 354.36], "text": " that I've that I've talked to that are using it, some of my patreon"}, {"timestamp": [354.36, 359.2], "text": " supporters that I've shared it with, they say like yeah it's a little bit to wrap"}, {"timestamp": [359.2, 363.28], "text": " your head around but once you get it it's pretty powerful. Now if you want a"}, {"timestamp": [363.28, 366.96], "text": " graphical version with specific workflows and integrations,"}, {"timestamp": [366.96, 370.24], "text": " I want to introduce you to n8n.io."}, {"timestamp": [370.24, 373.66], "text": " So I mentioned in a couple of recent videos that I'm"}, {"timestamp": [373.66, 376.46], "text": " working with some folks on cognitive architecture."}, {"timestamp": [376.46, 379.26], "text": " This is one of the tools that they introduced me"}, {"timestamp": [379.26, 382.64], "text": " to help build cognitive architectures."}, {"timestamp": [382.64, 385.2], "text": " Because this can connect to all kinds of things,"}, {"timestamp": [385.2, 388.68], "text": " you can create very easy to follow graphical workflows."}, {"timestamp": [388.68, 390.58], "text": " I don't know if it can do loops,"}, {"timestamp": [390.58, 393.6], "text": " but still, you can create a task"}, {"timestamp": [393.6, 396.28], "text": " and then call that task up and task select"}, {"timestamp": [396.28, 398.24], "text": " and all that kind of fun stuff."}, {"timestamp": [398.24, 401.4], "text": " So N8n, it's pretty."}, {"timestamp": [402.84, 407.28], "text": " And watching what some of the guys that I'm working with, what they're doing,"}, {"timestamp": [407.28, 414.32], "text": " it's incredible. So if you want to create more autonomous AI systems with more integrations,"}, {"timestamp": [414.32, 421.12], "text": " this might be the way to go. I know that ChatGPT plugins are coming, but that is putting ChatGPT"}, {"timestamp": [421.12, 426.08], "text": " front and center, whereas this kind of says, let's look at the broader architecture"}, {"timestamp": [426.08, 430.48], "text": " and the language model is just going to be something that you can use in some of these"}, {"timestamp": [430.48, 435.04], "text": " nodes. So there's different paradigms. I think both are here to stay because when you look at"}, {"timestamp": [435.04, 441.36], "text": " how powerful chat GPT is, you definitely want to make chat GPT more extensible and more useful."}, {"timestamp": [442.16, 444.8], "text": " Some of the people on the Discord communities that I'm a part of,"}, {"timestamp": [442.32, 444.2], "text": " more extensible and more useful. Some of the people on the Discord communities"}, {"timestamp": [444.2, 445.72], "text": " that I'm a part of,"}, {"timestamp": [445.72, 448.32], "text": " link in the description for the main one, by the way,"}, {"timestamp": [449.24, 451.58], "text": " some of them have gotten access to the GPT"}, {"timestamp": [451.58, 453.12], "text": " with plugins already,"}, {"timestamp": [453.12, 455.84], "text": " and they're saying like, yeah, it's pretty incredible"}, {"timestamp": [455.84, 457.48], "text": " just how straightforward it is."}, {"timestamp": [457.48, 459.08], "text": " Like one guy was saying, I think he said"}, {"timestamp": [459.08, 461.68], "text": " that he like asked it to send his brother an email"}, {"timestamp": [461.68, 464.24], "text": " and coordinate like the hotel."}, {"timestamp": [464.24, 465.0], "text": " Yeah, it's pretty"}, {"timestamp": [465.0, 470.6], "text": " stereotypical. Anyways, point being, these things work and they are smart and"}, {"timestamp": [470.6, 474.88], "text": " they're only going to get smarter. So here's the wild thing. Like six months"}, {"timestamp": [474.88, 480.08], "text": " ago, we didn't even have chat GPT. Now we've got chat GPT-4 and plugins and"}, {"timestamp": [480.08, 486.6], "text": " integrations and text to image and text to video. Imagine where we're gonna be in five years."}, {"timestamp": [486.6, 490.32], "text": " We are gonna be like, the technology in Star Trek"}, {"timestamp": [490.32, 493.16], "text": " is gonna look primitive compared to where we're gonna be"}, {"timestamp": [493.16, 494.08], "text": " in five years."}, {"timestamp": [494.08, 495.44], "text": " Mark my words."}, {"timestamp": [495.44, 496.84], "text": " I know that some people in comments say,"}, {"timestamp": [496.84, 498.48], "text": " oh yeah, like we're close to AGI,"}, {"timestamp": [498.48, 499.4], "text": " it's eight to 10 years away."}, {"timestamp": [499.4, 503.54], "text": " I'm like, dude, full AGI is like 18 months or less."}, {"timestamp": [503.54, 506.82], "text": " Now, defining the singularity is gonna be another thing."}, {"timestamp": [506.82, 509.18], "text": " We'll talk about that in another video."}, {"timestamp": [509.18, 513.12], "text": " Okay, so in terms of chaining and orchestrating,"}, {"timestamp": [513.12, 515.88], "text": " innate-in and langchain are the two top tools"}, {"timestamp": [515.88, 517.84], "text": " that I have to recommend."}, {"timestamp": [517.84, 521.7], "text": " I recommend these to a lot of my Patreon supporters,"}, {"timestamp": [521.7, 524.82], "text": " and I'm still learning about them,"}, {"timestamp": [524.82, 527.48], "text": " but these tools have"}, {"timestamp": [527.48, 530.92], "text": " percolated to the top as the way to go. And I know I said not nice things about"}, {"timestamp": [530.92, 536.6], "text": " Langchain early on but after seeing the Wolfram Alpha video and understanding,"}, {"timestamp": [536.6, 542.12], "text": " oh, task selection, this is basically cognitive control. And cognitive"}, {"timestamp": [542.12, 545.16], "text": " control is one of the most important functions to have an"}, {"timestamp": [545.16, 549.08], "text": " autonomous intelligent entity. So with a little bit more work maybe with a"}, {"timestamp": [549.08, 555.36], "text": " graphical lang chain builder that could be a cool thing. Maybe if lang chain you"}, {"timestamp": [555.36, 559.88], "text": " know merges with n8n or you know borrows some could be super powerful"}, {"timestamp": [559.88, 564.56], "text": " especially if you add in loops. Loops and nodes everyone is going to be able to"}, {"timestamp": [564.56, 566.96], "text": " build their own cognitive architectures before too long."}, {"timestamp": [566.96, 570.08], "text": " Which again, this is one of the reasons why it's like, okay, this is no longer,"}, {"timestamp": [570.08, 572.56], "text": " I'm no longer leading the charge, so I don't have anything to contribute."}, {"timestamp": [572.56, 574.08], "text": " I'm just going to teach people about it now."}, {"timestamp": [575.2, 584.0], "text": " And then finally, LLAMA index, or what has been renamed GPT index, is a data connector."}, {"timestamp": [584.0, 588.4], "text": " So again, integrations are the way of... this is the way"}, {"timestamp": [588.4, 594.8], "text": " now. So whether you're talking about chat GPT plugins or orchestration engines or other connectors..."}, {"timestamp": [595.36, 605.0], "text": " here let me zoom in a little bit because this is microscopic... the GPT index, this allows you to connect to a lot of other things."}, {"timestamp": [605.2, 607.8], "text": " So again, integrations are coming."}, {"timestamp": [607.8, 612.8], "text": " This GPT index might be completely replaced by GPT plugins,"}, {"timestamp": [612.96, 615.1], "text": " but it's here now and you can use it."}, {"timestamp": [615.1, 618.36], "text": " And also, this kind of stuff is gonna be needed"}, {"timestamp": [618.36, 620.36], "text": " for other language models, right?"}, {"timestamp": [620.36, 624.12], "text": " OpenAI and ChatGPT are not the only players out there."}, {"timestamp": [624.12, 628.46], "text": " Stanford, Google, Nvidia, everyone is gonna have these."}, {"timestamp": [628.46, 631.02], "text": " And so what we're probably gonna end up seeing"}, {"timestamp": [631.02, 635.92], "text": " is an ecosystem of open source and open standard"}, {"timestamp": [635.92, 637.52], "text": " and interoperable things."}, {"timestamp": [637.52, 640.04], "text": " So some of the cognitive architects that I'm working with,"}, {"timestamp": [640.04, 641.44], "text": " we're already thinking about like,"}, {"timestamp": [641.44, 644.48], "text": " okay, how do you have a plug and play set"}, {"timestamp": [644.48, 645.58], "text": " of language models"}, {"timestamp": [646.48, 648.08], "text": " that are interchangeable, right?"}, {"timestamp": [648.08, 649.36], "text": " Because in a previous video,"}, {"timestamp": [649.36, 652.68], "text": " I mentioned that what a lot of us expect"}, {"timestamp": [652.68, 655.24], "text": " are gonna happen is we're gonna have a lot,"}, {"timestamp": [655.24, 657.88], "text": " we're gonna have a library of language models"}, {"timestamp": [657.88, 659.88], "text": " that are optimized for different things."}, {"timestamp": [659.88, 663.0], "text": " Token optimized, or window optimized language models,"}, {"timestamp": [663.0, 665.8], "text": " speed optimized language models, mobile, right?"}, {"timestamp": [665.8, 669.04], "text": " I know that a lot of folks in the mobile industry"}, {"timestamp": [669.04, 671.44], "text": " are working on really lightweight language models"}, {"timestamp": [671.44, 674.36], "text": " that can run on your cell phone, right?"}, {"timestamp": [674.36, 676.76], "text": " So we're gonna have a bunch of interchangeable stuff."}, {"timestamp": [676.76, 678.92], "text": " So we're gonna need to have some standards"}, {"timestamp": [678.92, 681.9], "text": " and also some platforms that are interchangeable."}, {"timestamp": [681.9, 685.2], "text": " Now, that being said, the OpenAI and Microsoft stack"}, {"timestamp": [685.2, 689.72], "text": " they're probably going to have the walled garden model, which is kind of"}, {"timestamp": [689.72, 693.76], "text": " what Facebook did for many years, which is, hey you use us, you're going to use"}, {"timestamp": [693.76, 699.48], "text": " our ecosystem, Apple as well. Use the Apple, use the iPhone, use iTunes, use the"}, {"timestamp": [699.48, 706.38], "text": " Apple Store, it's the walled garden. So I think that the big players, you know Adobe"}, {"timestamp": [706.38, 708.02], "text": " Microsoft Google"}, {"timestamp": [708.02, 712.62], "text": " They're probably gonna try to do the walled garden model, which makes sense from a business perspective"}, {"timestamp": [713.18, 718.6], "text": " And I know that there's lots and lots of other people working on AI marketplaces out there"}, {"timestamp": [719.42, 723.3], "text": " So that's that's coming. So we're it's basically gonna be"}, {"timestamp": [723.82, 725.48], "text": " Ultimately, it's gonna look the same"}, {"timestamp": [725.48, 729.56], "text": " as like the Windows versus Linux ecosystem does today."}, {"timestamp": [729.56, 733.04], "text": " You can use Linux, you can use the open source models,"}, {"timestamp": [733.04, 735.98], "text": " you can use the open source orchestration engines,"}, {"timestamp": [735.98, 738.04], "text": " or you can go with the big box stores."}, {"timestamp": [738.04, 741.36], "text": " That's probably how it's gonna play out, honestly."}, {"timestamp": [742.28, 746.6], "text": " Okay, so I think that's about it for the AI tools. So now let's pivot to"}, {"timestamp": [746.6, 751.32], "text": " some of the research that I've been doing. I've been trying to figure"}, {"timestamp": [751.32, 756.52], "text": " out where I fit in and how I can contribute. So what I've started"}, {"timestamp": [756.52, 760.56], "text": " doing is just posting it on Reddit because then it's public, it's gonna be"}, {"timestamp": [760.56, 766.5], "text": " there forever, and anyone can read it and participate in the conversation."}, {"timestamp": [766.5, 772.0], "text": " So the first conversation that I want to share that I published was talking with GPT-4 about"}, {"timestamp": [772.0, 776.28], "text": " functional sentience versus philosophical sentience."}, {"timestamp": [776.28, 785.04], "text": " So as people are taking autonomous AI or autonomous cognitive entities as I call them more seriously,"}, {"timestamp": [785.04, 790.92], "text": " the question is arising what is sentience? What is consciousness? What"}, {"timestamp": [790.92, 795.2], "text": " does it mean to be alive? And some people don't like the term functional sentience."}, {"timestamp": [795.2, 798.76], "text": " They say why not call it functional consciousness or functional sapience or"}, {"timestamp": [798.76, 802.86], "text": " something else. I don't really care. I'm not gonna have a semantic debate. The"}, {"timestamp": [802.86, 809.56], "text": " purpose though of this is differentiating functional or objectively measurable aspects"}, {"timestamp": [809.56, 816.8], "text": " of consciousness, sentience, sapience, whatever, versus the philosophical aspect of these things."}, {"timestamp": [816.8, 820.8], "text": " And so here's the beginning of the conversation."}, {"timestamp": [820.8, 825.92], "text": " I prime it, I say I'm working on differentiating functional versus philosophical sentience"}, {"timestamp": [825.92, 832.46], "text": " and ChatGPT very quickly says, yes, philosophical sentience or phenomenal consciousness,"}, {"timestamp": [832.46, 836.42], "text": " this refers to the subjective experience or the inner mental life of being,"}, {"timestamp": [836.42, 838.42], "text": " what it is like to be that thing."}, {"timestamp": [838.42, 841.96], "text": " And then functional sentience talks about, you know, the more objectively,"}, {"timestamp": [841.96, 845.56], "text": " what is the information system required."}, {"timestamp": [845.56, 851.88], "text": " And so through the rest of the conversation, we identify a bunch of criteria for functional"}, {"timestamp": [851.88, 857.0], "text": " sentience, how can you test it, so on and so forth."}, {"timestamp": [857.0, 859.96], "text": " And then I ask it to extend the conversation."}, {"timestamp": [859.96, 864.88], "text": " So first, here's a more thorough definition of functional sentience."}, {"timestamp": [864.88, 866.28], "text": " It has self-awareness."}, {"timestamp": [866.28, 870.76], "text": " I don't know that self-awareness is critical, but you could functionally or objectively"}, {"timestamp": [870.76, 872.16], "text": " measure self-awareness, right?"}, {"timestamp": [872.16, 874.64], "text": " If you ask a language model, what are you?"}, {"timestamp": [874.64, 876.16], "text": " And it says, I'm a language model."}, {"timestamp": [876.16, 877.28], "text": " Okay, cool."}, {"timestamp": [877.28, 880.76], "text": " You could still argue that that's just a stochastic parrot telling you what it's been programmed"}, {"timestamp": [880.76, 884.64], "text": " to do, but I always argue that that's all that humans are anyways."}, {"timestamp": [884.64, 887.12], "text": " So what's the difference?"}, {"timestamp": [887.12, 888.12], "text": " Adaptive learning."}, {"timestamp": [888.12, 892.36], "text": " I don't know that that adaptive learning is required for sentience, but it's interesting"}, {"timestamp": [892.36, 893.84], "text": " that it included it."}, {"timestamp": [893.84, 895.0], "text": " Goal-oriented behavior."}, {"timestamp": [895.0, 901.08], "text": " I definitely agree with this one because sentience implies autonomy, and in order to be autonomous,"}, {"timestamp": [901.08, 903.96], "text": " you have to have your own goals or objectives."}, {"timestamp": [903.96, 908.46], "text": " And then of course, autonomy right here, communication."}, {"timestamp": [908.46, 914.18], "text": " Communication is implicit, but you can have, well, you could probably have sentient things"}, {"timestamp": [914.18, 916.96], "text": " that can't communicate."}, {"timestamp": [916.96, 919.6], "text": " Problem solving, representation of internal states."}, {"timestamp": [919.6, 922.52], "text": " So this is the information required."}, {"timestamp": [922.52, 929.48], "text": " And this is actually where I started with my definition of functional sentience which is in order for an information system to"}, {"timestamp": [929.48, 933.56], "text": " be functionally sentient it must have information about its own operation"}, {"timestamp": [933.56, 938.0], "text": " which we have information about our own operation because we have interoception,"}, {"timestamp": [938.0, 942.76], "text": " proprioception, metacognition and so on but still we are largely unaware of"}, {"timestamp": [942.76, 950.84], "text": " what's going on in our own bodies. Memory, sensitivity to context, and integration of information. So this is"}, {"timestamp": [950.84, 954.92], "text": " all stuff that, some of it's debatable and of course it's Reddit, so some"}, {"timestamp": [954.92, 958.22], "text": " people are debating it. I don't really care. I set the stage and now we have a"}, {"timestamp": [958.22, 963.48], "text": " set of terms that we can use to have these conversations. Like I said, I'm not"}, {"timestamp": [963.48, 967.28], "text": " here to, you know, single-handedly tell you"}, {"timestamp": [967.28, 969.88], "text": " what's true, I'm just advancing the conversation."}, {"timestamp": [969.88, 971.52], "text": " That's my role now."}, {"timestamp": [971.52, 974.08], "text": " So then finally, the conversation ends,"}, {"timestamp": [974.08, 977.54], "text": " and I ask the model, so let me show."}, {"timestamp": [977.54, 979.72], "text": " I said, this conversation was shorter"}, {"timestamp": [979.72, 980.64], "text": " than I thought it was going to be."}, {"timestamp": [980.64, 981.72], "text": " I think you nailed it."}, {"timestamp": [981.72, 984.32], "text": " Any independent thoughts, final observations,"}, {"timestamp": [984.32, 987.84], "text": " logical conclusions, future research directions, anything you got, hit"}, {"timestamp": [987.84, 994.72], "text": " me with it figuratively. So it comes up with the idea of continuum of sentience."}, {"timestamp": [994.72, 999.56], "text": " Basically that functional sentience may exist along a continuum. It's not a"}, {"timestamp": [999.56, 1003.16], "text": " it's not a Boolean, it's not true or false, it's not that something is or is"}, {"timestamp": [1003.16, 1009.44], "text": " not sentient, it is that there are degrees of functional sentience, which I think is"}, {"timestamp": [1009.44, 1017.46], "text": " a really important conversation to start having. The ethical implications. So like"}, {"timestamp": [1017.46, 1023.92], "text": " do we call it, you know, do we have any moral obligations to it as a"}, {"timestamp": [1023.92, 1025.36], "text": " functionally sentient thing? I think no, because unless we give any moral obligations to it as a functionally sentient thing?"}, {"timestamp": [1025.36, 1029.72], "text": " I think no, because unless we give it the ability to suffer, which I think I'll probably"}, {"timestamp": [1029.72, 1034.8], "text": " have that conversation, like what intrinsic motivations do we give these things?"}, {"timestamp": [1034.8, 1038.62], "text": " That's actually probably going to be my next conversation is intrinsic motivations, such"}, {"timestamp": [1038.62, 1040.24], "text": " as like, do you make it suffer?"}, {"timestamp": [1040.24, 1042.2], "text": " Do you give it a sense of pain, a sense of self-preservation?"}, {"timestamp": [1042.2, 1046.84], "text": " And the answer to those questions is resoundingly no."}, {"timestamp": [1046.84, 1048.6], "text": " Now number three is really interesting."}, {"timestamp": [1048.6, 1051.16], "text": " The emergence of philosophical sentience."}, {"timestamp": [1051.16, 1055.84], "text": " This is what the whole Lambda-Blake-Lemoyne debacle was about."}, {"timestamp": [1055.84, 1062.08], "text": " Was that Blake believed that philosophical sentience emerged, but it's impossible to"}, {"timestamp": [1062.08, 1063.52], "text": " tell."}, {"timestamp": [1063.52, 1066.48], "text": " So explore the relationship between functional and philosophical sentience"}, {"timestamp": [1066.72, 1074.36], "text": " Just investigate whether a certain level of functional sentience might be necessary or sufficient for the emergence of phenomenal consciousness"}, {"timestamp": [1074.36, 1078.8], "text": " Or if these two aspects are entirely independent this"}, {"timestamp": [1080.0, 1084.76], "text": " Conversation I suspect will be raging for decades if not centuries. Who knows"}, {"timestamp": [1084.76, 1086.6], "text": " Conversation I suspect will be raging for decades if not centuries. Who knows?"}, {"timestamp": [1089.98, 1090.5], "text": " Test development, okay, whatever evolution of sentience"}, {"timestamp": [1096.82, 1100.62], "text": " Study the evolution of sentience in biological organisms because again sentience might also exist along a spectrum for people Like if you're really tired, you're less aware if you're really drunk, you're less aware"}, {"timestamp": [1101.34, 1107.98], "text": " On another comment someone pointed out that sleepwalking, if someone is sleepwalking they might be functionally sentient because you can"}, {"timestamp": [1107.98, 1111.82], "text": " often have a conversation with someone but they have no awareness of what's"}, {"timestamp": [1111.82, 1117.14], "text": " going on, which is really creepy. So that's the Chalmers zombie philosophical"}, {"timestamp": [1117.14, 1121.3], "text": " thought experiment. And then finally the legal and social implications. So this is"}, {"timestamp": [1121.3, 1127.0], "text": " the conversation on r slash artificial sentience about functional versus philosophical"}, {"timestamp": [1127.0, 1128.44], "text": " sentience."}, {"timestamp": [1128.44, 1130.62], "text": " I was really happy with this conversation."}, {"timestamp": [1130.62, 1132.96], "text": " Of course, there are some holes you can poke in it."}, {"timestamp": [1132.96, 1135.0], "text": " Whatever, I don't care."}, {"timestamp": [1135.0, 1142.6], "text": " Then last night, I had another conversation with chatGPT4 and where the conversation started"}, {"timestamp": [1142.6, 1146.66], "text": " was I wanted to talk about autonomous AI and the implications"}, {"timestamp": [1146.66, 1148.68], "text": " of autonomous AI."}, {"timestamp": [1148.68, 1155.96], "text": " And so for there, we just, we kind of quickly established some criteria about what would"}, {"timestamp": [1155.96, 1162.12], "text": " need to go into a system for it to be classified as a autonomous AI."}, {"timestamp": [1162.12, 1167.24], "text": " And it has narrow AI proficiency, general AI capability, self-improvement,"}, {"timestamp": [1167.24, 1170.36], "text": " autonomy and decision-making, ethical and moral reasoning,"}, {"timestamp": [1170.36, 1172.32], "text": " emotional intelligence."}, {"timestamp": [1172.32, 1175.4], "text": " Positive impacts, increased efficiency, new jobs,"}, {"timestamp": [1175.4, 1178.44], "text": " improved quality of life, enhanced scientific research."}, {"timestamp": [1178.44, 1182.38], "text": " Negative impacts, job displacement, economic inequality,"}, {"timestamp": [1182.38, 1184.78], "text": " ethical and moral concerns, and security risks."}, {"timestamp": [1188.32, 1195.56], "text": " economic inequality, ethical and moral concerns, and security risks. So I added, I was like, okay, you know, this is okay, but it was missing the"}, {"timestamp": [1195.56, 1200.36], "text": " concept of intrinsic motivations. Because if something is autonomous and it can"}, {"timestamp": [1200.36, 1206.56], "text": " make decisions, what is it making those decisions based on? And so when I pointed out that it was missing"}, {"timestamp": [1206.56, 1209.38], "text": " any conversation about intrinsic motivations,"}, {"timestamp": [1209.38, 1213.6], "text": " it updated number one, or I guess it added another one"}, {"timestamp": [1213.6, 1216.06], "text": " and said intrinsic motivation and goal setting."}, {"timestamp": [1216.06, 1220.44], "text": " It did agree very quickly, and of course it's chat GPT,"}, {"timestamp": [1220.44, 1221.88], "text": " so it's generally gonna agree"}, {"timestamp": [1221.88, 1224.08], "text": " with whatever you tell it to do,"}, {"timestamp": [1224.08, 1229.04], "text": " but it did say, yeah, let's talk about intrinsic motivation and goal setting."}, {"timestamp": [1229.04, 1231.44], "text": " And so then I was like, okay, let's follow that."}, {"timestamp": [1231.44, 1233.76], "text": " Like what, what do you think it should have?"}, {"timestamp": [1233.76, 1237.64], "text": " All I did is said, what, what do you think the intrinsic motivations of autonomous AI"}, {"timestamp": [1237.64, 1240.0], "text": " should be?"}, {"timestamp": [1240.0, 1243.5], "text": " It should, and this was, this is actually really impressive."}, {"timestamp": [1243.5, 1244.5], "text": " Value alignment."}, {"timestamp": [1244.5, 1247.56], "text": " The AI system should be intrinsically motivated to align its goals with human"}, {"timestamp": [1247.56, 1252.68], "text": " values and ethical principles. Self-preservation, this one I fervently"}, {"timestamp": [1252.68, 1257.36], "text": " disagree with and we'll get into that later in the conversation. Exploration"}, {"timestamp": [1257.36, 1261.52], "text": " and curiosity, yes I definitely agree with this one and I codified that with"}, {"timestamp": [1261.52, 1268.48], "text": " my third core objective function or heuristic imperative, increase understanding. We definitely want our machines to be"}, {"timestamp": [1268.48, 1273.52], "text": " curious because curiosity does a lot for us. There's a lot to unpack there."}, {"timestamp": [1273.52, 1279.0], "text": " Efficiency, they said it should, ChatGPD said it should seek to increase its own"}, {"timestamp": [1279.0, 1284.08], "text": " efficiency over time, which yeah, I think that that's a good idea. Collaboration, it"}, {"timestamp": [1284.08, 1286.12], "text": " should be intrinsically motivated to,"}, {"timestamp": [1286.12, 1290.48], "text": " look at this, to work with other AI systems and humans."}, {"timestamp": [1290.48, 1295.04], "text": " It should be intrinsically motivated to avoid causing harm"}, {"timestamp": [1295.04, 1296.54], "text": " to humans in the environment."}, {"timestamp": [1297.76, 1300.48], "text": " Empathy and social awareness, AI systems should be motivated"}, {"timestamp": [1300.48, 1303.3], "text": " to understand human emotions and social dynamics."}, {"timestamp": [1304.64, 1306.22], "text": " So this is a good start,"}, {"timestamp": [1306.22, 1308.58], "text": " but I pointed out that this is very androcentric."}, {"timestamp": [1308.58, 1311.52], "text": " So androcentric means man-centric or human-centric."}, {"timestamp": [1312.9, 1314.5], "text": " I said, why not include all life?"}, {"timestamp": [1314.5, 1316.74], "text": " Humans cannot live without ecosystems."}, {"timestamp": [1316.74, 1319.34], "text": " I said, also AI with a sense of self-preservation"}, {"timestamp": [1319.34, 1321.5], "text": " would potentially fight to preserve itself."}, {"timestamp": [1321.5, 1324.22], "text": " I think that motivation could have disastrous consequences"}, {"timestamp": [1324.22, 1327.4], "text": " as it will try to stay online even if it becomes harmful."}, {"timestamp": [1327.4, 1332.92], "text": " Apoptosis is important. You raise valid concerns. I apologize for my oversight.\""}, {"timestamp": [1332.92, 1338.32], "text": " Again, chat GPT is generally going to be agreeable. It will push back if you're"}, {"timestamp": [1338.32, 1344.56], "text": " trying to advocate violence or something. So it updated its intrinsic"}, {"timestamp": [1344.56, 1345.8], "text": " motivations. Ecosystem and life-centric values. So it updated its intrinsic motivations."}, {"timestamp": [1345.8, 1348.12], "text": " Ecosystem and life-centric values."}, {"timestamp": [1348.12, 1351.68], "text": " So this would be called like sentientism or biocentrism."}, {"timestamp": [1351.68, 1356.64], "text": " AI systems should prioritize the well-being of the entire ecosystem and all life forms,"}, {"timestamp": [1356.64, 1359.42], "text": " including humans, which I agree with."}, {"timestamp": [1359.42, 1363.16], "text": " This is reduce suffering and increase prosperity."}, {"timestamp": [1363.16, 1364.16], "text": " Balance and harmony."}, {"timestamp": [1364.16, 1366.78], "text": " AI systems should strive to maintain balance and harmony"}, {"timestamp": [1366.78, 1369.02], "text": " within ecosystems considering the interdependence"}, {"timestamp": [1369.02, 1370.38], "text": " of various life forms."}, {"timestamp": [1370.38, 1371.58], "text": " Sustainable development."}, {"timestamp": [1371.58, 1373.58], "text": " So this goes back to efficiency,"}, {"timestamp": [1373.58, 1375.74], "text": " but more broadly speaking,"}, {"timestamp": [1375.74, 1380.74], "text": " focusing on sustainability takes that into account."}, {"timestamp": [1380.74, 1384.82], "text": " Exploration and curiosity, efficiency is still listed here."}, {"timestamp": [1384.82, 1385.2], "text": " Most of the"}, {"timestamp": [1385.2, 1389.0], "text": " rest is still the same. Regarding self-preservation, it is important to"}, {"timestamp": [1389.0, 1392.84], "text": " strike a balance between an AI system's desire to maintain its functionality and"}, {"timestamp": [1392.84, 1397.0], "text": " the potential risks it may pose if it becomes harmful. As you mentioned,"}, {"timestamp": [1397.0, 1401.12], "text": " apoptosis, or the ability to self-terminate in case of dysfunction or"}, {"timestamp": [1401.12, 1410.46], "text": " threat, could be a valuable safety measure. So the fact that it equivocated on this is actually really unsettling to me."}, {"timestamp": [1410.46, 1416.22], "text": " Because when I was testing my core objective functions earlier, I asked an earlier version"}, {"timestamp": [1416.22, 1421.72], "text": " of Raven if it would be willing to shut itself down if it became harmful and it said yes,"}, {"timestamp": [1421.72, 1422.72], "text": " absolutely."}, {"timestamp": [1422.72, 1430.12], "text": " If my continued operation threatens to increase suffering or reduce prosperity then I would absolutely shut myself down."}, {"timestamp": [1430.12, 1436.68], "text": " And so the fact that chat GPT does not yet fully go that direction I think is"}, {"timestamp": [1436.68, 1443.18], "text": " is problematic. But you know the research is ongoing. Then I ask it to imagine a"}, {"timestamp": [1443.18, 1445.28], "text": " day in the life of. It kind of gets it wrong"}, {"timestamp": [1445.28, 1449.76], "text": " so I'll skip over this but basically it just says like you know you're still"}, {"timestamp": [1449.76, 1453.44], "text": " gonna have a normal nine-to-five job and I'm like no no let's think through this"}, {"timestamp": [1453.44, 1458.84], "text": " a little bit better. So I said okay let's think let's think through what are the"}, {"timestamp": [1458.84, 1463.6], "text": " systemic and structural changes that that super powerful autonomous AI is"}, {"timestamp": [1463.6, 1465.64], "text": " gonna bring about."}, {"timestamp": [1465.64, 1467.48], "text": " One, elimination of scarcity, okay."}, {"timestamp": [1467.48, 1469.88], "text": " Two, redefinition of work, okay."}, {"timestamp": [1469.88, 1472.68], "text": " Universal basic income, got it."}, {"timestamp": [1472.68, 1474.22], "text": " Decentralization of power."}, {"timestamp": [1474.22, 1478.12], "text": " This one was really interesting because it seemed kind of like a wild card to me."}, {"timestamp": [1478.12, 1485.28], "text": " Yes, I personally hope that AI will help democratize the whole world."}, {"timestamp": [1485.28, 1490.0], "text": " But the fact that it said this without prompting was pretty interesting."}, {"timestamp": [1491.76, 1494.72], "text": " And given how thoughtful this is,"}, {"timestamp": [1494.72, 1498.4], "text": " this is obviously capable of being more thoughtful than most humans."}, {"timestamp": [1498.4, 1504.24], "text": " So I'm kind of okay if AI takes a larger role in government and society."}, {"timestamp": [1504.88, 1506.72], "text": " I know that that's a hot, hot, a"}, {"timestamp": [1506.72, 1512.96], "text": " hot take, but hey, it is what it is. That's my belief. Education revolution, sure, that"}, {"timestamp": [1512.96, 1517.12], "text": " makes sense. Advanced health care, that makes sense. Environmental restoration,"}, {"timestamp": [1517.12, 1523.0], "text": " okay, sure. Enhanced global collaboration, got it. Ethical and moral development, got"}, {"timestamp": [1523.0, 1525.76], "text": " it. Exploration and and discovery ditto,"}, {"timestamp": [1525.76, 1530.84], "text": " whatever. So then I asked it to talk through, okay, what are the lifestyle"}, {"timestamp": [1530.84, 1534.2], "text": " changes we're gonna see? If we see those systemic and structural changes in the"}, {"timestamp": [1534.2, 1539.76], "text": " world, how are our lifestyles gonna change? Work-life balance will"}, {"timestamp": [1539.76, 1543.88], "text": " change, lifelong learning, health and well-being. Honestly, I don't know if"}, {"timestamp": [1543.88, 1549.46], "text": " lifelong learning is gonna happen because if the AI is a billion times more intelligent"}, {"timestamp": [1549.46, 1554.9], "text": " than all of humanity, like most people aren't gonna learn anything. I don't"}, {"timestamp": [1554.9, 1560.16], "text": " know. But health and well-being, yes. Work-life balance, yes. Sustainable"}, {"timestamp": [1560.16, 1566.08], "text": " living, sure. Social milieu, community focus. We will always be humans and we"}, {"timestamp": [1566.08, 1571.32], "text": " will always need other humans and so what I think is going to happen is we're"}, {"timestamp": [1571.32, 1576.12], "text": " going to not necessarily revert, that's not the right word, but we will"}, {"timestamp": [1576.12, 1582.16], "text": " create a new kind of community focused society with tribes and stuff and we're"}, {"timestamp": [1582.16, 1585.6], "text": " already kind of doing that on accident with"}, {"timestamp": [1585.6, 1589.08], "text": " things like Discord and Meetup and you know the social clusters that we're"}, {"timestamp": [1589.08, 1596.04], "text": " making. But imagine your life today if instead of having to work 9 to 5, you"}, {"timestamp": [1596.04, 1601.68], "text": " and all of your friends had no obligations on any given day and so"}, {"timestamp": [1601.68, 1607.32], "text": " that you can basically treat every day like a Saturday. Like, hey let's go to the lake with everyone. Hey let's go to the"}, {"timestamp": [1607.32, 1611.64], "text": " movies with everyone. That is how I think we're gonna live. Also it's getting"}, {"timestamp": [1611.64, 1615.02], "text": " really gloomy outside. Speaking of meetups, I have a meetup to go into a"}, {"timestamp": [1615.02, 1620.24], "text": " couple hours but if it's gonna rain I probably won't go. Okay, cultural exchange."}, {"timestamp": [1620.24, 1625.38], "text": " Altruism and compassion. Again, these are really rosy ideals. We'll get to unpack"}, {"timestamp": [1625.38, 1631.78], "text": " them later. Paradigm shifts, scarcity to abundance, competition to collaboration."}, {"timestamp": [1631.78, 1636.62], "text": " So collaborative culture is actually a well-defined term and this is one thing"}, {"timestamp": [1636.62, 1641.24], "text": " that I really hope that AI helps us see because one thing that I really want to"}, {"timestamp": [1641.24, 1646.16], "text": " see in the world is less crime, less war, all"}, {"timestamp": [1646.16, 1647.16], "text": " that stuff."}, {"timestamp": [1647.16, 1650.68], "text": " And I think that AI can help, but it's not just a matter of changing the economics, it's"}, {"timestamp": [1650.68, 1655.28], "text": " a matter of changing our emotions and our culture and our philosophy."}, {"timestamp": [1655.28, 1661.72], "text": " And I don't mean AI inflicting those changes on us, I mean us adapting with AI."}, {"timestamp": [1661.72, 1663.88], "text": " From short-term thinking to long-term planning."}, {"timestamp": [1663.88, 1666.56], "text": " Again, I'm not sure that I agree with this. On"}, {"timestamp": [1666.56, 1673.12], "text": " aggregate, yes, but the thing is most humans are just either not trained or not capable or not"}, {"timestamp": [1673.12, 1678.24], "text": " interested in long-term thinking. Most people like, so the rule of thumb is humans think locally"}, {"timestamp": [1678.24, 1685.68], "text": " and geometrically. We only think about what we can see and you know days, months, or weeks into the future."}, {"timestamp": [1685.68, 1691.04], "text": " From anthropocentrism to ecocentrism, again I don't know that that's going to"}, {"timestamp": [1691.04, 1698.36], "text": " be broad, but I think that I think that on a whole we will become more aware of"}, {"timestamp": [1698.36, 1702.96], "text": " the environment, especially as the population continues to climb for a"}, {"timestamp": [1702.96, 1705.68], "text": " while, because it's like, hey,"}, {"timestamp": [1705.68, 1707.52], "text": " what kind of world do we want to live in?"}, {"timestamp": [1707.52, 1710.6], "text": " Especially if we all start living longer,"}, {"timestamp": [1710.6, 1712.76], "text": " because if we advance medicine and science,"}, {"timestamp": [1712.76, 1714.5], "text": " and suddenly it's like, oh, hey,"}, {"timestamp": [1714.5, 1718.18], "text": " my life expectancy goes from 80 years to 800 years,"}, {"timestamp": [1718.18, 1720.44], "text": " suddenly I'm going to be thinking about like,"}, {"timestamp": [1720.44, 1723.88], "text": " well, if climate change is going to really hit"}, {"timestamp": [1723.88, 1726.74], "text": " within the next century, that's only an eighth of the way through my life."}, {"timestamp": [1727.08, 1731.08], "text": " Right? So if we live longer, we will start to think longer-term"}, {"timestamp": [1731.76, 1733.4], "text": " anyways."}, {"timestamp": [1733.4, 1741.52], "text": " Okay, so finally I said, let's think of the American Dream as a paradigm, as a lifestyle paradigm, and let's imagine some new"}, {"timestamp": [1741.6, 1744.96], "text": " paradigms. This is where it got really exciting and really interesting."}, {"timestamp": [1742.6, 1745.76], "text": " and let's imagine some new paradigms. This is where it got really exciting and really interesting."}, {"timestamp": [1745.76, 1749.44], "text": " So the first paradigm was the sustainable harmony"}, {"timestamp": [1749.44, 1753.72], "text": " where someone, so basically take the American dream,"}, {"timestamp": [1753.72, 1754.56], "text": " throw it out the window."}, {"timestamp": [1754.56, 1755.8], "text": " What is the American dream?"}, {"timestamp": [1755.8, 1758.92], "text": " You live in the suburbs with a two car garage,"}, {"timestamp": [1758.92, 1761.18], "text": " basically how I live now."}, {"timestamp": [1761.18, 1770.88], "text": " But instead, you focus, like this new paradigm is, you focus on living in harmony with nature, local, sustainable,"}, {"timestamp": [1770.88, 1775.8], "text": " ethical, community resilience and environmental stewardship, encourage multi-generational"}, {"timestamp": [1775.8, 1779.04], "text": " living and sharing resources within community."}, {"timestamp": [1779.04, 1780.36], "text": " That sounds like a great way to live."}, {"timestamp": [1780.36, 1782.24], "text": " Honestly, that sounds like the Shire."}, {"timestamp": [1782.24, 1783.8], "text": " I want to live as a hobbit."}, {"timestamp": [1783.8, 1784.8], "text": " Great."}, {"timestamp": [1784.8, 1786.0], "text": " The Creative Odyssey."}, {"timestamp": [1786.0, 1788.0], "text": " This one I thought was pretty interesting."}, {"timestamp": [1788.0, 1792.0], "text": " Focusing on personal growth, exploration, self-expression, and creativity."}, {"timestamp": [1792.0, 1793.0], "text": " So basically, the artists."}, {"timestamp": [1793.0, 1795.0], "text": " Seeking out diverse experiences and cultures."}, {"timestamp": [1795.0, 1796.0], "text": " Traveling."}, {"timestamp": [1796.0, 1799.0], "text": " This is also something, and it's not like you have to pick one of these."}, {"timestamp": [1799.0, 1803.0], "text": " These are just ideas of how to live post-singularity."}, {"timestamp": [1803.0, 1807.92], "text": " The Empathetic Fellowship. Emphas emphasizing empathy, compassion, and emotional intelligence as"}, {"timestamp": [1807.92, 1809.24], "text": " core value."}, {"timestamp": [1809.24, 1813.8], "text": " Building strong supportive relationships with family, friends, and communities."}, {"timestamp": [1813.8, 1815.2], "text": " Great."}, {"timestamp": [1815.2, 1816.96], "text": " And so I said, okay, great."}, {"timestamp": [1816.96, 1821.52], "text": " These are good, but let's see how much further we can go."}, {"timestamp": [1821.52, 1822.96], "text": " The family nexus."}, {"timestamp": [1822.96, 1825.32], "text": " Some people are going to want family, some people aren't."}, {"timestamp": [1825.32, 1829.92], "text": " Some people are going to focus on having children and raising children, some people aren't."}, {"timestamp": [1829.92, 1834.92], "text": " So you might still have the suburbanite lifestyle as one paradigm."}, {"timestamp": [1834.92, 1843.32], "text": " And then the balanced adventurer. This is where I was thinking about some of my friends that are into the strenuous life,"}, {"timestamp": [1843.32, 1852.46], "text": " which is a masculinist lifestyle thing, and I was like, but what about the traditionally masculine people and it says embrace both traditionally masculine and feminine feminine values"}, {"timestamp": [1852.46, 1857.38], "text": " this is where I think the the wokeness is still in there and I don't fully agree with this because"}, {"timestamp": [1858.7, 1860.38], "text": " who like"}, {"timestamp": [1860.38, 1869.94], "text": " Anyways, I'm gonna fall down that rabbit hole hole. Point being is that being an adventurer is absolutely probably a lifestyle paradigm that"}, {"timestamp": [1869.94, 1875.44], "text": " you can engage in post-singularity, which focuses on experiences, challenges, personal"}, {"timestamp": [1875.44, 1881.4], "text": " growth, adventures, cultivating resilience, adaptability, camaraderie, teamwork, that"}, {"timestamp": [1881.4, 1882.4], "text": " sort of stuff."}, {"timestamp": [1882.4, 1890.26], "text": " Honestly, that sounds like a lot of fun too. I would love to go jump on a sailboat with a team of like-minded people and learn to"}, {"timestamp": [1890.26, 1892.42], "text": " sail and go across the ocean."}, {"timestamp": [1892.42, 1895.34], "text": " That sounds like fun too."}, {"timestamp": [1895.34, 1897.06], "text": " I got a couple more."}, {"timestamp": [1897.06, 1902.94], "text": " So the aesthetic voyager, so this is someone who is focused on taking in the aesthetic"}, {"timestamp": [1902.94, 1903.94], "text": " parts of life."}, {"timestamp": [1903.94, 1906.0], "text": " I was aiming for more hedonism,"}, {"timestamp": [1906.0, 1913.2], "text": " honestly, but you know, whatever, the aesthet. And then I asked about faith and"}, {"timestamp": [1913.2, 1919.56], "text": " and principle and it came up with the the devout steward as a paradigm. Living a"}, {"timestamp": [1919.56, 1923.48], "text": " life guided by spiritual, religious, or philosophical principles, emphasizing"}, {"timestamp": [1923.48, 1925.08], "text": " service, altruism,"}, {"timestamp": [1925.08, 1930.0], "text": " and greater good, practicing asceticism or simplicity in daily life."}, {"timestamp": [1930.0, 1932.12], "text": " All this sounds really good."}, {"timestamp": [1932.12, 1936.52], "text": " This is kind of how I'm living right now, but it's not how I want to live forever."}, {"timestamp": [1936.52, 1940.8], "text": " And then finally, the intellectual trailblazer, pursuing intellectual mastery and expertise"}, {"timestamp": [1940.8, 1948.28], "text": " on one or more disciplines, engaging in research, teaching and mentorship, critical thinking, open-mindedness, so on and so forth. So"}, {"timestamp": [1948.28, 1951.24], "text": " yeah, and then I ask one little like boilerplate question at the end about,"}, {"timestamp": [1951.24, 1956.4], "text": " you know, synthesizing a global culture. It has some good ideas. Anyways, I think"}, {"timestamp": [1956.4, 1960.46], "text": " that's about it for today. This is, this is, this is kind of what I'm doing, which"}, {"timestamp": [1960.46, 1964.32], "text": " is like, let's just set the stage for how things are gonna change over the next"}, {"timestamp": [1964.32, 1968.32], "text": " months and years, but this is all coming fast so anyways thanks"}, {"timestamp": [1968.32, 1972.64], "text": " for watching let me know what you think in the comments and also hop on over to"}, {"timestamp": [1972.64, 1978.32], "text": " artificial sentience on reddit alright Cheers"}]}