{"text": " Morning, everybody. David Shapiro here. We are back for part two of the Knowledge Graph Supreme Court decision thing. So we're using chat GPT and GPT-3 to help us along. And as a quick recap, where we left off was I didn't get that far, but I downloaded about 22 Supreme Court opinions. This was about antitrust law, so a very specific domain. And then I got them converted to text. So that is, I did that with another repo. It's fine. But then what we did was, the big thing that we achieved was that we figured out that we can get GPT-3 to just go ahead and write my, write the, whatchamacallit for us, the knowledge graph JSON. And so what I'm doing is the nodes that I asked for was each node should be a case citation precedent or prior opinion. Each note should have several properties such as date, case number, involved parties, reasoning for including in this opinion, and other relevant information. So that worked really well because you see like it's got a case number, it tells me when it happened, and then the reasoning, so like involved parties, like great, this is phenomenal information. So what we're doing is we're gonna create a cross-linked web as to like why all these things are interlinked. So that way, theoretically, this hypothetical use case, if an attorney is researching antitrust laws so that one, they can go to a court, court of appeals, or even present to the Supreme Court, they will have a masterful understanding of established law. And the reason that this is important is because common law is how law works in America. It's by prior precedent. So you've got the laws that are laid down by the legislative branch and then interpreted by the judicial branch. And so the judicial branch keeps track of their own interpretation, right? Cause there's the legislative branch, it has to do with separation of powers. Anyways, so that's how we got where we are. It worked really well. And there's all kinds of what ifs and gotchas that I'm not going to worry about because this worked really well and we can iterate over the over the long term. So but this I had to plug in manually and it's about four pages so like if we do if we search for how many new pages there are two three yeah one two three so that this has four pages total, which that was good. So the next problem is we got to take these and regardless of how long they are, we have to break them down into chunks of four pages maximum. So rather than do this manually, I was like, why don't I just ask chat GPT? So here we go. I have a folder named, let's see, Opinions, Text. This folder contains contains text files of SCOTUS decisions that were converted from PDFs. The pages are demarcated by the words new page. I need a Python function. So I'm basically talking to this thing like I'd be talking to a developer. I need a Python function where I pass... Actually, no, let's just ask it to do the whole thing. I need a Python function that reads every file in opinions underscore text and then breaks each file into chunks of four pages. The purpose of this is to limit the size of each subsequent file. Please then save the chunks file. Please then save the chunks into a folder named chunks text and append a serial number to the original file name. For instance, star underscore one, star underscore two, and so on. All right, let's see what it does. Why would this violate the content policy? Okay, I sent in feedback. Let's see what we've got. So, import OS split text files, input folder, output folder, pages per chunk. So, good, it's parameterized it. folder pages per chunk. So good, it's parameterized it. If not, output folder, make it nice. Okay. For file and OSLister, input folder with open OSPath join, input folder file, R as F, read it, excellent. Pages equals split on new page, perfect. So it understood that. For I in chunk enumerate page range zero pages per chunk. Excellent. So this is this is a list comprehension that will break it into equal chunks or chunks of four output file equals this underscore plus. Oh, dang. That's good. That's good. Okay. This is wonderful. So let's go to this. I had started writing it and then I was like, I don't have the energy for this. I'm telling you. I have said it on Twitter and I've said it on mostly Twitter, but LinkedIn and a few other places. English, your ability to describe what you want is going to be the primary programming language from now on. Period. End of story. If you can think through a function, then yeah, this is it. So let's run this. Let's see if this worked. Need a command prompt, CD, and we're in the SCOTUS opinions. And then we'll do Python step 01 split chunks. Why you no work? This actually happens quite a bit. Let's see if it can fix it. So thanks. That mostly worked, but through this error. Can you fix that error, please? Now, if this can debug this, I know exactly what it is. Yep. Yep. There you go. You need to specify the encoding. Yep. Perfect. Oh, wow. It's saying add the ignore flag. Wonderful. Wonderful. Adding and coding UTF-8 should be sufficient. So that goes do, do, do, do, do, do, do, do, do, do, do, do, do, do, do, do, do, do, do, do, do, Hmm, fascinating. Did it get farther? This is weird though. Input folder file, contents read encoding UTF-8 as in file. So sometimes this happens. Let's see, what is the encoding here? So sometimes what I do is I'll convert it to something and then I'll convert back. So let's... Yeah. Hmm. I wonder what happens if we do, let's add that ignore thing. Rather than getting lost in the weeds, let's just do errors equal ignore. Because you know what? I looked at the text file. It looks fine to me. Oh, and let's also see if it, um, okay, it got pretty far already. So, it got pretty far in the process before blowing up. One, two, three. So, now we've got all the chunks. Cool, cool, cool. Um, all right. Heck with it. Send it. What do you mean? All right, heck with it. Send it. What do you mean? This was in, so this was in split text files. F write, oh, it couldn't write it. Interesting. Oh, okay, okay, okay. So when we write it, we need to convert it to ASCII and back. So let's see if it understands this. Oh, man, I'll be jazzed if it understands this. Okay. Great. That worked. Now, I have a new problem. Here's the error. Please find a solution for this new bug. So the problem here is, and I, yeah, that you're trying to join a list of strings that contain spaces? I don't think so. New page. Nope, no, no, I don't think that's it. I think we need to fix the string encoding. Here's the last part of the error. I feel like I'm talking to like HAL 9000. Yep, there it is. That's it. Yep. Ah, so we need to add the encoding to UTF-8. Right, okay, that makes sense. This thing is smarter than me. Okay, so when we write it, yeah. Oh, that's the problem, okay. Encoding equals UTF-8. Okay, cool. But this took way less brain power. Okay, let's see if that works. CLS, clear screen. That was fast. All right, so now we have 144 chunks of text. Let's see what the biggest one is. 20. Uh. uh heh heh heh heh heh heh heh heh heh heh heh heh heh heh heh heh heh heh heh uh heh heh heh heh heh heh heh heh heh heh heh heh heh heh heh heh heh heh heh heh I think the uh, I think the OCR messed up with this one heh heh heh heh heh heh heh heh heh heh heh PROVIDES th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th- that the sherman act okay i'm probably disturbing my audience what's funny is that it got the capital letters fine but then the rest it's like, no i wonder if it was like if the scanner bed was like moving too slowly or something i'm sorry okay i'm gonna pause this because I'm going to keep laughing. Okay, I had to stop and make myself tea. I'm still probably going to be laughing at this. I'm sorry. Okay, now, normally, I'm sorry. I don't know why this is so funny. Normally, this would, what I would do is just delete data, but in this case, I don't want to lose anything. And imagine like, what if half of our files were like this? So let's come up with a solution. So I'm going to, so this function works, so I'm gonna say, okay, cool. Let's make a new script. So let's go back over to chat.gpt. Great, that all worked, but it turns out the OCR barfed on a few files. So there are lots of duplicated characters, such as, please write a new script using spaCy or nltk to deduplicate extra characters. Search through all the files in, let's see, what was the folder name? Chunks.txt in chunks underscore text. Deduplicate characters and then save the cleaned up copy in a new folder called deduped text. All right. Will that work? I don't know if that'll work. Is spaCy that good? Or tndoc. Um, okay. I think I'll need to add the encoding, but let's give it a shot. I think I'll need to add the encoding, but let's give it a shot. And let me make sure I've got pip install spacey. Okay. So while that's running, I will do save and we'll come back here and we'll do step 02. So you might notice I do my functions in order. So that way if you're looking at this repo, you don't have to try and reverse engineer what order to run things in. It's just intrinsic documentation. Ddupe characters.py. Okay. Group characters.py. Okay. Python step 02. And I know that it's going to barf on this. Let's do encoding equals UTF. UTF-9. UTF-9 is clearly better than UTF-8, right? It's the next mission. Sorry. I'm in a mood today, apparently. You having a giggle, mate? Okay. Um... Let's see if it works. I'm not going to use the GPU for something this simple. It's a small skipping register, can't find, doesn't seem to be a Python package. Huh. Let's see. It gave me this error. What does it mean? It didn't work. This is the value of having good error messages, kids. Interesting. All right. Let's see if that worked. Still didn't work. Um, okay. All right, so in this case, it seems like we found a limitation. Still didn't work. Spacey load. Is requirement already satisfied? Yeah, it says it's already satisfied. Let's go to Google. Let's see if this... All right. Import. Import So it looks like you need to do you need to install Let's try this. That looks like it did a thing. Sorry, I wasn't talking through it. So, basically, I was looking, I found a spacey issue on GitHub. And let's see, it hasn't bombed yet, so I wonder if it's working. Deduped. Oh, cool! There's nothing that's 20. No, it didn't work. Still didn't work. Okay. Yeah, so it seems like spacey is not sufficient, or at least this isn't. Okay. So let's go back here. Go back to this. Okay, I got spacey to load but the original script does not work. The words And some files are still wrong with lots of duplicated characters. So for instance, for example, I probably should have asked another way. Yep. Yep. Okay. So it's actually going to tell me. Yeah, use regex. So regex is actually the way I would have done it originally. So it looks like this might be the right way to do it. So, all right, let's see what it says. Bl will give that a try, but what about words where there are supposed to be duplicated characters, like book or look. Does your script handle that? Can we use NLTK or spaCy or something else to account for correct words. Also while this is running, I'm going to address the elephant in the room and that was a week ago I made a video saying, meh, chat GPT isn't that great. So obviously I kind of have my foot in my mouth because this is amazing. It also looks like it failed So Alright, let me do a time check we are at 23 minutes, so we're to give me that thing. So I think what we'll do is we'll just check to see if this happens, because it's better to have some data than none. So I think what we'll do, all right, split chunks, that one worked. Dedupe characters. So what we need to do is find the ones where this happened, right? Generally, it looks like it only happened in one document. Okay. So in this case, we'll say we'll pass in any file that starts with this. So we'll eat the cost. And what I mean by that is we'll just accept that some data is not going to be quite as good. But that's plausible because it's an OCR mistake. But the thing is, is we just need it to be small enough to fit in. mistake, but the thing is, is we just need it to be small enough to fit in. So deduplicate characters. Yeah, I don't think this is going to work. It's close, but it's not quite. Thanks. Can you modify the script that uses regex instead? The only problem is in files with the name. Can you just sort or filter out any other files? Okay. So let's see what it comes up with there. Meanwhile, it looks like this is the largest one that is not good, right? So it's 13,000 characters long. So let's see how many tokens this is. So as long as it's, that's getting pretty close. Let's see if we can, if our prompt will work. So prompt, and then we'll do text DaVinci 03, temperature zero, and our maximum length is going to be like 600 tokens. Otherwise it's going to be like 600 tokens. Otherwise, it's going to be too long. So let's see if that's enough. The output is pretty short, so. But JSON is pretty token intensive, so I wouldn't be surprised if it, yeah, so we ran out of space. So it looks like we need to go back and do smaller chunks. But fortunately, these earlier scripts are really easy. So for instance, we just come back here. And instead of doing, we just update this. So instead of four pages, we do three. And so then what we'll do is we'll come in here to opinions is fine, chunks, let's delete these. And then we'll rerun Python step 01. And so now what we should have is more chunks. So now we have 188 chunks, but you see the that one, that one. So this is now the largest and it's only 10 kilobytes or 9,000 characters long. So this should be small enough to run. Let's see how many tokens it is. Okay, so now we're down to 2,800 tokens. Let me remove the JSON part. So now we're at 2,500 tokens tops. So we can do like 1,450. So that's more than twice as many tokens. So let's see, it's more than twice as many tokens with 25% less input. So theoretically this should be the limit. Cool. All right. Excellent. I think this is good. All right, so we're almost done for the day. Let's see what chat GPT said. Deduplicate characters. Yeah, there we go. Okay. So let's do this for the dedupe. So let's come back here add the, whatchamacallit, encoding. Encoding equals UTF-8, and then for the write, encoding equals UTF-8. Okay, so now if we go to the deduped, oh actually here we need to delete this. It did all of them, interesting. Oh, that's, no, if not in file, it got the logic wrong. I'm like, no, it was only supposed to do like five of these. Try that again. There we go. Okay. So now the largest of these is eight kilobytes, which is plenty small. So we come back to chunks and we'll replace those. Replace. Yes. So now our absolute largest file is 10 kilobytes, 9,300 characters. So this should all easily fit within, no, this should all easily fit within our prompt window here. So now we need to just go ahead and run the thing. So, all right, so let's say, excellent, we are now ready to run our prompts. Are you familiar with OpenAI Python module? Python module. Open AI is. I'm wondering if it's slowing down because people are waking up. This is one advantage of being a super early bird is I get up earlier than everyone else. Granted, it's always middle of the day somewhere in the world. Anyways, so this may or may not help us with this part. So now let's see, open file, save file, open AI key, text DaVinci 03, temp that, that we can do this up to 1,450. That's fine. Encode. All right, so this, I just cannibalized another thing. We do not want to clean that up because this is going to be there. That's fine. All right. Network error. Yeah, I figured that would happen. Okay, so let's do a refresh. I have a folder called, what is the name of my folder? God, I have like chipmunk memory. It's hard, chipmunk memory. Called chunks.txt. Called chunks underscore text. That is full of .txt files. Each file, please write a Python script that uses OpenAI module and calls and uses text DaVinci file in the chunks folder to populate a prompt. Let's see. Prompt underscore JSON LD, citation nodes dot text, and has a placeholder called, what did I call the placeholder? Chunk. Called chunk. In other words, open the text file, or no, let and use this as the prompt for OpenAI. Set the temperature to 0 and the token count to 1450. Let's see if that works. Certainly here's a script that should do what you have described. I do it differently because I use Windows. I know I'm a charlatan. I think it's going to work. So this is the implications of this. If chat GPT knows how to call GPT, in theory, you can create a machine that can do its own experiments with language models. I want to say that again. The implication here is now we have a system of a machine that understands the code to call itself well enough, and then obviously this thing is intelligent enough to understand results, you could in theory have something that trains itself or makes its own data sets or whatever. Okay, so I like this. Whoops. Copy code. Let's come over here and do this. I guess I didn't say what to do with the response. So we'll do, let's see. And then, yeah, we don't need any of this stuff. That's fine. And then we need to, rather than print, we'll need to save. Great. The output from the, let's see. Great. Now, response.txt should be in JSON format. Can you please save the output to a new folder called, let's see, we'll say called ag underscore JSON instead of just printing. We should, let's see, otherwise, use the same file name as the .txt file, but just replace the .txt with .json. Let's see. Before you write this script, can you tell me if you understand? Give me some pseudocode so I can check to make sure we understand each other. If this works, yeah. Well it understands the concept of pseudocode and then it is going to go ahead and write the script. Okay, cool. Let's see if it fixes it. Asking for the pseudocode may or may not be viable, especially because this code is so simple. It might have been easier just to ask for it to just go ahead and do it, but yeah. So we're also going to need to do coding equals UTF-8, always need to do that. I'll just copy this. And then we'll need the same. Yep. And then we'll need the same. Yep, okay. Cool. So instead of printing it, we save it. So with open as blah, blah, blah, right. So let's go ahead and grab this. Comma. I think we're ready. So then one last thing, though, is what I like to do is we'll keep the print just so that way we know what's going on. And we'll add new line, new line, new line, and then response.text. Here actually we'll add a little demark. Let's see if this works. Little demark. Okay, let's see if this works. CLS, Python step 03, open file is not defined. Ah, right, because I used my own function for that. Do, do, do, do, do, do, do, do, do. So let me... ... Darn it. Here, let me pause this for a second. I'll just copy this function from somewhere else. You don't need to see that. Okay, so what I had to do is I had to add this function. So what I usually do is because I have a very particular way of doing things and I do it every time, I usually write my own open file and write and save file function, which always does it in UTF-8, which is why I have to keep manually adding this stuff. Because you pick a default and you stick with it. So rather than ASCII or ANSI or whatever, I just say everything is UTF-8. Anyways, this should work. CLS. And if this works, I'll pause it. We'll take a look at the results and call it a day because then the last step is going to be getting it all together and visualizing it. That is going to be fun. Come on, you can do it. KeyErrorText, response.text. Key error text. Response dot text. Okay, so it didn't like that. All right, well, let me look at one of my other functions. Let's see, let's do YouTube, generate chapters. So I do response, choices text. Ah, response. So it didn't understand that part, but that's fine. Okay. So instead we'll do text equals and we'll do dot strip. Then we'll just do text and then write text. That should work. Away we go. Ninety-five percent of this was done with ChatGPT, if it works. There was a couple of things that I had to fix manually, but it did its best. And what I was really impressed by, one of the things I was really impressed by, oh, there we go. No such file, it didn't like the backslash, backslash, but we got some good JSON here. Okay, so then we get to open KGJSON, replace dot text with blah. Okay, so then we got to open KGJSON replace dot text with blah. Okay. So let me tell it this, say, okay, okay, that mostly worked, but I got an error. It may be important to note I'm running on Windows. Here's the error. Okay, so it's gonna be fixing this. So anyways, there's just a couple things that it didn't like. Okay, it didn't... Wait, is it that simple that it just, what didn't exist? Oh, it didn't create wait, is it that simple that it just, what didn't exist? Oh, it didn't create it, okay. Because the previous script, it checked and then made sure it existed. Okay, so anyways, yeah, so there's only a couple things that I had to go outside of this or background knowledge that I had. But for instance, when I asked it to use spaCy or NLTK, it tried, it didn't work, but then it suggested use regex instead, which is, you know, I would have done that as someone who's been cleaning up bulk data for a long time. Okay, so then it should add the little thing, you know, check if the, yep, there we go. This function, this bit right here. I'm pointing at the screen, you can't see it. If it doesn't exist, then make it. Okay, cool. So basically all we need is this. Really, you only need to check once. You don't need to check every single time, but whatever. That's fine. So then we'll come down here, check if it exists. All right. CLS, clear screen. With any luck, this worked. But yeah, so the vast majority of the code, it did. I just told it what to do. Now, imagine you slap a voice interface, so then you don't even have to type it out, right? Use Whisper, use OpenAI's Whisper. Hey, are you listening OpenAI? I want this, I wanna be able to talk through the code. Okay, so now we're saving this stuff. It should be here. Hey, look at that. Okay, so this will take a little while to run, but we've got good JSON. It worked, so I'm gonna go ahead and stop the video for today. I'm gonna let this finish running, and then tomorrow we will merge all this together and visualize it. Thanks for watching.", "chunks": [{"timestamp": [0.0, 9.1], "text": " Morning, everybody. David Shapiro here. We are back for part two of the Knowledge Graph"}, {"timestamp": [9.1, 17.44], "text": " Supreme Court decision thing. So we're using chat GPT and GPT-3 to help us along. And as"}, {"timestamp": [17.44, 28.24], "text": " a quick recap, where we left off was I didn't get that far, but I downloaded about 22 Supreme Court opinions."}, {"timestamp": [28.24, 32.8], "text": " This was about antitrust law, so a very specific domain."}, {"timestamp": [32.8, 35.28], "text": " And then I got them converted to text."}, {"timestamp": [35.28, 38.76], "text": " So that is, I did that with another repo."}, {"timestamp": [38.76, 41.28], "text": " It's fine."}, {"timestamp": [41.28, 55.0], "text": " But then what we did was, the big thing that we achieved was that we figured out that we can get GPT-3 to just go ahead and write my, write the, whatchamacallit for us, the knowledge graph JSON."}, {"timestamp": [55.0, 66.3], "text": " And so what I'm doing is the nodes that I asked for was each node should be a case citation precedent or prior opinion. Each note"}, {"timestamp": [66.3, 69.24], "text": " should have several properties such as date, case number, involved parties,"}, {"timestamp": [69.24, 74.48], "text": " reasoning for including in this opinion, and other relevant information. So that"}, {"timestamp": [74.48, 78.66], "text": " worked really well because you see like it's got a case number, it tells me when"}, {"timestamp": [78.66, 87.52], "text": " it happened, and then the reasoning, so like involved parties, like great, this is phenomenal information."}, {"timestamp": [87.52, 89.04], "text": " So what we're doing is we're gonna create"}, {"timestamp": [89.04, 91.8], "text": " a cross-linked web as to like"}, {"timestamp": [91.8, 94.52], "text": " why all these things are interlinked."}, {"timestamp": [94.52, 96.52], "text": " So that way, theoretically,"}, {"timestamp": [99.08, 100.38], "text": " this hypothetical use case,"}, {"timestamp": [100.38, 104.2], "text": " if an attorney is researching antitrust laws"}, {"timestamp": [104.2, 106.48], "text": " so that one, they can go to a court,"}, {"timestamp": [106.48, 111.84], "text": " court of appeals, or even present to the Supreme Court, they will have a masterful understanding"}, {"timestamp": [111.84, 119.12], "text": " of established law. And the reason that this is important is because common law is how law works"}, {"timestamp": [119.12, 126.04], "text": " in America. It's by prior precedent. So you've got the laws that are laid down by the legislative branch"}, {"timestamp": [126.04, 128.52], "text": " and then interpreted by the judicial branch."}, {"timestamp": [128.52, 131.08], "text": " And so the judicial branch keeps track"}, {"timestamp": [131.08, 133.26], "text": " of their own interpretation, right?"}, {"timestamp": [133.26, 135.04], "text": " Cause there's the legislative branch,"}, {"timestamp": [135.04, 136.52], "text": " it has to do with separation of powers."}, {"timestamp": [136.52, 139.42], "text": " Anyways, so that's how we got where we are."}, {"timestamp": [139.42, 140.88], "text": " It worked really well."}, {"timestamp": [140.88, 144.28], "text": " And there's all kinds of what ifs and gotchas"}, {"timestamp": [144.28, 145.12], "text": " that I'm not going to worry"}, {"timestamp": [145.12, 149.84], "text": " about because this worked really well and we can iterate over the over the"}, {"timestamp": [149.84, 155.84], "text": " long term. So but this I had to plug in manually and it's about four pages so"}, {"timestamp": [155.84, 161.16], "text": " like if we do if we search for how many new pages there are two three yeah one"}, {"timestamp": [161.16, 168.64], "text": " two three so that this has four pages total, which that was good."}, {"timestamp": [168.64, 174.92], "text": " So the next problem is we got to take these and regardless of how long they are, we have"}, {"timestamp": [174.92, 179.34], "text": " to break them down into chunks of four pages maximum."}, {"timestamp": [179.34, 184.16], "text": " So rather than do this manually, I was like, why don't I just ask chat GPT?"}, {"timestamp": [184.16, 186.24], "text": " So here we go."}, {"timestamp": [200.96, 215.0], "text": " I have a folder named, let's see, Opinions, Text. This folder contains contains text files of SCOTUS decisions that were converted from PDFs."}, {"timestamp": [215.0, 230.32], "text": " The pages are demarcated by the words new page. I need a Python function. So I'm basically talking to this thing like"}, {"timestamp": [230.32, 272.8], "text": " I'd be talking to a developer. I need a Python function where I pass... Actually, no, let's just ask it to do the whole thing. I need a Python function that reads every file in opinions underscore text and then breaks each file into chunks of four pages. The purpose of this is to"}, {"timestamp": [275.28, 284.88], "text": " limit the size of each subsequent file. Please then save the chunks"}, {"timestamp": [305.0, 306.44], "text": " file. Please then save the chunks into a folder named chunks text and append a serial number to the original file name."}, {"timestamp": [311.28, 315.92], "text": " For instance, star underscore one, star underscore two, and so on."}, {"timestamp": [317.88, 319.4], "text": " All right, let's see what it does."}, {"timestamp": [324.04, 327.28], "text": " Why would this violate the content policy?"}, {"timestamp": [331.92, 338.8], "text": " Okay, I sent in feedback. Let's see what we've got. So, import OS split text files,"}, {"timestamp": [338.8, 342.96], "text": " input folder, output folder, pages per chunk. So, good, it's parameterized it."}, {"timestamp": [349.12, 350.0], "text": " folder pages per chunk. So good, it's parameterized it. If not, output folder, make it nice. Okay."}, {"timestamp": [359.12, 368.4], "text": " For file and OSLister, input folder with open OSPath join, input folder file, R as F, read it, excellent. Pages equals split on new page, perfect. So it understood that. For I in chunk enumerate page range zero pages per chunk."}, {"timestamp": [368.4, 368.8], "text": " Excellent."}, {"timestamp": [368.8, 373.7], "text": " So this is this is a list comprehension that will break it into equal chunks"}, {"timestamp": [373.8, 378.1], "text": " or chunks of four output file equals this underscore plus."}, {"timestamp": [378.1, 378.9], "text": " Oh, dang."}, {"timestamp": [378.9, 379.8], "text": " That's good."}, {"timestamp": [380.3, 381.3], "text": " That's good."}, {"timestamp": [381.3, 381.8], "text": " Okay."}, {"timestamp": [383.6, 384.6], "text": " This is wonderful."}, {"timestamp": [385.0, 387.0], "text": " So let's go to this."}, {"timestamp": [387.0, 391.0], "text": " I had started writing it and then I was like, I don't have the energy for this."}, {"timestamp": [391.0, 394.0], "text": " I'm telling you."}, {"timestamp": [394.0, 397.0], "text": " I have said it on Twitter and I've said it on"}, {"timestamp": [397.0, 400.0], "text": " mostly Twitter, but LinkedIn and a few other places."}, {"timestamp": [400.0, 405.68], "text": " English, your ability to describe what you want is going to be the primary programming"}, {"timestamp": [405.68, 413.88], "text": " language from now on. Period. End of story. If you can think through a function, then"}, {"timestamp": [413.88, 421.36], "text": " yeah, this is it. So let's run this. Let's see if this worked."}, {"timestamp": [421.36, 426.56], "text": " Need a command prompt, CD, and we're in the SCOTUS opinions."}, {"timestamp": [426.56, 432.0], "text": " And then we'll do Python step 01 split chunks."}, {"timestamp": [432.0, 434.2], "text": " Why you no work?"}, {"timestamp": [434.2, 436.4], "text": " This actually happens quite a bit."}, {"timestamp": [436.4, 443.0], "text": " Let's see if it can fix it."}, {"timestamp": [443.0, 445.2], "text": " So thanks."}, {"timestamp": [445.2, 449.34], "text": " That mostly worked, but through this error."}, {"timestamp": [452.9, 455.44], "text": " Can you fix that error, please?"}, {"timestamp": [456.64, 459.16], "text": " Now, if this can debug this, I know exactly what it is."}, {"timestamp": [460.9, 461.4], "text": " Yep."}, {"timestamp": [463.16, 463.5], "text": " Yep."}, {"timestamp": [463.54, 465.16], "text": " There you go."}, {"timestamp": [472.8, 475.88], "text": " You need to specify the encoding."}, {"timestamp": [475.88, 478.64], "text": " Yep. Perfect."}, {"timestamp": [481.36, 485.36], "text": " Oh, wow. It's saying add the ignore flag."}, {"timestamp": [488.32, 492.8], "text": " Wonderful. Wonderful. Adding and coding UTF-8 should be sufficient."}, {"timestamp": [494.88, 512.12], "text": " So that goes do, do, do, do, do, do, do, do, do, do, do, do, do, do, do, do, do, do, do, do, do, Hmm, fascinating."}, {"timestamp": [512.12, 515.9], "text": " Did it get farther?"}, {"timestamp": [515.9, 517.56], "text": " This is weird though."}, {"timestamp": [517.56, 522.28], "text": " Input folder file, contents read encoding UTF-8 as in file."}, {"timestamp": [522.28, 528.56], "text": " So sometimes this happens. Let's see, what is the encoding here? So sometimes what"}, {"timestamp": [528.56, 538.0], "text": " I do is I'll convert it to something and then I'll convert back. So let's..."}, {"timestamp": [552.64, 559.76], "text": " Yeah. Hmm. I wonder what happens if we do, let's add that ignore thing. Rather than getting lost in the weeds, let's just do errors equal ignore. Because you know what? I looked at the"}, {"timestamp": [559.76, 569.68], "text": " text file. It looks fine to me. Oh, and let's also see if it, um, okay, it got pretty far already. So,"}, {"timestamp": [569.68, 575.6], "text": " it got pretty far in the process before blowing up. One, two, three. So, now we've got all the"}, {"timestamp": [575.6, 583.76], "text": " chunks. Cool, cool, cool. Um, all right. Heck with it. Send it. What do you mean?"}, {"timestamp": [581.62, 582.46], "text": " All right, heck with it. Send it."}, {"timestamp": [583.38, 584.22], "text": " What do you mean?"}, {"timestamp": [587.74, 589.14], "text": " This was in,"}, {"timestamp": [591.26, 594.1], "text": " so this was in split text files."}, {"timestamp": [594.1, 596.58], "text": " F write, oh, it couldn't write it."}, {"timestamp": [596.58, 597.42], "text": " Interesting."}, {"timestamp": [600.06, 602.06], "text": " Oh, okay, okay, okay."}, {"timestamp": [603.9, 604.82], "text": " So when we write it,"}, {"timestamp": [604.82, 608.38], "text": " we need to convert it to ASCII and back."}, {"timestamp": [608.38, 611.84], "text": " So let's see if it understands this."}, {"timestamp": [611.84, 617.88], "text": " Oh, man, I'll be jazzed if it understands this."}, {"timestamp": [617.88, 618.88], "text": " Okay."}, {"timestamp": [618.88, 619.88], "text": " Great."}, {"timestamp": [619.88, 620.88], "text": " That worked."}, {"timestamp": [620.88, 624.12], "text": " Now, I have a new problem."}, {"timestamp": [624.12, 625.0], "text": " Here's the error."}, {"timestamp": [625.0, 632.0], "text": " Please find a solution for this new bug."}, {"timestamp": [632.0, 653.76], "text": " So the problem here is, and I, yeah, that you're trying to join a list of strings that contain spaces? I don't think so."}, {"timestamp": [655.52, 672.8], "text": " New page. Nope, no, no, I don't think that's it. I think we need to fix the"}, {"timestamp": [674.8, 679.68], "text": " string encoding. Here's the last part of the error."}, {"timestamp": [691.0, 694.2], "text": " I feel like I'm talking to like HAL 9000. Yep, there it is."}, {"timestamp": [694.2, 697.2], "text": " That's it."}, {"timestamp": [697.2, 699.2], "text": " Yep."}, {"timestamp": [699.2, 705.0], "text": " Ah, so we need to add the encoding to UTF-8."}, {"timestamp": [706.24, 708.06], "text": " Right, okay, that makes sense."}, {"timestamp": [709.3, 710.86], "text": " This thing is smarter than me."}, {"timestamp": [713.94, 716.18], "text": " Okay, so when we write it, yeah."}, {"timestamp": [716.18, 717.84], "text": " Oh, that's the problem, okay."}, {"timestamp": [719.92, 722.68], "text": " Encoding equals UTF-8."}, {"timestamp": [722.68, 723.88], "text": " Okay, cool."}, {"timestamp": [723.88, 725.92], "text": " But this took way less brain power."}, {"timestamp": [725.92, 728.64], "text": " Okay, let's see if that works."}, {"timestamp": [728.64, 730.6], "text": " CLS, clear screen."}, {"timestamp": [730.6, 731.84], "text": " That was fast."}, {"timestamp": [731.84, 735.5], "text": " All right, so now we have 144 chunks of text."}, {"timestamp": [735.5, 737.72], "text": " Let's see what the biggest one is."}, {"timestamp": [737.72, 738.56], "text": " 20."}, {"timestamp": [739.68, 745.0], "text": " Uh. uh heh heh heh heh heh heh heh heh heh heh heh heh heh heh heh heh heh heh"}, {"timestamp": [745.0, 745.5], "text": " heh"}, {"timestamp": [745.5, 746.0], "text": " uh"}, {"timestamp": [746.0, 746.5], "text": " heh heh"}, {"timestamp": [746.5, 747.0], "text": " heh heh"}, {"timestamp": [747.0, 747.5], "text": " heh heh"}, {"timestamp": [747.5, 748.0], "text": " heh heh"}, {"timestamp": [748.0, 748.5], "text": " heh heh"}, {"timestamp": [748.5, 749.0], "text": " heh heh"}, {"timestamp": [749.0, 749.5], "text": " heh heh"}, {"timestamp": [749.5, 750.0], "text": " heh heh"}, {"timestamp": [750.0, 750.5], "text": " heh"}, {"timestamp": [750.5, 751.0], "text": " heh"}, {"timestamp": [751.0, 751.5], "text": " heh"}, {"timestamp": [751.5, 752.0], "text": " heh"}, {"timestamp": [752.0, 755.0], "text": " I think the uh, I think the OCR messed up with this one"}, {"timestamp": [755.0, 755.5], "text": " heh heh"}, {"timestamp": [755.5, 756.0], "text": " heh heh"}, {"timestamp": [756.0, 756.5], "text": " heh heh"}, {"timestamp": [756.5, 757.0], "text": " heh heh"}, {"timestamp": [757.0, 757.5], "text": " heh heh"}, {"timestamp": [757.5, 758.0], "text": " heh"}, {"timestamp": [758.0, 765.44], "text": " PROVIDES th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th-th- that the sherman act okay i'm probably disturbing my audience"}, {"timestamp": [767.08, 769.4], "text": " what's funny is that it got the capital letters fine"}, {"timestamp": [769.4, 771.4], "text": " but then the rest it's like, no"}, {"timestamp": [771.4, 772.64], "text": " i wonder if it was like"}, {"timestamp": [772.64, 775.84], "text": " if the scanner bed was like moving too slowly or something"}, {"timestamp": [781.84, 782.6], "text": " i'm sorry"}, {"timestamp": [783.12, 783.62], "text": " okay"}, {"timestamp": [784.48, 787.0], "text": " i'm gonna pause this because I'm going to keep laughing."}, {"timestamp": [787.0, 793.32], "text": " Okay, I had to stop and make myself tea."}, {"timestamp": [793.32, 795.84], "text": " I'm still probably going to be laughing at this."}, {"timestamp": [795.84, 796.84], "text": " I'm sorry."}, {"timestamp": [796.84, 799.72], "text": " Okay, now, normally, I'm sorry."}, {"timestamp": [799.72, 807.36], "text": " I don't know why this is so funny. Normally, this would,"}, {"timestamp": [807.36, 809.16], "text": " what I would do is just delete data,"}, {"timestamp": [809.16, 811.16], "text": " but in this case, I don't want to lose anything."}, {"timestamp": [811.16, 814.96], "text": " And imagine like, what if half of our files were like this?"}, {"timestamp": [814.96, 817.08], "text": " So let's come up with a solution."}, {"timestamp": [818.12, 820.64], "text": " So I'm going to,"}, {"timestamp": [820.64, 822.68], "text": " so this function works,"}, {"timestamp": [822.68, 824.46], "text": " so I'm gonna say, okay, cool."}, {"timestamp": [824.46, 827.18], "text": " Let's make a new script."}, {"timestamp": [827.18, 829.72], "text": " So let's go back over to chat.gpt."}, {"timestamp": [829.72, 847.0], "text": " Great, that all worked, but it turns out the OCR barfed on a few files. So there are lots of duplicated characters, such as,"}, {"timestamp": [847.0, 872.04], "text": " please write a new script using spaCy or nltk to deduplicate extra characters. Search through all the files in, let's see, what was the folder name?"}, {"timestamp": [872.04, 894.2], "text": " Chunks.txt in chunks underscore text. Deduplicate characters and then save the cleaned up copy in a new folder called deduped"}, {"timestamp": [894.2, 941.64], "text": " text. All right. Will that work?"}, {"timestamp": [946.0, 948.0], "text": " I don't know if that'll work."}, {"timestamp": [948.0, 950.0], "text": " Is spaCy that good?"}, {"timestamp": [954.0, 956.0], "text": " Or tndoc."}, {"timestamp": [958.0, 960.0], "text": " Um, okay."}, {"timestamp": [960.0, 964.0], "text": " I think I'll need to add the encoding, but let's give it a shot."}, {"timestamp": [967.44, 971.36], "text": " I think I'll need to add the encoding, but let's give it a shot. And let me make sure I've got pip install spacey."}, {"timestamp": [971.36, 973.84], "text": " Okay."}, {"timestamp": [973.84, 985.12], "text": " So while that's running, I will do save and we'll come back here and we'll do step 02."}, {"timestamp": [985.12, 990.84], "text": " So you might notice I do my functions in order."}, {"timestamp": [990.84, 994.8], "text": " So that way if you're looking at this repo, you don't have to try and reverse engineer"}, {"timestamp": [994.8, 996.48], "text": " what order to run things in."}, {"timestamp": [996.48, 999.68], "text": " It's just intrinsic documentation."}, {"timestamp": [999.68, 1003.64], "text": " Ddupe characters.py."}, {"timestamp": [1003.64, 1006.04], "text": " Okay. Group characters.py."}, {"timestamp": [1006.04, 1007.04], "text": " Okay."}, {"timestamp": [1007.04, 1011.08], "text": " Python step 02."}, {"timestamp": [1011.08, 1014.72], "text": " And I know that it's going to barf on this."}, {"timestamp": [1014.72, 1019.32], "text": " Let's do encoding equals UTF."}, {"timestamp": [1019.32, 1020.32], "text": " UTF-9."}, {"timestamp": [1020.32, 1024.76], "text": " UTF-9 is clearly better than UTF-8, right?"}, {"timestamp": [1024.76, 1027.0], "text": " It's the next mission."}, {"timestamp": [1027.0, 1032.0], "text": " Sorry. I'm in a mood today, apparently. You having a giggle, mate?"}, {"timestamp": [1032.0, 1035.0], "text": " Okay. Um..."}, {"timestamp": [1035.0, 1040.0], "text": " Let's see if it works."}, {"timestamp": [1040.0, 1052.0], "text": " I'm not going to use the GPU for something this simple. It's a small skipping register, can't find, doesn't seem to be a Python package."}, {"timestamp": [1052.0, 1057.88], "text": " Huh."}, {"timestamp": [1057.88, 1061.3], "text": " Let's see."}, {"timestamp": [1061.3, 1065.84], "text": " It gave me this error."}, {"timestamp": [1072.6, 1077.44], "text": " What does it mean? It didn't work."}, {"timestamp": [1087.0, 1091.0], "text": " This is the value of having good error messages, kids. Interesting."}, {"timestamp": [1091.0, 1112.48], "text": " All right. Let's see if that worked."}, {"timestamp": [1114.24, 1115.28], "text": " Still didn't work."}, {"timestamp": [1119.24, 1121.08], "text": " Um, okay."}, {"timestamp": [1122.88, 1124.24], "text": " All right, so in this case,"}, {"timestamp": [1124.24, 1126.04], "text": " it seems like we found a limitation."}, {"timestamp": [1126.04, 1128.04], "text": " Still didn't work."}, {"timestamp": [1128.04, 1135.2], "text": " Spacey load."}, {"timestamp": [1135.2, 1137.2], "text": " Is requirement already satisfied?"}, {"timestamp": [1137.2, 1144.68], "text": " Yeah, it says it's already satisfied."}, {"timestamp": [1144.68, 1168.4], "text": " Let's go to Google. Let's see if this... All right. Import. Import"}, {"timestamp": [1174.8, 1177.36], "text": " So it looks like you need to do you need to install"}, {"timestamp": [1190.68, 1196.8], "text": " Let's try this."}, {"timestamp": [1198.12, 1207.72], "text": " That looks like it did a thing. Sorry, I wasn't talking through it."}, {"timestamp": [1207.72, 1213.08], "text": " So, basically, I was looking, I found a spacey issue on GitHub."}, {"timestamp": [1213.08, 1218.0], "text": " And let's see, it hasn't bombed yet, so I wonder if it's working."}, {"timestamp": [1218.0, 1219.68], "text": " Deduped."}, {"timestamp": [1219.68, 1223.36], "text": " Oh, cool!"}, {"timestamp": [1223.36, 1224.68], "text": " There's nothing that's 20."}, {"timestamp": [1224.68, 1228.88], "text": " No, it didn't work."}, {"timestamp": [1228.88, 1231.88], "text": " Still didn't work."}, {"timestamp": [1231.88, 1234.88], "text": " Okay."}, {"timestamp": [1234.88, 1244.48], "text": " Yeah, so it seems like spacey is not sufficient, or at least this isn't."}, {"timestamp": [1244.48, 1247.84], "text": " Okay. So let's go back here."}, {"timestamp": [1248.4, 1259.52], "text": " Go back to this. Okay, I got spacey to load but the original script does not work. The words"}, {"timestamp": [1270.0, 1287.0], "text": " And some files are still wrong with lots of duplicated characters. So for instance, for example, I probably should have asked another way."}, {"timestamp": [1287.0, 1289.0], "text": " Yep."}, {"timestamp": [1289.0, 1291.0], "text": " Yep."}, {"timestamp": [1291.0, 1292.0], "text": " Okay."}, {"timestamp": [1292.0, 1294.0], "text": " So it's actually going to tell me."}, {"timestamp": [1294.0, 1295.0], "text": " Yeah, use regex."}, {"timestamp": [1295.0, 1299.0], "text": " So regex is actually the way I would have done it originally."}, {"timestamp": [1299.0, 1301.0], "text": " So it looks like this might be the right way to do it."}, {"timestamp": [1301.0, 1333.6], "text": " So, all right, let's see what it says. Bl will give that a try, but what about words where"}, {"timestamp": [1334.64, 1347.0], "text": " there are supposed to be duplicated characters, like book or look."}, {"timestamp": [1347.6, 1353.08], "text": " Does your script handle that?"}, {"timestamp": [1353.08, 1371.92], "text": " Can we use NLTK or spaCy or something else to account for correct words."}, {"timestamp": [1371.92, 1375.9], "text": " Also while this is running, I'm going to address the elephant in the room and that was a week"}, {"timestamp": [1375.9, 1381.4], "text": " ago I made a video saying, meh, chat GPT isn't that great."}, {"timestamp": [1381.4, 1386.52], "text": " So obviously I kind of have my foot in my mouth because this is amazing. It also looks like it failed"}, {"timestamp": [1388.4, 1390.4], "text": " So"}, {"timestamp": [1391.0, 1415.52], "text": " Alright, let me do a time check we are at 23 minutes, so we're to give me that thing."}, {"timestamp": [1415.52, 1421.68], "text": " So I think what we'll do is we'll just check"}, {"timestamp": [1421.68, 1427.4], "text": " to see if this happens, because it's better to have some data than none."}, {"timestamp": [1427.4, 1431.92], "text": " So I think what we'll do, all right, split chunks, that one worked."}, {"timestamp": [1431.92, 1433.4], "text": " Dedupe characters."}, {"timestamp": [1433.4, 1457.04], "text": " So what we need to do is find the ones where this happened, right? Generally, it looks like it only happened in one document."}, {"timestamp": [1457.04, 1460.72], "text": " Okay. So in this case,"}, {"timestamp": [1460.72, 1465.04], "text": " we'll say we'll pass in any file that"}, {"timestamp": [1465.04, 1467.84], "text": " starts with this."}, {"timestamp": [1467.84, 1472.4], "text": " So we'll eat the cost."}, {"timestamp": [1472.4, 1474.52], "text": " And what I mean by that is we'll just"}, {"timestamp": [1474.52, 1477.6], "text": " accept that some data is not going to be quite as good."}, {"timestamp": [1477.6, 1480.52], "text": " But that's plausible because it's an OCR mistake."}, {"timestamp": [1480.52, 1482.16], "text": " But the thing is, is we just need it"}, {"timestamp": [1482.16, 1484.48], "text": " to be small enough to fit in."}, {"timestamp": [1488.12, 1491.68], "text": " mistake, but the thing is, is we just need it to be small enough to fit in. So deduplicate characters."}, {"timestamp": [1491.68, 1505.64], "text": " Yeah, I don't think this is going to work."}, {"timestamp": [1509.16, 1520.84], "text": " It's close, but it's not quite. Thanks. Can you modify the script that uses regex instead?"}, {"timestamp": [1520.84, 1534.4], "text": " The only problem is in files with the name. Can you just sort or filter out any"}, {"timestamp": [1534.4, 1549.28], "text": " other files? Okay. So let's see what it comes up with there. Meanwhile, it looks like this is the largest one that is not good, right?"}, {"timestamp": [1549.28, 1551.28], "text": " So it's 13,000 characters long."}, {"timestamp": [1551.28, 1552.88], "text": " So let's see how many tokens this is."}, {"timestamp": [1554.0, 1556.48], "text": " So as long as it's, that's getting pretty close."}, {"timestamp": [1557.68, 1565.6], "text": " Let's see if we can, if our prompt will work. So prompt,"}, {"timestamp": [1575.2, 1581.6], "text": " and then we'll do text DaVinci 03, temperature zero, and our maximum length is going to be"}, {"timestamp": [1582.32, 1585.0], "text": " like 600 tokens. Otherwise it's going to be like 600 tokens."}, {"timestamp": [1585.0, 1587.16], "text": " Otherwise, it's going to be too long."}, {"timestamp": [1587.16, 1589.98], "text": " So let's see if that's enough."}, {"timestamp": [1589.98, 1592.12], "text": " The output is pretty short, so."}, {"timestamp": [1594.18, 1596.26], "text": " But JSON is pretty token intensive,"}, {"timestamp": [1596.26, 1597.98], "text": " so I wouldn't be surprised if it,"}, {"timestamp": [1597.98, 1600.16], "text": " yeah, so we ran out of space."}, {"timestamp": [1600.16, 1603.24], "text": " So it looks like we need to go back and do smaller chunks."}, {"timestamp": [1604.5, 1608.0], "text": " But fortunately, these earlier scripts are really easy."}, {"timestamp": [1608.0, 1609.92], "text": " So for instance, we just come back here."}, {"timestamp": [1609.92, 1614.16], "text": " And instead of doing, we just update this."}, {"timestamp": [1614.16, 1617.36], "text": " So instead of four pages, we do three."}, {"timestamp": [1617.36, 1621.56], "text": " And so then what we'll do is we'll come in here to opinions"}, {"timestamp": [1621.56, 1628.0], "text": " is fine, chunks, let's delete these. And then we'll rerun"}, {"timestamp": [1628.0, 1632.0], "text": " Python step 01."}, {"timestamp": [1632.0, 1636.0], "text": " And so now what we should have is more chunks."}, {"timestamp": [1636.0, 1640.0], "text": " So now we have 188 chunks, but you see the"}, {"timestamp": [1640.0, 1644.0], "text": " that one, that one."}, {"timestamp": [1644.0, 1652.4], "text": " So this is now the largest and it's only 10 kilobytes or 9,000 characters long."}, {"timestamp": [1652.4, 1656.24], "text": " So this should be small enough to run."}, {"timestamp": [1656.24, 1660.24], "text": " Let's see how many tokens it is."}, {"timestamp": [1660.24, 1665.76], "text": " Okay, so now we're down to 2,800 tokens."}, {"timestamp": [1665.76, 1667.58], "text": " Let me remove the JSON part."}, {"timestamp": [1668.44, 1672.18], "text": " So now we're at 2,500 tokens tops."}, {"timestamp": [1672.18, 1677.18], "text": " So we can do like 1,450."}, {"timestamp": [1677.66, 1679.56], "text": " So that's more than twice as many tokens."}, {"timestamp": [1679.56, 1682.52], "text": " So let's see, it's more than twice as many tokens"}, {"timestamp": [1682.52, 1685.0], "text": " with 25% less input."}, {"timestamp": [1685.88, 1688.42], "text": " So theoretically this should be the limit."}, {"timestamp": [1691.0, 1692.56], "text": " Cool."}, {"timestamp": [1692.56, 1693.68], "text": " All right."}, {"timestamp": [1693.68, 1695.24], "text": " Excellent."}, {"timestamp": [1695.24, 1696.3], "text": " I think this is good."}, {"timestamp": [1698.54, 1700.74], "text": " All right, so we're almost done for the day."}, {"timestamp": [1702.8, 1709.36], "text": " Let's see what chat GPT said. Deduplicate characters. Yeah, there we go. Okay. So let's"}, {"timestamp": [1709.36, 1729.96], "text": " do this for the dedupe. So let's come back here add the, whatchamacallit, encoding. Encoding equals"}, {"timestamp": [1729.96, 1745.52], "text": " UTF-8, and then for the write, encoding equals UTF-8. Okay, so now if we go to the deduped, oh actually here we need to delete this."}, {"timestamp": [1749.28, 1750.88], "text": " It did all of them, interesting."}, {"timestamp": [1758.88, 1761.76], "text": " Oh, that's, no, if not in file,"}, {"timestamp": [1765.4, 1766.36], "text": " it got the logic wrong."}, {"timestamp": [1766.36, 1768.56], "text": " I'm like, no, it was only supposed to do like five of these."}, {"timestamp": [1769.12, 1769.84], "text": " Try that again."}, {"timestamp": [1772.84, 1773.48], "text": " There we go."}, {"timestamp": [1773.52, 1773.76], "text": " Okay."}, {"timestamp": [1773.76, 1777.72], "text": " So now the largest of these is eight kilobytes, which is plenty small."}, {"timestamp": [1778.12, 1781.08], "text": " So we come back to chunks and we'll replace those."}, {"timestamp": [1781.52, 1782.2], "text": " Replace."}, {"timestamp": [1782.24, 1782.64], "text": " Yes."}, {"timestamp": [1782.64, 1786.04], "text": " So now our absolute largest file is 10 kilobytes,"}, {"timestamp": [1786.04, 1788.0], "text": " 9,300 characters."}, {"timestamp": [1788.0, 1790.56], "text": " So this should all easily fit within,"}, {"timestamp": [1792.64, 1794.16], "text": " no, this should all easily fit"}, {"timestamp": [1794.16, 1796.92], "text": " within our prompt window here."}, {"timestamp": [1796.92, 1801.68], "text": " So now we need to just go ahead and run the thing."}, {"timestamp": [1804.24, 1806.94], "text": " So, all right, so let's say,"}, {"timestamp": [1809.72, 1814.72], "text": " excellent, we are now ready to run our prompts."}, {"timestamp": [1816.2, 1821.2], "text": " Are you familiar with OpenAI Python module?"}, {"timestamp": [1829.68, 1832.68], "text": " Python module. Open AI is."}, {"timestamp": [1832.68, 1837.02], "text": " I'm wondering if it's slowing down because people are waking up."}, {"timestamp": [1837.02, 1842.32], "text": " This is one advantage of being a super early bird is I get up earlier than everyone else."}, {"timestamp": [1842.32, 1845.4], "text": " Granted, it's always middle of the day somewhere in the world."}, {"timestamp": [1847.88, 1848.72], "text": " Anyways,"}, {"timestamp": [1850.66, 1855.24], "text": " so this may or may not help us with this part."}, {"timestamp": [1855.24, 1859.8], "text": " So now let's see, open file, save file, open AI key,"}, {"timestamp": [1859.8, 1861.6], "text": " text DaVinci 03, temp that,"}, {"timestamp": [1861.6, 1866.6], "text": " that we can do this up to 1,450."}, {"timestamp": [1866.6, 1868.56], "text": " That's fine."}, {"timestamp": [1868.56, 1869.64], "text": " Encode."}, {"timestamp": [1871.92, 1876.92], "text": " All right, so this, I just cannibalized another thing."}, {"timestamp": [1877.08, 1879.54], "text": " We do not want to clean that up"}, {"timestamp": [1879.54, 1882.44], "text": " because this is going to be there."}, {"timestamp": [1882.44, 1883.7], "text": " That's fine."}, {"timestamp": [1883.7, 1884.54], "text": " All right."}, {"timestamp": [1884.54, 1885.38], "text": " Network error."}, {"timestamp": [1885.38, 1887.68], "text": " Yeah, I figured that would happen."}, {"timestamp": [1887.68, 1889.52], "text": " Okay, so let's do a refresh."}, {"timestamp": [1891.56, 1894.0], "text": " I have a folder called,"}, {"timestamp": [1895.24, 1896.76], "text": " what is the name of my folder?"}, {"timestamp": [1896.76, 1900.56], "text": " God, I have like chipmunk memory."}, {"timestamp": [1900.56, 1902.44], "text": " It's hard, chipmunk memory."}, {"timestamp": [1903.48, 1910.76], "text": " Called chunks.txt. Called chunks underscore text."}, {"timestamp": [1910.76, 1915.32], "text": " That is full of .txt files."}, {"timestamp": [1915.32, 1974.84], "text": " Each file, please write a Python script that uses OpenAI module and calls and uses text DaVinci file in the chunks folder to populate a prompt. Let's see. Prompt underscore JSON LD, citation nodes dot text, and has a placeholder called, what"}, {"timestamp": [1974.84, 1977.84], "text": " did I call the placeholder?"}, {"timestamp": [1977.84, 1979.84], "text": " Chunk."}, {"timestamp": [1979.84, 2011.44], "text": " Called chunk. In other words, open the text file, or no, let and use this as the prompt for OpenAI."}, {"timestamp": [2011.44, 2019.16], "text": " Set the temperature to 0 and the token count to 1450."}, {"timestamp": [2019.16, 2022.76], "text": " Let's see if that works."}, {"timestamp": [2022.76, 2028.36], "text": " Certainly here's a script that should do what you have described."}, {"timestamp": [2028.36, 2030.2], "text": " I do it differently because I use Windows."}, {"timestamp": [2030.2, 2054.64], "text": " I know I'm a charlatan. I think it's going to work."}, {"timestamp": [2064.04, 2066.48], "text": " So this is the implications of this."}, {"timestamp": [2066.98, 2074.22], "text": " If chat GPT knows how to call GPT, in theory, you can create a machine that can"}, {"timestamp": [2074.22, 2076.98], "text": " do its own experiments with language models."}, {"timestamp": [2079.08, 2080.28], "text": " I want to say that again."}, {"timestamp": [2080.66, 2085.64], "text": " The implication here is now we have a system of a machine that understands the"}, {"timestamp": [2085.64, 2090.98], "text": " code to call itself well enough, and then obviously this thing is intelligent enough"}, {"timestamp": [2090.98, 2097.58], "text": " to understand results, you could in theory have something that trains itself or makes"}, {"timestamp": [2097.58, 2099.88], "text": " its own data sets or whatever."}, {"timestamp": [2099.88, 2106.48], "text": " Okay, so I like this. Whoops. Copy code."}, {"timestamp": [2106.48, 2109.44], "text": " Let's come over here and do this."}, {"timestamp": [2111.54, 2114.24], "text": " I guess I didn't say what to do with the response."}, {"timestamp": [2117.44, 2120.18], "text": " So we'll do, let's see."}, {"timestamp": [2136.14, 2137.64], "text": " And then, yeah, we don't need any of this stuff. That's fine."}, {"timestamp": [2137.64, 2146.0], "text": " And then we need to, rather than print, we'll need to save."}, {"timestamp": [2146.88, 2154.88], "text": " Great. The output from the, let's see."}, {"timestamp": [2154.88, 2162.0], "text": " Great. Now, response.txt should be in JSON format."}, {"timestamp": [2162.0, 2170.36], "text": " Can you please save the output to a new folder called, let's see, we'll say"}, {"timestamp": [2170.36, 2195.7], "text": " called ag underscore JSON instead of just printing. We should, let's see, otherwise, use the same file name as the .txt file, but just replace"}, {"timestamp": [2195.7, 2212.4], "text": " the .txt with .json. Let's see. Before you write this script, can you tell me if you understand?"}, {"timestamp": [2212.4, 2222.58], "text": " Give me some pseudocode so I can check to make sure we understand each other."}, {"timestamp": [2222.58, 2235.68], "text": " If this works, yeah."}, {"timestamp": [2235.68, 2240.64], "text": " Well it understands the concept of pseudocode and then it is going to go ahead and write"}, {"timestamp": [2240.64, 2241.64], "text": " the script."}, {"timestamp": [2241.64, 2242.64], "text": " Okay, cool."}, {"timestamp": [2242.64, 2248.82], "text": " Let's see if it fixes it. Asking for the pseudocode may or may not be viable,"}, {"timestamp": [2248.82, 2250.44], "text": " especially because this code is so simple."}, {"timestamp": [2250.44, 2252.64], "text": " It might have been easier just to ask for it"}, {"timestamp": [2254.96, 2258.06], "text": " to just go ahead and do it, but yeah."}, {"timestamp": [2258.06, 2261.16], "text": " So we're also going to need to do"}, {"timestamp": [2264.16, 2275.48], "text": " coding equals UTF-8, always need to do that."}, {"timestamp": [2275.48, 2281.6], "text": " I'll just copy this."}, {"timestamp": [2281.6, 2284.68], "text": " And then we'll need the same."}, {"timestamp": [2284.68, 2288.6], "text": " Yep. And then we'll need the same."}, {"timestamp": [2290.56, 2294.6], "text": " Yep, okay."}, {"timestamp": [2295.44, 2302.16], "text": " Cool."}, {"timestamp": [2306.56, 2309.56], "text": " So instead of printing it, we save it. So with open as blah, blah, blah, right."}, {"timestamp": [2309.56, 2312.68], "text": " So let's go ahead and grab this."}, {"timestamp": [2312.68, 2313.18], "text": " Comma."}, {"timestamp": [2317.28, 2319.08], "text": " I think we're ready."}, {"timestamp": [2319.08, 2324.24], "text": " So then one last thing, though, is what I like to do"}, {"timestamp": [2324.24, 2328.0], "text": " is we'll keep the print just so that way"}, {"timestamp": [2328.0, 2329.84], "text": " we know what's going on."}, {"timestamp": [2329.84, 2336.64], "text": " And we'll add new line, new line, new line, and then response.text."}, {"timestamp": [2336.64, 2345.4], "text": " Here actually we'll add a little demark. Let's see if this works. Little demark."}, {"timestamp": [2345.4, 2347.56], "text": " Okay, let's see if this works."}, {"timestamp": [2347.56, 2352.56], "text": " CLS, Python step 03, open file is not defined."}, {"timestamp": [2355.16, 2360.16], "text": " Ah, right, because I used my own function for that."}, {"timestamp": [2362.8, 2364.52], "text": " Do, do, do, do, do, do, do, do, do."}, {"timestamp": [2364.52, 2366.0], "text": " So let me..."}, {"timestamp": [2366.0, 2370.0], "text": " ..."}, {"timestamp": [2370.0, 2372.0], "text": " Darn it. Here, let me pause this for a second."}, {"timestamp": [2372.0, 2374.0], "text": " I'll just copy this function from somewhere else. You don't need to see that."}, {"timestamp": [2374.0, 2376.0], "text": " Okay, so what I had"}, {"timestamp": [2376.0, 2378.0], "text": " to do is I had to add this function."}, {"timestamp": [2378.0, 2380.0], "text": " So what I usually do is because"}, {"timestamp": [2380.0, 2382.0], "text": " I have a very particular way of doing things"}, {"timestamp": [2382.0, 2384.0], "text": " and I do it every time, I usually"}, {"timestamp": [2384.0, 2385.32], "text": " write my own open file"}, {"timestamp": [2385.32, 2388.16], "text": " and write and save file function,"}, {"timestamp": [2388.16, 2390.0], "text": " which always does it in UTF-8,"}, {"timestamp": [2390.0, 2392.56], "text": " which is why I have to keep manually adding this stuff."}, {"timestamp": [2392.56, 2395.12], "text": " Because you pick a default and you stick with it."}, {"timestamp": [2395.12, 2397.48], "text": " So rather than ASCII or ANSI or whatever,"}, {"timestamp": [2397.48, 2398.92], "text": " I just say everything is UTF-8."}, {"timestamp": [2398.92, 2400.26], "text": " Anyways, this should work."}, {"timestamp": [2401.12, 2401.96], "text": " CLS."}, {"timestamp": [2406.46, 2408.74], "text": " And if this works, I'll pause it. We'll take a look at the results and call it a day because"}, {"timestamp": [2408.74, 2410.56], "text": " then the last step is going to"}, {"timestamp": [2410.56, 2412.64], "text": " be getting it all together and visualizing it."}, {"timestamp": [2412.64, 2417.96], "text": " That is going to be fun. Come on, you can do it."}, {"timestamp": [2419.68, 2426.48], "text": " KeyErrorText, response.text. Key error text."}, {"timestamp": [2426.48, 2428.48], "text": " Response dot text."}, {"timestamp": [2428.48, 2432.36], "text": " Okay, so it didn't like that."}, {"timestamp": [2432.36, 2441.4], "text": " All right, well, let me look at one of my other functions."}, {"timestamp": [2441.4, 2445.86], "text": " Let's see, let's do YouTube, generate chapters."}, {"timestamp": [2445.86, 2449.84], "text": " So I do response, choices text."}, {"timestamp": [2449.84, 2452.16], "text": " Ah, response."}, {"timestamp": [2452.16, 2455.4], "text": " So it didn't understand that part, but that's fine."}, {"timestamp": [2455.4, 2456.66], "text": " Okay."}, {"timestamp": [2456.66, 2470.68], "text": " So instead we'll do text equals and we'll do dot strip. Then we'll just do text and then write text."}, {"timestamp": [2470.68, 2477.0], "text": " That should work. Away we go."}, {"timestamp": [2477.0, 2482.24], "text": " Ninety-five percent of this was done with ChatGPT, if it works."}, {"timestamp": [2482.24, 2485.04], "text": " There was a couple of things that I had to fix manually,"}, {"timestamp": [2486.4, 2488.2], "text": " but it did its best."}, {"timestamp": [2488.2, 2490.44], "text": " And what I was really impressed by,"}, {"timestamp": [2490.44, 2491.96], "text": " one of the things I was really impressed by,"}, {"timestamp": [2491.96, 2492.78], "text": " oh, there we go."}, {"timestamp": [2495.8, 2498.56], "text": " No such file, it didn't like the backslash, backslash,"}, {"timestamp": [2498.56, 2501.06], "text": " but we got some good JSON here."}, {"timestamp": [2502.04, 2504.96], "text": " Okay, so then we get to open KGJSON,"}, {"timestamp": [2504.96, 2507.68], "text": " replace dot text with blah. Okay, so then we got to open KGJSON replace dot text with blah. Okay."}, {"timestamp": [2510.16, 2516.88], "text": " So let me tell it this, say, okay, okay, that mostly worked, but I got an error."}, {"timestamp": [2518.16, 2525.92], "text": " It may be important to note I'm running on Windows."}, {"timestamp": [2527.16, 2531.48], "text": " Here's the error."}, {"timestamp": [2533.32, 2536.16], "text": " Okay, so it's gonna be fixing this. So anyways, there's just a couple things"}, {"timestamp": [2538.08, 2539.56], "text": " that it didn't like."}, {"timestamp": [2539.56, 2540.88], "text": " Okay, it didn't..."}, {"timestamp": [2543.7, 2545.0], "text": " Wait, is it that simple that it just, what didn't exist? Oh, it didn't create wait, is it that simple that it just,"}, {"timestamp": [2545.84, 2546.74], "text": " what didn't exist?"}, {"timestamp": [2546.74, 2548.24], "text": " Oh, it didn't create it, okay."}, {"timestamp": [2549.22, 2550.88], "text": " Because the previous script, it checked"}, {"timestamp": [2550.88, 2553.42], "text": " and then made sure it existed."}, {"timestamp": [2553.42, 2557.04], "text": " Okay, so anyways, yeah, so there's only a couple things"}, {"timestamp": [2557.04, 2558.6], "text": " that I had to go outside of this"}, {"timestamp": [2558.6, 2560.72], "text": " or background knowledge that I had."}, {"timestamp": [2560.72, 2564.32], "text": " But for instance, when I asked it to use spaCy or NLTK,"}, {"timestamp": [2567.04, 2572.58], "text": " it tried, it didn't work, but then it suggested use regex instead, which is, you know, I would have done that"}, {"timestamp": [2572.58, 2577.08], "text": " as someone who's been cleaning up bulk data for a long time."}, {"timestamp": [2577.08, 2585.0], "text": " Okay, so then it should add the little thing, you know, check if the,"}, {"timestamp": [2586.36, 2587.42], "text": " yep, there we go."}, {"timestamp": [2587.42, 2589.44], "text": " This function, this bit right here."}, {"timestamp": [2589.44, 2592.18], "text": " I'm pointing at the screen, you can't see it."}, {"timestamp": [2592.18, 2593.6], "text": " If it doesn't exist, then make it."}, {"timestamp": [2593.6, 2594.52], "text": " Okay, cool."}, {"timestamp": [2597.16, 2600.26], "text": " So basically all we need is this."}, {"timestamp": [2600.26, 2602.04], "text": " Really, you only need to check once."}, {"timestamp": [2602.04, 2608.54], "text": " You don't need to check every single time, but whatever. That's fine. So then we'll come down here,"}, {"timestamp": [2608.54, 2610.4], "text": " check if it exists."}, {"timestamp": [2610.4, 2614.72], "text": " All right. CLS, clear screen."}, {"timestamp": [2614.72, 2616.64], "text": " With any luck, this worked."}, {"timestamp": [2616.64, 2620.38], "text": " But yeah, so the vast majority of the code, it did."}, {"timestamp": [2620.38, 2621.76], "text": " I just told it what to do."}, {"timestamp": [2621.76, 2624.8], "text": " Now, imagine you slap a voice interface,"}, {"timestamp": [2624.8, 2628.7], "text": " so then you don't even have to type it out, right?"}, {"timestamp": [2628.7, 2630.86], "text": " Use Whisper, use OpenAI's Whisper."}, {"timestamp": [2630.86, 2632.86], "text": " Hey, are you listening OpenAI?"}, {"timestamp": [2632.86, 2635.92], "text": " I want this, I wanna be able to talk through the code."}, {"timestamp": [2635.92, 2637.8], "text": " Okay, so now we're saving this stuff."}, {"timestamp": [2637.8, 2639.48], "text": " It should be here."}, {"timestamp": [2639.48, 2640.72], "text": " Hey, look at that."}, {"timestamp": [2640.72, 2642.8], "text": " Okay, so this will take a little while to run,"}, {"timestamp": [2642.8, 2645.08], "text": " but we've got good JSON. It"}, {"timestamp": [2645.08, 2648.64], "text": " worked, so I'm gonna go ahead and stop the video for today. I'm gonna let this"}, {"timestamp": [2648.64, 2653.36], "text": " finish running, and then tomorrow we will merge all this together and visualize it."}, {"timestamp": [2653.36, 2656.56], "text": " Thanks for watching."}]}