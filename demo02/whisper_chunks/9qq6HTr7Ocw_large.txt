{"text": " Morning, everybody. David Shapiro here with another video. So this is a question that I get a lot. People ask, how do I fine tune GPT-3 on my corpus of data so that I can ask questions? So let's talk about fine tuning versus search, when to use which, and why. So as I just mentioned, I get a lot of questions about QA. How do I train my model on legal cases or statutes or contracts, technical documentation like APIs or KB articles, medical records, so on and so forth. I get this question all the time. And basically people want to be able to ask questions against their corpus and they think that fine-tuning a model is the way to do it, that all the knowledge will just be compressed into the model and you'll get good answers. You don't! That's not how it works. Next question. Okay, fine. I guess I'll explain this and unpack it. So first we have to talk about what is fine-tuning. Fine-tuning is a type of transfer learning. So transfer learning was originally created a few years back for image models, earlier image recognition models, but it also applies to NLP tasks. Now, if you look up like, what is fine-tuning good for? You'll see stuff like classification, sentiment analysis, and named entity recognition. This is old school. Ignore all that. That is like last generation NLP. We are no longer in NLP. NLP is spacey, NLTK, stuff like that. We are in NLU, natural language understanding and natural language generation. So pretty much if it's an NLP benchmark, ignore it. If it's an NLP task, ignore it. There are cheaper, faster, simpler ways of doing that. If you're using a large language model for named entity recognition, like that's using like nuclear fusion to power your house. It's way overkill. You can use smaller models like Curie and Babbage to do those if they're fine-tuned, but we'll get into that at a later date maybe if y'all want. So the short answer though is that when you do fine-tuning, you're teaching it a new task. You're not teaching it new information, you're teaching it a new task. You're not teaching it new information, you're teaching it a new task. It's kind of like tweaking a guitar just so that the final performance is a little bit better. We'll unpack that more in just a minute. What is semantic search? So in order to compare the two, you need to understand both of them. So semantic search is also called neural search or vector search. Semantic search is just easier to say, but if you hear neural search or vector search. Semantic search is just easier to say, but if you hear neural search or vector search, it's the same thing. And the TLDR of how it works is you use a semantic embedding, which is just a string of numbers that represents the meaning of the text. And it allows next-gen databases to scale very large, very fast, and also to search not just with keywords or indexes, it allows them to search based on the semantic meaning, the actual content, the context, and the topics discussed in the actual records in your new database. They can scale very large, they're very fast, and they're also very cheap, at least in comparison to fine-tuned models. So fine-tuning and semantic search sound drastically different. They're entirely different technologies. The only similarity is that at some point they use semantic embeddings or vector embeddings. That's the point. Fine-tuning for QA is like using a hammer when you really needed a broom. It is the wrong tool for the job. It's that simple. So how did we get here though? Why does everyone think that you can use fine-tuning to teach it new information and that you should then be able to do QA just with a single model. This is probably the biggest misconception about fine-tuning, because when you think like, oh, well, GPT-3 was trained on Wikipedia, and now it knows all of Wikipedia, so if I just fine-tune it with a little bit more data, then it should know that new data too, right? No, wrong. The reason is because it is transfer learning, and so it's only unfreezing a small portion of the model. It's not actually retraining the entire model. There's a few other problems where, and we'll get to this in the next slide, where fine tuning does not overrule confabulation or hallucination, it's the same thing. So basically what you're doing is, think of it like if you learn to tie your shoes you can tie pretty much any string. That is an example of transfer learning. You're not learning any fundamentally new physics, you're not learning how to do anything different with your hands, you're just saying I can tie my shoes now I can tie a string. Or if you can stack a wooden block then you can also stack bricks, right? That is an example of transfer learning where you take something that you've already learned to do and then you're just applying it to a slightly different task. So fine-tuning is just new tasks. It's not new information, it's not new knowledge, just a new task. Fine-tuning is not the same as taking the large language model back to school. To do that you have to unfreeze the entire model which is ludicrously expensive and even then it doesn't get rid of confabulation and hallucination. So these are just fancy anthropomorphic terms for gaps in LLM abilities. I talked about this in another video. The short version is LLMs on their own do not have an epistemology. They don't have a theory of knowledge. They don't even have a theory of mind, really. You can test it and they can talk about mind, but they don't have in practice any epistemological theory or abilities. They don't know what they know, and they don't know why they know it or anything. They just barf out a possibility. And so because of that, fine-tuning is not good as a knowledge store. Period. End of story. Do not use it. It is not reliable. Now, that being said, you can, like, so if you look at, if you look at chat GPT, like chat GPT, you might say, ah, no, chat GPT has some theory of knowledge because it'll tell me, like, I don't know that. No, it's just following a pattern. It was told, it was taught that if you ask certain questions, it's supposed to tell you that it doesn't know, but then you just ask a different way and it'll tell you, right? Because one chat GPT does not have any cognitive architecture, it is just a fine-tuned model. And this is one of the biggest gaps in OpenAI's approach. They are a model-only shop. They don't, as far as I can tell, OpenAI has not invested anything in understanding cognitive architecture or neuroscience. They seem to believe that all that they need is a bigger, more powerful model. And if they can do it, great. If they can create a model, a large language model, that understands what it doesn't know, great. But there are mathematicians out there that I've talked to that said a large language model, a single model, as we know it today, will never have this ability. It will never be able to understand what it does and does not know. You will have to have a system or a fundamentally different kind of model in order to have any sense of epistemology. So this is why fine tuning will probably never, at least with the current paradigm, will probably never be good as an information store. Not as a reliable one, at least. Another problem, fine tuning is slow, difficult, and expensive. I've seen really boneheaded claims out there, and I'm not gonna name names, but where people have said like, oh, it takes 200,000 samples to do fine tuning, and even then it doesn't work. And I'm like, buddy, that's saying more about yourself than anyone else. Anyways, that's BS. I have dozens of videos of fine tuning and showing that it is successful, but it does underscore an important point. Most people don't get it. Fine tuning is an entirely new discipline. You know, as far as I know, there aren't even good books out there. Like I've even thought about writing a book on fine tuning, but fine tuning is one of my most valuable skills. So it's like, you know, on the one hand, I want to teach the world, but on the other hand, I also have a startup, right? So I've got a conflict of interest there. But fine tuning is difficult. Most people do not figure it out. Most people don't get it. And even after I try and teach people, most people still don't get it. What I usually say is fine-tuning is 100 times more difficult than prompt engineering. It's actually more like 10,000 times more difficult. It is hard. It's also very expensive. Fine-tuning is so expensive that most other companies have not figured out how open AI does it, which also means that OpenAI, OpenAI is in the same boat as I am, and I know that I criticize OpenAI, and so does everyone else, where on the one hand, they want to help the world, but on the other hand, they have their profit motive to think of, and so I realize I can't criticize them anymore because I am withholding information for my own benefit as well. So I just want to put that out there that and after having some conversations with people in the alignment field This is an open question. How much do we share and why? Because there are there are dangerous players out there that are just leeches or that are using it for nefarious purposes So it's like okay, maybe we don't share everything. This is an open question. So I am still a little bit skeptical of open AI, but it is what it is. And I just wanted to add that little bit to be fair because like, pot calls kettle black, right? Like I'm withholding information, they're withholding information. I can't really criticize them. So I just wanted to address that elephant in the room. Okay, so let's compare, let's do a side-by-side of fine-tuning versus semantic search. Fine-tuning is slow, difficult, and expensive. Semantic search is fast, easy, and cheap. Which one do you think is better? Fine-tuning, prone to confabulation. Semantic search recalls exact information. Fine-tuning just teaches to confabulation, semantic search recalls exact information. Fine-tuning just teaches a new task, not new information. Whereas semantic search, it is very easy to add new information to your database or your index. Fine-tuning requires constant retraining. Whenever you add a new document, you need to retrain the entire model, and that is very expensive. Whereas with semantic search,. And that is very expensive. Whereas with semantic search, adding new elements is very easy. Fine tuning is not scalable. The cost of fine tuning goes up proportional to the amount of data that you have. Whereas semantic search is, I say infinitely scalable, and technically it's not infinitely scalable, but like the FAISS, the Facebook AI semantic search, that scales to like a trillion elements. So that's way more scalable than fine tuning. And I'll say that fine tuning does not work for QA with a little asterisk, we'll talk about that in a second. And then semantic search solves half of QA, and we'll get to the other half in just a moment. But first I wanted to address what do I mean when I say fine-tuning doesn't work for QA with an asterisk. That is that you can use a fine-tuned model to help with the QA process. So for instance when you're creating an answer you have a question, then you have a corpus or you know some reference material, and then the answer. So there's three components. And so when I talk about task, answering a question from a given corpus is a specific task. And OpenAI actually had a QA endpoint, but they deprecated it because it wasn't that good and nobody used it. But what I will say is that the current instruct models are perfectly fine. You just say, here's my question, here's the body of information, is the answer here yes or no? And if so, what is the answer? So it can be a component of it, but it's not necessary, especially with the latest instruct aligned models. So in short, using fine-tuning for QA is like using a hammer to drive a screw through a board on your knee. You could do it, but you're gonna regret it. It's not gonna work. It's the wrong tool for the job. Okay, so what is fine-tuning good for then? So I talked about how it teaches a new task. So the correct way to think about fine-tuning is that it teaches the model a pattern, right? What you're teaching it is not new information, you're teaching it a pattern. And so, chat GPT, for instance, is a pattern. The pattern is short user query, long machine response. Writing emails is a pattern. The pattern is short user query, long machine response. Writing emails is a pattern. All kinds of code, whether it's JSON, HTML, C++, whatever, those are all patterns, right? And fiction, even writing long-form fiction is a pattern. And yes, I trained Curie to write long-form fiction. I'm not going to show you how, but I will show you in a minute just to prove that it's possible. So basically the short answer is fine-tuning is really good at teaching it a new a task or pattern-based task. So without further ado, here is my Curie-based scene generator. So I have a very short input and then it goes and writes several pages of a fictional scene. And most of you won't believe that I did this on Curie. I don't care. Believe me or not. I'm not going to show you how because this is incredibly valuable. Anyways, okay, so at this point you're probably saying, yeah Dave, I get it. You know, I get the point, I get the concept. So how do we do QA? So there are, well, first, how do you do QA? How does a human do QA? First, you start with a question, then you go forage for information, then as you're foraging, you compile a corpus of relevant data, then you extract the salient bits from that corpus, and then you finally produce an answer. Do you remember libraries? So let's use a library analogy to do QA. So how do you find stuff in a library? Use a Dewey Decimal System. Dewey Decimal System is basically a human-readable semantic embedding. The Dewey Decimal System is basically a human-readable semantic embedding. The Dewey Decimal System is a string of numbers that tell you roughly what's contained in the book. And so when you have a question, you match your question to a Dewey Decimal Number, and you say, usually you ask a librarian, where in the library do I need to go? And it's like, okay, well, you probably need like 541.26 and you also want something from the 900s or whatever. And so then you go, you go get a stack of books. This is your semantic search, right? You go get a stack of books, you take them back to your desk. So now you have a corpus. You've gone from a huge amount of data to a much smaller subset that you're looking through. Then you skim them, you look at their appendices, you look at their chapters, whatever, and you say, ah, so you zoom in, you zoom in further and you say, this page on this book has what I need, right? That's what the index is for, is literally so that you can just say, ah, I'm looking for King George V or whatever, he's mentioned on page 286. So you go there, you jot down some notes, you compile all that data together, you're not answering your question yet, you're just getting all the relevant facts together. Finally, once you get all the notes together, then you have a much shorter document. You've gone from thousands of books, tens of thousands of books, to maybe, you know, a dozen books and you then you distill that further down into a page or two of relevant information, and finally you can answer your question. So let's break this down into simple steps that you can do with a machine. First, you index your corpus with semantic embeddings. This makes it searchable. And this is whatever your corpus is, case law, medical records, whatever. Then, once you have your question, you use your large language model to generate relevant search terms or queries, relevant questions, and then you also use an embedding, which is basically half of a language model. Say, okay, here's my search query. Generate a semantic embedding, okay, here's my search query, generate a semantic embedding, and then use that to go find, use your semantic search engine to go find the most relevant documents that you have to that query. So that's basically matching your Dewey Decimal System to pull the most relevant resorts and then you use the LLM to quickly read and summarize the relevant bits of those documents. And finally, you compile it all together and you have your answer. Oh, and by the way, I already did a video on this like six months ago, walking you through this exact process. It's called Answer Complex Questions with GPT-3 and Multiple Documents. Sounds pretty much like what you're trying to achieve, right? Okay, that's the end. You're welcome. pretty much like what you're trying to achieve, right? Okay, that's the end. You're welcome.", "chunks": [{"timestamp": [0.0, 2.88], "text": " Morning, everybody."}, {"timestamp": [2.88, 5.24], "text": " David Shapiro here with another video."}, {"timestamp": [5.24, 7.48], "text": " So this is a question that I get a lot."}, {"timestamp": [7.48, 17.12], "text": " People ask, how do I fine tune GPT-3 on my corpus of data so that I can ask questions?"}, {"timestamp": [17.12, 22.78], "text": " So let's talk about fine tuning versus search, when to use which, and why."}, {"timestamp": [22.78, 27.0], "text": " So as I just mentioned, I get a lot of questions about QA."}, {"timestamp": [27.0, 30.42], "text": " How do I train my model on legal cases"}, {"timestamp": [30.42, 33.8], "text": " or statutes or contracts, technical documentation"}, {"timestamp": [33.8, 38.16], "text": " like APIs or KB articles, medical records,"}, {"timestamp": [38.16, 39.2], "text": " so on and so forth."}, {"timestamp": [39.2, 41.28], "text": " I get this question all the time."}, {"timestamp": [42.44, 45.4], "text": " And basically people want to be able to ask questions against"}, {"timestamp": [45.4, 49.52], "text": " their corpus and they think that fine-tuning a model is the way to do it,"}, {"timestamp": [49.52, 52.84], "text": " that all the knowledge will just be compressed into the model and you'll get"}, {"timestamp": [52.84, 60.88], "text": " good answers. You don't! That's not how it works. Next question. Okay, fine. I guess"}, {"timestamp": [60.88, 68.24], "text": " I'll explain this and unpack it. So first we have to talk about what is fine-tuning. Fine-tuning is a type of"}, {"timestamp": [68.24, 71.12], "text": " transfer learning. So transfer learning was"}, {"timestamp": [71.12, 76.08], "text": " originally created a few years back for image models,"}, {"timestamp": [76.08, 83.36], "text": " earlier image recognition models, but it also applies to NLP tasks."}, {"timestamp": [83.36, 87.44], "text": " Now, if you look up like, what is fine-tuning good for?"}, {"timestamp": [87.44, 89.76], "text": " You'll see stuff like classification,"}, {"timestamp": [89.76, 92.02], "text": " sentiment analysis, and named entity recognition."}, {"timestamp": [92.02, 93.8], "text": " This is old school."}, {"timestamp": [93.8, 97.76], "text": " Ignore all that. That is like last generation NLP."}, {"timestamp": [97.76, 100.6], "text": " We are no longer in NLP."}, {"timestamp": [100.6, 104.28], "text": " NLP is spacey, NLTK, stuff like that."}, {"timestamp": [104.28, 107.16], "text": " We are in NLU, natural language understanding"}, {"timestamp": [107.16, 112.5], "text": " and natural language generation. So pretty much if it's an NLP benchmark, ignore it."}, {"timestamp": [112.5, 117.62], "text": " If it's an NLP task, ignore it. There are cheaper, faster, simpler ways of doing that."}, {"timestamp": [117.62, 126.56], "text": " If you're using a large language model for named entity recognition, like that's using like nuclear fusion to power your house."}, {"timestamp": [126.56, 128.68], "text": " It's way overkill."}, {"timestamp": [128.68, 131.68], "text": " You can use smaller models like Curie and Babbage"}, {"timestamp": [131.68, 133.28], "text": " to do those if they're fine-tuned,"}, {"timestamp": [133.28, 135.12], "text": " but we'll get into that at a later date maybe"}, {"timestamp": [135.12, 135.94], "text": " if y'all want."}, {"timestamp": [137.52, 141.24], "text": " So the short answer though is that"}, {"timestamp": [142.76, 145.84], "text": " when you do fine-tuning, you're teaching it a new task. You're not teaching it new information, you're teaching it a new task."}, {"timestamp": [145.84, 148.32], "text": " You're not teaching it new information, you're teaching it a new task."}, {"timestamp": [148.32, 152.8], "text": " It's kind of like tweaking a guitar just so that the final performance is a little bit better."}, {"timestamp": [152.8, 154.64], "text": " We'll unpack that more in just a minute."}, {"timestamp": [155.44, 157.04], "text": " What is semantic search?"}, {"timestamp": [157.04, 159.92], "text": " So in order to compare the two, you need to understand both of them."}, {"timestamp": [159.92, 163.2], "text": " So semantic search is also called neural search or vector search."}, {"timestamp": [163.84, 165.7], "text": " Semantic search is just easier to say, but if you hear neural search or vector search. Semantic search is just easier to say,"}, {"timestamp": [165.7, 168.98], "text": " but if you hear neural search or vector search, it's the same thing."}, {"timestamp": [168.98, 174.14], "text": " And the TLDR of how it works is you use a semantic embedding,"}, {"timestamp": [174.14, 177.78], "text": " which is just a string of numbers that represents the meaning of the text."}, {"timestamp": [177.78, 187.8], "text": " And it allows next-gen databases to scale very large, very fast,"}, {"timestamp": [187.8, 191.6], "text": " and also to search not just with keywords or indexes,"}, {"timestamp": [191.6, 195.92], "text": " it allows them to search based on the semantic meaning,"}, {"timestamp": [195.92, 200.2], "text": " the actual content, the context, and the topics discussed"}, {"timestamp": [200.2, 204.24], "text": " in the actual records in your new database."}, {"timestamp": [204.24, 206.16], "text": " They can scale very large, they're very fast,"}, {"timestamp": [206.16, 208.04], "text": " and they're also very cheap,"}, {"timestamp": [208.04, 210.54], "text": " at least in comparison to fine-tuned models."}, {"timestamp": [211.88, 214.2], "text": " So fine-tuning and semantic search"}, {"timestamp": [214.2, 215.86], "text": " sound drastically different."}, {"timestamp": [215.86, 217.76], "text": " They're entirely different technologies."}, {"timestamp": [217.76, 219.88], "text": " The only similarity is that at some point"}, {"timestamp": [219.88, 224.24], "text": " they use semantic embeddings or vector embeddings."}, {"timestamp": [224.24, 227.52], "text": " That's the point. Fine-tuning for QA is like"}, {"timestamp": [227.52, 232.64], "text": " using a hammer when you really needed a broom. It is the wrong tool for the job. It's that simple."}, {"timestamp": [233.84, 239.36], "text": " So how did we get here though? Why does everyone think that you can use fine-tuning to teach it"}, {"timestamp": [239.36, 247.0], "text": " new information and that you should then be able to do QA just with a single model. This is probably the biggest misconception about fine-tuning,"}, {"timestamp": [247.0, 249.5], "text": " because when you think like,"}, {"timestamp": [249.5, 251.5], "text": " oh, well, GPT-3 was trained on Wikipedia,"}, {"timestamp": [251.5, 253.0], "text": " and now it knows all of Wikipedia,"}, {"timestamp": [253.0, 255.5], "text": " so if I just fine-tune it with a little bit more data,"}, {"timestamp": [255.5, 258.5], "text": " then it should know that new data too, right?"}, {"timestamp": [258.5, 259.5], "text": " No, wrong."}, {"timestamp": [259.5, 262.0], "text": " The reason is because it is transfer learning,"}, {"timestamp": [262.0, 265.88], "text": " and so it's only unfreezing a small portion of the model."}, {"timestamp": [265.88, 268.92], "text": " It's not actually retraining the entire model."}, {"timestamp": [268.92, 273.04], "text": " There's a few other problems where,"}, {"timestamp": [273.04, 275.0], "text": " and we'll get to this in the next slide,"}, {"timestamp": [275.0, 277.8], "text": " where fine tuning does not overrule"}, {"timestamp": [277.8, 280.6], "text": " confabulation or hallucination, it's the same thing."}, {"timestamp": [281.8, 284.16], "text": " So basically what you're doing is,"}, {"timestamp": [284.16, 285.88], "text": " think of it like if you learn"}, {"timestamp": [285.88, 289.48], "text": " to tie your shoes you can tie pretty much any string. That is an example of"}, {"timestamp": [289.48, 292.76], "text": " transfer learning. You're not learning any fundamentally new physics, you're not"}, {"timestamp": [292.76, 296.36], "text": " learning how to do anything different with your hands, you're just saying I can"}, {"timestamp": [296.36, 300.04], "text": " tie my shoes now I can tie a string. Or if you can stack a wooden block then you"}, {"timestamp": [300.04, 303.88], "text": " can also stack bricks, right? That is an example of transfer learning where you"}, {"timestamp": [303.88, 308.16], "text": " take something that you've already learned to do and then you're just"}, {"timestamp": [308.16, 313.04], "text": " applying it to a slightly different task. So fine-tuning is just new tasks. It's"}, {"timestamp": [313.04, 317.08], "text": " not new information, it's not new knowledge, just a new task. Fine-tuning is"}, {"timestamp": [317.08, 321.68], "text": " not the same as taking the large language model back to school. To do that"}, {"timestamp": [321.68, 325.1], "text": " you have to unfreeze the entire model which is ludicrously"}, {"timestamp": [325.1, 330.22], "text": " expensive and even then it doesn't get rid of confabulation and hallucination."}, {"timestamp": [330.22, 335.98], "text": " So these are just fancy anthropomorphic terms for gaps in LLM abilities. I talked"}, {"timestamp": [335.98, 341.46], "text": " about this in another video. The short version is LLMs on their own"}, {"timestamp": [341.46, 345.9], "text": " do not have an epistemology. They don't have a theory of knowledge."}, {"timestamp": [345.9, 347.94], "text": " They don't even have a theory of mind, really."}, {"timestamp": [347.94, 350.58], "text": " You can test it and they can talk about mind,"}, {"timestamp": [350.58, 353.56], "text": " but they don't have in practice"}, {"timestamp": [353.56, 357.72], "text": " any epistemological theory or abilities."}, {"timestamp": [357.72, 358.94], "text": " They don't know what they know,"}, {"timestamp": [358.94, 361.34], "text": " and they don't know why they know it or anything."}, {"timestamp": [361.34, 363.82], "text": " They just barf out a possibility."}, {"timestamp": [367.6, 372.8], "text": " And so because of that, fine-tuning is not good as a knowledge store. Period. End of story. Do not use it. It is not reliable."}, {"timestamp": [374.72, 379.52], "text": " Now, that being said, you can, like, so if you look at, if you look at chat GPT,"}, {"timestamp": [379.52, 386.24], "text": " like chat GPT, you might say, ah, no, chat GPT has some theory of knowledge because it'll tell me,"}, {"timestamp": [386.24, 392.8], "text": " like, I don't know that. No, it's just following a pattern. It was told, it was taught that if you"}, {"timestamp": [392.8, 397.44], "text": " ask certain questions, it's supposed to tell you that it doesn't know, but then you just ask a"}, {"timestamp": [397.44, 404.32], "text": " different way and it'll tell you, right? Because one chat GPT does not have any cognitive architecture,"}, {"timestamp": [404.32, 405.96], "text": " it is just a fine-tuned model."}, {"timestamp": [405.96, 409.08], "text": " And this is one of the biggest gaps in OpenAI's approach."}, {"timestamp": [409.08, 411.28], "text": " They are a model-only shop."}, {"timestamp": [411.28, 413.84], "text": " They don't, as far as I can tell,"}, {"timestamp": [413.84, 417.2], "text": " OpenAI has not invested anything in understanding"}, {"timestamp": [417.2, 420.68], "text": " cognitive architecture or neuroscience."}, {"timestamp": [420.68, 423.28], "text": " They seem to believe that all that they need"}, {"timestamp": [423.28, 425.0], "text": " is a bigger, more powerful model."}, {"timestamp": [425.0, 428.0], "text": " And if they can do it, great."}, {"timestamp": [428.0, 435.0], "text": " If they can create a model, a large language model, that understands what it doesn't know, great."}, {"timestamp": [435.0, 446.56], "text": " But there are mathematicians out there that I've talked to that said a large language model, a single model, as we know it today, will never have this ability. It will never be able"}, {"timestamp": [446.56, 451.44], "text": " to understand what it does and does not know. You will have to have a system or a fundamentally"}, {"timestamp": [451.44, 460.72], "text": " different kind of model in order to have any sense of epistemology. So this is why fine tuning will"}, {"timestamp": [460.72, 467.36], "text": " probably never, at least with the current paradigm, will probably never be good as an information store."}, {"timestamp": [467.36, 469.0], "text": " Not as a reliable one, at least."}, {"timestamp": [470.2, 472.52], "text": " Another problem, fine tuning is slow, difficult,"}, {"timestamp": [472.52, 473.66], "text": " and expensive."}, {"timestamp": [473.66, 477.16], "text": " I've seen really boneheaded claims out there,"}, {"timestamp": [477.16, 479.24], "text": " and I'm not gonna name names,"}, {"timestamp": [479.24, 481.0], "text": " but where people have said like,"}, {"timestamp": [481.0, 483.48], "text": " oh, it takes 200,000 samples to do fine tuning,"}, {"timestamp": [483.48, 490.64], "text": " and even then it doesn't work. And I'm like, buddy, that's saying more about yourself than anyone else. Anyways, that's BS."}, {"timestamp": [491.44, 495.6], "text": " I have dozens of videos of fine tuning and showing that it is successful,"}, {"timestamp": [495.6, 500.72], "text": " but it does underscore an important point. Most people don't get it. Fine tuning is an"}, {"timestamp": [500.72, 505.2], "text": " entirely new discipline. You know, as far as I know, there aren't even good books out there."}, {"timestamp": [505.2, 508.04], "text": " Like I've even thought about writing a book on fine tuning,"}, {"timestamp": [508.04, 510.42], "text": " but fine tuning is one of my most valuable skills."}, {"timestamp": [510.42, 512.06], "text": " So it's like, you know, on the one hand,"}, {"timestamp": [512.06, 513.12], "text": " I want to teach the world,"}, {"timestamp": [513.12, 515.38], "text": " but on the other hand, I also have a startup, right?"}, {"timestamp": [515.38, 517.46], "text": " So I've got a conflict of interest there."}, {"timestamp": [517.46, 519.38], "text": " But fine tuning is difficult."}, {"timestamp": [519.38, 520.84], "text": " Most people do not figure it out."}, {"timestamp": [520.84, 522.1], "text": " Most people don't get it."}, {"timestamp": [522.1, 523.62], "text": " And even after I try and teach people,"}, {"timestamp": [523.62, 526.76], "text": " most people still don't get it."}, {"timestamp": [526.76, 530.46], "text": " What I usually say is fine-tuning is 100 times more difficult than prompt engineering."}, {"timestamp": [530.46, 533.4], "text": " It's actually more like 10,000 times more difficult."}, {"timestamp": [533.4, 535.4], "text": " It is hard."}, {"timestamp": [535.4, 537.8], "text": " It's also very expensive."}, {"timestamp": [537.8, 541.16], "text": " Fine-tuning is so expensive that most other companies have not figured out how open AI"}, {"timestamp": [541.16, 545.68], "text": " does it, which also means that OpenAI,"}, {"timestamp": [547.72, 549.32], "text": " OpenAI is in the same boat as I am, and I know that I criticize OpenAI,"}, {"timestamp": [549.32, 551.78], "text": " and so does everyone else, where on the one hand,"}, {"timestamp": [551.78, 555.1], "text": " they want to help the world, but on the other hand,"}, {"timestamp": [555.1, 558.84], "text": " they have their profit motive to think of,"}, {"timestamp": [558.84, 561.64], "text": " and so I realize I can't criticize them anymore"}, {"timestamp": [561.64, 563.52], "text": " because I am withholding information"}, {"timestamp": [563.52, 570.8], "text": " for my own benefit as well. So I just want to put that out there that and after having some conversations with people in the alignment"}, {"timestamp": [571.46, 572.56], "text": " field"}, {"timestamp": [572.56, 575.86], "text": " This is an open question. How much do we share and why?"}, {"timestamp": [576.38, 584.12], "text": " Because there are there are dangerous players out there that are just leeches or that are using it for nefarious purposes"}, {"timestamp": [584.2, 587.08], "text": " So it's like okay, maybe we don't share everything."}, {"timestamp": [587.08, 588.4], "text": " This is an open question."}, {"timestamp": [588.4, 593.4], "text": " So I am still a little bit skeptical of open AI,"}, {"timestamp": [593.96, 595.32], "text": " but it is what it is."}, {"timestamp": [595.32, 598.2], "text": " And I just wanted to add that little bit to be fair"}, {"timestamp": [598.2, 600.8], "text": " because like, pot calls kettle black, right?"}, {"timestamp": [600.8, 602.02], "text": " Like I'm withholding information,"}, {"timestamp": [602.02, 603.28], "text": " they're withholding information."}, {"timestamp": [603.28, 604.76], "text": " I can't really criticize them."}, {"timestamp": [604.76, 605.76], "text": " So I just wanted to address that"}, {"timestamp": [605.76, 610.24], "text": " elephant in the room. Okay, so let's compare, let's do a side-by-side of"}, {"timestamp": [610.24, 614.1], "text": " fine-tuning versus semantic search. Fine-tuning is slow, difficult, and"}, {"timestamp": [614.1, 618.96], "text": " expensive. Semantic search is fast, easy, and cheap. Which one do you think is"}, {"timestamp": [618.96, 624.24], "text": " better? Fine-tuning, prone to confabulation. Semantic search"}, {"timestamp": [624.24, 627.76], "text": " recalls exact information. Fine-tuning just teaches to confabulation, semantic search recalls exact information."}, {"timestamp": [627.76, 630.72], "text": " Fine-tuning just teaches a new task, not new information."}, {"timestamp": [630.72, 634.88], "text": " Whereas semantic search, it is very easy to add new information to your database or your"}, {"timestamp": [634.88, 636.88], "text": " index."}, {"timestamp": [636.88, 639.0], "text": " Fine-tuning requires constant retraining."}, {"timestamp": [639.0, 644.64], "text": " Whenever you add a new document, you need to retrain the entire model, and that is very"}, {"timestamp": [644.64, 645.48], "text": " expensive. Whereas with semantic search,. And that is very expensive."}, {"timestamp": [645.48, 646.58], "text": " Whereas with semantic search,"}, {"timestamp": [646.58, 649.38], "text": " adding new elements is very easy."}, {"timestamp": [649.38, 651.68], "text": " Fine tuning is not scalable."}, {"timestamp": [651.68, 654.02], "text": " The cost of fine tuning goes up proportional"}, {"timestamp": [654.02, 656.84], "text": " to the amount of data that you have."}, {"timestamp": [656.84, 659.8], "text": " Whereas semantic search is, I say infinitely scalable,"}, {"timestamp": [659.8, 661.76], "text": " and technically it's not infinitely scalable,"}, {"timestamp": [661.76, 666.94], "text": " but like the FAISS, the Facebook AI semantic search,"}, {"timestamp": [668.24, 671.64], "text": " that scales to like a trillion elements."}, {"timestamp": [671.64, 674.82], "text": " So that's way more scalable than fine tuning."}, {"timestamp": [674.82, 678.16], "text": " And I'll say that fine tuning does not work for QA"}, {"timestamp": [678.16, 680.92], "text": " with a little asterisk, we'll talk about that in a second."}, {"timestamp": [681.96, 684.84], "text": " And then semantic search solves half of QA,"}, {"timestamp": [684.84, 687.2], "text": " and we'll get to the other half in just a moment."}, {"timestamp": [687.2, 691.68], "text": " But first I wanted to address what do I mean when I say fine-tuning doesn't work for QA with an"}, {"timestamp": [691.68, 698.08], "text": " asterisk. That is that you can use a fine-tuned model to help with the QA process. So for instance"}, {"timestamp": [698.08, 705.46], "text": " when you're creating an answer you have a question, then you have a corpus or you know some"}, {"timestamp": [705.46, 709.3], "text": " reference material, and then the answer. So there's three components. And so when"}, {"timestamp": [709.3, 714.22], "text": " I talk about task, answering a question from a given corpus is a specific task."}, {"timestamp": [714.22, 720.54], "text": " And OpenAI actually had a QA endpoint, but they deprecated it because it"}, {"timestamp": [720.54, 726.32], "text": " wasn't that good and nobody used it. But what I will say is that the current instruct models"}, {"timestamp": [726.32, 727.36], "text": " are perfectly fine."}, {"timestamp": [727.36, 729.4], "text": " You just say, here's my question,"}, {"timestamp": [729.4, 731.06], "text": " here's the body of information,"}, {"timestamp": [731.06, 732.84], "text": " is the answer here yes or no?"}, {"timestamp": [732.84, 735.96], "text": " And if so, what is the answer?"}, {"timestamp": [737.36, 740.28], "text": " So it can be a component of it, but it's not necessary,"}, {"timestamp": [740.28, 744.3], "text": " especially with the latest instruct aligned models."}, {"timestamp": [744.3, 748.64], "text": " So in short, using"}, {"timestamp": [748.64, 754.64], "text": " fine-tuning for QA is like using a hammer to drive a screw through a board"}, {"timestamp": [754.64, 760.6], "text": " on your knee. You could do it, but you're gonna regret it. It's not gonna work. It's"}, {"timestamp": [760.6, 764.92], "text": " the wrong tool for the job. Okay, so what is fine-tuning good for then? So I"}, {"timestamp": [764.92, 767.0], "text": " talked about how it teaches a new task."}, {"timestamp": [767.0, 769.0], "text": " So the correct way to think about fine-tuning"}, {"timestamp": [769.0, 774.0], "text": " is that it teaches the model a pattern, right?"}, {"timestamp": [774.0, 775.0], "text": " What you're teaching it is not new information,"}, {"timestamp": [775.0, 777.0], "text": " you're teaching it a pattern."}, {"timestamp": [777.0, 781.0], "text": " And so, chat GPT, for instance, is a pattern."}, {"timestamp": [781.0, 785.9], "text": " The pattern is short user query, long machine response. Writing emails is a pattern. The pattern is short user query, long machine response. Writing"}, {"timestamp": [785.9, 791.14], "text": " emails is a pattern. All kinds of code, whether it's JSON, HTML, C++, whatever,"}, {"timestamp": [791.14, 796.22], "text": " those are all patterns, right? And fiction, even writing long-form fiction"}, {"timestamp": [796.22, 802.26], "text": " is a pattern. And yes, I trained Curie to write long-form fiction. I'm not going to"}, {"timestamp": [802.26, 811.76], "text": " show you how, but I will show you in a minute just to prove that it's possible. So basically the short answer is fine-tuning is really good at teaching"}, {"timestamp": [811.76, 821.72], "text": " it a new a task or pattern-based task. So without further ado, here is my Curie-based scene generator."}, {"timestamp": [821.72, 825.12], "text": " So I have a very short input and then it goes and writes"}, {"timestamp": [825.12, 831.48], "text": " several pages of a fictional scene. And most of you won't believe that I did"}, {"timestamp": [831.48, 837.64], "text": " this on Curie. I don't care. Believe me or not. I'm not going to show you how"}, {"timestamp": [837.64, 842.12], "text": " because this is incredibly valuable. Anyways, okay, so at this point you're"}, {"timestamp": [842.12, 846.44], "text": " probably saying, yeah Dave, I get it. You know, I get the point, I get the concept."}, {"timestamp": [846.44, 848.68], "text": " So how do we do QA?"}, {"timestamp": [848.68, 853.68], "text": " So there are, well, first, how do you do QA?"}, {"timestamp": [854.12, 855.28], "text": " How does a human do QA?"}, {"timestamp": [855.28, 856.92], "text": " First, you start with a question,"}, {"timestamp": [857.84, 860.08], "text": " then you go forage for information,"}, {"timestamp": [860.08, 861.8], "text": " then as you're foraging,"}, {"timestamp": [861.8, 864.52], "text": " you compile a corpus of relevant data,"}, {"timestamp": [864.52, 868.4], "text": " then you extract the salient bits from that corpus, and then you finally produce"}, {"timestamp": [868.4, 872.64], "text": " an answer. Do you remember libraries?"}, {"timestamp": [872.64, 878.24], "text": " So let's use a library analogy to do QA. So how do you find stuff in a library?"}, {"timestamp": [878.24, 881.2], "text": " Use a Dewey Decimal System. Dewey Decimal System"}, {"timestamp": [881.2, 884.72], "text": " is basically a human-readable semantic embedding."}, {"timestamp": [884.72, 885.36], "text": " The Dewey Decimal System is basically a human-readable semantic embedding."}, {"timestamp": [889.6, 896.32], "text": " The Dewey Decimal System is a string of numbers that tell you roughly what's contained in the book. And so when you have a question, you match your question to a Dewey Decimal Number, and you"}, {"timestamp": [896.32, 901.76], "text": " say, usually you ask a librarian, where in the library do I need to go? And it's like, okay,"}, {"timestamp": [901.76, 905.2], "text": " well, you probably need like 541.26"}, {"timestamp": [905.2, 910.12], "text": " and you also want something from the 900s or whatever. And so then you go, you go get"}, {"timestamp": [910.12, 915.4], "text": " a stack of books. This is your semantic search, right? You go get a stack of books, you take"}, {"timestamp": [915.4, 919.64], "text": " them back to your desk. So now you have a corpus. You've gone from a huge amount of"}, {"timestamp": [919.64, 927.96], "text": " data to a much smaller subset that you're looking through. Then you skim them, you look at their appendices, you look at their chapters, whatever, and"}, {"timestamp": [927.96, 932.96], "text": " you say, ah, so you zoom in, you zoom in further and you say, this page on this book has what"}, {"timestamp": [932.96, 934.32], "text": " I need, right?"}, {"timestamp": [934.32, 938.28], "text": " That's what the index is for, is literally so that you can just say, ah, I'm looking"}, {"timestamp": [938.28, 943.68], "text": " for King George V or whatever, he's mentioned on page 286."}, {"timestamp": [943.68, 945.3], "text": " So you go there, you jot down some"}, {"timestamp": [945.3, 949.38], "text": " notes, you compile all that data together, you're not answering your question yet,"}, {"timestamp": [949.38, 954.28], "text": " you're just getting all the relevant facts together. Finally, once you get all"}, {"timestamp": [954.28, 959.16], "text": " the notes together, then you have a much shorter document. You've gone from"}, {"timestamp": [959.16, 964.04], "text": " thousands of books, tens of thousands of books, to maybe, you know, a dozen books"}, {"timestamp": [964.04, 966.0], "text": " and you then you distill that further"}, {"timestamp": [966.0, 972.32], "text": " down into a page or two of relevant information, and finally you can answer your question."}, {"timestamp": [973.6, 976.96], "text": " So let's break this down into simple steps that you can do with a machine."}, {"timestamp": [977.52, 981.12], "text": " First, you index your corpus with semantic embeddings. This makes it searchable."}, {"timestamp": [982.0, 986.0], "text": " And this is whatever your corpus is, case law, medical records, whatever."}, {"timestamp": [986.0, 991.0], "text": " Then, once you have your question, you use your large language model"}, {"timestamp": [991.0, 995.0], "text": " to generate relevant search terms or queries, relevant questions,"}, {"timestamp": [995.0, 1001.0], "text": " and then you also use an embedding, which is basically half of a language model."}, {"timestamp": [1001.0, 1004.0], "text": " Say, okay, here's my search query."}, {"timestamp": [1004.0, 1005.0], "text": " Generate a semantic embedding, okay, here's my search query, generate a semantic"}, {"timestamp": [1005.0, 1010.38], "text": " embedding, and then use that to go find, use your semantic search engine to go"}, {"timestamp": [1010.38, 1014.78], "text": " find the most relevant documents that you have to that query. So that's"}, {"timestamp": [1014.78, 1019.62], "text": " basically matching your Dewey Decimal System to pull the most relevant resorts"}, {"timestamp": [1019.62, 1026.04], "text": " and then you use the LLM to quickly read and summarize the relevant bits of those documents."}, {"timestamp": [1026.04, 1029.04], "text": " And finally, you compile it all together and you have your answer."}, {"timestamp": [1029.04, 1033.64], "text": " Oh, and by the way, I already did a video on this like six months ago, walking you through"}, {"timestamp": [1033.64, 1035.22], "text": " this exact process."}, {"timestamp": [1035.22, 1039.72], "text": " It's called Answer Complex Questions with GPT-3 and Multiple Documents."}, {"timestamp": [1039.72, 1042.48], "text": " Sounds pretty much like what you're trying to achieve, right?"}, {"timestamp": [1042.48, 1043.84], "text": " Okay, that's the end."}, {"timestamp": [1043.84, 1044.2], "text": " You're welcome."}, {"timestamp": [1041.06, 1043.46], "text": " pretty much like what you're trying to achieve, right?"}, {"timestamp": [1043.46, 1047.06], "text": " Okay, that's the end. You're welcome."}]}