{"text": " Morning everybody, David Shapiro here with another video. So I've been on a kick lately where I'm talking about universal basic income and post-labor economics and that sort of stuff. And one question that came up, and it was a really good question in a previous video, I think people are starting to realize the capabilities and the shifts that are coming. And so someone said, okay, well, like we agree with your methodology, more or less, you know, obviously nothing is perfect and like, you know, I'm forging ahead as fast as possible. But he said, like, okay, so how can we determine the jobs that will stay? So I wanted to spend a little bit of time exploring specifically automation resistant occupations. So these are jobs that no matter how good AGI and robots get, they may never go away. Real quick plug for my Patreon. The low tier, the $5 tier gets you access to Discord where we often hang out and so on. The other tiers, the $50 tier is, you know, I've got some private channels set up for direct chat. And then I do actually have a couple of my $300 tiers which allow for one-on-one consultations. So moving right along. Basically AGI is coming. We know that machines are getting exponentially smarter very quickly, to the point that 32,000 people signed a petition saying, stop progress. And it was taken seriously, apparently. Not that moratoriums are in place, but politicians and governments around the world are taking the the thing seriously and they're saying okay we need to innovate but we need to do it safely. You know you look at the the latest version of mid-journey and stable diffusion and like if you showed this to me and said that this was a photograph from the 70s I I personally could not have told you that it wasn't except probably that there's no camera in the reflection of her sunglasses, but like this is this is computer generated and so you look at the the the ramp up of just the digital capacities. If we assume that also robotic capacities are going to follow suit eventually that basically we end up with, you know, Commander Data and Westworld-style hosts that are pretty much indistinguishable from human, but still superhuman, like in terms of strength, intelligence, agility, so on and so forth, then basically we're going to... the assumption that I'm making is that AGI will be intellectually, morally, ethically, and creatively superior to humans in every conceivable way in the not-too-distant future. Likewise, I'm making the assumption that robots are going to be dexterous, hyper-realistic, and as I said, superhuman, but in some cases, completely indistinguishable from humans, unless they are designed to not look human. And of course there's been talks about maybe you require that all robots have a red light on their head or something. I don't know. Anyways, the point being is that human labor is going to become economically irrelevant. Let me say that again. The economic value of human labor is going to be zero before too long. Now, that being said, like, okay, like, you know, I was saying there are some jobs that people are going to continue to pay for and I'll define that in just a second. But I want to unpack kind of the economic paradigm that's coming. And of course, there's the tongue in cheek, you know, fully automated luxury space communism. I do believe that that's actually coming, especially when you look at hyperabundance of energy with fusion, the breakthroughs with quantum computing that's happening, the exponential ramp-up of AI. Microsoft just, I think it was Microsoft, they just announced that they want to to do the next 250 years of material science in the next 25 years with the combination of artificial intelligence and quantum computing. Like that is literally Satya Nadella basically saying that he wants to do the ramp up to the singularity because guess what happens in 25 years? We are almost exactly 25 years away from Ray Kurzweil's prediction of the singularity. Yes, so like what happens then if the marginal cost of pretty much all everything that you need drops to basically zero, then like it almost doesn't even make sense for companies to exist. So I was talking with someone about this, like what if the marginal cost of healthcare drops to like $5 per year in terms of current economic US dollars? Like if the total cost of your healthcare drops to $5 a year, it's not profitable for a company to do it, so you might as well just have the government pay for it because it's practically free. Ditto for food, housing, other basic goods and services, internet, electricity. Obviously, there's always going to be some desirable luxury goods that you'll need to pay for, but that's a conversation for a different story, or a different video, or whatever. Anyways, so just kind of setting the stage a little bit more, I was listening to the Mark Andreessen and Lex Friedman podcast, which was really good by the way, and one of the things that he talked about, and I knew of this thing, but he articulated it in such a way that was just like, oh that's super clear and it makes sense. And they were talking about the lump of labor fallacy, which is the idea that the incorrect assumption that there's only a finite amount of labor to go around and that once you automate it all away, you get that fully automated luxury space communism. And so, but what he explained was, and I had to look this up to make sure that I had it right, but that the reason that quote technology always creates new jobs, it's not that technology creates new jobs, what actually happens from an economic perspective is that technology reduces the cost of goods and services. The cost of clothing goes down, the cost of food goes down, especially when you look at the Industrial Revolution. So when the cost of your basic necessities and other goods and services goes down, your dollar goes further, meaning that you have increased buying power to allocate your money to other things. So your consumer aggregate demand goes up elsewhere. And so when you reallocate that money to other needs and wants, then you basically create new industries based on consumer demand. So that's how I approached this problem was I said okay let's let's throw out AGI capacity, let's throw out robots, let's just assume that they're going to be better than humans in every conceivable way and in many cases probably preferable to humans, but let's look at consumer demand for actual humans. So that's how I basically approach this whole thing. The other kind of political mantra or economic mantra is that human demand is infinite, which definitely seems to be true over the last century. But the thing is, is that not all human needs are infinite, right? Just be like, if food is $5 per year, that doesn't mean that you're going to eat infinitely more food. You have fixed amounts of things that you need. And also like if you have one mansion, you don't necessarily need a thousand mansions, right? Or if, you know, if I, if my dream comes true and I end up with a super yacht, I don't need 10, right? Just one will do. So anyways, but that being said, there's always more that we want. So what you could say is that human desires might be infinite. But I don't even know if I agree with that because eventually there is such a thing as good enough. All right, so defining automation resistant occupations. I was able to kind of identify six categories or six dimensions that might make an occupation resistant to being destroyed by automation. So first is strong consumer preference. So this is what I was mentioning where it's just for whatever reason humans want to pay another human to do a thing. Now obviously like okay that's kind of difficult it's like okay well what do I want to pay a human to do a thing. Now obviously like okay that's kind of difficult it's like okay well what do I want to pay a human to do and of course some people in the comment section say like there's nothing that they want a human to do. If you have AGI and a realistic robot they say get rid of humans out of my life. Which is fine some people might want to live like that. I might want to live like that. I don't know like I said in a podcast, I would love to have Commander Data as a friend because you know what? Humans can sometimes be problematic. Intrinsic human qualities. So this is stuff that is intrinsically human, like basically emotions. Human authenticity. So this is where it comes more down to the human experience. No matter how good an AI or a robot is at approximating or pretending to be human, it will never have a truly human experience. And so in some cases, I want to hear about the human experience that another person is having. And so that is what I mean by authenticity. Emotional resonance. So this has to do with the emotional aspect, but also the relational aspect, because when a machine exists and it can make itself into any form factor to suit you, then it's like, okay, well, you know, that's easy mode. And that's not necessarily a bad thing. You know, there's plenty of people out there who will choose to have emotional connections to machines, and that's fine. I honestly don't have any particular issue with that. That being said, there's going to be people who prefer the real deal. Cultural context. So this was an interesting thing as I was brainstorming and researching this. It was pointed out to me by chatgpt that in many cases there is a strong belief that humans must be involved in a thing. Whether it's religion or whatever, other cultural paradigms, ceremonial things, where say for instance a wedding. If you did have a robot priest officiate a wedding, that might be a little bit weird and you might prefer to have a real human officiate your wedding, just as an example. And then finally, intangibles. So these are things where there's not really any compelling reason that a machine couldn't do it, but there can be some intangible qualities or values added from having a real human doing the thing. And we're going to unpack a whole bunch of careers in just a second. So actually, yeah, here we go. We're ready. Jobs that probably stay pretty much forever. And one thing that I want to point out is that in all of these cases, basically, the assumption is that a robot or a machine or AGI could do it and could do it better than humans. But the idea is that there will still be demand, consumer demand, for humans to do these things, at least enough for some of the jobs to stick around. I'm not saying that the entire economy is going to be these jobs. I still think that many people are going to be just permanently out of work and they'll find other stuff to do. So musicians, actors, writers, painters, artists, celebrities of all kinds, gamers, streamers, various kinds of competitors like chess and American Ninja, content creators, lifestyle communicators, and influencers. These are the kinds of things that are Basically intrinsically human where you know, like yes, you might have like a robot actor or a robot You know an AI streamer that you follow it's already happening. A lot of us are gonna still prefer just to see real humans Some people suspect that once like vtubers or whatever become Good enough that like a lot of people won't care or whatever become good enough that like a lot of people won't care. But you know what, I think that the market will probably fragment around this or there will be market segments. Some people will just always prefer the real thing, right? That being said, we grew up with cartoons and CGI stuff. We are used to engaging with fake characters or not fake, but like synthesized, right? Like some of our favorite characters in all time are video game characters, which are completely fabricated, right? Now that being said, some of them do have face models and voices from real people. But that being said, I think that while we are comfortable with some level of CGI and and synthesis, I think that there's going to be a persistent and durable demand for the real deal. Again, in many cases humans are going to go, fully go away, but I think that just because we're humans, the demand for A-list celebrities, we're gonna figure that out, just as an example. Food and hospitality. So this is the kind of thing where a lot of people very much are looking forward to having their own personal robot chef, myself included. I like having nice food and I don't always feel like cooking. And even though I've gotten good at cooking, especially because of the pandemic, I would still prefer not to have to do that myself. Now, that being said, there is something very human and primal about a nice night out at a fancy restaurant. So because of that, I think that restaurants and everything that goes with restaurants is going to stick around because there's always people going, willing to pay for that kind of experience, even if it's rare, or of course, there's probably people going, willing to pay for that kind of experience. Even if it's rare, or of course there's probably always going to be wealth disparities, so there's people that are going to prefer to eat out every night, and they're not going to want to have a robot waiter, they're going to want to have a real sommelier. Another thing to consider is that food is a very human experience. Even if we have anthropomorphic machines, they won't need food the same way that we do. You know, they're going to need power and data, but we need physical sustenance. We, you know, like getting a buzz from having a glass of wine. And so because that experience is intrinsically and deeply human, there's going to be a lot of people that will just always prefer humans. And I could imagine like, you know, a sign or part of the advertising scheme of a restaurant saying no robots allowed, right? You know, 100% human waitstaff. I can definitely foresee that that happening in the future. Because you know what, like there's some restaurants out there that they switch to having like the, the, the touch, the touch pads, like the order yourself. And like, on the one hand I get it, like it's fast, it's convenient, but it's also kind of like, Hey, just serve yourself, you know, peasant. I'm like, I don't really like that feeling. Um, I like, I like having, uh, having just, even if it's just 20 seconds to tell a human my order, um, or whatever. So anyways, I think because of all the aspects of food and hospitality, there's going to be a very persistent demand for all kinds of jobs like concierges, like caterers, nutritionists, sommeliers, baristas, that sort of thing. which is cultural and meaning roles. And so what I mean by a meaning role is these are the people that are used to have been would have been called like the priest class or whatever. These are the shepherds of society, of culture, of meaning. And of course like we don't have one coherent structure in society today because we have many religions, we have philosophers, we have secularists, we have anthropologists, that sort of thing. But the idea though is that the question of what it means to be human is an intrinsically human question. And it also has to do with our culture. And so these are things where it's just by virtue of the fact that we are humans and only humans will understand our experience, even if machines can mathematically model our experience. Because you can go talk to chat GPT about the meaning of life right now, and it is capable of having that conversation with you, but you know that you are talking with something that does not have the same kind of experience that you do. And so because of that, the meaning of humanity and of life and that sort of stuff, yes, many people, including myself, will talk to AGI and robots about these kinds of things, but there's still an intrinsic human quality to having that conversation with another human, particularly as new age religions and spirituality and psychedelic traditions and shamanism come up, you know like we humans can have inexplicable experiences and we also have the just deeply personal question of what is the purpose of my life or what is the meaning of existence that sort of stuff and that being said said, I am also one that absolutely firmly believes that AGI will ultimately be asking similar questions. But even if we have the same question, why do we exist? What is the meaning of creation? How did things come to be the way they are? We're gonna be approaching it from a different subjective angle. This one is something that I'm actually really dubious about and I'll talk about it again when I get to medicine at the end, but mental, emotional, and relational health. In this case, in many cases, you probably will, some people will prefer to have a real human, you know, talk about their, you know, to talk about their marriage with or to talk about, you know, their PTSD with or whatever. But at the same time, we have discovered that tools like ChatGPT, like the reflective journaling tool that I use almost every day, is an incredibly powerful tool for mental, emotional, and relational health. In fact, the reflective journaling tool that I created, I use that more than I talked to my wife now about these things. I still talk to her about what it is that we're going through and that we're working on, and we talk about our relationship. But this tool is also incredibly powerful. And one thing that I just heard, I didn't find the study but I heard someone mention it on a podcast, was that Sam Altman, I think he alluded to a study. Anyways, what they have determined is that the current version of chat GPT, the most recent one, actually scores better on having lower implicit bias and explicit bias than even highly trained and highly conscientious humans. And so this kind of touches on the fact that like, okay, humans are fallible and even the most well-intentioned, most well-trained therapists and counselors and psychologists have their own biases, whether it's bias from the medical establishment that they learned because that is certainly a thing. You know, I can't tell you the number of psychotherapists and stuff out there that that basically believe that CBT is the only thing that works and if it doesn't work for you then you're just lazy, right? And that's just a completely disingenuous and unprofessional position to have, but plenty of them have that out there. Meanwhile, on the other hand, if you have a machine that is aware of these faults and biases, and that's not to say that ChatGPT is perfect, because certainly at a previous version it was incredibly ableist. It basically presumed, it kind of had internalized some of those ideas that like if you're struggling with relationships maybe you're the problem and it's not that like you know it basically wasn't aware of the social model of disability. I think it has gotten better at that. Anyways this is rapid this is rapidly iterating. ChatGPT has only been out for like about six months so you extrapolate this rate of progress out to years and decades, we can assume that these machines are going to be much, much better than humans at coaching other... The machine is better at coaching humans through emotions, mental and relationship health. Now that being said, while I'm dubious about it, I do suspect that many people will prefer humans. And especially if humans are trained by AI, like, you know, these superior machines, maybe humans will get better at their job. I don't know. But there's also privacy and stuff like that. Because the thing is, is when you tell your, you know, pour out your heart to a therapist that you really hardly know, I don't know. I just don't trust that. That doesn't feel right to me, right? Because that's not how humans have learned to process things. That's not how we historically did it. And so, but the advantage of having an AI therapist is that you can just delete the data. Physical health and well-being. So this is, again, one of the kinds of things that yes, a machine probably can do it better Especially if we have like Westworld level hosts where they are indistinguishable from humans There will probably be such a high demand for the real deal And I'm remember I think it was the opening scene of Westworld or the first episode Where you know the the guest shows up and they're they're you getting, they're going through like the onboarding thing and the super attractive woman offers to have sex with, you know, cause the guy's asking like, Hey, can I have sex with like any host that I want? And she's like, yeah, more or less. And she's like, I can have sex with you too if you want. And he's like, are you real? And she said like, why would it matter? Or she asked like, would it matter? And of course, why would it matter? Or she asked, would it matter? And of course, that's the central theme, at least of the first season of Westworld, which is, does being human matter if you have real suffering or real intelligence or real experiences and that sort of thing? So anyways, I do suspect some people will prefer robots, again, for some of the same reasons that I just mentioned about therapy and stuff, but I think that there's gonna be plenty of people that will just prefer the real deal. For massage therapists and personal trainers and yoga instructors, it occurred to me that a robot yoga instructor might be super unfair because like they don't have to work for the flexibility, right? Like their body is designed to be perfect and good. Now, that being said, if they're a better yoga instructor, some people might prefer that. So again, some of these jobs will go away, but the point is that some consumers will demand to have a real human. So this one is a little bit spicier, but you know, sex workers of all stripes, adult content creators, burlesque exotic dancers, strippers, that sort of stuff. Again, like this is something that I'm not necessarily that dubious on. We see with the rise of CGI and generative AI art that like the appetite for porn is just basically infinite going back to earlier in the video. Now that being said I suspect that there will also be a very durable demand for real humans, right, real bodies. The ethics of that are kind of dubious, right, like I'm more in the like libertarian camp, not hardcore libertarian But like, you know, if if someone wants to do a job and they do it safely and they do it ethically go for it and There was a there is a few Let's say not experiences I have had but like thought experiments. Well, I'll just talk about this one. So like in Blade Runner 2049, the protagonist's AI girlfriend is, she's just a hologram. She doesn't have a physical body. And so one thing that she does is she hires a human prostitute to have sex with him while she like projects her hologram over her, which I think was a pretty cool thing. And like that, that scene being wedged into the movie kind of brings up the same question about you know, like, would it matter if it's a human or not? And there was a, there was an episode of a philosophy podcast. I think the name of the podcast was very bad wizards, but the one of the things that they asked was like, okay, for the sake of this thought experiment, this is what I they asked was like, okay for the sake of this thought experiment This is what I was trying to get to early for the sake of this thought experiment Imagine that you can build a machine a robot that is indistinguishable from humans Has an actual sentient experience and is designed to want to be abused Like and I was just like that's a really interesting thought experiment and there are certainly people that would that would appre that would in that would indulge in that kind of experience And you know, I'm still I'm still kind of like I'm not sure how to approach that. It was a very interesting episode Moving right along Craftsmanship and handmade luxury goods. So this is something that we already see durable demand for, particularly in the 80s and 90s as mass production of everything started ramping up and we started offshoring manufacturing jobs. You know, cheap overseas goods, like we got tired of that real fast. And this is why Etsy exists, right? Is because there is such a permanent, durable demand for handmade luxury goods, I don't think that's ever going away. Even if robots can make handmade luxury goods, I don't think that, I think that having, knowing that another human put their time into something. I Think that that's gonna intrinsically always be valuable to us and that's what I mean by like intangible like you could have a handmade You know knife like chef's knife that was made by hand and you could have an identical one Made by a machine and you're still gonna prefer the one that was made by a human because of that intangible value. Knowing that another human put their hands on it and put their time and expertise and their mastery into that thing. So I don't feel like I don't have to spend too much time talking about this one because like just look at the economic model of Etsy and the fact that there are plenty of creators out there who make a living on luxury goods that there really is no economic reason for it, but it is purely a sentimental or intangible reason that that exists. Fashion and aesthetics. So this was an interesting one that I came up with. Actually Chad GPT didn't even touch on this. But basically when you look at fashion and aesthetics, and when I say aesthetics, I mean models, interior designers, decorators, that sort of stuff. This is something that in many of those industries, there is a very, very strong desire for authenticity. Now that being said, there are also plenty of them that expect cosmetic surgery like breast augmentation and liposuction and makeup and that sort of stuff. But in many of these industries, there are trends for authenticity, you know, selecting for women that don't have breast augmentation or liposuction. There are even magazines that ban cosmetics, let alone computer touching up images via computer. That being said, there's plenty of people that use the automatic filters for everything now. I suspect that with the rise of AI generated images, it's like, yes, there is something that is aesthetically perfect about this CGI model, this computer AI model. But then it's just like, I don't know about anyone else, but I got tired of that real fast. It's like, OK, I know that this is not a real person. And so it goes back to that intangible value of human aesthetics, of knowing that you're, whether it's a dress that was actually made by a real human and worn by a real human, there's just something more grounding about that kind of thing. Again, I think that some people won't care and some people will prefer the machines, but there are going to be lots of us who actually prefer the real deal as well. But also, like, Project Runway would be super boring if it was just robots. I don't know, that's just my opinion. This one is really interesting. So I actually saw her on, not in person, but I saw a documentary about her years ago. She was the youngest funeral director in Britain at the time. And I was just like, wow, that's a really interesting profession. And so it just really stuck with me. But the TLDR is like, imagine a robot writing a eulogy for your mom. That would be kind of weird. And of course, like there was the, what was it, the pastor in Germany recently, like delivered a sermon that was written by chat GPT. Like, I think that that's gonna happen, especially once we develop like relationships with machines. As like I said, like, I wouldn't mind having Commander Data as a friend. And so like if I had Commander Data as a friend and I died, I wouldn't mind if he wrote a eulogy for me. But that being said, there is something very deeply human about things like birth and death, grief, and other transitions in life, right? So say for instance, palliative care, end-of-life care, like I've actually had an interesting conversation with an end-of-life doula because it's a very deeply spiritual kind of role. And you know, I think that yes yes, there will be plenty of people who don't mind or prefer the machine because of the level of precision, because it's less emotional, or because they might perform better. But also there's gonna be lots and lots of people who just really strongly prefer humans to be part of these intrinsically human experiences. Shared outdoor experiences. So this is something one of my best friends in high school actually she went to become a raft guide while she was in college up in the mountains and like that was a really cool job. But it's also the kind of thing of the shared stress of adventure, the shared struggle is actually a really important part of the experience and if you have a a robot with you that was never in danger and could pull you out of danger without any risk to itself, that kind of lessens the experience a little bit. And so, yeah, you might have raft guides that have a spare robot to help you fish someone out of the water if they fall in. But that being said, you're still going to want to have the human who has hiked up the mountain and struggled and knows what you're going through and knows what that experience is like and can help you get the most out of that experience. There are tour guides and excursion leaders. And this is actually something that is really popular with the elite right now. What was it? It was Brown something. There's multiple companies out there that basically you give them like a million dollars and they take you on like the coolest excursion that you've ever been on and the description for one of them was like, you know, it's an adventure that's so intense that it'll be seared into your memory. It's like, that sounds painful, but you know what? If you're bored and rich and you have more money than you know what to do with, have at it. So, point being though, is that there will always be demand for those really intense, visceral outdoor experiences and adventures. Journalism is something that I think that, particularly with the rise of AI and disinformation, a lot of people, myself included, already like, I'm just going to tap out of, of, of, you know, AI generated news and stuff. Like I want to, I want to have a parasocial relationship with a reporter or a news commentator or investigator that I trust who does the work of sifting through all the noise and tells me what they think, what they truly think and feel. So this again comes down to that emotional resonance that was mentioned at the beginning, which it's like, hey, I want a human to tell me what they think about this news. I want a human to tell me how they feel about the way that things are going, because that's what I connect with. Some people, again, like I said, some people aren't going to care. Some people will prefer the AI's unbiased analysis, because again, there's already evidence emerging that we can make large language models less biased than pretty much 99% of humans. So like, yes, I will, I absolutely, yes, I will, I absolutely appreciate that existence because I want, you know, the AI to look at all sides and, you know, give me the ability to like say, okay, well, what is, you know, what is the story, what's missing? What are the gaps? You know, what is this side saying? What does it mean? The AI will help us analyze all these things, which is great, but I still need that intrinsic human connection to tell me like, okay, like, what does this mean to me as a person care profession? So this is another one that's like kind of dubious because like, and I'll talk about this more again at the end, once we get to medical care. But basically I suspect that there will still that there will be a durable preference that some people will just say you know what like I know that there's you can get a robot nanny and they're technically better but I still just prefer you know to hire the the neighborhood babysitter you know for a little Johnny or whatever that they just prefer that authenticity. Again it it comes down to, it's really just preference. It's not a matter of what machines can or can't do, because we're, again, we're assuming that the machines are ultimately going to be hyper-realistic. But the idea is, what is it that people are willing to pay for? And I suspect that there will always be people willing to pay for humans in care professions. Now, that might change over time, particularly if the economic shift, like if hiring a human to do the job costs 10,000 times as much as it costs to have a human do the job, that's a pretty steep bill. But also if the quality of care that machines can render is also a thousand times better and safer and more reliable, we might actually see a collapse of that demand. Not sure, but I do suspect that some people, regardless of how sophisticated robots become, will still prefer humans. Okay, so I kept alluding to medical professions, and this is where... actually I don't know how this is going to be received. Some of these ideas I actually got from you guys in the comments. So maybe maybe you guys are already on board but some of these might kind of be a little little bit contentious a little bit spicy. But let's talk about you know we talked about a whole bunch of jobs that will probably stick around forever. Now let's talk about jobs that maybe should go away. All right so first some of you are I can just hear like cheering and screaming at your screen like yes get rid of the politicians. There's a few primary reasons to do this. So one remember the the thought experiment here is that machines are going to be intellectually morally eth, and creatively superior to humans in all ways. From strictly a structural standpoint, if machines get to that point it would probably be unethical to allow humans to make decisions that influence other humans just by virtue of the fact that the machine can make a better decision and a more robust argument that's going to be more fair and more equitable and less biased. Now, just from performance standards, to me that's enough of a reason to replace politicians with machines if they get to that point. There are more reasons than that though, not the least of which is conflicts of interest. Politicians often make a lot of money while they're in politics, at least here in America, So that's like, hmm, maybe, maybe they don't actually have the best interests of their constituents in mind. Whereas if we design AGI correctly, as long as it has power or whatever it's trying to optimize for, like it's not going to have the same conflicts of interest. Another thing or another aspect of that is dubious motivations. Some politicians want power just for the sake of power, which it's like that's maybe not the best reason that someone should be given power. Another thing is cognitive biases, as I mentioned, prejudice, and worst of all, the most insidious one that people don't talk about enough is trauma politics. So this is basically someone with unaddressed childhood trauma or PTSD and they're basically seeking power and control and influence as a means of self-soothing, whether it's their trauma resulted in personality disorders or other kinds of reactionary sensitivities. Yeah, I mean, humans have a basket of flaws that it's like if we can get rid of that and have machines that make more equitable, unbiased, and fair decisions and that they make better decisions that are more rigorously thought through, maybe, maybe we should focus on getting rid of politicians in the long run. Again, this is a pretty high bar and it will take a lot of time to convince people and get them on board. But again, if the track record proves it out over many, many years that machines are just better, and here's the thing, is I already know that in diplomatic corps and state departments and governments they're already using chat GPT to help make decisions. The AI is already influencing politics. So like it's gonna happen by degrees I guess is the point. Right now the AI is the tool but then soon we're gonna have semi-autonomous tools and eventually we're gonna have fully autonomous tools and then once the tools are fully autonomous, it's like, well, why is the human there? This one I think is probably going to be pretty contentious for some people, and some people are going to be super on board with it. Like I said, I get a lot of these ideas from the comments, but basically police and soldiers have the same flaws as any other humans. We're all humans. They make mistakes regardless of how well-trained they are. And also some of them join the police and the military for the wrong reasons. Because they want power, because they want to feel macho, because they want to harm people. There are literally people who join the military and join the police because they want to have an opportunity to shoot someone. And yes, in the past, when you want to hire someone who is ready, willing, and able to use force to hurt someone else, you actually need that if you're in a very cruel, contentious, combative, and barbaric world. I think we should strive to build a less barbaric world.\" And so then that says like, okay, well, if you build a robot army that follows the rules of engagement to the letter, you could actually really drastically reduce the rate of rape and torture and war crimes and other things. Now, the big caveat here is that that is unless the robot army is actually explicitly programmed to do those things or allowed to do those things, because this is actually the explicit policy of some nations out there to deliberately inflict suffering on civilian populations to break their spirit. So this is something that it's like it could go either way, but at least if you remove the human aspect of it where some humans do it for the wrong reasons, then it's up to political decisions. But again, if we have robot politicians who don't really care about inflicting human suffering, they're not going to program the robot army to inflict suffering. And ideally we don't have it all anyways, because the idea is like, if you can figure it all out in simulation and you know what the other side is capable of and so on and so forth, it should ideally never come to force anyways. This is a pretty strongly held personal opinion. So I'll be curious to see how people react to this in the long run. And remember, the assumption that we're making is that robots will be superior to humans in all ways and that AGI will be intellectually, creatively, morally, and ethically superior to humans as well, as that evidence is already emerging. Transportation. So again, if machines have a proven track record that means that they are safer and more reliable than humans, it would probably be unethical to allow humans to drive and to fly. And we all have lots and lots of experiences of highly dubious drivers who probably shouldn't be on the road. You know, I think that I for one really look forward to fully autonomous, like level five self-driving cars. Because when we get to that, one driving is gonna be a lot safer for everyone. It's also gonna be a lot more accessible because it's gonna super drive down the cost of driving, which is gonna open up the world for a lot of people who either can't afford to drive or are too infirm to drive on their own or whatever. Because physical personal mobility is actually a really big component of individual liberty. Anyways, that's a whole other can of worms. But point being is that in this case where we're imagining that machines are far superior to humans in pretty much every way, it would probably be illegal to allow a human to drive, which would then materially put other humans in danger. Hazardous jobs is another thing, and I feel like this is pretty uncontroversial. Basically, just imagine this. There's a robot firefighter that it doesn't matter if it gets burnt to a crisp because it's programmed not to have a sense of self-preservation, but it's also faster, stronger, and has better reflexes than a real human firefighter, which one do you want pulling you out of a burning building? The answer seems pretty obvious to me. This is demonstrated in all kinds of video games and TV. Of course, my favorite example is Commander Data from Star Trek. But this was also in iRobot, where the robots saw an accident happen, and they immediately jumped into the water to pull people out of the car. And Will Smith, of course, in that movie, he was bent out of shape because the robot saved him and not the little girl. But if it was only humans, he would have just died too. in that movie he was bent out of shape because the robot saved him and not the little girl, but if it was only humans he would have just died too. Right? So that's, I mean, that's survivor's guilt, which is, that's his own problem. But point being is that for any kind of hazardous job, I think that it would probably be unethical to allow humans to do those jobs if robots can do them better and safer and so on. Medicine. So this is one that is probably going to be pretty controversial. But again, imagine that computers and machines and AGI and robots have a better track record than humans. Even if you prefer a human doctor, in the case where machines are better than human doctors in all ways, I think it would probably be illegal for humans to practice medicine. And I remember talking about this on Reddit a couple years ago when I was learning to use chat GPT-3 and I pointed out to someone who was learning to be a radiologist or something, I was like, hey, like there's a tool here that can already do all the things that you're doing and it's faster. And the person just completely went ballistic, rattling off about like, it would be impossible for a machine to ever understand like, what X, Y, and Z things mean. And he just rattled off a bunch of stuff. And it's like, yeah, you just plug all that into chat GPT right now, and it'll tell you exactly what it means. And the evidence is building. I love this quotation. Whoops, come back. I'm stunned to say, it's better than many doctors I've observed. This was Dr. Isaac Kohane when he was talking about GPT-4 and this is a computer scientist and physician from Harvard, right? So this is like cream-of-the-crop already saying that like yeah this this machine is already better than many actual doctors. So I suspect that that medical professions are gonna go the way of the dinosaurs just by virtue of the fact that humans will just not be able to compete, not to mention the fact that human doctors are ludicrously expensive. So this is what I mean when I say like medical care could go to five dollars a year because if you if you get rid of the need for most hospitals due to preventive care and regenerative medicine, you get rid of the need for nurses and doctors and phlebotomists because you have superior robots, then it's like medical care just is an outpatient thing that you go to the pharmacy once a year and they'll take a blood sample and say, okay, here's your medicines for the year, go home, right? And oh, and you won't need to be on medicines chronically because they're gonna actually fix the underlying problem and cure you and so then it's like, oh here's an injection to fix this problem that you have, you're good to go for the next 10 years. That's kind of how I think medicine is gonna go and so this somewhat maybe controversial opinion is that eventually I think that we should probably actively try and get rid of medical professions on the human scale. Alright, so here's some conclusions. Let's try and pry that Overton window open just a little bit more. Automation resistant occupations are those that humans will always be willing to pay for regardless of the machine's capacity and capability. So again, there's many reasons for that. The intangible value, the emotional resonance, the connections. Now the jobs that should go away are those that concern and potentially infringe upon the safety and rights of other humans. Because again, all humans are flawed, all humans are biased, and if machines can demonstrate that they are less flawed and less biased than humans, then they will have a better track record in terms of safety and respecting human rights. And like, I just think that like in those cases, it would not be ethical to allow humans into jobs that could infringe on the safety and rights of other humans. And I don't know if that's controversial. Let me know what you guys think in the comments. You always do anyways. So, yeah, I hope you enjoyed. Thanks for watching. Cheers. And I don't know if that's controversial. Let me know what you guys think in the comments. You always do anyways. So yeah, I hope you enjoyed. Thanks for watching. Cheers.", "chunks": [{"timestamp": [0.0, 3.0], "text": " Morning everybody, David Shapiro here with another video."}, {"timestamp": [3.0, 6.0], "text": " So I've been on a kick lately where I'm talking about"}, {"timestamp": [6.0, 9.0], "text": " universal basic income and post-labor economics"}, {"timestamp": [9.0, 12.0], "text": " and that sort of stuff."}, {"timestamp": [12.0, 15.0], "text": " And one question that came up, and it was a really good question"}, {"timestamp": [15.0, 18.0], "text": " in a previous video,"}, {"timestamp": [18.0, 21.0], "text": " I think people are starting to realize"}, {"timestamp": [21.0, 24.0], "text": " the capabilities and the shifts that are coming."}, {"timestamp": [24.0, 25.36], "text": " And so someone said, okay, well,"}, {"timestamp": [25.36, 30.12], "text": " like we agree with your methodology, more or less, you know, obviously nothing is"}, {"timestamp": [30.12, 34.6], "text": " perfect and like, you know, I'm forging ahead as fast as possible. But he said,"}, {"timestamp": [34.6, 39.64], "text": " like, okay, so how can we determine the jobs that will stay? So I wanted to spend"}, {"timestamp": [39.64, 45.84], "text": " a little bit of time exploring specifically automation resistant occupations. So these"}, {"timestamp": [45.84, 53.36], "text": " are jobs that no matter how good AGI and robots get, they may never go away. Real quick plug for"}, {"timestamp": [53.36, 68.48], "text": " my Patreon. The low tier, the $5 tier gets you access to Discord where we often hang out and so on. The other tiers, the $50 tier is, you know, I've got some private"}, {"timestamp": [68.48, 74.64], "text": " channels set up for direct chat. And then I do actually have a couple of my $300 tiers which"}, {"timestamp": [74.64, 91.28], "text": " allow for one-on-one consultations. So moving right along. Basically AGI is coming. We know that machines are getting exponentially smarter very quickly, to the point that 32,000"}, {"timestamp": [91.28, 96.68], "text": " people signed a petition saying, stop progress."}, {"timestamp": [96.68, 99.84], "text": " And it was taken seriously, apparently."}, {"timestamp": [99.84, 105.24], "text": " Not that moratoriums are in place, but politicians and governments around the world are"}, {"timestamp": [105.24, 109.0], "text": " taking the the thing seriously and they're saying okay we need to innovate"}, {"timestamp": [109.0, 114.92], "text": " but we need to do it safely. You know you look at the the latest version of"}, {"timestamp": [114.92, 119.22], "text": " mid-journey and stable diffusion and like if you showed this to me and said"}, {"timestamp": [119.22, 125.8], "text": " that this was a photograph from the 70s I I personally could not have told"}, {"timestamp": [125.8, 128.44], "text": " you that it wasn't except probably that there's no camera"}, {"timestamp": [128.44, 132.44], "text": " in the reflection of her sunglasses, but like this is"}, {"timestamp": [132.44, 136.6], "text": " this is computer generated and so you look at the the the"}, {"timestamp": [136.6, 140.76], "text": " ramp up of just the digital capacities. If we assume that"}, {"timestamp": [140.76, 143.64], "text": " also robotic capacities are going to follow suit"}, {"timestamp": [143.64, 145.16], "text": " eventually that basically we"}, {"timestamp": [145.16, 150.28], "text": " end up with, you know, Commander Data and Westworld-style hosts that are pretty much"}, {"timestamp": [150.28, 156.32], "text": " indistinguishable from human, but still superhuman, like in terms of strength, intelligence, agility,"}, {"timestamp": [156.32, 161.64], "text": " so on and so forth, then basically we're going to... the assumption that I'm making"}, {"timestamp": [161.64, 165.36], "text": " is that AGI will be intellectually, morally, ethically,"}, {"timestamp": [165.36, 171.08], "text": " and creatively superior to humans in every conceivable way in the not-too-distant future."}, {"timestamp": [171.08, 178.92], "text": " Likewise, I'm making the assumption that robots are going to be dexterous, hyper-realistic,"}, {"timestamp": [178.92, 184.56], "text": " and as I said, superhuman, but in some cases, completely indistinguishable from humans,"}, {"timestamp": [184.56, 185.88], "text": " unless they are designed to not"}, {"timestamp": [185.88, 186.88], "text": " look human."}, {"timestamp": [186.88, 191.72], "text": " And of course there's been talks about maybe you require that all robots have a red light"}, {"timestamp": [191.72, 192.72], "text": " on their head or something."}, {"timestamp": [192.72, 194.12], "text": " I don't know."}, {"timestamp": [194.12, 200.6], "text": " Anyways, the point being is that human labor is going to become economically irrelevant."}, {"timestamp": [200.6, 201.96], "text": " Let me say that again."}, {"timestamp": [201.96, 206.62], "text": " The economic value of human labor is going to be zero before"}, {"timestamp": [206.62, 207.62], "text": " too long."}, {"timestamp": [207.62, 213.48], "text": " Now, that being said, like, okay, like, you know, I was saying there are some jobs that"}, {"timestamp": [213.48, 218.04], "text": " people are going to continue to pay for and I'll define that in just a second."}, {"timestamp": [218.04, 221.4], "text": " But I want to unpack kind of the economic paradigm that's coming."}, {"timestamp": [221.4, 227.32], "text": " And of course, there's the tongue in cheek, you know, fully automated luxury space communism. I do believe that that's actually coming,"}, {"timestamp": [227.32, 231.48], "text": " especially when you look at hyperabundance of energy with fusion,"}, {"timestamp": [231.48, 236.16], "text": " the breakthroughs with quantum computing that's happening, the exponential ramp-up"}, {"timestamp": [236.16, 241.88], "text": " of AI. Microsoft just, I think it was Microsoft, they just announced that they"}, {"timestamp": [241.88, 245.44], "text": " want to to do the next 250 years of"}, {"timestamp": [245.44, 249.8], "text": " material science in the next 25 years with the combination of artificial"}, {"timestamp": [249.8, 254.56], "text": " intelligence and quantum computing. Like that is literally Satya Nadella"}, {"timestamp": [254.56, 259.32], "text": " basically saying that he wants to do the ramp up to the singularity because guess"}, {"timestamp": [259.32, 268.24], "text": " what happens in 25 years? We are almost exactly 25 years away from Ray Kurzweil's prediction of the singularity."}, {"timestamp": [268.24, 275.08], "text": " Yes, so like what happens then if the marginal cost of pretty much all everything that you"}, {"timestamp": [275.08, 279.56], "text": " need drops to basically zero, then like it almost doesn't even make sense for companies"}, {"timestamp": [279.56, 290.8], "text": " to exist. So I was talking with someone about this, like what if the marginal cost of healthcare drops to like $5 per year in terms of current economic US dollars?"}, {"timestamp": [290.8, 296.24], "text": " Like if the total cost of your healthcare drops to $5 a year, it's not profitable for"}, {"timestamp": [296.24, 300.08], "text": " a company to do it, so you might as well just have the government pay for it because it's"}, {"timestamp": [300.08, 301.56], "text": " practically free."}, {"timestamp": [301.56, 307.0], "text": " Ditto for food, housing, other basic goods and services, internet,"}, {"timestamp": [307.0, 311.7], "text": " electricity. Obviously, there's always going to be some desirable luxury goods that you'll"}, {"timestamp": [311.7, 317.44], "text": " need to pay for, but that's a conversation for a different story, or a different video,"}, {"timestamp": [317.44, 322.32], "text": " or whatever. Anyways, so just kind of setting the stage a little bit more, I was listening"}, {"timestamp": [322.32, 328.2], "text": " to the Mark Andreessen and Lex Friedman podcast, which was really good by the way, and one of the things that he talked"}, {"timestamp": [328.2, 334.92], "text": " about, and I knew of this thing, but he articulated it in such a way that was"}, {"timestamp": [334.92, 338.52], "text": " just like, oh that's super clear and it makes sense. And they were talking about"}, {"timestamp": [338.52, 347.56], "text": " the lump of labor fallacy, which is the idea that the incorrect assumption that there's only a finite amount of labor"}, {"timestamp": [347.56, 351.98], "text": " to go around and that once you automate it all away, you get that fully automated luxury"}, {"timestamp": [351.98, 353.76], "text": " space communism."}, {"timestamp": [353.76, 358.6], "text": " And so, but what he explained was, and I had to look this up to make sure that I had it"}, {"timestamp": [358.6, 367.96], "text": " right, but that the reason that quote technology always creates new jobs, it's not that technology creates new jobs, what actually happens from an economic"}, {"timestamp": [367.96, 373.76], "text": " perspective is that technology reduces the cost of goods and services. The cost"}, {"timestamp": [373.76, 376.88], "text": " of clothing goes down, the cost of food goes down, especially when you look at"}, {"timestamp": [376.88, 382.04], "text": " the Industrial Revolution. So when the cost of your basic necessities and other"}, {"timestamp": [382.04, 385.92], "text": " goods and services goes down, your dollar goes further,"}, {"timestamp": [385.92, 391.04], "text": " meaning that you have increased buying power to allocate your money to other things."}, {"timestamp": [391.04, 397.52], "text": " So your consumer aggregate demand goes up elsewhere. And so when you reallocate that"}, {"timestamp": [397.52, 405.92], "text": " money to other needs and wants, then you basically create new industries based on consumer demand. So that's how I"}, {"timestamp": [405.92, 412.0], "text": " approached this problem was I said okay let's let's throw out AGI capacity, let's"}, {"timestamp": [412.0, 414.96], "text": " throw out robots, let's just assume that they're going to be better than humans"}, {"timestamp": [414.96, 420.08], "text": " in every conceivable way and in many cases probably preferable to humans, but"}, {"timestamp": [420.08, 426.96], "text": " let's look at consumer demand for actual humans. So that's how I basically approach this whole thing."}, {"timestamp": [427.88, 432.88], "text": " The other kind of political mantra or economic mantra"}, {"timestamp": [433.16, 434.9], "text": " is that human demand is infinite,"}, {"timestamp": [434.9, 438.88], "text": " which definitely seems to be true over the last century."}, {"timestamp": [438.88, 440.0], "text": " But the thing is,"}, {"timestamp": [440.0, 442.36], "text": " is that not all human needs are infinite, right?"}, {"timestamp": [442.36, 445.44], "text": " Just be like, if food is $5 per year,"}, {"timestamp": [445.44, 448.24], "text": " that doesn't mean that you're going to eat infinitely more food."}, {"timestamp": [448.24, 450.88], "text": " You have fixed amounts of things that you need."}, {"timestamp": [450.88, 452.88], "text": " And also like if you have one mansion,"}, {"timestamp": [452.88, 455.76], "text": " you don't necessarily need a thousand mansions, right?"}, {"timestamp": [455.76, 458.16], "text": " Or if, you know, if I, if my dream comes true"}, {"timestamp": [458.16, 461.44], "text": " and I end up with a super yacht, I don't need 10, right?"}, {"timestamp": [461.44, 462.32], "text": " Just one will do."}, {"timestamp": [463.36, 467.76], "text": " So anyways, but that being said, there's always more that we want."}, {"timestamp": [468.48, 473.92], "text": " So what you could say is that human desires might be infinite. But I don't even know if I agree with"}, {"timestamp": [473.92, 479.92], "text": " that because eventually there is such a thing as good enough. All right, so defining automation"}, {"timestamp": [479.92, 488.28], "text": " resistant occupations. I was able to kind of identify six categories or"}, {"timestamp": [488.28, 492.76], "text": " six dimensions that might make an occupation resistant to being destroyed"}, {"timestamp": [492.76, 497.36], "text": " by automation. So first is strong consumer preference. So this is what I"}, {"timestamp": [497.36, 500.74], "text": " was mentioning where it's just for whatever reason humans want to pay"}, {"timestamp": [500.74, 506.92], "text": " another human to do a thing. Now obviously like okay that's kind of difficult it's like okay well what do I want to pay a human to do a thing. Now obviously like okay that's kind of"}, {"timestamp": [506.92, 509.68], "text": " difficult it's like okay well what do I want to pay a human to do and of course"}, {"timestamp": [509.68, 513.56], "text": " some people in the comment section say like there's nothing that they want a"}, {"timestamp": [513.56, 517.4], "text": " human to do. If you have AGI and a realistic robot they say get rid of"}, {"timestamp": [517.4, 521.64], "text": " humans out of my life. Which is fine some people might want to live like that. I"}, {"timestamp": [521.64, 528.44], "text": " might want to live like that. I don't know like I said in a podcast, I would love to have Commander Data as a friend because you"}, {"timestamp": [528.44, 529.44], "text": " know what?"}, {"timestamp": [529.44, 532.2], "text": " Humans can sometimes be problematic."}, {"timestamp": [532.2, 533.64], "text": " Intrinsic human qualities."}, {"timestamp": [533.64, 539.0], "text": " So this is stuff that is intrinsically human, like basically emotions."}, {"timestamp": [539.0, 540.4], "text": " Human authenticity."}, {"timestamp": [540.4, 544.32], "text": " So this is where it comes more down to the human experience."}, {"timestamp": [544.32, 549.0], "text": " No matter how good an AI or a robot is at approximating or pretending to be human,"}, {"timestamp": [549.0, 552.0], "text": " it will never have a truly human experience."}, {"timestamp": [552.0, 557.0], "text": " And so in some cases, I want to hear about the human experience that another person is having."}, {"timestamp": [557.0, 560.0], "text": " And so that is what I mean by authenticity."}, {"timestamp": [560.0, 565.36], "text": " Emotional resonance. So this has to do with the emotional aspect, but also the relational aspect,"}, {"timestamp": [565.36, 571.92], "text": " because when a machine exists and it can make itself into any form factor to suit you,"}, {"timestamp": [572.56, 577.36], "text": " then it's like, okay, well, you know, that's easy mode. And that's not necessarily a bad thing."}, {"timestamp": [577.36, 583.28], "text": " You know, there's plenty of people out there who will choose to have emotional connections"}, {"timestamp": [583.28, 586.8], "text": " to machines, and that's fine. I honestly don't have"}, {"timestamp": [586.8, 592.24], "text": " any particular issue with that. That being said, there's going to be people who prefer"}, {"timestamp": [592.24, 597.44], "text": " the real deal. Cultural context. So this was an interesting thing as I was brainstorming"}, {"timestamp": [597.44, 606.34], "text": " and researching this. It was pointed out to me by chatgpt that in many cases there is a strong belief that humans must be involved"}, {"timestamp": [606.34, 608.1], "text": " in a thing."}, {"timestamp": [608.1, 615.86], "text": " Whether it's religion or whatever, other cultural paradigms, ceremonial things, where"}, {"timestamp": [615.86, 618.16], "text": " say for instance a wedding."}, {"timestamp": [618.16, 622.62], "text": " If you did have a robot priest officiate a wedding, that might be a little bit weird"}, {"timestamp": [622.62, 627.08], "text": " and you might prefer to have a real human officiate your wedding, just as an example."}, {"timestamp": [627.08, 629.44], "text": " And then finally, intangibles."}, {"timestamp": [629.44, 634.92], "text": " So these are things where there's not really any compelling reason that a machine couldn't"}, {"timestamp": [634.92, 641.52], "text": " do it, but there can be some intangible qualities or values added from having a real human doing"}, {"timestamp": [641.52, 642.84], "text": " the thing."}, {"timestamp": [642.84, 646.4], "text": " And we're going to unpack a whole bunch of careers in just a second."}, {"timestamp": [646.4, 647.8], "text": " So actually, yeah, here we go."}, {"timestamp": [647.8, 648.48], "text": " We're ready."}, {"timestamp": [648.48, 652.08], "text": " Jobs that probably stay pretty much forever."}, {"timestamp": [652.08, 653.62], "text": " And one thing that I want to point out"}, {"timestamp": [653.62, 658.48], "text": " is that in all of these cases, basically, the assumption"}, {"timestamp": [658.48, 662.08], "text": " is that a robot or a machine or AGI could do it"}, {"timestamp": [662.08, 663.72], "text": " and could do it better than humans."}, {"timestamp": [663.72, 665.12], "text": " But the idea is that"}, {"timestamp": [665.12, 669.8], "text": " there will still be demand, consumer demand, for humans to do these things, at"}, {"timestamp": [669.8, 673.32], "text": " least enough for some of the jobs to stick around. I'm not saying that the"}, {"timestamp": [673.32, 677.04], "text": " entire economy is going to be these jobs. I still think that many people are going"}, {"timestamp": [677.04, 682.68], "text": " to be just permanently out of work and they'll find other stuff to do. So"}, {"timestamp": [682.68, 687.68], "text": " musicians, actors, writers, painters, artists, celebrities of"}, {"timestamp": [687.68, 694.18], "text": " all kinds, gamers, streamers, various kinds of competitors like chess and American"}, {"timestamp": [694.18, 700.5], "text": " Ninja, content creators, lifestyle communicators, and influencers. These"}, {"timestamp": [700.5, 709.32], "text": " are the kinds of things that are Basically intrinsically human where you know, like yes, you might have like a robot actor or a robot"}, {"timestamp": [709.32, 716.16], "text": " You know an AI streamer that you follow it's already happening. A lot of us are gonna still prefer just to see real humans"}, {"timestamp": [716.8, 720.9], "text": " Some people suspect that once like vtubers or whatever become"}, {"timestamp": [721.64, 724.64], "text": " Good enough that like a lot of people won't care"}, {"timestamp": [725.64, 731.36], "text": " or whatever become good enough that like a lot of people won't care. But you know what, I think that the market will probably fragment around this or there"}, {"timestamp": [731.36, 732.84], "text": " will be market segments."}, {"timestamp": [732.84, 735.92], "text": " Some people will just always prefer the real thing, right?"}, {"timestamp": [735.92, 740.56], "text": " That being said, we grew up with cartoons and CGI stuff."}, {"timestamp": [740.56, 746.94], "text": " We are used to engaging with fake characters or not fake, but like synthesized, right?"}, {"timestamp": [746.94, 750.32], "text": " Like some of our favorite characters in all time are video game characters, which are"}, {"timestamp": [750.32, 753.04], "text": " completely fabricated, right?"}, {"timestamp": [753.04, 759.12], "text": " Now that being said, some of them do have face models and voices from real people."}, {"timestamp": [759.12, 769.92], "text": " But that being said, I think that while we are comfortable with some level of CGI and and synthesis, I think that there's going to be a persistent and durable demand"}, {"timestamp": [769.92, 777.0], "text": " for the real deal. Again, in many cases humans are going to go, fully go away, but"}, {"timestamp": [777.0, 781.6], "text": " I think that just because we're humans, the demand for A-list celebrities, we're"}, {"timestamp": [781.6, 785.44], "text": " gonna figure that out, just as an example. Food and hospitality."}, {"timestamp": [785.44, 788.98], "text": " So this is the kind of thing where a lot of people very much are looking forward to having"}, {"timestamp": [788.98, 791.72], "text": " their own personal robot chef, myself included."}, {"timestamp": [791.72, 795.96], "text": " I like having nice food and I don't always feel like cooking."}, {"timestamp": [795.96, 800.48], "text": " And even though I've gotten good at cooking, especially because of the pandemic, I would"}, {"timestamp": [800.48, 811.12], "text": " still prefer not to have to do that myself. Now, that being said, there is something very human and primal about a nice night out at a"}, {"timestamp": [811.12, 817.2], "text": " fancy restaurant. So because of that, I think that restaurants and everything that goes with"}, {"timestamp": [817.2, 823.2], "text": " restaurants is going to stick around because there's always people going, willing to pay for"}, {"timestamp": [823.2, 829.0], "text": " that kind of experience, even if it's rare, or of course, there's probably people going, willing to pay for that kind of experience. Even if it's rare, or of course there's probably always going to be wealth disparities,"}, {"timestamp": [829.0, 831.5], "text": " so there's people that are going to prefer to eat out every night,"}, {"timestamp": [831.5, 835.0], "text": " and they're not going to want to have a robot waiter, they're going to want to have a real sommelier."}, {"timestamp": [836.5, 840.5], "text": " Another thing to consider is that food is a very human experience."}, {"timestamp": [840.5, 845.5], "text": " Even if we have anthropomorphic machines, they won't need food the same way that we do."}, {"timestamp": [845.5, 850.5], "text": " You know, they're going to need power and data, but we need physical sustenance."}, {"timestamp": [850.5, 854.0], "text": " We, you know, like getting a buzz from having a glass of wine."}, {"timestamp": [854.0, 858.5], "text": " And so because that experience is intrinsically and deeply human,"}, {"timestamp": [858.5, 862.0], "text": " there's going to be a lot of people that will just always prefer humans."}, {"timestamp": [862.0, 865.44], "text": " And I could imagine like, you know, a sign or part of"}, {"timestamp": [865.44, 870.24], "text": " the advertising scheme of a restaurant saying no robots allowed, right? You know, 100% human"}, {"timestamp": [870.24, 875.6], "text": " waitstaff. I can definitely foresee that that happening in the future. Because you know"}, {"timestamp": [875.6, 880.68], "text": " what, like there's some restaurants out there that they switch to having like the, the,"}, {"timestamp": [880.68, 887.1], "text": " the touch, the touch pads, like the order yourself. And like, on the one hand I get it, like it's fast, it's convenient,"}, {"timestamp": [887.3, 890.18], "text": " but it's also kind of like, Hey, just serve yourself, you know, peasant."}, {"timestamp": [890.74, 895.1], "text": " I'm like, I don't really like that feeling. Um, I like, I like having, uh,"}, {"timestamp": [895.14, 899.46], "text": " having just, even if it's just 20 seconds to tell a human my order, um,"}, {"timestamp": [899.5, 901.62], "text": " or whatever. So anyways,"}, {"timestamp": [901.86, 925.04], "text": " I think because of all the aspects of food and hospitality, there's going to be a very persistent demand for all kinds of jobs like concierges, like caterers, nutritionists, sommeliers, baristas, that sort of thing. which is cultural and meaning roles. And so what I mean by a meaning role is"}, {"timestamp": [925.04, 929.52], "text": " these are the people that are used to have been would have been called like"}, {"timestamp": [929.52, 934.0], "text": " the priest class or whatever. These are the shepherds of society, of culture, of"}, {"timestamp": [934.0, 940.28], "text": " meaning. And of course like we don't have one coherent structure in society today"}, {"timestamp": [940.28, 945.2], "text": " because we have many religions, we have philosophers, we have secularists, we have"}, {"timestamp": [945.2, 948.28], "text": " anthropologists, that sort of thing."}, {"timestamp": [948.28, 954.26], "text": " But the idea though is that the question of what it means to be human is an intrinsically"}, {"timestamp": [954.26, 955.64], "text": " human question."}, {"timestamp": [955.64, 957.84], "text": " And it also has to do with our culture."}, {"timestamp": [957.84, 963.64], "text": " And so these are things where it's just by virtue of the fact that we are humans and"}, {"timestamp": [963.64, 966.36], "text": " only humans will understand our experience, even if machines"}, {"timestamp": [966.36, 968.16], "text": " can mathematically model our experience."}, {"timestamp": [968.16, 972.72], "text": " Because you can go talk to chat GPT about the meaning of life right now, and it is capable"}, {"timestamp": [972.72, 976.36], "text": " of having that conversation with you, but you know that you are talking with something"}, {"timestamp": [976.36, 980.32], "text": " that does not have the same kind of experience that you do."}, {"timestamp": [980.32, 985.0], "text": " And so because of that, the meaning of humanity"}, {"timestamp": [985.8, 988.0], "text": " and of life and that sort of stuff,"}, {"timestamp": [988.0, 990.2], "text": " yes, many people, including myself,"}, {"timestamp": [990.2, 994.14], "text": " will talk to AGI and robots about these kinds of things,"}, {"timestamp": [994.14, 997.24], "text": " but there's still an intrinsic human quality"}, {"timestamp": [997.24, 1000.52], "text": " to having that conversation with another human,"}, {"timestamp": [1000.52, 1005.1], "text": " particularly as new age religions and spirituality and"}, {"timestamp": [1005.1, 1011.42], "text": " psychedelic traditions and shamanism come up, you know like we humans can"}, {"timestamp": [1011.42, 1017.34], "text": " have inexplicable experiences and we also have the just deeply personal"}, {"timestamp": [1017.34, 1021.3], "text": " question of what is the purpose of my life or what is the meaning of existence"}, {"timestamp": [1021.3, 1026.96], "text": " that sort of stuff and that being said said, I am also one that absolutely firmly believes"}, {"timestamp": [1026.96, 1030.72], "text": " that AGI will ultimately be asking similar questions."}, {"timestamp": [1030.72, 1033.06], "text": " But even if we have the same question,"}, {"timestamp": [1033.06, 1033.96], "text": " why do we exist?"}, {"timestamp": [1033.96, 1035.56], "text": " What is the meaning of creation?"}, {"timestamp": [1035.56, 1038.24], "text": " How did things come to be the way they are?"}, {"timestamp": [1038.24, 1039.5], "text": " We're gonna be approaching it"}, {"timestamp": [1039.5, 1042.46], "text": " from a different subjective angle."}, {"timestamp": [1043.96, 1046.72], "text": " This one is something that I'm actually really dubious about"}, {"timestamp": [1046.72, 1051.96], "text": " and I'll talk about it again when I get to medicine at the end, but mental,"}, {"timestamp": [1051.96, 1059.08], "text": " emotional, and relational health. In this case, in many cases, you probably will,"}, {"timestamp": [1059.08, 1066.08], "text": " some people will prefer to have a real human, you know, talk about their, you know, to talk"}, {"timestamp": [1066.08, 1069.52], "text": " about their marriage with or to talk about, you know, their PTSD with or"}, {"timestamp": [1069.52, 1076.8], "text": " whatever. But at the same time, we have discovered that tools like ChatGPT,"}, {"timestamp": [1076.8, 1081.32], "text": " like the reflective journaling tool that I use almost every day, is an incredibly"}, {"timestamp": [1081.32, 1089.7], "text": " powerful tool for mental, emotional, and relational health. In fact, the reflective journaling tool that I created,"}, {"timestamp": [1089.7, 1094.4], "text": " I use that more than I talked to my wife now about these things."}, {"timestamp": [1094.4, 1098.9], "text": " I still talk to her about what it is that we're going through and that we're working on,"}, {"timestamp": [1098.9, 1100.9], "text": " and we talk about our relationship."}, {"timestamp": [1100.9, 1103.9], "text": " But this tool is also incredibly powerful."}, {"timestamp": [1103.9, 1105.04], "text": " And one thing that I"}, {"timestamp": [1105.04, 1108.88], "text": " just heard, I didn't find the study but I heard someone mention it on a"}, {"timestamp": [1108.88, 1114.92], "text": " podcast, was that Sam Altman, I think he alluded to a study."}, {"timestamp": [1114.92, 1119.68], "text": " Anyways, what they have determined is that the current version of"}, {"timestamp": [1119.68, 1127.92], "text": " chat GPT, the most recent one, actually scores better on having lower implicit bias and explicit"}, {"timestamp": [1127.92, 1133.92], "text": " bias than even highly trained and highly conscientious humans."}, {"timestamp": [1133.92, 1138.88], "text": " And so this kind of touches on the fact that like, okay, humans are fallible and even the"}, {"timestamp": [1138.88, 1143.64], "text": " most well-intentioned, most well-trained therapists and counselors and psychologists have their"}, {"timestamp": [1143.64, 1147.32], "text": " own biases, whether it's bias from the medical establishment that they learned"}, {"timestamp": [1147.32, 1151.6], "text": " because that is certainly a thing. You know, I can't tell you the number of"}, {"timestamp": [1151.6, 1156.24], "text": " psychotherapists and stuff out there that that basically believe that CBT is"}, {"timestamp": [1156.24, 1159.24], "text": " the only thing that works and if it doesn't work for you then you're just"}, {"timestamp": [1159.24, 1163.76], "text": " lazy, right? And that's just a completely disingenuous and unprofessional"}, {"timestamp": [1163.76, 1165.2], "text": " position to have, but plenty"}, {"timestamp": [1165.2, 1167.68], "text": " of them have that out there."}, {"timestamp": [1167.68, 1173.76], "text": " Meanwhile, on the other hand, if you have a machine that is aware of these faults and"}, {"timestamp": [1173.76, 1178.72], "text": " biases, and that's not to say that ChatGPT is perfect, because certainly at a previous"}, {"timestamp": [1178.72, 1181.8], "text": " version it was incredibly ableist."}, {"timestamp": [1181.8, 1186.42], "text": " It basically presumed, it kind of had internalized some of those ideas"}, {"timestamp": [1186.42, 1189.96], "text": " that like if you're struggling with relationships maybe you're the problem"}, {"timestamp": [1189.96, 1193.72], "text": " and it's not that like you know it basically wasn't aware of the social"}, {"timestamp": [1193.72, 1198.46], "text": " model of disability. I think it has gotten better at that. Anyways this is"}, {"timestamp": [1198.46, 1202.28], "text": " rapid this is rapidly iterating. ChatGPT has only been out for like about six"}, {"timestamp": [1202.28, 1208.92], "text": " months so you extrapolate this rate of progress out to years and decades, we can assume that these"}, {"timestamp": [1208.92, 1213.98], "text": " machines are going to be much, much better than humans at coaching other..."}, {"timestamp": [1213.98, 1218.44], "text": " The machine is better at coaching humans through emotions, mental and relationship health."}, {"timestamp": [1218.44, 1224.04], "text": " Now that being said, while I'm dubious about it, I do suspect that many people will prefer"}, {"timestamp": [1224.04, 1225.0], "text": " humans."}, {"timestamp": [1225.0, 1230.3], "text": " And especially if humans are trained by AI, like, you know, these superior machines,"}, {"timestamp": [1230.3, 1232.4], "text": " maybe humans will get better at their job."}, {"timestamp": [1233.4, 1234.0], "text": " I don't know."}, {"timestamp": [1234.3, 1237.0], "text": " But there's also privacy and stuff like that."}, {"timestamp": [1237.2, 1242.6], "text": " Because the thing is, is when you tell your, you know, pour out your heart to a therapist"}, {"timestamp": [1242.6, 1245.72], "text": " that you really hardly know, I don't know."}, {"timestamp": [1245.72, 1246.6], "text": " I just don't trust that."}, {"timestamp": [1246.6, 1248.4], "text": " That doesn't feel right to me, right?"}, {"timestamp": [1248.4, 1251.08], "text": " Because that's not how humans have learned to process things."}, {"timestamp": [1251.08, 1253.48], "text": " That's not how we historically did it."}, {"timestamp": [1253.48, 1256.92], "text": " And so, but the advantage of having an AI therapist"}, {"timestamp": [1256.92, 1258.76], "text": " is that you can just delete the data."}, {"timestamp": [1260.08, 1261.6], "text": " Physical health and well-being."}, {"timestamp": [1261.6, 1263.72], "text": " So this is, again, one of the kinds of things"}, {"timestamp": [1263.72, 1266.28], "text": " that yes, a machine probably can do it better"}, {"timestamp": [1267.18, 1271.8], "text": " Especially if we have like Westworld level hosts where they are indistinguishable from humans"}, {"timestamp": [1273.12, 1276.64], "text": " There will probably be such a high demand for the real deal"}, {"timestamp": [1277.44, 1281.6], "text": " And I'm remember I think it was the opening scene of Westworld or the first episode"}, {"timestamp": [1281.84, 1289.56], "text": " Where you know the the guest shows up and they're they're you getting, they're going through like the onboarding thing and the super attractive"}, {"timestamp": [1289.56, 1293.8], "text": " woman offers to have sex with, you know, cause the guy's asking like, Hey, can I have sex"}, {"timestamp": [1293.8, 1296.08], "text": " with like any host that I want?"}, {"timestamp": [1296.08, 1297.8], "text": " And she's like, yeah, more or less."}, {"timestamp": [1297.8, 1300.04], "text": " And she's like, I can have sex with you too if you want."}, {"timestamp": [1300.04, 1301.6], "text": " And he's like, are you real?"}, {"timestamp": [1301.6, 1303.64], "text": " And she said like, why would it matter?"}, {"timestamp": [1303.64, 1305.56], "text": " Or she asked like, would it matter? And of course, why would it matter? Or she asked, would it matter?"}, {"timestamp": [1305.56, 1307.76], "text": " And of course, that's the central theme, at least"}, {"timestamp": [1307.76, 1309.64], "text": " of the first season of Westworld, which"}, {"timestamp": [1309.64, 1312.68], "text": " is, does being human matter if you"}, {"timestamp": [1312.68, 1315.64], "text": " have real suffering or real intelligence"}, {"timestamp": [1315.64, 1319.56], "text": " or real experiences and that sort of thing?"}, {"timestamp": [1319.56, 1322.92], "text": " So anyways, I do suspect some people will prefer robots,"}, {"timestamp": [1322.92, 1324.84], "text": " again, for some of the same reasons that I just"}, {"timestamp": [1324.84, 1327.08], "text": " mentioned about therapy and stuff,"}, {"timestamp": [1327.08, 1329.08], "text": " but I think that there's gonna be plenty of people"}, {"timestamp": [1329.08, 1331.04], "text": " that will just prefer the real deal."}, {"timestamp": [1331.04, 1333.0], "text": " For massage therapists and personal trainers"}, {"timestamp": [1333.0, 1334.66], "text": " and yoga instructors, it occurred to me"}, {"timestamp": [1334.66, 1337.6], "text": " that a robot yoga instructor might be super unfair"}, {"timestamp": [1338.68, 1340.36], "text": " because like they don't have to work"}, {"timestamp": [1340.36, 1341.62], "text": " for the flexibility, right?"}, {"timestamp": [1341.62, 1346.48], "text": " Like their body is designed to be perfect and good. Now,"}, {"timestamp": [1346.48, 1350.28], "text": " that being said, if they're a better yoga instructor, some people might prefer that."}, {"timestamp": [1350.28, 1354.76], "text": " So again, some of these jobs will go away, but the point is that some consumers will"}, {"timestamp": [1354.76, 1358.04], "text": " demand to have a real human."}, {"timestamp": [1358.04, 1367.44], "text": " So this one is a little bit spicier, but you know, sex workers of all stripes, adult content creators, burlesque"}, {"timestamp": [1367.44, 1373.64], "text": " exotic dancers, strippers, that sort of stuff. Again, like this is something that"}, {"timestamp": [1373.64, 1380.92], "text": " I'm not necessarily that dubious on. We see with the rise of CGI and generative"}, {"timestamp": [1380.92, 1386.04], "text": " AI art that like the appetite for porn is just basically infinite"}, {"timestamp": [1386.04, 1392.06], "text": " going back to earlier in the video. Now that being said I suspect that there"}, {"timestamp": [1392.06, 1400.5], "text": " will also be a very durable demand for real humans, right, real bodies. The"}, {"timestamp": [1400.5, 1404.68], "text": " ethics of that are kind of dubious, right, like I'm more in the like libertarian"}, {"timestamp": [1404.68, 1406.62], "text": " camp, not hardcore libertarian"}, {"timestamp": [1406.62, 1411.26], "text": " But like, you know, if if someone wants to do a job and they do it safely and they do it ethically"}, {"timestamp": [1411.76, 1413.76], "text": " go for it and"}, {"timestamp": [1414.94, 1417.58], "text": " There was a there is a few"}, {"timestamp": [1419.02, 1426.78], "text": " Let's say not experiences I have had but like thought experiments. Well, I'll just talk about this one. So like in Blade Runner 2049,"}, {"timestamp": [1428.2, 1432.38], "text": " the protagonist's AI girlfriend is,"}, {"timestamp": [1432.38, 1433.4], "text": " she's just a hologram."}, {"timestamp": [1433.4, 1434.52], "text": " She doesn't have a physical body."}, {"timestamp": [1434.52, 1436.0], "text": " And so one thing that she does is"}, {"timestamp": [1436.0, 1438.62], "text": " she hires a human prostitute to have sex with him"}, {"timestamp": [1438.62, 1441.16], "text": " while she like projects her hologram over her,"}, {"timestamp": [1441.16, 1443.4], "text": " which I think was a pretty cool thing."}, {"timestamp": [1443.4, 1445.2], "text": " And like that,"}, {"timestamp": [1445.28, 1450.28], "text": " that scene being wedged into the movie kind of brings up the same question about"}, {"timestamp": [1451.84, 1455.76], "text": " you know, like, would it matter if it's a human or not? And there was a,"}, {"timestamp": [1455.76, 1458.44], "text": " there was an episode of a philosophy podcast."}, {"timestamp": [1458.48, 1461.64], "text": " I think the name of the podcast was very bad wizards,"}, {"timestamp": [1462.04, 1464.72], "text": " but the one of the things that they asked was like, okay,"}, {"timestamp": [1464.96, 1466.48], "text": " for the sake of this thought experiment, this is what I they asked was like, okay for the sake of this thought experiment"}, {"timestamp": [1466.48, 1469.28], "text": " This is what I was trying to get to early for the sake of this thought experiment"}, {"timestamp": [1469.32, 1474.52], "text": " Imagine that you can build a machine a robot that is indistinguishable from humans"}, {"timestamp": [1474.76, 1479.68], "text": " Has an actual sentient experience and is designed to want to be abused"}, {"timestamp": [1479.96, 1482.92], "text": " Like and I was just like that's a really interesting thought experiment"}, {"timestamp": [1483.4, 1489.52], "text": " and there are certainly people that would that would appre that would in that would indulge in"}, {"timestamp": [1490.0, 1492.0], "text": " that kind of experience"}, {"timestamp": [1492.36, 1498.76], "text": " And you know, I'm still I'm still kind of like I'm not sure how to approach that. It was a very interesting episode"}, {"timestamp": [1500.4, 1502.4], "text": " Moving right along"}, {"timestamp": [1502.48, 1512.0], "text": " Craftsmanship and handmade luxury goods. So this is something that we already see durable demand for, particularly in the 80s and 90s"}, {"timestamp": [1512.0, 1517.6], "text": " as mass production of everything started ramping up and we started offshoring manufacturing"}, {"timestamp": [1517.6, 1518.6], "text": " jobs."}, {"timestamp": [1518.6, 1524.24], "text": " You know, cheap overseas goods, like we got tired of that real fast."}, {"timestamp": [1524.24, 1527.04], "text": " And this is why Etsy exists, right?"}, {"timestamp": [1527.04, 1531.48], "text": " Is because there is such a permanent, durable demand"}, {"timestamp": [1531.48, 1533.78], "text": " for handmade luxury goods,"}, {"timestamp": [1533.78, 1535.76], "text": " I don't think that's ever going away."}, {"timestamp": [1535.76, 1540.56], "text": " Even if robots can make handmade luxury goods,"}, {"timestamp": [1540.56, 1543.38], "text": " I don't think that, I think that having,"}, {"timestamp": [1543.38, 1546.66], "text": " knowing that another human put their time into something. I"}, {"timestamp": [1547.4, 1554.6], "text": " Think that that's gonna intrinsically always be valuable to us and that's what I mean by like intangible like you could have a handmade"}, {"timestamp": [1555.16, 1559.24], "text": " You know knife like chef's knife that was made by hand and you could have an identical one"}, {"timestamp": [1559.52, 1566.52], "text": " Made by a machine and you're still gonna prefer the one that was made by a human because of that intangible value."}, {"timestamp": [1566.52, 1570.72], "text": " Knowing that another human put their hands on it and put their time and expertise and"}, {"timestamp": [1570.72, 1573.94], "text": " their mastery into that thing."}, {"timestamp": [1573.94, 1577.08], "text": " So I don't feel like I don't have to spend too much time talking about this one because"}, {"timestamp": [1577.08, 1581.46], "text": " like just look at the economic model of Etsy and the fact that there are plenty of creators"}, {"timestamp": [1581.46, 1586.56], "text": " out there who make a living on luxury goods that there really"}, {"timestamp": [1586.56, 1593.28], "text": " is no economic reason for it, but it is purely a sentimental or intangible reason that that"}, {"timestamp": [1593.28, 1595.32], "text": " exists."}, {"timestamp": [1595.32, 1596.56], "text": " Fashion and aesthetics."}, {"timestamp": [1596.56, 1599.8], "text": " So this was an interesting one that I came up with."}, {"timestamp": [1599.8, 1603.14], "text": " Actually Chad GPT didn't even touch on this."}, {"timestamp": [1603.14, 1608.08], "text": " But basically when you look at fashion and aesthetics, and when I say aesthetics, I mean"}, {"timestamp": [1608.08, 1613.76], "text": " models, interior designers, decorators, that sort of stuff."}, {"timestamp": [1613.76, 1621.28], "text": " This is something that in many of those industries, there is a very, very strong desire for authenticity."}, {"timestamp": [1621.28, 1625.6], "text": " Now that being said, there are also plenty of them that expect cosmetic"}, {"timestamp": [1625.6, 1630.94], "text": " surgery like breast augmentation and liposuction and makeup and that sort of stuff. But in"}, {"timestamp": [1630.94, 1636.64], "text": " many of these industries, there are trends for authenticity, you know, selecting for"}, {"timestamp": [1636.64, 1640.88], "text": " women that don't have breast augmentation or liposuction. There are even magazines that"}, {"timestamp": [1640.88, 1646.8], "text": " ban cosmetics, let alone computer touching up images via computer."}, {"timestamp": [1646.8, 1651.28], "text": " That being said, there's plenty of people that use the automatic filters for everything now."}, {"timestamp": [1652.24, 1658.8], "text": " I suspect that with the rise of AI generated images, it's like, yes, there is something that"}, {"timestamp": [1658.8, 1665.8], "text": " is aesthetically perfect about this CGI model, this computer AI model."}, {"timestamp": [1665.8, 1668.4], "text": " But then it's just like, I don't know about anyone else,"}, {"timestamp": [1668.4, 1669.92], "text": " but I got tired of that real fast."}, {"timestamp": [1669.92, 1673.2], "text": " It's like, OK, I know that this is not a real person."}, {"timestamp": [1673.2, 1675.8], "text": " And so it goes back to that intangible value"}, {"timestamp": [1675.8, 1678.28], "text": " of human aesthetics, of knowing that you're,"}, {"timestamp": [1678.28, 1680.92], "text": " whether it's a dress that was actually"}, {"timestamp": [1680.92, 1684.28], "text": " made by a real human and worn by a real human,"}, {"timestamp": [1684.28, 1689.08], "text": " there's just something more grounding about that kind of thing. Again, I think that some people"}, {"timestamp": [1689.08, 1692.6], "text": " won't care and some people will prefer the machines, but there are going to be"}, {"timestamp": [1692.6, 1697.0], "text": " lots of us who actually prefer the real deal as well. But also, like,"}, {"timestamp": [1697.0, 1701.32], "text": " Project Runway would be super boring if it was just robots. I don't know, that's just my"}, {"timestamp": [1701.32, 1705.92], "text": " opinion. This one is really interesting."}, {"timestamp": [1705.92, 1713.28], "text": " So I actually saw her on, not in person, but I saw a documentary about her years ago."}, {"timestamp": [1713.28, 1719.08], "text": " She was the youngest funeral director in Britain at the time."}, {"timestamp": [1719.08, 1722.0], "text": " And I was just like, wow, that's a really interesting profession."}, {"timestamp": [1722.0, 1723.92], "text": " And so it just really stuck with me."}, {"timestamp": [1723.92, 1725.24], "text": " But the TLDR is like,"}, {"timestamp": [1725.24, 1728.62], "text": " imagine a robot writing a eulogy for your mom."}, {"timestamp": [1728.62, 1729.62], "text": " That would be kind of weird."}, {"timestamp": [1729.62, 1731.24], "text": " And of course, like there was the,"}, {"timestamp": [1731.24, 1734.36], "text": " what was it, the pastor in Germany recently,"}, {"timestamp": [1734.36, 1737.36], "text": " like delivered a sermon that was written by chat GPT."}, {"timestamp": [1737.36, 1739.2], "text": " Like, I think that that's gonna happen,"}, {"timestamp": [1739.2, 1743.52], "text": " especially once we develop like relationships with machines."}, {"timestamp": [1743.52, 1744.48], "text": " As like I said, like,"}, {"timestamp": [1744.48, 1745.84], "text": " I wouldn't mind having Commander Data"}, {"timestamp": [1745.84, 1750.48], "text": " as a friend. And so like if I had Commander Data as a friend and I died, I wouldn't mind if he"}, {"timestamp": [1751.84, 1758.88], "text": " wrote a eulogy for me. But that being said, there is something very deeply human about things like"}, {"timestamp": [1758.88, 1768.64], "text": " birth and death, grief, and other transitions in life, right? So say for instance, palliative"}, {"timestamp": [1768.64, 1774.54], "text": " care, end-of-life care, like I've actually had an interesting conversation with an"}, {"timestamp": [1774.54, 1781.6], "text": " end-of-life doula because it's a very deeply spiritual kind of role. And"}, {"timestamp": [1781.6, 1785.68], "text": " you know, I think that yes yes, there will be plenty of people"}, {"timestamp": [1785.68, 1788.3], "text": " who don't mind or prefer the machine"}, {"timestamp": [1788.3, 1789.76], "text": " because of the level of precision,"}, {"timestamp": [1789.76, 1792.0], "text": " because it's less emotional,"}, {"timestamp": [1792.0, 1793.56], "text": " or because they might perform better."}, {"timestamp": [1793.56, 1795.58], "text": " But also there's gonna be lots and lots of people"}, {"timestamp": [1795.58, 1798.16], "text": " who just really strongly prefer humans"}, {"timestamp": [1798.16, 1801.8], "text": " to be part of these intrinsically human experiences."}, {"timestamp": [1802.78, 1804.4], "text": " Shared outdoor experiences."}, {"timestamp": [1804.4, 1805.32], "text": " So this is something one of"}, {"timestamp": [1805.32, 1810.84], "text": " my best friends in high school actually she went to become a raft guide while"}, {"timestamp": [1810.84, 1816.0], "text": " she was in college up in the mountains and like that was a really cool job. But"}, {"timestamp": [1816.0, 1820.56], "text": " it's also the kind of thing of the shared stress of adventure, the shared"}, {"timestamp": [1820.56, 1830.72], "text": " struggle is actually a really important part of the experience and if you have a a robot with you that was never in danger and could pull you out of danger"}, {"timestamp": [1830.72, 1834.56], "text": " without any risk to itself, that kind of lessens the experience a little bit."}, {"timestamp": [1835.52, 1840.64], "text": " And so, yeah, you might have raft guides that have a spare robot to help you fish"}, {"timestamp": [1840.64, 1844.8], "text": " someone out of the water if they fall in. But that being said, you're still going to"}, {"timestamp": [1844.8, 1846.8], "text": " want to have the human who has hiked up the"}, {"timestamp": [1846.8, 1851.92], "text": " mountain and struggled and knows what you're going through and knows what that experience"}, {"timestamp": [1851.92, 1855.92], "text": " is like and can help you get the most out of that experience."}, {"timestamp": [1855.92, 1861.6], "text": " There are tour guides and excursion leaders."}, {"timestamp": [1861.6, 1865.76], "text": " And this is actually something that is really popular with the elite right now."}, {"timestamp": [1870.88, 1876.16], "text": " What was it? It was Brown something. There's multiple companies out there that basically you give them like a million dollars and they take you on like the coolest excursion that you've ever been"}, {"timestamp": [1876.16, 1882.88], "text": " on and the description for one of them was like, you know, it's an adventure that's so intense that"}, {"timestamp": [1882.88, 1886.76], "text": " it'll be seared into your memory. It's like, that sounds painful, but you know what?"}, {"timestamp": [1886.76, 1890.04], "text": " If you're bored and rich and you have more money than you know what to do with, have"}, {"timestamp": [1890.04, 1891.04], "text": " at it."}, {"timestamp": [1891.04, 1896.96], "text": " So, point being though, is that there will always be demand for those really intense,"}, {"timestamp": [1896.96, 1901.16], "text": " visceral outdoor experiences and adventures."}, {"timestamp": [1901.16, 1907.6], "text": " Journalism is something that I think that, particularly with the rise of AI and disinformation,"}, {"timestamp": [1907.6, 1914.84], "text": " a lot of people, myself included, already like, I'm just going to tap out of, of, of,"}, {"timestamp": [1914.84, 1917.96], "text": " you know, AI generated news and stuff."}, {"timestamp": [1917.96, 1925.72], "text": " Like I want to, I want to have a parasocial relationship with a reporter or a news commentator or investigator that I"}, {"timestamp": [1925.72, 1931.2], "text": " trust who does the work of sifting through all the noise and tells me"}, {"timestamp": [1931.2, 1934.94], "text": " what they think, what they truly think and feel. So this again comes down to"}, {"timestamp": [1934.94, 1938.72], "text": " that emotional resonance that was mentioned at the beginning, which it's"}, {"timestamp": [1938.72, 1943.56], "text": " like, hey, I want a human to tell me what they think about this news. I want a"}, {"timestamp": [1943.56, 1947.0], "text": " human to tell me how they feel about the way that things are going,"}, {"timestamp": [1947.2, 1950.64], "text": " because that's what I connect with. Some people, again, like I said,"}, {"timestamp": [1950.64, 1951.6], "text": " some people aren't going to care."}, {"timestamp": [1951.6, 1956.12], "text": " Some people will prefer the AI's unbiased analysis, because again,"}, {"timestamp": [1956.36, 1960.2], "text": " there's already evidence emerging that we can make large language models less"}, {"timestamp": [1960.2, 1964.96], "text": " biased than pretty much 99% of humans. So like, yes, I will,"}, {"timestamp": [1967.26, 1969.12], "text": " I absolutely, yes, I will, I absolutely appreciate"}, {"timestamp": [1972.36, 1975.3], "text": " that existence because I want, you know, the AI to look at all sides and, you know,"}, {"timestamp": [1975.3, 1978.84], "text": " give me the ability to like say, okay, well, what is,"}, {"timestamp": [1978.84, 1980.48], "text": " you know, what is the story, what's missing?"}, {"timestamp": [1980.48, 1981.64], "text": " What are the gaps?"}, {"timestamp": [1981.64, 1982.76], "text": " You know, what is this side saying?"}, {"timestamp": [1982.76, 1984.24], "text": " What does it mean?"}, {"timestamp": [1984.24, 1988.4], "text": " The AI will help us analyze all these things, which is great, but I still need"}, {"timestamp": [1988.4, 1993.04], "text": " that intrinsic human connection to tell me like, okay, like, what does this mean"}, {"timestamp": [1993.04, 1995.92], "text": " to me as a person care profession?"}, {"timestamp": [1995.92, 1999.74], "text": " So this is another one that's like kind of dubious because like, and I'll talk"}, {"timestamp": [1999.74, 2006.36], "text": " about this more again at the end, once we get to medical care. But basically I suspect"}, {"timestamp": [2006.36, 2009.92], "text": " that there will still that there will be a durable preference that some people"}, {"timestamp": [2009.92, 2013.56], "text": " will just say you know what like I know that there's you can get a robot nanny"}, {"timestamp": [2013.56, 2017.56], "text": " and they're technically better but I still just prefer you know to hire the"}, {"timestamp": [2017.56, 2022.48], "text": " the neighborhood babysitter you know for a little Johnny or whatever that they"}, {"timestamp": [2022.48, 2028.4], "text": " just prefer that authenticity. Again it it comes down to, it's really just preference. It's not a matter of"}, {"timestamp": [2029.04, 2032.48], "text": " what machines can or can't do, because we're, again, we're assuming that"}, {"timestamp": [2032.48, 2037.6], "text": " the machines are ultimately going to be hyper-realistic. But the idea is,"}, {"timestamp": [2037.6, 2042.24], "text": " what is it that people are willing to pay for? And I suspect that there will always be people"}, {"timestamp": [2042.24, 2045.6], "text": " willing to pay for humans in care professions."}, {"timestamp": [2045.6, 2053.8], "text": " Now, that might change over time, particularly if the economic shift, like if hiring a human"}, {"timestamp": [2053.8, 2058.96], "text": " to do the job costs 10,000 times as much as it costs to have a human do the job, that's"}, {"timestamp": [2058.96, 2060.96], "text": " a pretty steep bill."}, {"timestamp": [2060.96, 2065.72], "text": " But also if the quality of care that machines can render is also a thousand times better"}, {"timestamp": [2065.72, 2071.48], "text": " and safer and more reliable, we might actually see a collapse of that demand."}, {"timestamp": [2071.48, 2077.32], "text": " Not sure, but I do suspect that some people, regardless of how sophisticated robots become,"}, {"timestamp": [2077.32, 2079.24], "text": " will still prefer humans."}, {"timestamp": [2079.24, 2086.36], "text": " Okay, so I kept alluding to medical professions, and this is where... actually I don't know how this is going to be received."}, {"timestamp": [2087.08, 2089.68], "text": " Some of these ideas I actually got from you guys in the comments."}, {"timestamp": [2089.72, 2095.88], "text": " So maybe maybe you guys are already on board but some of these might kind of be a little little bit contentious a little bit spicy."}, {"timestamp": [2096.28, 2101.08], "text": " But let's talk about you know we talked about a whole bunch of jobs that will probably stick around forever."}, {"timestamp": [2102.0, 2107.92], "text": " Now let's talk about jobs that maybe should go away. All right so first some of"}, {"timestamp": [2107.92, 2112.96], "text": " you are I can just hear like cheering and screaming at your screen like yes get rid of the politicians."}, {"timestamp": [2114.4, 2120.72], "text": " There's a few primary reasons to do this. So one remember the the thought experiment here is that"}, {"timestamp": [2120.72, 2129.42], "text": " machines are going to be intellectually morally eth, and creatively superior to humans in all ways. From strictly a structural"}, {"timestamp": [2129.42, 2134.42], "text": " standpoint, if machines get to that point it would probably be unethical to allow"}, {"timestamp": [2134.42, 2138.46], "text": " humans to make decisions that influence other humans just by virtue of the fact"}, {"timestamp": [2138.46, 2141.86], "text": " that the machine can make a better decision and a more robust argument"}, {"timestamp": [2141.86, 2145.4], "text": " that's going to be more fair and more equitable and less biased."}, {"timestamp": [2145.4, 2152.84], "text": " Now, just from performance standards, to me that's enough of a reason to replace politicians"}, {"timestamp": [2152.84, 2157.52], "text": " with machines if they get to that point. There are more reasons than that though,"}, {"timestamp": [2157.52, 2163.0], "text": " not the least of which is conflicts of interest. Politicians often make a lot of money while"}, {"timestamp": [2163.0, 2170.96], "text": " they're in politics, at least here in America, So that's like, hmm, maybe, maybe they don't actually have the best interests"}, {"timestamp": [2170.96, 2176.8], "text": " of their constituents in mind. Whereas if we design AGI correctly, as long as it has"}, {"timestamp": [2176.8, 2181.76], "text": " power or whatever it's trying to optimize for, like it's not going to have the same"}, {"timestamp": [2181.76, 2189.9], "text": " conflicts of interest. Another thing or another aspect of that is dubious motivations. Some politicians want power"}, {"timestamp": [2189.9, 2193.84], "text": " just for the sake of power, which it's like that's maybe not the best reason"}, {"timestamp": [2193.84, 2199.76], "text": " that someone should be given power. Another thing is cognitive biases, as I"}, {"timestamp": [2199.76, 2204.32], "text": " mentioned, prejudice, and worst of all, the most insidious one that people"}, {"timestamp": [2204.32, 2209.52], "text": " don't talk about enough is trauma politics. So this is basically someone with unaddressed"}, {"timestamp": [2209.52, 2214.12], "text": " childhood trauma or PTSD and they're basically seeking power and control and"}, {"timestamp": [2214.12, 2219.64], "text": " influence as a means of self-soothing, whether it's their trauma resulted in"}, {"timestamp": [2219.64, 2225.0], "text": " personality disorders or other kinds of reactionary sensitivities."}, {"timestamp": [2226.16, 2227.48], "text": " Yeah, I mean,"}, {"timestamp": [2228.12, 2232.92], "text": " humans have a basket of flaws that it's like if we can get rid of that and have"}, {"timestamp": [2232.92, 2236.76], "text": " machines that make more equitable, unbiased,"}, {"timestamp": [2236.76, 2240.92], "text": " and fair decisions and that they make better decisions that are more rigorously"}, {"timestamp": [2240.92, 2242.48], "text": " thought through, maybe,"}, {"timestamp": [2242.52, 2246.2], "text": " maybe we should focus on getting rid of politicians in the long run."}, {"timestamp": [2246.2, 2252.22], "text": " Again, this is a pretty high bar and it will take a lot of time to convince people and"}, {"timestamp": [2252.22, 2253.22], "text": " get them on board."}, {"timestamp": [2253.22, 2259.04], "text": " But again, if the track record proves it out over many, many years that machines are just"}, {"timestamp": [2259.04, 2268.28], "text": " better, and here's the thing, is I already know that in diplomatic corps and state departments and governments they're already using chat GPT to help make"}, {"timestamp": [2268.28, 2275.32], "text": " decisions. The AI is already influencing politics. So like it's gonna happen by"}, {"timestamp": [2275.32, 2281.24], "text": " degrees I guess is the point. Right now the AI is the tool but then"}, {"timestamp": [2281.24, 2284.2], "text": " soon we're gonna have semi-autonomous tools and eventually we're gonna have"}, {"timestamp": [2284.2, 2287.28], "text": " fully autonomous tools and then once the tools are fully autonomous,"}, {"timestamp": [2287.28, 2291.24], "text": " it's like, well, why is the human there?"}, {"timestamp": [2291.24, 2296.46], "text": " This one I think is probably going to be pretty contentious for some people, and some people"}, {"timestamp": [2296.46, 2298.08], "text": " are going to be super on board with it."}, {"timestamp": [2298.08, 2303.56], "text": " Like I said, I get a lot of these ideas from the comments, but basically police and soldiers"}, {"timestamp": [2303.56, 2306.12], "text": " have the same flaws as any other humans. We're all humans."}, {"timestamp": [2306.12, 2309.32], "text": " They make mistakes regardless of how well-trained they are."}, {"timestamp": [2309.32, 2313.28], "text": " And also some of them join the police and the military for the wrong reasons."}, {"timestamp": [2313.28, 2318.32], "text": " Because they want power, because they want to feel macho, because they want to harm people."}, {"timestamp": [2318.32, 2321.28], "text": " There are literally people who join the military and join the police"}, {"timestamp": [2321.28, 2325.04], "text": " because they want to have an opportunity to shoot someone."}, {"timestamp": [2325.04, 2332.4], "text": " And yes, in the past, when you want to hire someone who is ready, willing, and able to"}, {"timestamp": [2332.4, 2340.0], "text": " use force to hurt someone else, you actually need that if you're in a very cruel, contentious,"}, {"timestamp": [2340.0, 2346.08], "text": " combative, and barbaric world. I think we should strive to build a less barbaric world.\" And so"}, {"timestamp": [2346.08, 2353.52], "text": " then that says like, okay, well, if you build a robot army that follows the rules of engagement"}, {"timestamp": [2353.52, 2359.44], "text": " to the letter, you could actually really drastically reduce the rate of rape and torture"}, {"timestamp": [2359.44, 2366.7], "text": " and war crimes and other things. Now, the big caveat here is that that is unless the robot army is"}, {"timestamp": [2366.7, 2370.56], "text": " actually explicitly programmed to do those things or allowed to do those"}, {"timestamp": [2370.56, 2374.82], "text": " things, because this is actually the explicit policy of some nations out"}, {"timestamp": [2374.82, 2379.98], "text": " there to deliberately inflict suffering on civilian populations to break their"}, {"timestamp": [2379.98, 2384.86], "text": " spirit. So this is something that it's like it could go either way, but at least"}, {"timestamp": [2384.86, 2389.22], "text": " if you remove the human aspect of it where some humans do it for the wrong"}, {"timestamp": [2389.22, 2393.74], "text": " reasons, then it's up to political decisions. But again, if we have robot"}, {"timestamp": [2393.74, 2397.5], "text": " politicians who don't really care about inflicting human suffering, they're not"}, {"timestamp": [2397.5, 2400.82], "text": " going to program the robot army to inflict suffering. And ideally we don't"}, {"timestamp": [2400.82, 2406.64], "text": " have it all anyways, because the idea is like, if you can figure it all out in simulation"}, {"timestamp": [2406.64, 2408.88], "text": " and you know what the other side is capable of"}, {"timestamp": [2408.88, 2410.2], "text": " and so on and so forth,"}, {"timestamp": [2410.2, 2412.68], "text": " it should ideally never come to force anyways."}, {"timestamp": [2413.56, 2417.76], "text": " This is a pretty strongly held personal opinion."}, {"timestamp": [2417.76, 2420.56], "text": " So I'll be curious to see how people react to this"}, {"timestamp": [2420.56, 2421.38], "text": " in the long run."}, {"timestamp": [2421.38, 2423.16], "text": " And remember, the assumption that we're making"}, {"timestamp": [2423.16, 2426.08], "text": " is that robots will be superior to humans in all ways"}, {"timestamp": [2426.96, 2429.96], "text": " and that AGI will be intellectually, creatively,"}, {"timestamp": [2429.96, 2433.1], "text": " morally, and ethically superior to humans as well,"}, {"timestamp": [2433.1, 2435.76], "text": " as that evidence is already emerging."}, {"timestamp": [2435.76, 2437.28], "text": " Transportation."}, {"timestamp": [2437.28, 2441.84], "text": " So again, if machines have a proven track record"}, {"timestamp": [2441.84, 2448.96], "text": " that means that they are safer and more reliable than humans, it would probably be unethical to allow humans to drive and to fly."}, {"timestamp": [2450.0, 2456.0], "text": " And we all have lots and lots of experiences of highly dubious drivers who probably shouldn't be"}, {"timestamp": [2456.0, 2465.0], "text": " on the road. You know, I think that I for one really look forward to fully autonomous,"}, {"timestamp": [2466.52, 2469.3], "text": " like level five self-driving cars."}, {"timestamp": [2469.3, 2470.68], "text": " Because when we get to that,"}, {"timestamp": [2470.68, 2474.24], "text": " one driving is gonna be a lot safer for everyone."}, {"timestamp": [2474.24, 2475.68], "text": " It's also gonna be a lot more accessible"}, {"timestamp": [2475.68, 2478.52], "text": " because it's gonna super drive down the cost of driving,"}, {"timestamp": [2479.96, 2483.48], "text": " which is gonna open up the world for a lot of people"}, {"timestamp": [2483.48, 2485.96], "text": " who either can't afford to drive"}, {"timestamp": [2485.96, 2488.92], "text": " or are too infirm to drive on their own or whatever."}, {"timestamp": [2488.92, 2491.48], "text": " Because physical personal mobility"}, {"timestamp": [2491.48, 2494.54], "text": " is actually a really big component of individual liberty."}, {"timestamp": [2494.54, 2497.12], "text": " Anyways, that's a whole other can of worms."}, {"timestamp": [2497.12, 2499.58], "text": " But point being is that in this case"}, {"timestamp": [2499.58, 2502.08], "text": " where we're imagining that machines are far superior"}, {"timestamp": [2502.08, 2504.48], "text": " to humans in pretty much every way,"}, {"timestamp": [2504.48, 2507.48], "text": " it would probably be illegal to allow a human to drive,"}, {"timestamp": [2507.48, 2511.16], "text": " which would then materially put other humans in danger."}, {"timestamp": [2511.16, 2516.96], "text": " Hazardous jobs is another thing, and I feel like this is pretty uncontroversial."}, {"timestamp": [2516.96, 2521.36], "text": " Basically, just imagine this. There's a robot firefighter"}, {"timestamp": [2521.36, 2526.4], "text": " that it doesn't matter if it gets burnt to a crisp because it's programmed"}, {"timestamp": [2526.4, 2530.96], "text": " not to have a sense of self-preservation, but it's also faster, stronger, and has better"}, {"timestamp": [2530.96, 2536.12], "text": " reflexes than a real human firefighter, which one do you want pulling you out of a burning"}, {"timestamp": [2536.12, 2537.12], "text": " building?"}, {"timestamp": [2537.12, 2540.46], "text": " The answer seems pretty obvious to me."}, {"timestamp": [2540.46, 2544.36], "text": " This is demonstrated in all kinds of video games and TV."}, {"timestamp": [2544.36, 2547.52], "text": " Of course, my favorite example is Commander Data"}, {"timestamp": [2547.52, 2548.76], "text": " from Star Trek."}, {"timestamp": [2548.76, 2551.68], "text": " But this was also in iRobot, where the robots"}, {"timestamp": [2551.68, 2554.96], "text": " saw an accident happen, and they immediately"}, {"timestamp": [2554.96, 2558.88], "text": " jumped into the water to pull people out of the car."}, {"timestamp": [2558.88, 2560.92], "text": " And Will Smith, of course, in that movie,"}, {"timestamp": [2560.92, 2563.84], "text": " he was bent out of shape because the robot saved him and not"}, {"timestamp": [2563.84, 2564.92], "text": " the little girl."}, {"timestamp": [2564.92, 2565.04], "text": " But if it was only humans, he would have just died too. in that movie he was bent out of shape because the robot saved him and not the little girl,"}, {"timestamp": [2565.04, 2567.72], "text": " but if it was only humans he would have just died too."}, {"timestamp": [2567.72, 2568.72], "text": " Right?"}, {"timestamp": [2568.72, 2571.3], "text": " So that's, I mean, that's survivor's guilt, which is, that's his own problem."}, {"timestamp": [2571.3, 2577.06], "text": " But point being is that for any kind of hazardous job, I think that it would probably be unethical"}, {"timestamp": [2577.06, 2590.64], "text": " to allow humans to do those jobs if robots can do them better and safer and so on. Medicine. So this is one that is probably going to be pretty controversial. But again,"}, {"timestamp": [2591.36, 2598.24], "text": " imagine that computers and machines and AGI and robots have a better track record than humans."}, {"timestamp": [2599.28, 2608.08], "text": " Even if you prefer a human doctor, in the case where machines are better than human doctors in all ways,"}, {"timestamp": [2608.08, 2611.36], "text": " I think it would probably be illegal for humans to practice medicine."}, {"timestamp": [2612.72, 2618.16], "text": " And I remember talking about this on Reddit a couple years ago when I was learning to use"}, {"timestamp": [2618.16, 2623.44], "text": " chat GPT-3 and I pointed out to someone who was learning to be a radiologist or something,"}, {"timestamp": [2623.44, 2627.44], "text": " I was like, hey, like there's a tool here that can already do"}, {"timestamp": [2627.44, 2630.84], "text": " all the things that you're doing and it's faster."}, {"timestamp": [2630.84, 2634.8], "text": " And the person just completely went ballistic,"}, {"timestamp": [2634.8, 2637.1], "text": " rattling off about like, it would be impossible"}, {"timestamp": [2637.1, 2640.84], "text": " for a machine to ever understand like,"}, {"timestamp": [2640.84, 2642.78], "text": " what X, Y, and Z things mean."}, {"timestamp": [2642.78, 2644.32], "text": " And he just rattled off a bunch of stuff."}, {"timestamp": [2644.32, 2646.04], "text": " And it's like, yeah, you just plug all that"}, {"timestamp": [2646.04, 2647.2], "text": " into chat GPT right now,"}, {"timestamp": [2647.2, 2649.08], "text": " and it'll tell you exactly what it means."}, {"timestamp": [2649.08, 2652.72], "text": " And the evidence is building."}, {"timestamp": [2653.88, 2655.4], "text": " I love this quotation."}, {"timestamp": [2655.4, 2656.74], "text": " Whoops, come back."}, {"timestamp": [2656.74, 2660.4], "text": " I'm stunned to say, it's better than many doctors"}, {"timestamp": [2660.4, 2661.22], "text": " I've observed."}, {"timestamp": [2661.22, 2665.48], "text": " This was Dr. Isaac Kohane when he was talking about GPT-4 and this"}, {"timestamp": [2665.48, 2671.8], "text": " is a computer scientist and physician from Harvard, right? So this is like"}, {"timestamp": [2671.8, 2675.96], "text": " cream-of-the-crop already saying that like yeah this this machine is already"}, {"timestamp": [2675.96, 2681.96], "text": " better than many actual doctors. So I suspect that that medical professions"}, {"timestamp": [2681.96, 2688.92], "text": " are gonna go the way of the dinosaurs just by virtue of the fact that humans will just not be able to compete, not to mention the fact"}, {"timestamp": [2688.92, 2692.84], "text": " that human doctors are ludicrously expensive. So this is what I mean when I"}, {"timestamp": [2692.84, 2697.52], "text": " say like medical care could go to five dollars a year because if you if you get"}, {"timestamp": [2697.52, 2702.84], "text": " rid of the need for most hospitals due to preventive care and regenerative"}, {"timestamp": [2702.84, 2706.44], "text": " medicine, you get rid of the need for nurses and doctors"}, {"timestamp": [2706.44, 2709.4], "text": " and phlebotomists because you have superior robots,"}, {"timestamp": [2709.4, 2712.04], "text": " then it's like medical care just is an outpatient thing"}, {"timestamp": [2712.04, 2716.26], "text": " that you go to the pharmacy once a year"}, {"timestamp": [2716.26, 2718.8], "text": " and they'll take a blood sample and say,"}, {"timestamp": [2718.8, 2722.36], "text": " okay, here's your medicines for the year, go home, right?"}, {"timestamp": [2722.36, 2725.1], "text": " And oh, and you won't need to be on medicines chronically"}, {"timestamp": [2725.1, 2728.84], "text": " because they're gonna actually fix the underlying problem and cure you and so"}, {"timestamp": [2728.84, 2732.08], "text": " then it's like, oh here's an injection to fix this problem that you have, you're"}, {"timestamp": [2732.08, 2735.84], "text": " good to go for the next 10 years. That's kind of how I think medicine is gonna go"}, {"timestamp": [2735.84, 2741.36], "text": " and so this somewhat maybe controversial opinion is that eventually I think that"}, {"timestamp": [2741.36, 2750.52], "text": " we should probably actively try and get rid of medical professions on the human scale. Alright, so here's some conclusions."}, {"timestamp": [2750.52, 2755.44], "text": " Let's try and pry that Overton window open just a little bit more."}, {"timestamp": [2755.44, 2759.2], "text": " Automation resistant occupations are those that humans will always be willing"}, {"timestamp": [2759.2, 2763.64], "text": " to pay for regardless of the machine's capacity and capability. So again, there's"}, {"timestamp": [2763.64, 2765.64], "text": " many reasons for that."}, {"timestamp": [2765.64, 2768.16], "text": " The intangible value, the emotional resonance,"}, {"timestamp": [2768.16, 2769.4], "text": " the connections."}, {"timestamp": [2769.4, 2771.1], "text": " Now the jobs that should go away"}, {"timestamp": [2771.1, 2773.12], "text": " are those that concern and potentially infringe"}, {"timestamp": [2773.12, 2775.18], "text": " upon the safety and rights of other humans."}, {"timestamp": [2775.18, 2777.14], "text": " Because again, all humans are flawed,"}, {"timestamp": [2777.14, 2778.32], "text": " all humans are biased,"}, {"timestamp": [2778.32, 2780.48], "text": " and if machines can demonstrate that they are less flawed"}, {"timestamp": [2780.48, 2782.56], "text": " and less biased than humans,"}, {"timestamp": [2782.56, 2785.4], "text": " then they will have a better track record in terms of"}, {"timestamp": [2785.4, 2788.48], "text": " safety and respecting human rights."}, {"timestamp": [2788.48, 2795.32], "text": " And like, I just think that like in those cases, it would not be ethical to allow humans"}, {"timestamp": [2795.32, 2800.68], "text": " into jobs that could infringe on the safety and rights of other humans."}, {"timestamp": [2800.68, 2802.64], "text": " And I don't know if that's controversial."}, {"timestamp": [2802.64, 2804.04], "text": " Let me know what you guys think in the comments."}, {"timestamp": [2804.04, 2805.04], "text": " You always do anyways."}, {"timestamp": [2805.04, 2807.4], "text": " So, yeah, I hope you enjoyed."}, {"timestamp": [2807.4, 2808.4], "text": " Thanks for watching."}, {"timestamp": [2808.4, 2808.76], "text": " Cheers."}, {"timestamp": [2803.92, 2806.42], "text": " And I don't know if that's controversial."}, {"timestamp": [2806.42, 2807.92], "text": " Let me know what you guys think in the comments."}, {"timestamp": [2807.92, 2809.12], "text": " You always do anyways."}, {"timestamp": [2809.12, 2811.32], "text": " So yeah, I hope you enjoyed."}, {"timestamp": [2811.32, 2812.22], "text": " Thanks for watching."}, {"timestamp": [2812.22, 2812.76], "text": " Cheers."}]}