{"text": " All right, cool. We are recording, so just a quick introduction. These are some of the guys from the Heuristic Imperatives Discord, the research group. They're building a cognitive architecture. So I'll let you guys kind of, if you want to introduce yourselves, not required, but yeah, let's jump in and just kind of talk about where we're at in terms of cognitive architecture and some of the stuff that you guys have been working on. Yeah, sure. I'm Database. I'm on the Cognitive AI channel too. Y'all see me all of the time. I'm the one who's always arguing with everybody. Ansel, if you wanna. Yeah, well, I'm Ansel, I'm on the same Discord. I'm a computer science engineer, and I guess I'm really fascinated by this subject, so I just had to go and dive in. Excellent, excellent. And so, give us a tiny bit of background actually, because you guys, or database, I remember your story. You jumped into cognitive architecture, what, like just a few weeks ago, right? Yeah, basically. So, it was about the time that AutoGPT went viral. I was like, this is really cool. I don't want to have to pay for it. So, I started trying to convert it to a local model, which we ran into some issues with that. But that's, you know, before then I hadn't really done a whole lot with programming or Python at all. And so most of what I've learned in the past three weeks now, I guess, has been primarily through chat GPT. Nice. Excellent. Yep, that's the case for many people. And Ansel, you've been a developer or an engineer for a little bit longer, correct? Yes, yes. Right, right. I've been an engineer already for like three years. I have years of experience mostly in C Sharp. That's like my main language. So yeah, I got into this project like three weeks ago with data and same with Python. So basically, I've just been converting everything I know from C sharp to Python. And it's been a great experience learning a lot of things and it's pretty cool. Excellent. So, you know, obviously auto GPT, baby AGI, chaos GPT, all that is relatively new. GPT-4 just came out, you know, what, four or five weeks ago. And so, like, walk us through the process, because I've had the privilege of kind of watching you guys figure stuff out from the beginning. But can you tell us a little bit about, like, where you got started, what were the problems that you've overcome, and what problems you're working on now? you've overcome and what problems you're working on now? Yeah, the biggest problem that we ran into to start with was just finding a host for a language model that had a working API. We started with Llama CPP, but it's Python API didn't work on x64 Windows for whatever reason. There were a couple of others that we worked with, and then eventually we came around to UbaBuga. They've got the API fixed now, we have people using it. Right. The real advantage of UbaBuga is that it gives us, it lets us host multiple language models. So we're not just stuck with llama or alpaca. The new Vicuna model is working in there. It has some of the science and coding language models available to it as well. We haven't done a whole lot of testing on that. We've switched over to OpenAI on the 3.5 model just to rapidly iterate on the development process and save some resources at home. And by the time we did that was mostly because we were stuck with the UbaBuga API and OpenAI was working so we just like if we want to develop we need to switch fast to that. Gotcha. And then the auto GPT code base was, let's just say it was not ideal. I spent an entire day trying to fix that. Yeah. So we ended up moving over to Baby AGI. We got Baby working on OpenAI and UbaBuga temporarily. And then UbaBuga broke their API for like two weeks, which was wild. But they've got it back working now. The people who are using our new project, some of them are using the UbaBuga API and running it against Vicuna, which was the original goal. So it works, we're trying to keep it stable as best we can for those people, and we're super excited, honestly, that all of this is coming together. Excellent. Data, Database database and Ansel, you guys have been working super hard on what you call the salience module. Can you talk us through that a little bit? Because that is a pretty fascinating set of problems. Right, so I have it loaded up right here. As you can see, it's just a simple Python script. One of the main reasons we decided to work on our own project was because AutoGPT was not made to be extensively modified. I spent an entire day just trying to modify it myself, and I had a pretty bad time. I'm not going to lie. So we decided to just take the minimum viable version there was and start our own architecture. So we created this little salience loop here. We basically start by instantiating all the agents that we have. And then we start looping through it, loading a task list, and everything. So let me just run it for you first. Let's see, Python. We can edit this out in post, right? We can edit this out in post, yeah. The logic loop that we built. OK, cool. Yeah, basically, we built this entire thing in one Saturday. Okay. Got this pulled up. Yeah. I'm watching it. Can you zoom in a little bit and tell us a little bit about what this diagram is? There we go. Right. So this is the logic loop. One of the really helpful, or not helpful, but one of the things that we've kind of designed from the get-go on this system was to try to make it easy to build agents and logic loops in a very short fashion so that you can iterate quickly, as opposed to, you know, if you wanted to change the logic that OpenAI uses, or even baby AGI, really, you really have to understand the entire code base that they're using and how different things interact. We're trying to build a streamlined flow where you can just write a logic loop for the actual interaction where it takes the prompt and then decides where to store it and you chain them together. So in a similar fashion to the way that AutoGPT works, right now in the salience agent, we're working with a predefined task list. Baby AGI generates the task list automatically, and later we're going to do a hybrid where we integrate both. But for now, we're just working with a predefined task list. So we sort the task list because every time you make an edit to an item in ChromaDB, it falls to the end of the table or collection is what they're called in vector databases. But we sort the list, we filter it during the sort, we filter for any completed tasks and pass the current task to the job agent. So what the job agent does is it searches the vector database or the results database for any results related to the current task, summarizes those, passes them down to the job agent. The job agent then passes the context, so that's your current task, the related results from the summary, and a couple of other metadata related things. And it runs the execute process, which is right now identical to what Baby was using. But we've broken the prompt for that out into a easily editable JSON file that so that you can change that prompt on the fly. So the execute agent pulls the prompt from the JSON, runs it, and then passes the results back to the job agent. We don't have frustration implemented yet, but that's going to be based on the write-up that you did on Reddit the other day. Yeah. To kind of check things out. And then once it passes frustration or skips frustration, Once it passes frustration or skips frustration, then we pass those results back to the results database and it goes to the analyst agent. So, the analyst agent is here. Do I have everything? There we go. The analyst agent is here. And it's a little bit more complex, actually, even though it looks simpler than that loopy stuff. We're actually taking multiple items, or more items, and adding them to the prompt. It's basically as, go ahead. Let me pause you for a second and ask, how much of this architecture did you borrow from other projects, and how much of this is stuff that you guys have have created on your own? So right now, the only thing that borrowed is the execution age. And it's right now, essentially just the prompt. So we what we did was we took, we took Baby AGI's architecture and broke it out into lots of different pieces. And then we changed all of those pieces completely and re-imported them, or re-integrated them as classes in multiple agents. But originally, Baby-AGI was only one script, and it was less than 200 lines. That was the entire purpose of Baby-AGI. We're over 3,000 lines on this code repo now. Yeah, we're averaging about a thousand. No, stop counting. Stop counting. So you've taken kind of the initial idea and really you've gone 10x on it. You've made it more modular. You've added a few new ideas, new loops, one of the modules that you haven't integrated yet. I think earlier you said you haven't seen a need for the frustration signal yet. But yes. We haven't gotten into very complex tasks yet, so maybe that's why we haven't needed frustration yet, but I'm guessing we are going to need it at some point. Davey Absolutely. Sean That's fair. Davey Absolutely. Sean For any viewers who aren't familiar with the write-up that I did on frustration as a signal, basically it is you keep a ratio, the simplest version is you keep a ratio of successes to failures, and if the failure rate goes up, then that tells you to maybe switch to a smarter model, or you can back up and try a different approach, or eventually you can just stop and ask for help. There's any number of things that you can do with the frustration signal, but basically this is, frustration is a key component of cognitive control, which is how humans say, hey, I expected to be making more forward progress, and I'm not, and so if you're not making the progress that you expect, then it's time to either change your approach, ask for help, or change something. So thanks for giving some context. Did you wanna go ahead and jump into your analyst agent? Yeah, yeah, absolutely. So the analyst agent is a little bit more complex because we're taking the results, the most recent results and the current test, plus we're getting the summary from this agent, the job agent or salience agent as well, and we're feeding it feeding it the the a little bit more context on the task. We're asking the the the GBT agent to decide is this job completed yet and if it's you know if not then what we can do is send if it's if it's reached the frustration level, we can send that task back to the task creation agent to generate subtasks potentially or new tasks. And then we're also this weekend going to set up sending feedback back into the agent. And you'll see what that feedback the feedback I think is going to really change the game on getting fewer runs to complete a particular task. And then of course if it does complete it, then we update the task with the task scheduler and tell it to move on to the next task. Did you get the terminal resize canceled? I'm already sharing my screen again, yeah. I could not figure out how to get it resized, so what I actually did was resize your monitor display. Yeah. All right. I actually increased the scale of it. And we just zoom in. All right, Ansel, you ready? Database, were you sufficiently? Yeah, yeah, that's where we're at right now. Okay, cool. We'll talk about all this stuff in the future. So Ansel, give us a little bit of a background. What is it that you're about to demonstrate for us? Well, I'm about to run the salience loop. As you can see, it's asking me a few things. It's asking me if I wanna start from where it left off, basically restore the previous state, and if I wanna allow auto mode or manual mode, for now, let's just go with manual mode. And it's starting to initialize the agents here. If you want to explain, go ahead, Data. Well, I was going to say, the restore from previous state is, to my knowledge, not something that's present in any other autonomous uh, any other autonomous AI system out there yet. So, really cool stuff. Yeah. So, tell us a little bit about that feature, because it sounds, sounds valuable. Like you can, uh, you're in the middle of cooking dinner and someone knocks on the door and you come back and remember where you were, right? Right. Well, you could always just leave it sitting there because the system has this, as you can see, it has a auto mode or a manual mode. Since we set manual mode, every loop it's going to stop and ask us for feedback. Alright. But if you have to turn your computer off because the FBI show up, then when you power it back up, all of the task statuses and results are stored persistently in ChromaDB. So you never lose any data unless you tell it you want, you don't want to restore from a previous state. That makes sense. You want to go ahead, go ahead Angel. So in this case I basically wiped this memory, it doesn't know anything. I'm just gonna say yes, just to keep it simple for now. And it started to run the salience agent, And a salience agent is going to call the execution agent to start running the task list. For now, the task lists are defined from our persona JSON. So what we wanted to do was separate the code from the prompts. So whoever wants to develop agents can simply look at two things, the code of the agent, what it's supposed to do logically, and they can alter the prompts on the JSON file. So I'll show you the JSON file in a second. Right now, the first task is, well, to develop a task list to achieve a goal, which in this case, I don't believe I'm printing it here. Yes, it's supposed to create a program for an AI to search the internet. So it did the first task. Let's just go ahead and let it run again. It's going for the second task. Right now, it's only showing you the info, like what you really want to see it's doing. You're not seeing all the processing behind. There's also a debug mode you can do that starts showing the prompts, what's going in, what's in the database. I can run another loop later with that turned on to show you what it's doing internally. And it'll just keep going. Apparently, it's reflected on the task. So yeah, let's just leave it in auto mode. I can change it to auto mode. And it's now in auto mode. You can see it says you can press Escape to return to auto mode. I can change it to auto mode. And it's now in auto mode. You can see it says you can press Escape to return to auto mode. So at any point in the code, if I press Escape, it's just going to say, switching back to auto mode. And it'll stop and ask me for feedback again. CHANCELLOR MOORE Excellent. VICTOR BROWN At this point, I don't know if it's going to say if it completed the task or not. Because the last task is to act out the task list it made. But it very much depends on the status agent, if it decides it did it or not. In this case, it says it completed it. And it also, the good thing is it provides a reasoning for why it decided it's completed or not. So you can also get more information as to why it took that decision and help you do better prompt engineering so you can change the prompt easier. So let's pause for a second because I think that there's a tremendous amount of significance here. So walk us through the steps. From scratch, it had what appeared to be a metacognitive step where it said, okay, what am I doing? And then it designed its own task list, followed through the task list, and then also evaluated its own performance to know when it had finished. Correct? Okay. Yes. So here it's basically where it starts. Let's see. Yep. At the beginning. So the first thing it does is start to develop a task list and it's searching for results in its memory. Since it's white, it says there is no results. It sends that results to summary, since no results exist yet. It just says no previous actions have been taken. Because this is fed to, I don't remember if it's fed to the execution agent or if it's fed to the status agent. One of those two. Both of them, actually. Oh, both of them, though. Both of them, actually. Oh, both of them. OK. So that the agents at least know what step of the process they are, or any other actions they've taken before. It's basically like a very primitive sort of memory as to, OK, what have I done before, right? Right. And basically, we send all of that information to the agent. It runs, and here's the result we get from the LLM, which is, well, it did create a task list. So at that point, we send those results to the status agent, and it's going to check if that task has been completed. In this case, it says, yes, the task has been completed, and it provides a reasoning right here for why it thinks it's done so. And at that point, we go back into the loop. So it's going to ask me again, do you want to continue or not? Go ahead, Data. Yeah, so I want to come back to the status agent. So not only are we returning the status agent. Not only are we returning the status of whether or not it's completed, we're also providing feedback. If you get a status that's not completed, and this isn't in yet, but this should be relatively simple to incorporate. One of the things that we can do is provide additional feedback to the execution agent the next time it runs. In this situation, what we would want to do to help automate this is pass it the feedback from the status agent. The status agent is going to act as a project manager, where it has all of its little dev minions that go out and do their things and then they come back with their results and they present a summarized result of some kind. Now, that execution agent needs to be expanded upon so that we can get web searching for research and code execution to or to do code testing and stuff. We may even have a code QA agent separately, but we can take that feedback from the project manager status agent and push it back in if the agent fails so that it can do better the next time and it's not always running into the same results. Yeah. So let's unpack that real quick. I think we should switch over to the personas default. I've got this pulled up now. Hey, Data, before we proceed, because what you're talking about is cognitive neuroscience, and a lot of people are going to be lost. The status agent, that's the supervisor, right? That kind of sits above the other things and it dispatches, let me make sure I got it right, it dispatches the execution agent says, hey, this is your set of tasks to go do. And then that uses the salience loop in order to loop through and ensure that that task gets completed. Is that the correct stack? It's the salience loop that calls the execution agent and status agent separately. Okay. So the salience is what binds it together. Right, exactly. The salience loop is what binds them together, correct. Okay, and so by iterating on that, you are checking multiple times for whether you whether you're being successful the feedback that you're getting and it can because it's iterative it can adapt its strategy as it goes. of talking to itself in this sense, so it's really more, it's less like corporate developer type of environment and more just like internal monologue. Like, if you were, you know, building a, if you were building a raised garden bed, for example, you know, you're like, okay, first thing I need to do is take measurements, and then I want to cut take measurements and then I want to cut wood and then I want to nail wood together. Finally we put it in place and then we fill it with... You kind of like outline that and then, you know, as you're cutting wood, like, okay, is this actually going to work? Are these going to fit together? Is this nail going to stick through? So, it's... we're trying to replicate that internal monologue. Excellent. Excellent. So it shouldn't theoretically take any jobs from any developers anytime soon. At least not any more than ChatGPT is already a good read of. Sure. Sure. Right. Right. But the point is that you have a self-reflection and kind of a set of metacognitive functions that are evaluating what it's doing and it's thinking through what it's doing every step of the way iteratively. All right, cool. That's right. So take it away. I think you said you wanted to move over to personas or something else? Yeah. So, well, you were asking about how these all interconnect. So I've got the personason file pulled up here. The primary goal is for anybody who's just picking the software up that doesn't want to learn how to program, the most that they're ever going to have to touch if they just use the pre-existing agents is this file and the main loop. So this file is where we set down our prompt. So you know, the system prompt is just like the system prompt in OpenAI, and then these other prompts go in as user prompts. So, we're taking, kind of like the way that you send chat history into chat GPT-4 when you're using a Homebot. In the same way, we're using these variables here to inject data from other agents into this bot in a human readable format. And then every bot we can set whether it's going to use GPT 3.5 or 3.4. The plan is to also be able to leverage local models if you're running UBA or you know you we can we eventually plan to incorporate hugging face and you know maybe maybe at some point Lang, we'll see. But each agent gets its own parameters for sending to the language model. And we can't minimize here, but each agent has its prompt exposed without any code. Then of course, the main loop is so simple. Where is salience? So here's salience. So if you ignore the beginning section here, you can see that our entire loop is five lines of code, plus comments. And, you know, it's super simple for anybody to kind of go in and build this, you know, this logic loop. One issue right now is that the, where are you? So, this salient agent run kind of has agents embedded in it, so you can't modify it, but you can also just use those agents outright. So, our mainpy function, this is actually, this is actually the architecture of baby AGI that's been rebuilt into our system. So you can, you know, you have a really simple starting point. Right. And then when you go into the agents, like that's getting a little bit more complex, but you should be able to also build agents without having to dig into the rest of the code base. The loop of the agent could all be self-contained, and most of these functions are already templated out for you. So it's almost plug and play. We're not there yet, but we're slowly organizing things. So let's talk about this architecture real quick because you've got several layers of nested loops. You've got a modular and configurable architecture. And like you said, the goal is to get to plug and play, and you're almost there. So talk us through a little bit about how you came to some of these architectural decisions, because for someone who's only been coding for three or four weeks, you've kind of unpacked a lot of really important concepts and development. And I know that you've had Ansel to help you out. So, maybe you can't take full credit and then chat GPT as well. You guys have ... I see you in chat all day, every day some days. Talk us through how you came to some of these ideas and what is the overall status of how close are you to having something that is it looks like semi-autonomous or fully autonomous. What are the missing steps and who do you want to get in touch with you and so on and so forth? Where do you need help? Well, you know, if Bill Gates wants to give me a call, I will totally take his call. I only charge $2,000 an hour, which is pretty cheap. Considering the loop is there. The loop is already there, at least when you compare it to auto GPT, which kind of has a functioning loop too. I haven't looked at their stuff since I started this project. Even before I went, like we had ChaosGPT was looping at least. So, it loops. So, now what we're doing is expanding functionality, and we're expanding compatibility with these other systems. We've got OpenAI working. We've got UBA working, which should work with any other language model. Chroma is done manually, so it doesn't rely on Lang chain. But if we incorporated Lang chain, that would open up functionality in a much broader capacity. That's right. Yeah, I was just about to ask for extensibility, for instance, can this code, can it talk to APIs? Yeah, go for just about to ask for extensibility, for instance, like, you know, can this output code, can it talk to APIs? Yeah, go for it, Ansel. Now that you mention extensibility, that was the main reason for developing this, because like I mentioned before, I tried to mess with auto GPT to get it to do something I wanted just for testing purposes, and I wasted my time trying to modify it. Because it's, I don't want to say it like the developers didn't pay attention to it, but it's just the structure of it is not user-friendly at all. So when we went into this, the main goal was to make it extensible, organized, and very easy to know what's going on where. In their defense, I don't think that they were writing auto GPT for other people to come in and mess with it and make it do what they wanted. From the ground up, we've been building this so that other people can come in behind us. And really what we need more than anything is for people to come in and build new agents. For example, this execution agent right here, the execution agent needs to be expanded in a much more broad fashion. The and then we need to work on the task generation. Right. So Baby relied heavily on task generation to determine if it had completed a step. And that ended up with it re-doing a lot of work, which we didn't like. But I think that that could be solved with, And that ended up with it reword, redoing a lot of work which we didn't like, but I think that that could be solved with. With a with. Set in stone primary goals at and allowing it to generate sub goals. So if somebody wants to take a crack at task generation, we actually have a kind of prototype outline, although we haven't actually done any work on this stage yet. Those are the two things that we have going forward to improve its capacity, is building out execution agent, rebuilding this task generation, and then a few odds and ends here and there just to make it run a little bit more smoothly. I find that the biggest gains are usually from prompt engineering though. And sometimes even small changes to the text in the persona. Wording is everything. Yeah. Yeah. Wording is everything. Like let's see if I can find. Yeah, so here's the status agent, and it just does not. It's too long. But yeah. Too complicated. We spent a good hour working on the prompt for status agent, and ultimately, we still ended up having to switch over to GPT-4 for this. So yeah, the running version that we have right now is using two separate language models. So it can handle multiple language models. So you've got a lot of the extensibility and configurability figured out. So you mentioned earlier that you're getting close to making it plug and play, and like you said, all the different agents are configurable just via JSON, and you're getting close to adding some more extensible things. So how do people collaborate with you? Do you just all go through GitHub? If anyone wants to jump in, what's the best way for them to get in touch with you guys? We have a project set up in the community project section of the Cognitive AI Discord, specifically for agents. But if there's other stuff that you think that that you can contribute to, for example, we'd love to have a graphical interface. Right, any UI that's similar to Langflow. Uhm, to to make this even lower code for people. Uhm? And then you know, of course the you know, of course, the, you know, the, if there's a new model that comes out or a new host somewhere and they have their own API that isn't OpenAI compatible, writing API interfaces for that. So, for example, the current V2 version of of the UbaBuga API was not actually written by us. This was written by... that's so strange that he's not listed as a contributor here. I think his name was Max, though. It was Max something. But he wrote- I don't remember, but he fixed it. Yeah. Oh, Michco. In Michco. So he did get credit for this one, but he rewrote the interface for the UbaBuga API, and people are out there using this and it's working. You can see the old codes listed here. Right, because another thing you can do is also host your local model on a cloud server and use the API to connect to it, And you can just run the interface on your phone or web browser or whatever. Interesting. You can see the endpoint code is listed here as a variable. And what we'll do later is come in and set this as configurable within the INI file. Oh, yeah, that's something else I should just touch on briefly. Things like determining which language model you're using, which database you wanna use, your embeddings, function that you're using, all of that is configurable here in the config.ini file as well. We really tried to get as much of the configuration as we could out of the code and into files that people are gonna find useful. Wonderful. And be able to assess. So what's next? I know you guys have outlined a lot of open problems and some things that you need help with and I think there's quite a few people that are expressing some interest. So where do you guys wanna take this project? Like what, you know, given a month or six months or if you have 20 people jump in, what do you want it to be able to do? This weekend, we are taking it to a hackathon. We don't know what the objective is yet, but our objective is to win the hackathon with this out of left field AGI framework that nobody has ever seen before. There you go. But beyond that, I'd like to see this just used more broadly. see this just used more broadly. You know, this is all this is all in a what about there it is I missed. So this is all in the GNU general public license just like Linux. So anybody can take this and use it for commercial purposes with restrictions. And me personally, I would love to, once we get this model pounded out and set in stone, I would love to just build bespoke AI cognitive systems for companies on either a direct, direct to market kind of solution, or even in a research capacity. I've already built some agents, or at least one agent, and then made some modifications as well to work on the heuristic imperatives project that you've got going, Dave. And I really want to be this. I want this to be an engine for your project so that you can iterate quickly and you don't get hung up in the details of working manually or having to write your own code for every single little thing that you do. We can just have an agent and plug those agents in, spit data at it, and see what comes out. There you go. Spin up a whole fleet of them. Yeah, for me, the ultimate goal is basically empowerment. Human language has given us the ability to do everything we've done up until this point. And we've basically given that ability to machines now. And with this kind of architecture, we can give that to everybody. As long as they have a model to run, they could have some kind of agent working for them. So it might sound science fiction or outlandish, but it's basically like constructing your own Jarvis, right? That's the goal. That's the goal. That's the goal. Yeah, yeah, I do not want to be the person who develops the the the next Raven though. Let me just say that like I'm I'm being part of it, but the a autonomous assistant is going to be a lot of work. Oh definitely. That's why I said the ultimate goal. a autonomous assistant is going to be a lot of work. Oh, definitely. That's why I said the ultimate goal. Yeah, just looking at what we've done already, like a better Siri, for example, is a mini person project, not just two guys in a garage. Yeah. Yeah. person project not just two guys in a garage yeah yeah so this is like the very first you know 2022 there were very few of us even talking about cognitive architecture 2023 hits and suddenly like everyone's a cognitive architect but you guys are definitely like lunging ahead forward, which is just incredible to see. So thanks for sharing your work so far. And I know that you guys have a lot of work that you're working on. It's getting close to being semi-autonomous. It doesn't quite come up with its own objectives, but it can autonomously work through a lot of... It's coming. It's coming, it's coming. But it can think through open-ended objectives that you give it, which is really incredible. So any final thoughts from you guys or anyone else before we wrap up tonight's recording? Yeah, well, if you had told me in December that I would be diving into a project on GitHub about cognitive architecture, I would have spat my beer at you. So everything is changing really fast, it's getting really silly, it is impossible to keep up, and it's exciting, and it's is impossible to keep up and it's exciting and it's just thrilling to be working on this. Yeah, absolutely. Yeah, impossibly keep up is definitely the situation right now. Even with the past week or so where AI news has been relatively slow. There haven't been a whole lot of interviews here lately. I've still got dozens of tabs open of AI stuff that I just haven't been able to read yet. think that a lot of people are getting way more concerned about artificial intelligence than they need to be. We still need to be concerned. We need to be working on these things. But we're not quite in runaway AI yet. I hate to disagree with you, Dave, but if we told AI to build better AI, that would be like telling you to do brain surgery on yourself. We're not quite that smart yet. So we don't need to bomb the data centers? No, but we should definitely have bombs in the data centers, just in case. Just in case, okay. And local backups for your shows or anything you want to watch after the apocalypse. So yes. There you go. I'll just etch it out on clay tablets. Alright gang, thanks for everything and definitely keep up the good work. And yeah, I hope that you get some more folks reaching out to you. We will of course have ongoing updates, maybe not weekly, we'll see. But you know, we're doing more live streams lately just to keep everyone up to date because as you guys mentioned, it's happening so fast and it's good to show people what's possible. So I'm gonna go ahead and stop the, go ahead. One more thing, I think that getting everybody involved and talking about this is really the best way forward. Yeah. Because, you know, up until now, all of the discussion about AI and ethics and morality of AI has been siloed and gatekept by the, you know, a few people at these major corporations. Yeah. And, you know, you and the communities that you've helped get it off the ground, I think has really opened it up and is going to be one of the most important things for the future of AI. It's definitely already having an impact. Well, thanks so much, and I'm glad that it's having hopefully a positive impact in the long run. We'll see. All right, gang. I'm going to knock off the recording. Have a good night, everybody, and we'll talk again soon. Cheers. Hasta luego. Alright gang, I'm gonna knock off the recording, have a good night everybody, and we'll talk again soon. Cheers! Hasta luego!", "chunks": [{"timestamp": [0.0, 1.88], "text": " All right, cool."}, {"timestamp": [1.88, 7.4], "text": " We are recording, so just a quick introduction."}, {"timestamp": [7.4, 14.5], "text": " These are some of the guys from the Heuristic Imperatives Discord, the research group."}, {"timestamp": [14.5, 18.04], "text": " They're building a cognitive architecture."}, {"timestamp": [18.04, 22.2], "text": " So I'll let you guys kind of, if you want to introduce yourselves, not required, but"}, {"timestamp": [22.2, 26.4], "text": " yeah, let's jump in and just kind of talk about where we're at in terms of cognitive architecture"}, {"timestamp": [26.4, 29.48], "text": " and some of the stuff that you guys have been working on."}, {"timestamp": [30.72, 31.88], "text": " Yeah, sure."}, {"timestamp": [31.88, 33.64], "text": " I'm Database."}, {"timestamp": [33.64, 37.48], "text": " I'm on the Cognitive AI channel too."}, {"timestamp": [37.48, 39.28], "text": " Y'all see me all of the time."}, {"timestamp": [39.28, 41.68], "text": " I'm the one who's always arguing with everybody."}, {"timestamp": [43.48, 44.48], "text": " Ansel, if you wanna."}, {"timestamp": [46.0, 49.24], "text": " Yeah, well, I'm Ansel, I'm on the same Discord."}, {"timestamp": [49.24, 50.96], "text": " I'm a computer science engineer,"}, {"timestamp": [50.96, 55.28], "text": " and I guess I'm really fascinated by this subject,"}, {"timestamp": [56.44, 58.84], "text": " so I just had to go and dive in."}, {"timestamp": [59.74, 61.36], "text": " Excellent, excellent."}, {"timestamp": [61.36, 65.68], "text": " And so, give us a tiny bit of background actually,"}, {"timestamp": [65.68, 69.84], "text": " because you guys, or database, I remember your story."}, {"timestamp": [69.84, 71.94], "text": " You jumped into cognitive architecture, what,"}, {"timestamp": [71.94, 75.22], "text": " like just a few weeks ago, right?"}, {"timestamp": [75.22, 76.92], "text": " Yeah, basically."}, {"timestamp": [76.92, 81.0], "text": " So, it was about the time that AutoGPT went viral."}, {"timestamp": [81.86, 83.16], "text": " I was like, this is really cool."}, {"timestamp": [83.16, 84.96], "text": " I don't want to have to pay for it."}, {"timestamp": [84.96, 88.0], "text": " So, I started trying to convert it to"}, {"timestamp": [88.0, 92.0], "text": " a local model, which"}, {"timestamp": [92.0, 96.0], "text": " we ran into some issues with that."}, {"timestamp": [96.0, 100.0], "text": " But that's, you know, before then"}, {"timestamp": [100.0, 104.0], "text": " I hadn't really done a whole lot with programming or Python"}, {"timestamp": [104.0, 105.88], "text": " at all."}, {"timestamp": [105.88, 110.92], "text": " And so most of what I've learned in the past three weeks now,"}, {"timestamp": [110.92, 115.8], "text": " I guess, has been primarily through chat GPT."}, {"timestamp": [115.8, 116.88], "text": " Nice."}, {"timestamp": [116.88, 117.36], "text": " Excellent."}, {"timestamp": [117.36, 120.12], "text": " Yep, that's the case for many people."}, {"timestamp": [120.12, 124.2], "text": " And Ansel, you've been a developer or an engineer"}, {"timestamp": [124.2, 125.68], "text": " for a little bit longer, correct?"}, {"timestamp": [125.68, 126.68], "text": " Yes, yes."}, {"timestamp": [126.68, 128.28], "text": " Right, right."}, {"timestamp": [128.28, 131.52], "text": " I've been an engineer already for like three years."}, {"timestamp": [131.52, 134.6], "text": " I have years of experience mostly in C Sharp."}, {"timestamp": [134.6, 136.88], "text": " That's like my main language."}, {"timestamp": [136.88, 141.04], "text": " So yeah, I got into this project like three weeks ago with data"}, {"timestamp": [141.04, 142.72], "text": " and same with Python."}, {"timestamp": [142.72, 146.24], "text": " So basically, I've just been converting everything I know"}, {"timestamp": [146.24, 148.6], "text": " from C sharp to Python."}, {"timestamp": [148.6, 151.56], "text": " And it's been a great experience learning a lot of things"}, {"timestamp": [151.56, 153.12], "text": " and it's pretty cool."}, {"timestamp": [153.12, 154.2], "text": " Excellent."}, {"timestamp": [154.2, 159.2], "text": " So, you know, obviously auto GPT, baby AGI, chaos GPT,"}, {"timestamp": [159.56, 161.52], "text": " all that is relatively new."}, {"timestamp": [161.52, 165.0], "text": " GPT-4 just came out, you know, what, four or five weeks ago."}, {"timestamp": [165.0, 170.0], "text": " And so, like, walk us through the process,"}, {"timestamp": [170.34, 172.56], "text": " because I've had the privilege of kind of watching"}, {"timestamp": [172.56, 174.9], "text": " you guys figure stuff out from the beginning."}, {"timestamp": [174.9, 177.6], "text": " But can you tell us a little bit about,"}, {"timestamp": [177.6, 178.76], "text": " like, where you got started,"}, {"timestamp": [178.76, 181.86], "text": " what were the problems that you've overcome,"}, {"timestamp": [181.86, 184.72], "text": " and what problems you're working on now?"}, {"timestamp": [185.0, 186.14], "text": " you've overcome and what problems you're working on now?"}, {"timestamp": [190.98, 195.98], "text": " Yeah, the biggest problem that we ran into to start with was just finding a host for a language model"}, {"timestamp": [196.1, 198.32], "text": " that had a working API."}, {"timestamp": [199.74, 204.1], "text": " We started with Llama CPP,"}, {"timestamp": [204.1, 212.36], "text": " but it's Python API didn't work on x64 Windows for whatever reason."}, {"timestamp": [212.36, 215.72], "text": " There were a couple of others that we worked with,"}, {"timestamp": [215.72, 219.76], "text": " and then eventually we came around to UbaBuga."}, {"timestamp": [220.2, 222.8], "text": " They've got the API fixed now,"}, {"timestamp": [222.8, 225.4], "text": " we have people using it."}, {"timestamp": [225.4, 226.8], "text": " Right."}, {"timestamp": [226.8, 232.0], "text": " The real advantage of UbaBuga is that it gives us,"}, {"timestamp": [232.0, 234.76], "text": " it lets us host multiple language models."}, {"timestamp": [234.76, 242.48], "text": " So we're not just stuck with llama or alpaca."}, {"timestamp": [242.48, 246.0], "text": " The new Vicuna model is working in there."}, {"timestamp": [246.0, 251.82], "text": " It has some of the science and coding language models"}, {"timestamp": [251.82, 253.64], "text": " available to it as well."}, {"timestamp": [253.64, 256.36], "text": " We haven't done a whole lot of testing on that."}, {"timestamp": [256.36, 261.14], "text": " We've switched over to OpenAI on the 3.5 model"}, {"timestamp": [261.14, 269.44], "text": " just to rapidly iterate on the development process and save some resources at home."}, {"timestamp": [269.44, 275.92], "text": " And by the time we did that was mostly because we were stuck with the UbaBuga API and OpenAI"}, {"timestamp": [275.92, 287.48], "text": " was working so we just like if we want to develop we need to switch fast to that. Gotcha. And then the auto GPT code base was,"}, {"timestamp": [287.48, 290.04], "text": " let's just say it was not ideal."}, {"timestamp": [290.04, 293.0], "text": " I spent an entire day trying to fix that."}, {"timestamp": [293.0, 294.24], "text": " Yeah."}, {"timestamp": [294.24, 298.2], "text": " So we ended up moving over to Baby AGI."}, {"timestamp": [298.2, 308.0], "text": " We got Baby working on OpenAI and UbaBuga temporarily. And then UbaBuga"}, {"timestamp": [308.0, 312.0], "text": " broke their API for like two weeks,"}, {"timestamp": [312.0, 316.0], "text": " which was wild. But they've got it back working now."}, {"timestamp": [316.0, 320.0], "text": " The people who are using our new project, some of them are"}, {"timestamp": [320.0, 324.0], "text": " using the UbaBuga"}, {"timestamp": [324.0, 327.68], "text": " API and running it against Vicuna,"}, {"timestamp": [329.32, 331.94], "text": " which was the original goal. So it works, we're trying to keep it stable"}, {"timestamp": [331.94, 334.54], "text": " as best we can for those people,"}, {"timestamp": [334.54, 337.36], "text": " and we're super excited, honestly,"}, {"timestamp": [338.9, 341.4], "text": " that all of this is coming together."}, {"timestamp": [341.4, 342.24], "text": " Excellent."}, {"timestamp": [344.12, 346.24], "text": " Data, Database database and Ansel,"}, {"timestamp": [346.24, 348.76], "text": " you guys have been working super hard"}, {"timestamp": [348.76, 352.96], "text": " on what you call the salience module."}, {"timestamp": [352.96, 354.76], "text": " Can you talk us through that a little bit?"}, {"timestamp": [354.76, 358.0], "text": " Because that is a pretty fascinating set of problems."}, {"timestamp": [358.0, 361.12], "text": " Right, so I have it loaded up right here."}, {"timestamp": [361.12, 365.28], "text": " As you can see, it's just a simple Python script."}, {"timestamp": [365.28, 367.14], "text": " One of the main reasons we decided"}, {"timestamp": [367.14, 372.52], "text": " to work on our own project was because AutoGPT was not"}, {"timestamp": [372.52, 376.44], "text": " made to be extensively modified."}, {"timestamp": [376.44, 381.04], "text": " I spent an entire day just trying to modify it myself,"}, {"timestamp": [381.04, 383.8], "text": " and I had a pretty bad time."}, {"timestamp": [383.8, 385.12], "text": " I'm not going to lie."}, {"timestamp": [385.12, 388.48], "text": " So we decided to just take the minimum viable version there"}, {"timestamp": [388.48, 392.2], "text": " was and start our own architecture."}, {"timestamp": [392.2, 396.4], "text": " So we created this little salience loop here."}, {"timestamp": [396.4, 400.08], "text": " We basically start by instantiating all the agents"}, {"timestamp": [400.08, 402.36], "text": " that we have."}, {"timestamp": [402.36, 405.16], "text": " And then we start looping through it,"}, {"timestamp": [405.16, 408.8], "text": " loading a task list, and everything."}, {"timestamp": [408.8, 410.9], "text": " So let me just run it for you first."}, {"timestamp": [410.9, 413.72], "text": " Let's see, Python."}, {"timestamp": [413.72, 415.84], "text": " We can edit this out in post, right?"}, {"timestamp": [415.84, 418.84], "text": " We can edit this out in post, yeah."}, {"timestamp": [418.84, 422.52], "text": " The logic loop that we built."}, {"timestamp": [422.52, 423.98], "text": " OK, cool."}, {"timestamp": [423.98, 430.04], "text": " Yeah, basically, we built this entire thing in one Saturday."}, {"timestamp": [430.04, 431.4], "text": " Okay."}, {"timestamp": [431.4, 433.2], "text": " Got this pulled up."}, {"timestamp": [433.2, 435.2], "text": " Yeah. I'm watching it."}, {"timestamp": [435.2, 436.96], "text": " Can you zoom in a little bit and tell us"}, {"timestamp": [436.96, 439.56], "text": " a little bit about what this diagram is? There we go."}, {"timestamp": [439.56, 443.64], "text": " Right. So this is the logic loop."}, {"timestamp": [443.64, 448.26], "text": " One of the really helpful, or not helpful,"}, {"timestamp": [448.26, 452.06], "text": " but one of the things that we've kind of designed"}, {"timestamp": [452.06, 460.66], "text": " from the get-go on this system was"}, {"timestamp": [460.66, 467.0], "text": " to try to make it easy to build agents and logic loops"}, {"timestamp": [467.0, 471.0], "text": " in a very short fashion so that you can iterate quickly,"}, {"timestamp": [471.0, 476.0], "text": " as opposed to, you know, if you wanted to change the logic"}, {"timestamp": [476.0, 480.0], "text": " that OpenAI uses, or even baby AGI, really,"}, {"timestamp": [480.0, 484.0], "text": " you really have to understand the entire code base"}, {"timestamp": [484.0, 487.08], "text": " that they're using and how different things interact."}, {"timestamp": [487.08, 489.44], "text": " We're trying to build a streamlined flow"}, {"timestamp": [489.44, 491.88], "text": " where you can just write a logic loop"}, {"timestamp": [491.88, 496.32], "text": " for the actual interaction where it takes the prompt"}, {"timestamp": [496.32, 498.52], "text": " and then decides where to store it"}, {"timestamp": [498.52, 500.88], "text": " and you chain them together."}, {"timestamp": [502.12, 510.88], "text": " So in a similar fashion to the way that AutoGPT works, right now in the"}, {"timestamp": [510.88, 518.6], "text": " salience agent, we're working with a predefined task list. Baby AGI generates the task list"}, {"timestamp": [518.6, 528.92], "text": " automatically, and later we're going to do a hybrid where we integrate both. But for now, we're just working with a predefined task list."}, {"timestamp": [528.92, 534.84], "text": " So we sort the task list because every time you make an edit"}, {"timestamp": [534.84, 543.04], "text": " to an item in ChromaDB, it falls to the end of the table"}, {"timestamp": [543.04, 546.84], "text": " or collection is what they're called in vector databases."}, {"timestamp": [546.84, 552.68], "text": " But we sort the list, we filter it during the sort, we filter for any completed"}, {"timestamp": [552.68, 560.24], "text": " tasks and pass the current task to the job agent. So what the job agent does is"}, {"timestamp": [560.24, 569.4], "text": " it searches the vector database or the results database for any results related to the current task,"}, {"timestamp": [569.4, 573.4], "text": " summarizes those, passes them down to the job agent."}, {"timestamp": [573.4, 586.0], "text": " The job agent then passes the context, so that's your current task, the related results from the summary,"}, {"timestamp": [586.0, 592.0], "text": " and a couple of other metadata related things."}, {"timestamp": [592.0, 596.0], "text": " And it runs the execute process,"}, {"timestamp": [596.0, 600.0], "text": " which is right now identical to what Baby was using."}, {"timestamp": [600.0, 608.36], "text": " But we've broken the prompt for that out into a easily editable JSON file"}, {"timestamp": [608.36, 615.04], "text": " that so that you can change that prompt on the fly."}, {"timestamp": [615.04, 619.56], "text": " So the execute agent pulls the prompt from the JSON,"}, {"timestamp": [619.56, 624.36], "text": " runs it, and then passes the results back to the job agent."}, {"timestamp": [624.36, 628.56], "text": " We don't have frustration implemented yet,"}, {"timestamp": [628.56, 634.72], "text": " but that's going to be based on the write-up that you did on Reddit the other day."}, {"timestamp": [634.72, 635.44], "text": " Yeah."}, {"timestamp": [637.12, 643.04], "text": " To kind of check things out. And then once it passes frustration or skips frustration,"}, {"timestamp": [643.44, 647.84], "text": " Once it passes frustration or skips frustration, then we pass those results back to the results database"}, {"timestamp": [647.84, 650.34], "text": " and it goes to the analyst agent."}, {"timestamp": [650.34, 653.64], "text": " So, the analyst agent is here."}, {"timestamp": [653.64, 654.64], "text": " Do I have everything?"}, {"timestamp": [654.64, 655.64], "text": " There we go."}, {"timestamp": [655.64, 658.14], "text": " The analyst agent is here."}, {"timestamp": [658.14, 660.84], "text": " And it's a little bit more complex, actually,"}, {"timestamp": [660.84, 663.84], "text": " even though it looks simpler than that loopy stuff."}, {"timestamp": [663.84, 669.04], "text": " We're actually taking multiple items, or more items,"}, {"timestamp": [669.04, 674.04], "text": " and adding them to the prompt."}, {"timestamp": [674.32, 676.76], "text": " It's basically as, go ahead."}, {"timestamp": [676.76, 679.72], "text": " Let me pause you for a second and ask,"}, {"timestamp": [679.72, 683.5], "text": " how much of this architecture did you borrow"}, {"timestamp": [683.5, 688.22], "text": " from other projects, and how much of this is stuff that you guys have have created"}, {"timestamp": [688.22, 688.92], "text": " on your own?"}, {"timestamp": [690.0, 695.24], "text": " So right now, the only thing that borrowed is the execution"}, {"timestamp": [695.24, 700.84], "text": " age. And it's right now, essentially just the prompt. So"}, {"timestamp": [701.08, 705.0], "text": " we what we did was we took, we took Baby AGI's architecture"}, {"timestamp": [707.44, 711.44], "text": " and broke it out into lots of different pieces."}, {"timestamp": [711.44, 715.96], "text": " And then we changed all of those pieces completely"}, {"timestamp": [717.16, 722.16], "text": " and re-imported them, or re-integrated them as classes"}, {"timestamp": [724.28, 730.0], "text": " in multiple agents."}, {"timestamp": [730.0, 737.44], "text": " But originally, Baby-AGI was only one script,"}, {"timestamp": [737.44, 739.52], "text": " and it was less than 200 lines."}, {"timestamp": [739.52, 743.72], "text": " That was the entire purpose of Baby-AGI."}, {"timestamp": [743.72, 748.32], "text": " We're over 3,000 lines on this code repo now."}, {"timestamp": [750.84, 752.38], "text": " Yeah, we're averaging about a thousand."}, {"timestamp": [752.38, 753.96], "text": " No, stop counting."}, {"timestamp": [753.96, 755.2], "text": " Stop counting."}, {"timestamp": [756.06, 759.08], "text": " So you've taken kind of the initial idea"}, {"timestamp": [759.08, 762.14], "text": " and really you've gone 10x on it."}, {"timestamp": [762.14, 763.78], "text": " You've made it more modular."}, {"timestamp": [763.78, 766.88], "text": " You've added a few new ideas, new loops,"}, {"timestamp": [769.44, 773.52], "text": " one of the modules that you haven't integrated yet. I think earlier you said you haven't seen"}, {"timestamp": [773.52, 782.4], "text": " a need for the frustration signal yet. But yes. We haven't gotten into very complex tasks yet,"}, {"timestamp": [782.4, 786.56], "text": " so maybe that's why we haven't needed frustration yet, but"}, {"timestamp": [786.56, 788.52], "text": " I'm guessing we are going to need it at some point."}, {"timestamp": [788.52, 789.52], "text": " Davey Absolutely."}, {"timestamp": [789.52, 790.52], "text": " Sean That's fair."}, {"timestamp": [790.52, 791.52], "text": " Davey Absolutely."}, {"timestamp": [791.52, 794.56], "text": " Sean For any viewers who aren't familiar with"}, {"timestamp": [794.56, 800.36], "text": " the write-up that I did on frustration as a signal, basically it is you keep a ratio,"}, {"timestamp": [800.36, 805.72], "text": " the simplest version is you keep a ratio of successes to failures, and if the failure"}, {"timestamp": [805.72, 814.36], "text": " rate goes up, then that tells you to maybe switch to a smarter model, or you can back"}, {"timestamp": [814.36, 819.12], "text": " up and try a different approach, or eventually you can just stop and ask for help."}, {"timestamp": [819.12, 823.68], "text": " There's any number of things that you can do with the frustration signal, but basically"}, {"timestamp": [823.68, 826.64], "text": " this is, frustration is a key component"}, {"timestamp": [826.64, 829.08], "text": " of cognitive control, which is how humans say,"}, {"timestamp": [829.08, 831.7], "text": " hey, I expected to be making more forward progress,"}, {"timestamp": [831.7, 834.56], "text": " and I'm not, and so if you're not making the progress"}, {"timestamp": [834.56, 836.56], "text": " that you expect, then it's time to either"}, {"timestamp": [836.56, 839.94], "text": " change your approach, ask for help, or change something."}, {"timestamp": [839.94, 842.08], "text": " So thanks for giving some context."}, {"timestamp": [842.08, 845.56], "text": " Did you wanna go ahead and jump into your analyst agent?"}, {"timestamp": [845.56, 849.6], "text": " Yeah, yeah, absolutely."}, {"timestamp": [849.6, 867.92], "text": " So the analyst agent is a little bit more complex because we're taking the results, the most recent results and the current test, plus we're getting"}, {"timestamp": [867.92, 880.72], "text": " the summary from this agent, the job agent or salience agent as well, and we're feeding it"}, {"timestamp": [888.32, 896.72], "text": " feeding it the the a little bit more context on the task. We're asking the the the GBT agent to decide is this job completed yet and if it's you know if"}, {"timestamp": [896.72, 908.0], "text": " not then what we can do is send if it's if it's reached the frustration level, we can send that task back to the"}, {"timestamp": [908.0, 912.0], "text": " task creation agent to generate"}, {"timestamp": [912.0, 916.0], "text": " subtasks potentially or new tasks."}, {"timestamp": [916.0, 920.0], "text": " And then we're also this weekend"}, {"timestamp": [920.0, 924.0], "text": " going to set up sending feedback back"}, {"timestamp": [924.0, 928.0], "text": " into the agent. And you'll see what that feedback"}, {"timestamp": [928.0, 932.0], "text": " the feedback I think is going to really change the game on"}, {"timestamp": [932.0, 936.0], "text": " getting fewer runs"}, {"timestamp": [936.0, 940.0], "text": " to complete a particular task. And then of course if it does complete"}, {"timestamp": [940.0, 944.0], "text": " it, then we update the task with the task scheduler"}, {"timestamp": [944.0, 948.68], "text": " and tell it to move on to the next task."}, {"timestamp": [951.4, 954.12], "text": " Did you get the terminal resize canceled?"}, {"timestamp": [954.12, 956.84], "text": " I'm already sharing my screen again, yeah."}, {"timestamp": [956.84, 959.24], "text": " I could not figure out how to get it resized,"}, {"timestamp": [959.24, 964.4], "text": " so what I actually did was resize your monitor display."}, {"timestamp": [964.4, 965.36], "text": " Yeah."}, {"timestamp": [965.36, 967.16], "text": " All right."}, {"timestamp": [967.16, 969.8], "text": " I actually increased the scale of it."}, {"timestamp": [969.8, 971.04], "text": " And we just zoom in."}, {"timestamp": [972.42, 975.04], "text": " All right, Ansel, you ready?"}, {"timestamp": [975.04, 978.12], "text": " Database, were you sufficiently?"}, {"timestamp": [979.28, 982.2], "text": " Yeah, yeah, that's where we're at right now."}, {"timestamp": [982.2, 983.04], "text": " Okay, cool."}, {"timestamp": [983.04, 984.84], "text": " We'll talk about all this stuff in the future."}, {"timestamp": [984.84, 989.68], "text": " So Ansel, give us a little bit of a background."}, {"timestamp": [989.68, 992.84], "text": " What is it that you're about to demonstrate for us?"}, {"timestamp": [992.84, 996.76], "text": " Well, I'm about to run the salience loop."}, {"timestamp": [996.76, 998.36], "text": " As you can see, it's asking me a few things."}, {"timestamp": [998.36, 1001.8], "text": " It's asking me if I wanna start from where it left off,"}, {"timestamp": [1001.8, 1003.84], "text": " basically restore the previous state,"}, {"timestamp": [1003.84, 1006.6], "text": " and if I wanna allow auto mode or manual mode, for now,"}, {"timestamp": [1006.6, 1008.84], "text": " let's just go with manual mode."}, {"timestamp": [1008.84, 1011.68], "text": " And it's starting to initialize the agents here."}, {"timestamp": [1011.68, 1014.4], "text": " If you want to explain, go ahead, Data."}, {"timestamp": [1014.4, 1018.96], "text": " Well, I was going to say, the restore from previous state"}, {"timestamp": [1018.96, 1021.08], "text": " is, to my knowledge, not something"}, {"timestamp": [1021.08, 1026.84], "text": " that's present in any other autonomous uh, any other autonomous AI system"}, {"timestamp": [1026.84, 1027.84], "text": " out there yet."}, {"timestamp": [1027.84, 1029.76], "text": " So, really cool stuff."}, {"timestamp": [1029.76, 1030.76], "text": " Yeah."}, {"timestamp": [1030.76, 1034.08], "text": " So, tell us a little bit about that feature, because it sounds, sounds valuable."}, {"timestamp": [1034.08, 1037.64], "text": " Like you can, uh, you're in the middle of cooking dinner and someone knocks on the door"}, {"timestamp": [1037.64, 1041.56], "text": " and you come back and remember where you were, right?"}, {"timestamp": [1041.56, 1042.56], "text": " Right."}, {"timestamp": [1042.56, 1049.16], "text": " Well, you could always just leave it sitting there because the system has this,"}, {"timestamp": [1049.16, 1053.38], "text": " as you can see, it has a auto mode or a manual mode."}, {"timestamp": [1053.38, 1059.32], "text": " Since we set manual mode, every loop it's going to stop and ask us for feedback."}, {"timestamp": [1059.32, 1066.56], "text": " Alright. But if you have to turn your computer off because the FBI show up,"}, {"timestamp": [1066.56, 1073.16], "text": " then when you power it back up,"}, {"timestamp": [1074.52, 1081.92], "text": " all of the task statuses and results are stored persistently in ChromaDB."}, {"timestamp": [1081.92, 1086.78], "text": " So you never lose any data unless you tell it you want, you don't"}, {"timestamp": [1086.78, 1089.2], "text": " want to restore from a previous state."}, {"timestamp": [1089.2, 1091.2], "text": " That makes sense."}, {"timestamp": [1091.2, 1092.6], "text": " You want to go ahead, go ahead Angel."}, {"timestamp": [1092.6, 1096.3], "text": " So in this case I basically wiped this memory, it doesn't know anything."}, {"timestamp": [1096.3, 1100.4], "text": " I'm just gonna say yes, just to keep it simple for now."}, {"timestamp": [1100.4, 1107.9], "text": " And it started to run the salience agent, And a salience agent is going to call the execution agent"}, {"timestamp": [1107.9, 1110.74], "text": " to start running the task list."}, {"timestamp": [1110.74, 1115.98], "text": " For now, the task lists are defined from our persona JSON."}, {"timestamp": [1115.98, 1118.54], "text": " So what we wanted to do was separate the code"}, {"timestamp": [1118.54, 1119.62], "text": " from the prompts."}, {"timestamp": [1119.62, 1121.54], "text": " So whoever wants to develop agents"}, {"timestamp": [1121.54, 1127.44], "text": " can simply look at two things, the code of the agent, what it's supposed to do logically,"}, {"timestamp": [1127.44, 1131.32], "text": " and they can alter the prompts on the JSON file."}, {"timestamp": [1131.32, 1134.16], "text": " So I'll show you the JSON file in a second."}, {"timestamp": [1134.16, 1136.0], "text": " Right now, the first task is, well,"}, {"timestamp": [1136.0, 1138.52], "text": " to develop a task list to achieve a goal, which"}, {"timestamp": [1138.52, 1142.76], "text": " in this case, I don't believe I'm printing it here."}, {"timestamp": [1142.76, 1145.56], "text": " Yes, it's supposed to create a program for an AI"}, {"timestamp": [1145.56, 1147.16], "text": " to search the internet."}, {"timestamp": [1147.16, 1149.24], "text": " So it did the first task."}, {"timestamp": [1149.24, 1152.2], "text": " Let's just go ahead and let it run again."}, {"timestamp": [1152.2, 1153.8], "text": " It's going for the second task."}, {"timestamp": [1153.8, 1156.56], "text": " Right now, it's only showing you the info,"}, {"timestamp": [1156.56, 1158.36], "text": " like what you really want to see it's doing."}, {"timestamp": [1158.36, 1161.04], "text": " You're not seeing all the processing behind."}, {"timestamp": [1161.04, 1162.56], "text": " There's also a debug mode you can"}, {"timestamp": [1162.56, 1166.16], "text": " do that starts showing the prompts, what's going in,"}, {"timestamp": [1166.16, 1167.12], "text": " what's in the database."}, {"timestamp": [1167.12, 1170.84], "text": " I can run another loop later with that turned on"}, {"timestamp": [1170.84, 1173.68], "text": " to show you what it's doing internally."}, {"timestamp": [1173.68, 1176.4], "text": " And it'll just keep going."}, {"timestamp": [1176.4, 1178.6], "text": " Apparently, it's reflected on the task."}, {"timestamp": [1178.6, 1181.0], "text": " So yeah, let's just leave it in auto mode."}, {"timestamp": [1181.0, 1183.64], "text": " I can change it to auto mode."}, {"timestamp": [1183.64, 1185.62], "text": " And it's now in auto mode. You can see it says you can press Escape to return to auto mode. I can change it to auto mode. And it's now in auto mode."}, {"timestamp": [1185.62, 1186.88], "text": " You can see it says you can press"}, {"timestamp": [1186.88, 1188.64], "text": " Escape to return to auto mode."}, {"timestamp": [1188.64, 1190.62], "text": " So at any point in the code, if I press Escape,"}, {"timestamp": [1190.62, 1192.78], "text": " it's just going to say, switching back to auto mode."}, {"timestamp": [1192.78, 1196.32], "text": " And it'll stop and ask me for feedback again."}, {"timestamp": [1196.32, 1197.78], "text": " CHANCELLOR MOORE Excellent."}, {"timestamp": [1197.78, 1199.2], "text": " VICTOR BROWN At this point, I don't"}, {"timestamp": [1199.2, 1202.7], "text": " know if it's going to say if it completed the task or not."}, {"timestamp": [1202.7, 1209.24], "text": " Because the last task is to act out the task list it made."}, {"timestamp": [1209.24, 1213.36], "text": " But it very much depends on the status agent,"}, {"timestamp": [1213.36, 1215.2], "text": " if it decides it did it or not."}, {"timestamp": [1215.2, 1218.52], "text": " In this case, it says it completed it."}, {"timestamp": [1218.52, 1220.48], "text": " And it also, the good thing is it"}, {"timestamp": [1220.48, 1224.4], "text": " provides a reasoning for why it decided it's completed or not."}, {"timestamp": [1224.4, 1232.82], "text": " So you can also get more information as to why it took that decision and help you do"}, {"timestamp": [1232.82, 1236.2], "text": " better prompt engineering so you can change the prompt easier."}, {"timestamp": [1236.2, 1244.32], "text": " So let's pause for a second because I think that there's a tremendous amount of significance"}, {"timestamp": [1244.32, 1245.12], "text": " here."}, {"timestamp": [1245.12, 1249.6], "text": " So walk us through the steps."}, {"timestamp": [1249.6, 1255.52], "text": " From scratch, it had what appeared to be a metacognitive step where it said, okay, what"}, {"timestamp": [1255.52, 1257.0], "text": " am I doing?"}, {"timestamp": [1257.0, 1263.38], "text": " And then it designed its own task list, followed through the task list, and then also evaluated"}, {"timestamp": [1263.38, 1265.76], "text": " its own performance to know when it had finished."}, {"timestamp": [1267.12, 1267.96], "text": " Correct?"}, {"timestamp": [1267.96, 1268.78], "text": " Okay."}, {"timestamp": [1268.78, 1269.62], "text": " Yes."}, {"timestamp": [1269.62, 1271.16], "text": " So here it's basically where it starts."}, {"timestamp": [1271.16, 1272.8], "text": " Let's see."}, {"timestamp": [1272.8, 1273.76], "text": " Yep."}, {"timestamp": [1273.76, 1274.6], "text": " At the beginning."}, {"timestamp": [1274.6, 1277.72], "text": " So the first thing it does is start to develop a task list"}, {"timestamp": [1277.72, 1280.32], "text": " and it's searching for results in its memory."}, {"timestamp": [1280.32, 1283.26], "text": " Since it's white, it says there is no results."}, {"timestamp": [1284.44, 1286.4], "text": " It sends that results to summary,"}, {"timestamp": [1286.4, 1290.08], "text": " since no results exist yet."}, {"timestamp": [1290.08, 1293.04], "text": " It just says no previous actions have been taken."}, {"timestamp": [1293.04, 1296.12], "text": " Because this is fed to, I don't remember"}, {"timestamp": [1296.12, 1297.64], "text": " if it's fed to the execution agent"}, {"timestamp": [1297.64, 1301.96], "text": " or if it's fed to the status agent."}, {"timestamp": [1301.96, 1303.48], "text": " One of those two."}, {"timestamp": [1303.48, 1304.84], "text": " Both of them, actually."}, {"timestamp": [1304.84, 1305.24], "text": " Oh, both of them, though. Both of them, actually."}, {"timestamp": [1305.24, 1306.0], "text": " Oh, both of them."}, {"timestamp": [1306.0, 1307.72], "text": " OK."}, {"timestamp": [1307.72, 1312.92], "text": " So that the agents at least know what step of the process"}, {"timestamp": [1312.92, 1315.48], "text": " they are, or any other actions they've taken before."}, {"timestamp": [1315.48, 1318.88], "text": " It's basically like a very primitive sort of memory"}, {"timestamp": [1318.88, 1321.6], "text": " as to, OK, what have I done before, right?"}, {"timestamp": [1321.6, 1323.12], "text": " Right."}, {"timestamp": [1323.12, 1327.28], "text": " And basically, we send all of that information to the agent."}, {"timestamp": [1327.28, 1329.0], "text": " It runs, and here's the result we"}, {"timestamp": [1329.0, 1335.32], "text": " get from the LLM, which is, well, it did create a task list."}, {"timestamp": [1335.32, 1339.32], "text": " So at that point, we send those results to the status agent,"}, {"timestamp": [1339.32, 1342.44], "text": " and it's going to check if that task has been completed."}, {"timestamp": [1342.44, 1345.34], "text": " In this case, it says, yes, the task has been completed,"}, {"timestamp": [1345.34, 1347.74], "text": " and it provides a reasoning right here"}, {"timestamp": [1347.74, 1349.78], "text": " for why it thinks it's done so."}, {"timestamp": [1349.78, 1352.78], "text": " And at that point, we go back into the loop."}, {"timestamp": [1352.78, 1357.18], "text": " So it's going to ask me again, do you want to continue or not?"}, {"timestamp": [1357.18, 1358.22], "text": " Go ahead, Data."}, {"timestamp": [1358.22, 1363.3], "text": " Yeah, so I want to come back to the status agent."}, {"timestamp": [1363.3, 1365.92], "text": " So not only are we returning the status agent. Not only are we returning"}, {"timestamp": [1365.92, 1370.36], "text": " the status of whether or not it's completed,"}, {"timestamp": [1370.36, 1372.44], "text": " we're also providing feedback."}, {"timestamp": [1372.44, 1375.68], "text": " If you get a status that's not completed,"}, {"timestamp": [1375.68, 1377.08], "text": " and this isn't in yet,"}, {"timestamp": [1377.08, 1380.6], "text": " but this should be relatively simple to incorporate."}, {"timestamp": [1380.6, 1383.44], "text": " One of the things that we can do is provide"}, {"timestamp": [1383.44, 1385.0], "text": " additional feedback"}, {"timestamp": [1385.0, 1389.0], "text": " to the execution agent the next time it runs."}, {"timestamp": [1389.0, 1397.0], "text": " In this situation, what we would want to do to help automate this"}, {"timestamp": [1397.0, 1402.0], "text": " is pass it the feedback from the status agent."}, {"timestamp": [1402.0, 1407.52], "text": " The status agent is going to act as a project manager,"}, {"timestamp": [1407.52, 1412.4], "text": " where it has all of its little dev minions that go out and do"}, {"timestamp": [1412.4, 1415.86], "text": " their things and then they come back with their results and they"}, {"timestamp": [1415.86, 1421.32], "text": " present a summarized result of some kind."}, {"timestamp": [1421.32, 1428.64], "text": " Now, that execution agent needs to be expanded upon so that we can get web searching"}, {"timestamp": [1428.64, 1437.2], "text": " for research and code execution to or to do code testing and stuff. We may even have a code QA"}, {"timestamp": [1438.16, 1450.16], "text": " agent separately, but we can take that feedback from the project manager status agent and push it back in if"}, {"timestamp": [1450.16, 1456.8], "text": " the agent fails so that it can do better the next time and it's not always running into"}, {"timestamp": [1456.8, 1458.28], "text": " the same results."}, {"timestamp": [1458.28, 1459.28], "text": " Yeah."}, {"timestamp": [1459.28, 1463.84], "text": " So let's unpack that real quick."}, {"timestamp": [1463.84, 1469.56], "text": " I think we should switch over to the personas default."}, {"timestamp": [1469.56, 1471.12], "text": " I've got this pulled up now."}, {"timestamp": [1471.12, 1479.36], "text": " Hey, Data, before we proceed, because what you're talking about is cognitive neuroscience,"}, {"timestamp": [1479.36, 1481.52], "text": " and a lot of people are going to be lost."}, {"timestamp": [1481.52, 1486.64], "text": " The status agent, that's the supervisor, right? That kind of sits above"}, {"timestamp": [1486.64, 1491.6], "text": " the other things and it dispatches, let me make sure I got it right, it dispatches the execution"}, {"timestamp": [1491.6, 1498.64], "text": " agent says, hey, this is your set of tasks to go do. And then that uses the salience loop in order"}, {"timestamp": [1498.64, 1509.88], "text": " to loop through and ensure that that task gets completed. Is that the correct stack? It's the salience loop that calls the execution agent"}, {"timestamp": [1510.52, 1512.56], "text": " and status agent separately."}, {"timestamp": [1512.56, 1513.4], "text": " Okay."}, {"timestamp": [1513.4, 1516.64], "text": " So the salience is what binds it together."}, {"timestamp": [1516.64, 1517.56], "text": " Right, exactly."}, {"timestamp": [1517.56, 1519.92], "text": " The salience loop is what binds them together, correct."}, {"timestamp": [1519.92, 1523.02], "text": " Okay, and so by iterating on that,"}, {"timestamp": [1523.02, 1536.0], "text": " you are checking multiple times for whether you whether you're being successful the feedback that you're getting and it can because it's iterative it can adapt its strategy as it goes."}, {"timestamp": [1547.04, 1553.6], "text": " of talking to itself in this sense, so it's really more, it's less like corporate developer type of environment and more just like internal monologue. Like, if you were, you know, building"}, {"timestamp": [1554.16, 1560.72], "text": " a, if you were building a raised garden bed, for example, you know, you're like, okay, first thing"}, {"timestamp": [1560.72, 1565.48], "text": " I need to do is take measurements, and then I want to cut take measurements and then I want to cut wood and then I want"}, {"timestamp": [1565.48, 1567.16], "text": " to nail wood together."}, {"timestamp": [1567.16, 1570.28], "text": " Finally we put it in place and then we fill it with..."}, {"timestamp": [1570.28, 1575.36], "text": " You kind of like outline that and then, you know, as you're cutting wood, like, okay,"}, {"timestamp": [1575.36, 1576.6], "text": " is this actually going to work?"}, {"timestamp": [1576.6, 1578.06], "text": " Are these going to fit together?"}, {"timestamp": [1578.06, 1580.2], "text": " Is this nail going to stick through?"}, {"timestamp": [1580.2, 1585.0], "text": " So, it's... we're trying to replicate that internal monologue."}, {"timestamp": [1585.0, 1586.0], "text": " Excellent."}, {"timestamp": [1586.0, 1587.0], "text": " Excellent."}, {"timestamp": [1587.0, 1592.84], "text": " So it shouldn't theoretically take any jobs from any developers anytime soon."}, {"timestamp": [1592.84, 1596.36], "text": " At least not any more than ChatGPT is already a good read of."}, {"timestamp": [1596.36, 1597.36], "text": " Sure."}, {"timestamp": [1597.36, 1598.36], "text": " Sure."}, {"timestamp": [1598.36, 1599.36], "text": " Right."}, {"timestamp": [1599.36, 1600.36], "text": " Right."}, {"timestamp": [1600.36, 1604.56], "text": " But the point is that you have a self-reflection and kind of a set of metacognitive functions"}, {"timestamp": [1604.56, 1606.6], "text": " that are evaluating what it's doing"}, {"timestamp": [1606.6, 1609.44], "text": " and it's thinking through what it's doing every step of the way iteratively."}, {"timestamp": [1609.44, 1610.44], "text": " All right, cool."}, {"timestamp": [1610.44, 1611.44], "text": " That's right."}, {"timestamp": [1611.44, 1612.44], "text": " So take it away."}, {"timestamp": [1612.44, 1615.32], "text": " I think you said you wanted to move over to personas or something else?"}, {"timestamp": [1615.32, 1616.32], "text": " Yeah."}, {"timestamp": [1616.32, 1623.16], "text": " So, well, you were asking about how these all interconnect."}, {"timestamp": [1623.16, 1628.72], "text": " So I've got the personason file pulled up here."}, {"timestamp": [1628.72, 1634.4], "text": " The primary goal is for anybody who's"}, {"timestamp": [1634.4, 1636.08], "text": " just picking the software up that"}, {"timestamp": [1636.08, 1639.04], "text": " doesn't want to learn how to program,"}, {"timestamp": [1639.04, 1641.2], "text": " the most that they're ever going to"}, {"timestamp": [1641.2, 1643.04], "text": " have to touch if they just use the"}, {"timestamp": [1643.04, 1645.84], "text": " pre-existing agents is this"}, {"timestamp": [1645.84, 1649.48], "text": " file and the main loop."}, {"timestamp": [1649.48, 1652.76], "text": " So this file is where we set down our prompt."}, {"timestamp": [1652.76, 1662.4], "text": " So you know, the system prompt is just like the system prompt in OpenAI, and then these"}, {"timestamp": [1662.4, 1666.0], "text": " other prompts go in as user prompts."}, {"timestamp": [1666.0, 1676.0], "text": " So, we're taking, kind of like the way that you send chat history into chat GPT-4"}, {"timestamp": [1676.0, 1680.0], "text": " when you're using a Homebot."}, {"timestamp": [1680.0, 1696.0], "text": " In the same way, we're using these variables here to inject data from other agents into this bot in a human readable format."}, {"timestamp": [1696.0, 1707.4], "text": " And then every bot we can set whether it's going to use GPT 3.5 or 3.4. The plan is to also be able to leverage local models if you're"}, {"timestamp": [1707.4, 1714.08], "text": " running UBA or you know you we can we eventually plan to incorporate"}, {"timestamp": [1714.08, 1730.0], "text": " hugging face and you know maybe maybe at some point Lang, we'll see. But each agent gets its own parameters for sending to the"}, {"timestamp": [1731.44, 1746.76], "text": " language model. And we can't minimize here, but each agent has its prompt exposed without any code."}, {"timestamp": [1746.76, 1751.8], "text": " Then of course, the main loop is so simple."}, {"timestamp": [1751.88, 1755.64], "text": " Where is salience? So here's salience."}, {"timestamp": [1755.64, 1761.76], "text": " So if you ignore the beginning section here,"}, {"timestamp": [1761.76, 1767.28], "text": " you can see that our entire loop is five lines of code,"}, {"timestamp": [1767.28, 1777.64], "text": " plus comments. And, you know, it's super simple for anybody to kind of go in and"}, {"timestamp": [1777.64, 1790.94], "text": " build this, you know, this logic loop. One issue right now is that the, where are you?"}, {"timestamp": [1790.94, 1795.7], "text": " So, this salient agent run kind of has agents embedded in it,"}, {"timestamp": [1795.7, 1802.0], "text": " so you can't modify it, but you can also just use those agents"}, {"timestamp": [1802.0, 1803.1], "text": " outright."}, {"timestamp": [1803.1, 1811.0], "text": " So, our mainpy function, this is actually, this is actually the"}, {"timestamp": [1811.0, 1820.3], "text": " architecture of baby AGI that's been rebuilt into our system. So you can, you"}, {"timestamp": [1820.3, 1830.7], "text": " know, you have a really simple starting point. Right. And then when you go into the agents,"}, {"timestamp": [1830.7, 1833.8], "text": " like that's getting a little bit more complex,"}, {"timestamp": [1833.8, 1839.58], "text": " but you should be able to also build agents"}, {"timestamp": [1839.58, 1848.64], "text": " without having to dig into the rest of the code base."}, {"timestamp": [1850.8, 1856.7], "text": " The loop of the agent could all be self-contained,"}, {"timestamp": [1856.7, 1862.48], "text": " and most of these functions are already templated out for you."}, {"timestamp": [1862.48, 1864.74], "text": " So it's almost plug and play."}, {"timestamp": [1864.74, 1868.88], "text": " We're not there yet, but we're slowly organizing things."}, {"timestamp": [1868.88, 1872.4], "text": " So let's talk about this architecture real quick"}, {"timestamp": [1872.4, 1877.2], "text": " because you've got several layers of nested loops."}, {"timestamp": [1877.2, 1880.92], "text": " You've got a modular and configurable architecture."}, {"timestamp": [1880.92, 1883.2], "text": " And like you said, the goal is to get to plug and play,"}, {"timestamp": [1883.2, 1884.8], "text": " and you're almost there."}, {"timestamp": [1884.8, 1892.0], "text": " So talk us through a little bit about how you came to some of these architectural decisions,"}, {"timestamp": [1892.0, 1897.0], "text": " because for someone who's only been coding for three or four weeks, you've kind of unpacked"}, {"timestamp": [1897.0, 1902.76], "text": " a lot of really important concepts and development. And I know that you've had Ansel to help you"}, {"timestamp": [1902.76, 1909.4], "text": " out. So, maybe you can't take full credit and then chat GPT as well."}, {"timestamp": [1909.4, 1916.0], "text": " You guys have ... I see you in chat all day, every day some days."}, {"timestamp": [1916.0, 1930.62], "text": " Talk us through how you came to some of these ideas and what is the overall status of how close are you to having something that is"}, {"timestamp": [1930.62, 1934.34], "text": " it looks like semi-autonomous or fully autonomous."}, {"timestamp": [1934.34, 1938.96], "text": " What are the missing steps and who do you want to get in touch with you and so on and"}, {"timestamp": [1938.96, 1939.96], "text": " so forth?"}, {"timestamp": [1939.96, 1940.96], "text": " Where do you need help?"}, {"timestamp": [1940.96, 1946.92], "text": " Well, you know, if Bill Gates wants to give me a call, I will totally take his call."}, {"timestamp": [1946.92, 1952.88], "text": " I only charge $2,000 an hour, which is pretty cheap."}, {"timestamp": [1952.88, 1958.08], "text": " Considering the loop is there."}, {"timestamp": [1958.08, 1962.84], "text": " The loop is already there, at least when you compare it"}, {"timestamp": [1962.84, 1967.96], "text": " to auto GPT, which kind of has a functioning loop too."}, {"timestamp": [1967.96, 1972.36], "text": " I haven't looked at their stuff since I started this project."}, {"timestamp": [1972.36, 1974.3], "text": " Even before I went,"}, {"timestamp": [1974.3, 1978.56], "text": " like we had ChaosGPT was looping at least."}, {"timestamp": [1978.56, 1981.2], "text": " So, it loops."}, {"timestamp": [1981.2, 1986.0], "text": " So, now what we're doing is expanding functionality,"}, {"timestamp": [1986.0, 1997.0], "text": " and we're expanding compatibility"}, {"timestamp": [1997.0, 1998.0], "text": " with these other systems."}, {"timestamp": [1998.0, 2001.0], "text": " We've got OpenAI working."}, {"timestamp": [2001.0, 2003.0], "text": " We've got UBA working, which should work"}, {"timestamp": [2003.0, 2006.08], "text": " with any other language model."}, {"timestamp": [2006.08, 2008.92], "text": " Chroma is done manually,"}, {"timestamp": [2008.92, 2011.04], "text": " so it doesn't rely on Lang chain."}, {"timestamp": [2011.04, 2013.56], "text": " But if we incorporated Lang chain,"}, {"timestamp": [2013.56, 2019.28], "text": " that would open up functionality in a much broader capacity."}, {"timestamp": [2019.28, 2020.44], "text": " That's right."}, {"timestamp": [2020.44, 2023.44], "text": " Yeah, I was just about to ask for extensibility,"}, {"timestamp": [2023.44, 2026.32], "text": " for instance, can this code, can it talk to APIs? Yeah, go for just about to ask for extensibility, for instance, like, you know, can this output"}, {"timestamp": [2026.32, 2027.92], "text": " code, can it talk to APIs?"}, {"timestamp": [2027.92, 2029.56], "text": " Yeah, go for it, Ansel."}, {"timestamp": [2029.56, 2034.56], "text": " Now that you mention extensibility, that was the main reason for developing this, because"}, {"timestamp": [2034.56, 2039.18], "text": " like I mentioned before, I tried to mess with auto GPT to get it to do something I wanted"}, {"timestamp": [2039.18, 2049.2], "text": " just for testing purposes, and I wasted my time trying to modify it. Because it's, I don't want to say it like the developers"}, {"timestamp": [2049.2, 2051.96], "text": " didn't pay attention to it, but it's just the structure of it"}, {"timestamp": [2051.96, 2055.2], "text": " is not user-friendly at all."}, {"timestamp": [2055.2, 2059.36], "text": " So when we went into this, the main goal"}, {"timestamp": [2059.36, 2063.92], "text": " was to make it extensible, organized, and very easy"}, {"timestamp": [2063.92, 2065.84], "text": " to know what's going on where."}, {"timestamp": [2065.84, 2072.12], "text": " In their defense, I don't think that they were writing auto GPT for other people to"}, {"timestamp": [2072.12, 2079.44], "text": " come in and mess with it and make it do what they wanted."}, {"timestamp": [2079.44, 2092.8], "text": " From the ground up, we've been building this so that other people can come in behind us. And really what we need more than anything is for people to come in and build new agents."}, {"timestamp": [2092.8, 2096.8], "text": " For example, this execution agent right here,"}, {"timestamp": [2096.8, 2109.88], "text": " the execution agent needs to be expanded in a much more broad fashion. The and then we need to work on the task generation."}, {"timestamp": [2109.88, 2110.4], "text": " Right."}, {"timestamp": [2110.4, 2119.28], "text": " So Baby relied heavily on task generation to determine if it had completed a step."}, {"timestamp": [2119.28, 2123.6], "text": " And that ended up with it re-doing a lot of work,"}, {"timestamp": [2123.6, 2124.88], "text": " which we didn't like."}, {"timestamp": [2124.88, 2126.4], "text": " But I think that that could be solved with, And that ended up with it reword, redoing a lot of work which we didn't like,"}, {"timestamp": [2126.4, 2130.26], "text": " but I think that that could be solved with."}, {"timestamp": [2130.26, 2133.78], "text": " With a with."}, {"timestamp": [2133.78, 2136.82], "text": " Set in stone primary goals at"}, {"timestamp": [2136.82, 2140.3], "text": " and allowing it to generate sub goals."}, {"timestamp": [2140.3, 2143.12], "text": " So if somebody wants to take"}, {"timestamp": [2143.12, 2145.0], "text": " a crack at task generation,"}, {"timestamp": [2145.0, 2150.0], "text": " we actually have a kind of prototype outline,"}, {"timestamp": [2150.0, 2155.0], "text": " although we haven't actually done any work on this stage yet."}, {"timestamp": [2155.0, 2164.0], "text": " Those are the two things that we have going forward to improve its capacity,"}, {"timestamp": [2164.0, 2165.92], "text": " is building out"}, {"timestamp": [2165.92, 2171.36], "text": " execution agent, rebuilding this task generation,"}, {"timestamp": [2171.36, 2175.4], "text": " and then a few odds and ends here and there just"}, {"timestamp": [2175.4, 2180.6], "text": " to make it run a little bit more smoothly."}, {"timestamp": [2180.6, 2184.88], "text": " I find that the biggest gains are usually"}, {"timestamp": [2184.88, 2189.96], "text": " from prompt engineering though."}, {"timestamp": [2189.96, 2198.76], "text": " And sometimes even small changes to the text in the persona."}, {"timestamp": [2198.76, 2199.76], "text": " Wording is everything."}, {"timestamp": [2199.76, 2200.76], "text": " Yeah."}, {"timestamp": [2200.76, 2201.76], "text": " Yeah."}, {"timestamp": [2201.76, 2205.76], "text": " Wording is everything. Like let's see if I can find."}, {"timestamp": [2205.76, 2210.4], "text": " Yeah, so here's the status agent, and it just does not."}, {"timestamp": [2213.0, 2213.84], "text": " It's too long."}, {"timestamp": [2213.84, 2214.8], "text": " But yeah."}, {"timestamp": [2214.8, 2215.76], "text": " Too complicated."}, {"timestamp": [2215.76, 2219.36], "text": " We spent a good hour working on the prompt for status agent,"}, {"timestamp": [2219.36, 2223.28], "text": " and ultimately, we still ended up"}, {"timestamp": [2223.28, 2226.58], "text": " having to switch over to GPT-4 for this."}, {"timestamp": [2226.58, 2229.24], "text": " So yeah, the running version that we have"}, {"timestamp": [2229.24, 2232.28], "text": " right now is using two separate language models."}, {"timestamp": [2232.28, 2236.2], "text": " So it can handle multiple language models."}, {"timestamp": [2236.2, 2238.08], "text": " So you've got a lot of"}, {"timestamp": [2238.08, 2242.28], "text": " the extensibility and configurability figured out."}, {"timestamp": [2242.28, 2243.76], "text": " So you mentioned earlier that you're"}, {"timestamp": [2243.76, 2247.46], "text": " getting close to making it plug and play, and like you said,"}, {"timestamp": [2247.46, 2252.46], "text": " all the different agents are configurable just via JSON,"}, {"timestamp": [2252.86, 2256.58], "text": " and you're getting close to adding"}, {"timestamp": [2256.58, 2258.6], "text": " some more extensible things."}, {"timestamp": [2258.6, 2261.46], "text": " So how do people collaborate with you?"}, {"timestamp": [2261.46, 2264.26], "text": " Do you just all go through GitHub?"}, {"timestamp": [2267.0, 2271.68], "text": " If anyone wants to jump in, what's the best way for them to get in touch with you guys?"}, {"timestamp": [2271.68, 2280.28], "text": " We have a project set up in the community project section of the Cognitive AI Discord,"}, {"timestamp": [2280.28, 2288.32], "text": " specifically for agents. But if there's other stuff that you think that that you can contribute to,"}, {"timestamp": [2288.32, 2289.24], "text": " for example,"}, {"timestamp": [2289.24, 2292.04], "text": " we'd love to have a graphical interface."}, {"timestamp": [2292.04, 2292.44], "text": " Right,"}, {"timestamp": [2292.44, 2296.12], "text": " any UI that's similar to Langflow."}, {"timestamp": [2296.12, 2300.76], "text": " Uhm, to to make this even lower code for people."}, {"timestamp": [2300.76, 2303.72], "text": " Uhm? And then you know,"}, {"timestamp": [2303.72, 2311.6], "text": " of course the you know, of course, the, you know, the, if there's a new model that comes out"}, {"timestamp": [2311.6, 2321.8], "text": " or a new host somewhere and they have their own API that isn't OpenAI compatible, writing"}, {"timestamp": [2321.8, 2329.68], "text": " API interfaces for that. So, for example, the current V2 version of"}, {"timestamp": [2329.68, 2336.72], "text": " of the UbaBuga API was not actually written by us."}, {"timestamp": [2336.72, 2341.76], "text": " This was written by..."}, {"timestamp": [2341.84, 2346.0], "text": " that's so strange that he's not listed as a contributor here."}, {"timestamp": [2346.0, 2349.24], "text": " I think his name was Max, though."}, {"timestamp": [2349.24, 2350.8], "text": " It was Max something."}, {"timestamp": [2350.8, 2352.08], "text": " But he wrote-"}, {"timestamp": [2352.08, 2353.48], "text": " I don't remember, but he fixed it."}, {"timestamp": [2353.48, 2357.2], "text": " Yeah. Oh, Michco."}, {"timestamp": [2357.2, 2360.72], "text": " In Michco. So he did get credit for this one,"}, {"timestamp": [2360.72, 2368.02], "text": " but he rewrote the interface for the UbaBuga API, and people"}, {"timestamp": [2368.02, 2371.3], "text": " are out there using this and it's working."}, {"timestamp": [2371.3, 2374.3], "text": " You can see the old codes listed here."}, {"timestamp": [2374.3, 2381.1], "text": " Right, because another thing you can do is also host your local model on a cloud server"}, {"timestamp": [2381.1, 2385.36], "text": " and use the API to connect to it, And you can just run the interface on your phone"}, {"timestamp": [2385.36, 2387.04], "text": " or web browser or whatever."}, {"timestamp": [2387.04, 2387.72], "text": " Interesting."}, {"timestamp": [2387.72, 2394.96], "text": " You can see the endpoint code is listed here as a variable."}, {"timestamp": [2394.96, 2400.48], "text": " And what we'll do later is come in and set this as configurable"}, {"timestamp": [2400.48, 2404.08], "text": " within the INI file."}, {"timestamp": [2404.08, 2409.3], "text": " Oh, yeah, that's something else I should just touch on briefly."}, {"timestamp": [2409.3, 2414.2], "text": " Things like determining which language model you're using,"}, {"timestamp": [2414.2, 2418.4], "text": " which database you wanna use, your embeddings,"}, {"timestamp": [2418.4, 2423.6], "text": " function that you're using, all of that is configurable"}, {"timestamp": [2423.6, 2430.0], "text": " here in the config.ini file as well."}, {"timestamp": [2430.0, 2438.24], "text": " We really tried to get as much of the configuration as we could out of"}, {"timestamp": [2438.24, 2445.0], "text": " the code and into files that people are gonna find useful."}, {"timestamp": [2446.4, 2447.24], "text": " Wonderful."}, {"timestamp": [2447.24, 2449.36], "text": " And be able to assess."}, {"timestamp": [2449.36, 2450.64], "text": " So what's next?"}, {"timestamp": [2450.64, 2452.96], "text": " I know you guys have outlined a lot of open problems"}, {"timestamp": [2452.96, 2454.44], "text": " and some things that you need help with"}, {"timestamp": [2454.44, 2456.52], "text": " and I think there's quite a few people"}, {"timestamp": [2456.52, 2459.38], "text": " that are expressing some interest."}, {"timestamp": [2459.38, 2461.66], "text": " So where do you guys wanna take this project?"}, {"timestamp": [2461.66, 2468.36], "text": " Like what, you know, given a month or six months or if you have 20 people jump in, what do you want it to"}, {"timestamp": [2468.36, 2470.92], "text": " be able to do?"}, {"timestamp": [2470.92, 2476.28], "text": " This weekend, we are taking it to a hackathon."}, {"timestamp": [2476.28, 2487.84], "text": " We don't know what the objective is yet, but our objective is to win the hackathon with this out of left field AGI framework"}, {"timestamp": [2487.84, 2489.6], "text": " that nobody has ever seen before."}, {"timestamp": [2489.6, 2491.36], "text": " There you go."}, {"timestamp": [2491.36, 2502.8], "text": " But beyond that, I'd like to see this just used more broadly."}, {"timestamp": [2504.16, 2507.92], "text": " see this just used more broadly. You know, this is all"}, {"timestamp": [2507.92, 2512.8], "text": " this is all in a what"}, {"timestamp": [2512.8, 2516.96], "text": " about there it is I missed. So this is all"}, {"timestamp": [2516.96, 2520.08], "text": " in the GNU general public license just"}, {"timestamp": [2520.08, 2521.28], "text": " like Linux."}, {"timestamp": [2521.28, 2528.44], "text": " So anybody can take this and use it for commercial purposes with restrictions."}, {"timestamp": [2533.42, 2536.84], "text": " And me personally, I would love to,"}, {"timestamp": [2536.84, 2540.04], "text": " once we get this model pounded out and set in stone,"}, {"timestamp": [2540.04, 2545.0], "text": " I would love to just build bespoke AI cognitive systems"}, {"timestamp": [2546.66, 2550.06], "text": " for companies on either a direct,"}, {"timestamp": [2552.06, 2557.06], "text": " direct to market kind of solution,"}, {"timestamp": [2557.52, 2560.64], "text": " or even in a research capacity."}, {"timestamp": [2562.22, 2567.44], "text": " I've already built some agents, or at least one agent,"}, {"timestamp": [2567.44, 2571.56], "text": " and then made some modifications as well"}, {"timestamp": [2571.56, 2574.8], "text": " to work on the heuristic imperatives project"}, {"timestamp": [2574.8, 2577.56], "text": " that you've got going, Dave."}, {"timestamp": [2577.56, 2581.64], "text": " And I really want to be this."}, {"timestamp": [2581.64, 2584.72], "text": " I want this to be an engine for your project"}, {"timestamp": [2584.72, 2589.0], "text": " so that you can iterate quickly and you don't get hung up"}, {"timestamp": [2589.0, 2595.0], "text": " in the details of working manually"}, {"timestamp": [2595.0, 2601.4], "text": " or having to write your own code for every single little thing"}, {"timestamp": [2601.4, 2602.08], "text": " that you do."}, {"timestamp": [2602.08, 2606.12], "text": " We can just have an agent and plug those agents in,"}, {"timestamp": [2606.12, 2608.56], "text": " spit data at it, and see what comes out."}, {"timestamp": [2608.56, 2610.28], "text": " There you go."}, {"timestamp": [2610.28, 2612.16], "text": " Spin up a whole fleet of them."}, {"timestamp": [2612.16, 2617.72], "text": " Yeah, for me, the ultimate goal is basically empowerment."}, {"timestamp": [2617.72, 2620.36], "text": " Human language has given us the ability"}, {"timestamp": [2620.36, 2623.1], "text": " to do everything we've done up until this point."}, {"timestamp": [2623.1, 2627.04], "text": " And we've basically given that ability to machines now."}, {"timestamp": [2627.04, 2629.08], "text": " And with this kind of architecture,"}, {"timestamp": [2629.08, 2630.64], "text": " we can give that to everybody."}, {"timestamp": [2630.64, 2633.52], "text": " As long as they have a model to run,"}, {"timestamp": [2633.52, 2636.16], "text": " they could have some kind of agent working for them."}, {"timestamp": [2636.16, 2639.44], "text": " So it might sound science fiction or outlandish,"}, {"timestamp": [2639.44, 2642.84], "text": " but it's basically like constructing your own Jarvis,"}, {"timestamp": [2642.84, 2644.2], "text": " right?"}, {"timestamp": [2644.2, 2646.76], "text": " That's the goal. That's the goal."}, {"timestamp": [2648.52, 2651.76], "text": " That's the goal. Yeah, yeah, I do not want to be the person who"}, {"timestamp": [2651.84, 2654.92], "text": " develops the the the next Raven though."}, {"timestamp": [2654.92, 2659.0], "text": " Let me just say that like I'm I'm being part"}, {"timestamp": [2659.08, 2659.68], "text": " of it,"}, {"timestamp": [2659.68, 2663.4], "text": " but the a autonomous assistant is going to be a"}, {"timestamp": [2663.48, 2664.4], "text": " lot of work."}, {"timestamp": [2664.4, 2665.6], "text": " Oh definitely. That's why I said the ultimate goal. a autonomous assistant is going to be a lot of work."}, {"timestamp": [2665.6, 2666.92], "text": " Oh, definitely."}, {"timestamp": [2666.92, 2669.2], "text": " That's why I said the ultimate goal."}, {"timestamp": [2669.2, 2673.0], "text": " Yeah, just looking at what we've done already,"}, {"timestamp": [2673.0, 2677.68], "text": " like a better Siri, for example,"}, {"timestamp": [2677.68, 2681.68], "text": " is a mini person project,"}, {"timestamp": [2681.68, 2684.72], "text": " not just two guys in a garage."}, {"timestamp": [2684.72, 2689.78], "text": " Yeah. Yeah. person project not just two guys in a garage yeah yeah so this is like the"}, {"timestamp": [2689.78, 2696.88], "text": " very first you know 2022 there were very few of us even talking about cognitive"}, {"timestamp": [2696.88, 2703.72], "text": " architecture 2023 hits and suddenly like everyone's a cognitive architect but you"}, {"timestamp": [2703.72, 2708.12], "text": " guys are definitely like lunging ahead forward,"}, {"timestamp": [2708.12, 2710.48], "text": " which is just incredible to see."}, {"timestamp": [2710.48, 2713.56], "text": " So thanks for sharing your work so far."}, {"timestamp": [2713.56, 2715.56], "text": " And I know that you guys have a lot of work"}, {"timestamp": [2715.56, 2718.12], "text": " that you're working on."}, {"timestamp": [2718.12, 2722.46], "text": " It's getting close to being semi-autonomous."}, {"timestamp": [2722.46, 2727.0], "text": " It doesn't quite come up with its own objectives, but it can autonomously"}, {"timestamp": [2727.0, 2728.24], "text": " work through a lot of..."}, {"timestamp": [2728.24, 2729.24], "text": " It's coming."}, {"timestamp": [2729.24, 2731.6], "text": " It's coming, it's coming."}, {"timestamp": [2731.6, 2737.32], "text": " But it can think through open-ended objectives that you give it, which is really incredible."}, {"timestamp": [2737.32, 2746.04], "text": " So any final thoughts from you guys or anyone else before we wrap up tonight's recording?"}, {"timestamp": [2749.26, 2752.84], "text": " Yeah, well, if you had told me in December that I would be diving into a project on GitHub"}, {"timestamp": [2752.84, 2754.54], "text": " about cognitive architecture,"}, {"timestamp": [2754.54, 2756.2], "text": " I would have spat my beer at you."}, {"timestamp": [2757.32, 2761.04], "text": " So everything is changing really fast,"}, {"timestamp": [2761.04, 2764.34], "text": " it's getting really silly, it is impossible to keep up,"}, {"timestamp": [2764.34, 2765.16], "text": " and it's exciting, and it's is impossible to keep up and it's exciting"}, {"timestamp": [2765.16, 2769.32], "text": " and it's just thrilling to be working on this."}, {"timestamp": [2769.32, 2770.72], "text": " Yeah, absolutely."}, {"timestamp": [2770.72, 2779.14], "text": " Yeah, impossibly keep up is definitely the situation right now."}, {"timestamp": [2779.14, 2788.42], "text": " Even with the past week or so where AI news has been relatively slow. There haven't been a whole lot of interviews here lately."}, {"timestamp": [2788.42, 2812.0], "text": " I've still got dozens of tabs open of AI stuff that I just haven't been able to read yet. think that a lot of people are getting way more concerned"}, {"timestamp": [2812.0, 2816.04], "text": " about artificial intelligence than they need to be."}, {"timestamp": [2816.04, 2817.54], "text": " We still need to be concerned."}, {"timestamp": [2817.54, 2820.6], "text": " We need to be working on these things."}, {"timestamp": [2820.6, 2825.0], "text": " But we're not quite in runaway AI yet."}, {"timestamp": [2825.06, 2827.38], "text": " I hate to disagree with you, Dave,"}, {"timestamp": [2827.38, 2832.38], "text": " but if we told AI to build better AI,"}, {"timestamp": [2835.02, 2836.74], "text": " that would be like telling you"}, {"timestamp": [2836.74, 2839.1], "text": " to do brain surgery on yourself."}, {"timestamp": [2839.1, 2841.04], "text": " We're not quite that smart yet."}, {"timestamp": [2841.04, 2843.5], "text": " So we don't need to bomb the data centers?"}, {"timestamp": [2843.5, 2848.44], "text": " No, but we should definitely have bombs in the data centers, just in case."}, {"timestamp": [2848.44, 2850.2], "text": " Just in case, okay."}, {"timestamp": [2850.2, 2854.2], "text": " And local backups for your shows or anything you want to watch after the apocalypse."}, {"timestamp": [2854.2, 2855.2], "text": " So yes."}, {"timestamp": [2855.2, 2856.2], "text": " There you go."}, {"timestamp": [2856.2, 2858.6], "text": " I'll just etch it out on clay tablets."}, {"timestamp": [2858.6, 2864.16], "text": " Alright gang, thanks for everything and definitely keep up the good work."}, {"timestamp": [2864.16, 2866.16], "text": " And yeah, I hope that you get some more folks"}, {"timestamp": [2866.16, 2867.36], "text": " reaching out to you."}, {"timestamp": [2867.36, 2870.02], "text": " We will of course have ongoing updates,"}, {"timestamp": [2870.02, 2872.04], "text": " maybe not weekly, we'll see."}, {"timestamp": [2872.04, 2875.32], "text": " But you know, we're doing more live streams lately"}, {"timestamp": [2875.32, 2876.52], "text": " just to keep everyone up to date"}, {"timestamp": [2876.52, 2879.64], "text": " because as you guys mentioned, it's happening so fast"}, {"timestamp": [2879.64, 2882.08], "text": " and it's good to show people what's possible."}, {"timestamp": [2882.08, 2884.4], "text": " So I'm gonna go ahead and stop the, go ahead."}, {"timestamp": [2886.3, 2893.26], "text": " One more thing, I think that getting everybody involved and talking about this is really the best way"}, {"timestamp": [2893.26, 2894.26], "text": " forward."}, {"timestamp": [2894.26, 2895.26], "text": " Yeah."}, {"timestamp": [2895.26, 2910.92], "text": " Because, you know, up until now, all of the discussion about AI and ethics and morality of AI has been siloed and gatekept by the, you know, a few"}, {"timestamp": [2910.92, 2913.56], "text": " people at these major corporations."}, {"timestamp": [2913.56, 2914.56], "text": " Yeah."}, {"timestamp": [2914.56, 2921.16], "text": " And, you know, you and the communities that you've helped get it off the ground, I think"}, {"timestamp": [2921.16, 2929.0], "text": " has really opened it up and is going to be one of the most important things for the future of AI."}, {"timestamp": [2929.0, 2931.0], "text": " It's definitely already having an impact."}, {"timestamp": [2931.0, 2937.0], "text": " Well, thanks so much, and I'm glad that it's having hopefully a positive impact in the long run."}, {"timestamp": [2937.0, 2939.0], "text": " We'll see."}, {"timestamp": [2939.0, 2945.0], "text": " All right, gang. I'm going to knock off the recording. Have a good night, everybody, and we'll talk again soon."}, {"timestamp": [2945.0, 2946.0], "text": " Cheers."}, {"timestamp": [2946.0, 2947.0], "text": " Hasta luego."}, {"timestamp": [2941.79, 2945.83], "text": " Alright gang, I'm gonna knock off the recording, have a good night everybody, and we'll talk"}, {"timestamp": [2945.83, 2946.83], "text": " again soon."}, {"timestamp": [2946.83, 2947.83], "text": " Cheers!"}, {"timestamp": [2947.83, 2948.33], "text": " Hasta luego!"}]}