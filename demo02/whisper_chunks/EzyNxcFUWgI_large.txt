{"text": " In this video, we're gonna talk about predictions for AGI. Artificial General Intelligence. And you might ask, what's that? Well, imagine that your favorite toy, video game, cartoon character, whatever, could think for itself. It could learn new things without anybody teaching it, understand and chat with you about any topic, and even come up with its own ideas, just like a real person. Well, that's Artificial General Intelligence, AGI. Imagine an AI robot that, instead of being programmed to dance in a specific way, gets upgraded to becoming an AGI robot, meaning that it can invent its own dance moves that have never been seen, and it might even just dance the way that it wants to inside. Then write a song about it and try to get your feedback as it wonders what you think of what it created. But before we dive into what these experts think, I have to give credit and acknowledge Casey Armstrong for writing this blog post. He did a great job compiling what some of the experts think, so I started to use that as a base for this video. And follow all of his VR updates on X at crowdsourcingkc. So let's start with Elon Musk. Way back in 2016, he said five to 10 years is what he thought it would take before we had AGI. In the same interview, he said, \"'AI is far more advanced than people realize and the advancements are going to be exponential. So that's where he got that 5 to 10 year frame from and we're right in the middle of that prediction today in 2023. But we can get another clue from some statements he made during the founding of OpenAI back in 2015 where he talked about wanting to build this global nonprofit to help protect humanity from AGI and that he felt a strong need to build this company right now because it's in the near future. Also just reading between the lines a lot of the urgency Musk has about regulation and concerns and worries and the fact that in 2017 he said that we need AI regulation in place yesterday gives me the impression that he's worried about it happening really soon. Next up let's talk about Dr. Alan D Thompson. He's probably the most interesting person on this list because he actually has a timeline where he really documents each percentage point. So on this website lifearchitect.ai you can see Dr. Alan's conservative countdown to AI and where we're at 54% right now. I love this timeline because you can actually see all of his updates, the date they were made, and why he ratchets up or down the percentages the way that he does. But the big conclusion is that Dr. Alan D. Thompson thinks that Artificial General Intelligence is coming in June of 2026. That means we gotta start thinking about AGI in terms of months, not years. And to back up his claim, he talks about how GPT-4 can pass so many general human intelligence tests. He cites the fact that, generally speaking, GPT-4 gets about 152 IQ points when tested, and references AI researchers like Alan Turing and Nick Bostrom to argue that AI might already contain some kind of a consciousness or a soul if we really think deeply about it. Also, as a result of actually inventing, maybe what they would call man's last invention, something that can invent on its own, he draws the conclusion that there will be tech companies that are worth well over $100 trillion in the future. That'll be due to AI's contribution to the company, allowing them to make money in many verticals at the same time and have these things basically run 24-7, superhumans, infinite amount of employees, as many as you want to spin up on the hardware. Now to get to this AGI, it also has to be embodied in robots, but if it wasn't for that, this percentage might even be higher. So with an 80% confidence, he believes that in July of 2025, we might come across AGI. And then you have to jump forward to about June of 2026 before you hit the main prediction without the confidence interval. All right, another big name on the list, the other half of the cage fight. What do you guys think about Mark Zuckerberg? Now he's expressed his views on artificial intelligence several times, but of course he hasn't given us like a specific date to hold him to. He's a smart CEO like that. But it's safe to say that he's more optimistic and less worried about the bad outcomes, which makes me think that he thinks about AGI, at least the negative consequences of it, being quite far away. Like anytime you bring up the question with him he gives you this optimistic world where he can make this big difference in health care and education and if we make it freely open the open-source community can do all these great things with it without the red tape of government and big companies and never really mentioning the problems with the llama 2 and soon-to-be llama 3 model being open source that can be used for all sorts of negative mischievous things. For example when asked to contrast his view to some of the warnings Elon Musk had, Zuck in stark contrast to Elon said that these were overly pessimistic views and that we need to start focusing on the social benefits. David Shapiro believes that AGI, Artificial General Intelligence, will be achieved within 18 months. So he points to the recent Morgan Stanley report, where they did a deep dive into how NVIDIA really sees AGI as a long-term winner for their company, having serious business implications, like the kind that you can have for the foreseeable future in terms of profit. He also talks about how open source models and alternatives like Anthropx Cloud are actually just advancing at rapid pace, how tools like Langflow have showed up to make an easy GUI interface for people to work with this stuff, and how there's experiments with things like constitutional AI, basically an AI that has another AI that watches it so they can kind of play off each other in a reinforcing kind of feedback loop. And as all that comes together this thing can just really take off. That's why within 18 months we might see something so much more powerful than what we have now. And he talks about how we've already planted the seed for some of these autonomous agents too, to just go out there and churn away at problems 24-7. Okay, so here's a name, you might not know it, but it's Demis Hassabis. And if you don't, it's because you know the parent company from DeepMind, which is called Google. Actually, the parent company's Alphabet, but they're all part of the same umbrella. But needless to say, Demis Hassabis is the guy. He's the person who's in charge of the division inside of Google that has done the major AI breakthroughs over the last decade. And their mission is actually to create AGI, to create intelligence and then let intelligence go on and solve all the other problems. He's also one of the few people that recently has made a prediction. So this year in May of 2023 he actually did an interview with the Wall Street Journal and said that he believes AGI could be achieved within a few years. So I take that as three years. And if I could summarize it, it seemed like what he was saying his reasoning was, was that we've maybe done some of the biggest breakthroughs that we need to in terms of understanding if it's possible. And now it's more of a how much data can you push in there? How much bigger can you make the models? How much better can you engineer the specifics? And that kind of thing is so clear and the outcome's so clear and the money is there when you solve it, everybody's attacking it. So he thinks, okay, now we just have to sort of wait for all of that to smooth itself out. He's also known for always making the distinction when you talk about AVE GI saying, you know, there's a difference between intelligence and consciousness. Seems like he gets frustrated with people confusing the two or something. But he stresses that even if it's not conscious just the intelligence system that is not a self-aware and not something we need to get rights to could still easily become generally intelligent just like us. So we don't need to wait for consciousness to actually start treating it that way. Now of course his frenemy arch rival slash probably partner in some ways Sam Altman who's the CEO of OpenAI and created the GPT-4 model that powers chat GPT, said back in 2016 that he gauged a 5 to 10% likelihood of AGI materializing within 5 years. So 5 to 10% we'll use our Bayesian thinking here, but a small percentage of the chance that it happens within 5 to 10 years. So that was a while ago, but if that number still holds, that would be even by like 2026, he thinks there's a 10% chance we achieve it. But he had a little bit of an update, one that we can kind of look into when he was on the Tim Ferriss podcast in 2022, because on that podcast, he had optimism that it would happen within 10 to 20 years. So 2022, jumping to 2032, and then the decade after that, he thinks that's when it's gonna happen. When asked just the right way, he does sort of seem to say, it's probably gonna happen in my lifetime, but there's so much uncertainty, I hate to put a date anywhere because just predicting times is so hard. Now, one of his close competitors, the CEO of Anthropic, who actually was part of OpenAI at one point, and went on, branched out into his own company, and they're doing great, huge models like Clawed, he was just on a long- form podcast that addressed this also. And he thinks that an AGI or at least an AI system that is generally well educated like a human is probably only two or three years away. So we can put his prediction at 2026. And along with that prediction, he put together internally what's happening at Anthropic and across the industry, just how swiftly these things are being upgraded and changing. And that there's these emergent properties, like when they were working with GPT-3 and GPT-35 turbo, and how like mathematical ability sort of popped into existence, some of that emergence, and how we don't really know when that happens, but if we continue down this path, we should expect more and more emergence at some point. And considering how fast the progress is going, and that all sorts of different new people are now kind of honed in on the same problem, it might get faster and faster and faster. And of course we have to talk about Ray Kurzweil because he's just been making specific dates for so long. He's like the modern day Nostradamus. And you know, he does miss some dates, but he is actually pretty accurate in a lot of them too. And his line of thinking with exponentials is important. So let's go over it. So way earlier than anyone else on this list, but back in 1999, he predicted that AI would pass the Turing test by 2029. Now the Turing test is just a text-based test. It seems like ChatGBT would pass that with flying colors to me. But if you want to take a more advanced version of that where it tricks you maybe in a more multimodal way where you think about the video and the audio and things like that, I think that could be achievable by 2029. Ray Kurzweil points out that even today's best LLM models, the large language models like chat GPT still sometimes do things that a human wouldn't do. So he can kind of tell us. Ray Kurzweil, 2029. Oh, and by the way, that's about the same time this video from Ray Kurzweil's prediction says that we're gonna figure out how to stop aging. Immortality, anyone? So that said, where do I fall on the spectrum of when we're gonna see AGI? Well I think that it's already arrived and that it's in the past. I just feel like the way the average person thinks about AGI just isn't reflective of what general intelligence actually is. My guess is that if you ask somebody like random on the street is this AGI they're not gonna see it as AGI until it's like embodied in a robot. And one that they're kind of comfortable around, maybe at the grocery store, stocking shelves, talking with customers, making their food, then they're going to be like, oh, AGI, I kind of, I get it, this is pretty much like having a human, these robots around. But at that point, we're gonna be so far past AGI, you should call it ASI, going from artificial general intelligence to artificial super intelligence. My argument is that as soon as you see it, it's too late. It happened quite a while ago. We have to look at the nuance to really understand if it's generally intelligent, and we can find that nuance right now in chat GPT. We know a human brain is generally intelligent because that's literally what we're comparing it to. But if a human brain was inside of a computer and it was limited in the same way that chat GPT is, just to like text and all that stuff, I bet it wouldn't even perform as well. And there's no way we would think that's generally intelligent, but it is once it's embodied in the three-dimensional body that we have and it's connected to our hormones and all of that stuff. And that's a different question. If you want to say that chat GPT is generally intelligent, but we need to wait for it to show up in sort of a robot and be trained on enough data to like move the robot around, then that's not it. That's already the same weights, the same model that we have right now that is generally intelligent. It's just missing some of its functionality. So let me know your prediction for when we're gonna get AGI in the comments below. Help me get to 6,000 subscribers. Smash that subscribe button. Help me get to 6,000 subscribers. Smash that subscribe button.", "chunks": [{"timestamp": [0.0, 4.4], "text": " In this video, we're gonna talk about predictions for AGI."}, {"timestamp": [4.4, 6.48], "text": " Artificial General Intelligence."}, {"timestamp": [6.48, 7.72], "text": " And you might ask, what's that?"}, {"timestamp": [7.72, 9.64], "text": " Well, imagine that your favorite toy, video game,"}, {"timestamp": [9.64, 12.32], "text": " cartoon character, whatever, could think for itself."}, {"timestamp": [12.32, 14.48], "text": " It could learn new things without anybody teaching it,"}, {"timestamp": [14.48, 16.88], "text": " understand and chat with you about any topic,"}, {"timestamp": [16.88, 18.84], "text": " and even come up with its own ideas,"}, {"timestamp": [18.84, 20.28], "text": " just like a real person."}, {"timestamp": [20.28, 23.64], "text": " Well, that's Artificial General Intelligence, AGI."}, {"timestamp": [23.64, 24.92], "text": " Imagine an AI robot that,"}, {"timestamp": [24.92, 27.52], "text": " instead of being programmed to dance in a specific way, gets"}, {"timestamp": [27.52, 31.84], "text": " upgraded to becoming an AGI robot, meaning that it can invent its own dance moves that"}, {"timestamp": [31.84, 35.84], "text": " have never been seen, and it might even just dance the way that it wants to inside."}, {"timestamp": [35.84, 39.06], "text": " Then write a song about it and try to get your feedback as it wonders what you think"}, {"timestamp": [39.06, 40.06], "text": " of what it created."}, {"timestamp": [40.06, 44.14], "text": " But before we dive into what these experts think, I have to give credit and acknowledge"}, {"timestamp": [44.14, 45.76], "text": " Casey Armstrong"}, {"timestamp": [45.76, 47.52], "text": " for writing this blog post."}, {"timestamp": [47.52, 48.82], "text": " He did a great job compiling"}, {"timestamp": [48.82, 49.96], "text": " what some of the experts think,"}, {"timestamp": [49.96, 52.2], "text": " so I started to use that as a base for this video."}, {"timestamp": [52.2, 56.18], "text": " And follow all of his VR updates on X at crowdsourcingkc."}, {"timestamp": [56.18, 58.12], "text": " So let's start with Elon Musk."}, {"timestamp": [58.12, 60.88], "text": " Way back in 2016, he said five to 10 years"}, {"timestamp": [60.88, 63.18], "text": " is what he thought it would take before we had AGI."}, {"timestamp": [63.18, 64.76], "text": " In the same interview, he said,"}, {"timestamp": [64.76, 67.96], "text": " \"'AI is far more advanced than people realize and the"}, {"timestamp": [67.96, 72.0], "text": " advancements are going to be exponential. So that's where he got that 5 to 10 year"}, {"timestamp": [72.0, 76.38], "text": " frame from and we're right in the middle of that prediction today in 2023. But we"}, {"timestamp": [76.38, 79.4], "text": " can get another clue from some statements he made during the founding"}, {"timestamp": [79.4, 83.82], "text": " of OpenAI back in 2015 where he talked about wanting to build this global"}, {"timestamp": [83.82, 88.56], "text": " nonprofit to help protect humanity from AGI and that he felt a strong need to build this"}, {"timestamp": [88.56, 91.68], "text": " company right now because it's in the near future. Also just reading between"}, {"timestamp": [91.68, 95.56], "text": " the lines a lot of the urgency Musk has about regulation and concerns and"}, {"timestamp": [95.56, 100.16], "text": " worries and the fact that in 2017 he said that we need AI regulation in place"}, {"timestamp": [100.16, 103.44], "text": " yesterday gives me the impression that he's worried about it happening really"}, {"timestamp": [103.44, 107.2], "text": " soon. Next up let's talk about Dr. Alan D Thompson. He's probably the most"}, {"timestamp": [107.2, 110.64], "text": " interesting person on this list because he actually has a timeline where he"}, {"timestamp": [110.64, 115.4], "text": " really documents each percentage point. So on this website lifearchitect.ai you"}, {"timestamp": [115.4, 120.24], "text": " can see Dr. Alan's conservative countdown to AI and where we're at 54%"}, {"timestamp": [120.24, 123.76], "text": " right now. I love this timeline because you can actually see all of his updates,"}, {"timestamp": [123.76, 127.96], "text": " the date they were made, and why he ratchets up or down the percentages the way that he does."}, {"timestamp": [127.96, 131.7], "text": " But the big conclusion is that Dr. Alan D. Thompson thinks that Artificial General Intelligence"}, {"timestamp": [131.7, 134.28], "text": " is coming in June of 2026."}, {"timestamp": [134.28, 138.48], "text": " That means we gotta start thinking about AGI in terms of months, not years."}, {"timestamp": [138.48, 143.16], "text": " And to back up his claim, he talks about how GPT-4 can pass so many general human intelligence"}, {"timestamp": [143.16, 144.16], "text": " tests."}, {"timestamp": [144.16, 149.44], "text": " He cites the fact that, generally speaking, GPT-4 gets about 152 IQ points when tested,"}, {"timestamp": [149.44, 154.14], "text": " and references AI researchers like Alan Turing and Nick Bostrom to argue that AI might already"}, {"timestamp": [154.14, 158.08], "text": " contain some kind of a consciousness or a soul if we really think deeply about it."}, {"timestamp": [158.08, 162.28], "text": " Also, as a result of actually inventing, maybe what they would call man's last invention,"}, {"timestamp": [162.28, 166.08], "text": " something that can invent on its own, he draws the conclusion that there will be tech companies"}, {"timestamp": [166.08, 169.56], "text": " that are worth well over $100 trillion in the future."}, {"timestamp": [169.56, 172.32], "text": " That'll be due to AI's contribution to the company,"}, {"timestamp": [172.32, 174.4], "text": " allowing them to make money in many verticals"}, {"timestamp": [174.4, 176.72], "text": " at the same time and have these things basically run"}, {"timestamp": [176.72, 179.7], "text": " 24-7, superhumans, infinite amount of employees,"}, {"timestamp": [179.7, 181.56], "text": " as many as you want to spin up on the hardware."}, {"timestamp": [181.56, 184.0], "text": " Now to get to this AGI, it also has to be embodied"}, {"timestamp": [184.0, 185.64], "text": " in robots, but if it wasn't for that,"}, {"timestamp": [185.64, 187.4], "text": " this percentage might even be higher."}, {"timestamp": [187.4, 188.88], "text": " So with an 80% confidence,"}, {"timestamp": [188.88, 191.52], "text": " he believes that in July of 2025,"}, {"timestamp": [191.52, 193.48], "text": " we might come across AGI."}, {"timestamp": [195.24, 198.48], "text": " And then you have to jump forward to about June of 2026"}, {"timestamp": [198.48, 200.16], "text": " before you hit the main prediction"}, {"timestamp": [200.16, 201.52], "text": " without the confidence interval."}, {"timestamp": [201.52, 202.8], "text": " All right, another big name on the list,"}, {"timestamp": [202.8, 204.12], "text": " the other half of the cage fight."}, {"timestamp": [204.12, 206.56], "text": " What do you guys think about Mark Zuckerberg?"}, {"timestamp": [206.56, 207.84], "text": " Now he's expressed his views"}, {"timestamp": [207.84, 209.8], "text": " on artificial intelligence several times,"}, {"timestamp": [209.8, 211.08], "text": " but of course he hasn't given us"}, {"timestamp": [211.08, 212.72], "text": " like a specific date to hold him to."}, {"timestamp": [212.72, 214.3], "text": " He's a smart CEO like that."}, {"timestamp": [214.3, 216.44], "text": " But it's safe to say that he's more optimistic"}, {"timestamp": [216.44, 218.4], "text": " and less worried about the bad outcomes,"}, {"timestamp": [218.4, 220.76], "text": " which makes me think that he thinks about AGI,"}, {"timestamp": [220.76, 222.36], "text": " at least the negative consequences of it,"}, {"timestamp": [222.36, 223.88], "text": " being quite far away."}, {"timestamp": [223.88, 225.72], "text": " Like anytime you bring up the question with him"}, {"timestamp": [225.72, 231.2], "text": " he gives you this optimistic world where he can make this big difference in health care and education and if we make it freely open"}, {"timestamp": [231.2, 236.68], "text": " the open-source community can do all these great things with it without the red tape of government and big companies and never really mentioning the"}, {"timestamp": [236.84, 243.52], "text": " problems with the llama 2 and soon-to-be llama 3 model being open source that can be used for all sorts of negative mischievous things."}, {"timestamp": [243.52, 248.68], "text": " For example when asked to contrast his view to some of the warnings Elon Musk had, Zuck"}, {"timestamp": [248.68, 252.84], "text": " in stark contrast to Elon said that these were overly pessimistic views and that we"}, {"timestamp": [252.84, 255.68], "text": " need to start focusing on the social benefits."}, {"timestamp": [255.68, 260.78], "text": " David Shapiro believes that AGI, Artificial General Intelligence, will be achieved within"}, {"timestamp": [260.78, 262.52], "text": " 18 months."}, {"timestamp": [262.52, 265.16], "text": " So he points to the recent Morgan Stanley report,"}, {"timestamp": [265.16, 268.32], "text": " where they did a deep dive into how NVIDIA really sees AGI"}, {"timestamp": [268.32, 270.44], "text": " as a long-term winner for their company,"}, {"timestamp": [270.44, 272.62], "text": " having serious business implications,"}, {"timestamp": [272.62, 274.88], "text": " like the kind that you can have for the foreseeable future"}, {"timestamp": [274.88, 275.92], "text": " in terms of profit."}, {"timestamp": [275.92, 278.68], "text": " He also talks about how open source models and alternatives"}, {"timestamp": [278.68, 280.96], "text": " like Anthropx Cloud are actually just advancing"}, {"timestamp": [280.96, 283.8], "text": " at rapid pace, how tools like Langflow have showed up"}, {"timestamp": [283.8, 286.84], "text": " to make an easy GUI interface for people to work with this stuff, and how there's"}, {"timestamp": [286.84, 290.76], "text": " experiments with things like constitutional AI, basically an AI that"}, {"timestamp": [290.76, 293.6], "text": " has another AI that watches it so they can kind of play off each other in a"}, {"timestamp": [293.6, 297.54], "text": " reinforcing kind of feedback loop. And as all that comes together this thing can"}, {"timestamp": [297.54, 301.0], "text": " just really take off. That's why within 18 months we might see something so much"}, {"timestamp": [301.0, 303.56], "text": " more powerful than what we have now. And he talks about how we've already planted"}, {"timestamp": [303.56, 305.6], "text": " the seed for some of these autonomous agents too,"}, {"timestamp": [305.6, 308.24], "text": " to just go out there and churn away at problems 24-7."}, {"timestamp": [308.24, 309.8], "text": " Okay, so here's a name, you might not know it,"}, {"timestamp": [309.8, 311.48], "text": " but it's Demis Hassabis."}, {"timestamp": [311.48, 313.88], "text": " And if you don't, it's because you know the parent company"}, {"timestamp": [313.88, 316.0], "text": " from DeepMind, which is called Google."}, {"timestamp": [316.0, 317.56], "text": " Actually, the parent company's Alphabet,"}, {"timestamp": [317.56, 319.54], "text": " but they're all part of the same umbrella."}, {"timestamp": [319.54, 322.28], "text": " But needless to say, Demis Hassabis is the guy."}, {"timestamp": [322.28, 324.56], "text": " He's the person who's in charge of the division"}, {"timestamp": [324.56, 328.24], "text": " inside of Google that has done the major AI breakthroughs over the last decade."}, {"timestamp": [328.24, 332.24], "text": " And their mission is actually to create AGI, to create intelligence and then let"}, {"timestamp": [332.24, 335.4], "text": " intelligence go on and solve all the other problems. He's also one of the few"}, {"timestamp": [335.4, 339.8], "text": " people that recently has made a prediction. So this year in May of 2023"}, {"timestamp": [339.8, 342.88], "text": " he actually did an interview with the Wall Street Journal and said that he"}, {"timestamp": [342.88, 347.2], "text": " believes AGI could be achieved within a few years."}, {"timestamp": [347.2, 349.2], "text": " So I take that as three years."}, {"timestamp": [349.2, 350.36], "text": " And if I could summarize it,"}, {"timestamp": [350.36, 352.44], "text": " it seemed like what he was saying his reasoning was,"}, {"timestamp": [352.44, 355.34], "text": " was that we've maybe done some of the biggest breakthroughs"}, {"timestamp": [355.34, 358.0], "text": " that we need to in terms of understanding if it's possible."}, {"timestamp": [358.0, 361.52], "text": " And now it's more of a how much data can you push in there?"}, {"timestamp": [361.52, 363.28], "text": " How much bigger can you make the models?"}, {"timestamp": [363.28, 365.72], "text": " How much better can you engineer the specifics?"}, {"timestamp": [365.72, 367.8], "text": " And that kind of thing is so clear"}, {"timestamp": [367.8, 369.08], "text": " and the outcome's so clear"}, {"timestamp": [369.08, 370.52], "text": " and the money is there when you solve it,"}, {"timestamp": [370.52, 371.7], "text": " everybody's attacking it."}, {"timestamp": [371.7, 373.88], "text": " So he thinks, okay, now we just have to sort of wait"}, {"timestamp": [373.88, 375.64], "text": " for all of that to smooth itself out."}, {"timestamp": [375.64, 377.62], "text": " He's also known for always making the distinction"}, {"timestamp": [377.62, 379.0], "text": " when you talk about AVE GI saying,"}, {"timestamp": [379.0, 379.92], "text": " you know, there's a difference"}, {"timestamp": [379.92, 381.92], "text": " between intelligence and consciousness."}, {"timestamp": [381.92, 382.96], "text": " Seems like he gets frustrated"}, {"timestamp": [382.96, 384.44], "text": " with people confusing the two or something."}, {"timestamp": [384.44, 386.38], "text": " But he stresses that even if it's not conscious"}, {"timestamp": [386.38, 390.5], "text": " just the intelligence system that is not a self-aware and not something we need"}, {"timestamp": [390.5, 394.34], "text": " to get rights to could still easily become generally intelligent just like"}, {"timestamp": [394.34, 397.06], "text": " us. So we don't need to wait for consciousness to actually start treating"}, {"timestamp": [397.06, 400.62], "text": " it that way. Now of course his frenemy arch rival slash probably partner in"}, {"timestamp": [400.62, 411.0], "text": " some ways Sam Altman who's the CEO of OpenAI and created the GPT-4 model that powers chat GPT, said back in 2016 that he gauged a 5 to 10%"}, {"timestamp": [411.0, 417.12], "text": " likelihood of AGI materializing within 5 years. So 5 to 10% we'll use our"}, {"timestamp": [417.12, 421.48], "text": " Bayesian thinking here, but a small percentage of the chance that it happens"}, {"timestamp": [421.48, 425.04], "text": " within 5 to 10 years. So that was a while ago, but if that number still holds,"}, {"timestamp": [425.04, 426.92], "text": " that would be even by like 2026,"}, {"timestamp": [426.92, 429.0], "text": " he thinks there's a 10% chance we achieve it."}, {"timestamp": [429.0, 430.44], "text": " But he had a little bit of an update,"}, {"timestamp": [430.44, 431.72], "text": " one that we can kind of look into"}, {"timestamp": [431.72, 434.72], "text": " when he was on the Tim Ferriss podcast in 2022,"}, {"timestamp": [434.72, 437.04], "text": " because on that podcast, he had optimism"}, {"timestamp": [437.04, 439.56], "text": " that it would happen within 10 to 20 years."}, {"timestamp": [439.56, 444.0], "text": " So 2022, jumping to 2032, and then the decade after that,"}, {"timestamp": [444.0, 445.32], "text": " he thinks that's when it's gonna happen."}, {"timestamp": [445.32, 446.48], "text": " When asked just the right way,"}, {"timestamp": [446.48, 447.56], "text": " he does sort of seem to say,"}, {"timestamp": [447.56, 449.08], "text": " it's probably gonna happen in my lifetime,"}, {"timestamp": [449.08, 450.66], "text": " but there's so much uncertainty,"}, {"timestamp": [450.66, 451.84], "text": " I hate to put a date anywhere"}, {"timestamp": [451.84, 454.12], "text": " because just predicting times is so hard."}, {"timestamp": [454.12, 455.6], "text": " Now, one of his close competitors,"}, {"timestamp": [455.6, 456.76], "text": " the CEO of Anthropic,"}, {"timestamp": [456.76, 459.28], "text": " who actually was part of OpenAI at one point,"}, {"timestamp": [459.28, 461.14], "text": " and went on, branched out into his own company,"}, {"timestamp": [461.14, 463.44], "text": " and they're doing great, huge models like Clawed,"}, {"timestamp": [463.44, 466.72], "text": " he was just on a long- form podcast that addressed this also."}, {"timestamp": [466.72, 471.84], "text": " And he thinks that an AGI or at least an AI system that is generally well educated like"}, {"timestamp": [471.84, 474.96], "text": " a human is probably only two or three years away."}, {"timestamp": [474.96, 478.02], "text": " So we can put his prediction at 2026."}, {"timestamp": [478.02, 481.56], "text": " And along with that prediction, he put together internally what's happening at Anthropic and"}, {"timestamp": [481.56, 485.58], "text": " across the industry, just how swiftly these things are being upgraded and changing."}, {"timestamp": [485.58, 487.14], "text": " And that there's these emergent properties,"}, {"timestamp": [487.14, 491.24], "text": " like when they were working with GPT-3 and GPT-35 turbo,"}, {"timestamp": [491.24, 493.94], "text": " and how like mathematical ability sort of popped"}, {"timestamp": [493.94, 495.56], "text": " into existence, some of that emergence,"}, {"timestamp": [495.56, 497.42], "text": " and how we don't really know when that happens,"}, {"timestamp": [497.42, 498.88], "text": " but if we continue down this path,"}, {"timestamp": [498.88, 501.36], "text": " we should expect more and more emergence at some point."}, {"timestamp": [501.36, 503.72], "text": " And considering how fast the progress is going,"}, {"timestamp": [503.72, 505.42], "text": " and that all sorts of different new people"}, {"timestamp": [505.42, 507.56], "text": " are now kind of honed in on the same problem,"}, {"timestamp": [507.56, 508.88], "text": " it might get faster and faster and faster."}, {"timestamp": [508.88, 510.44], "text": " And of course we have to talk about Ray Kurzweil"}, {"timestamp": [510.44, 513.16], "text": " because he's just been making specific dates for so long."}, {"timestamp": [513.16, 514.64], "text": " He's like the modern day Nostradamus."}, {"timestamp": [514.64, 516.48], "text": " And you know, he does miss some dates,"}, {"timestamp": [516.48, 518.54], "text": " but he is actually pretty accurate in a lot of them too."}, {"timestamp": [518.54, 520.92], "text": " And his line of thinking with exponentials is important."}, {"timestamp": [520.92, 521.76], "text": " So let's go over it."}, {"timestamp": [521.76, 523.4], "text": " So way earlier than anyone else on this list,"}, {"timestamp": [523.4, 527.0], "text": " but back in 1999, he predicted that AI"}, {"timestamp": [527.0, 530.16], "text": " would pass the Turing test by 2029."}, {"timestamp": [530.16, 532.52], "text": " Now the Turing test is just a text-based test."}, {"timestamp": [532.52, 534.32], "text": " It seems like ChatGBT would pass that"}, {"timestamp": [534.32, 535.44], "text": " with flying colors to me."}, {"timestamp": [535.44, 537.42], "text": " But if you want to take a more advanced version of that"}, {"timestamp": [537.42, 539.8], "text": " where it tricks you maybe in a more multimodal way"}, {"timestamp": [539.8, 541.48], "text": " where you think about the video and the audio"}, {"timestamp": [541.48, 543.32], "text": " and things like that, I think that could be achievable"}, {"timestamp": [543.32, 544.32], "text": " by 2029."}, {"timestamp": [544.32, 547.36], "text": " Ray Kurzweil points out that even today's best LLM models,"}, {"timestamp": [547.36, 549.04], "text": " the large language models like chat GPT"}, {"timestamp": [549.04, 551.22], "text": " still sometimes do things that a human wouldn't do."}, {"timestamp": [551.22, 552.36], "text": " So he can kind of tell us."}, {"timestamp": [552.36, 553.96], "text": " Ray Kurzweil, 2029."}, {"timestamp": [553.96, 556.02], "text": " Oh, and by the way, that's about the same time"}, {"timestamp": [556.02, 558.64], "text": " this video from Ray Kurzweil's prediction says"}, {"timestamp": [558.64, 561.08], "text": " that we're gonna figure out how to stop aging."}, {"timestamp": [561.08, 562.88], "text": " Immortality, anyone?"}, {"timestamp": [562.88, 565.96], "text": " So that said, where do I fall on the spectrum of when"}, {"timestamp": [565.96, 570.36], "text": " we're gonna see AGI? Well I think that it's already arrived and that it's in"}, {"timestamp": [570.36, 573.48], "text": " the past. I just feel like the way the average person thinks about AGI just"}, {"timestamp": [573.48, 577.6], "text": " isn't reflective of what general intelligence actually is. My guess is"}, {"timestamp": [577.6, 581.88], "text": " that if you ask somebody like random on the street is this AGI they're not gonna"}, {"timestamp": [581.88, 585.62], "text": " see it as AGI until it's like embodied in a robot."}, {"timestamp": [585.62, 587.5], "text": " And one that they're kind of comfortable around,"}, {"timestamp": [587.5, 589.54], "text": " maybe at the grocery store, stocking shelves,"}, {"timestamp": [589.54, 591.44], "text": " talking with customers, making their food,"}, {"timestamp": [591.44, 592.62], "text": " then they're going to be like,"}, {"timestamp": [592.62, 594.6], "text": " oh, AGI, I kind of, I get it,"}, {"timestamp": [594.6, 596.28], "text": " this is pretty much like having a human,"}, {"timestamp": [596.28, 597.7], "text": " these robots around."}, {"timestamp": [597.7, 600.7], "text": " But at that point, we're gonna be so far past AGI,"}, {"timestamp": [600.7, 602.1], "text": " you should call it ASI,"}, {"timestamp": [602.1, 604.02], "text": " going from artificial general intelligence"}, {"timestamp": [604.02, 605.82], "text": " to artificial super intelligence."}, {"timestamp": [605.82, 609.78], "text": " My argument is that as soon as you see it, it's too late. It happened quite a while ago."}, {"timestamp": [609.78, 616.7], "text": " We have to look at the nuance to really understand if it's generally intelligent, and we can find that nuance right now in chat GPT."}, {"timestamp": [616.7, 620.64], "text": " We know a human brain is generally intelligent because that's literally what we're comparing it to."}, {"timestamp": [620.64, 626.16], "text": " But if a human brain was inside of a computer and it was limited in the same way that chat GPT is,"}, {"timestamp": [626.16, 628.04], "text": " just to like text and all that stuff,"}, {"timestamp": [628.04, 629.76], "text": " I bet it wouldn't even perform as well."}, {"timestamp": [629.76, 630.88], "text": " And there's no way we would think"}, {"timestamp": [630.88, 632.0], "text": " that's generally intelligent,"}, {"timestamp": [632.0, 635.56], "text": " but it is once it's embodied in the three-dimensional body"}, {"timestamp": [635.56, 637.56], "text": " that we have and it's connected to our hormones"}, {"timestamp": [637.56, 638.4], "text": " and all of that stuff."}, {"timestamp": [638.4, 639.44], "text": " And that's a different question."}, {"timestamp": [639.44, 642.26], "text": " If you want to say that chat GPT is generally intelligent,"}, {"timestamp": [642.26, 647.04], "text": " but we need to wait for it to show up in sort of a robot and be trained on enough data to like move the"}, {"timestamp": [647.04, 651.52], "text": " robot around, then that's not it. That's already the same weights, the same model"}, {"timestamp": [651.52, 654.88], "text": " that we have right now that is generally intelligent. It's just missing some of"}, {"timestamp": [654.88, 658.68], "text": " its functionality. So let me know your prediction for when we're gonna get AGI"}, {"timestamp": [658.68, 663.84], "text": " in the comments below. Help me get to 6,000 subscribers. Smash that subscribe"}, {"timestamp": [663.84, 666.2], "text": " button."}, {"timestamp": [659.51, 662.11], "text": " Help me get to 6,000 subscribers."}, {"timestamp": [662.11, 663.81], "text": " Smash that subscribe button."}]}