{"text": " Hey everyone, David Shapiro here with an update. So before we get started, I will plug my Patreon. This will take just a second. I'm able to do AI full-time because of the support that I get on Patreon. So if you want to support me, jump over, support me on Patreon. Also if you want any direct help, if you sign up for the higher tiers on Patreon, I am happy to jump in and give you advice or help you solve problems. And this goes as far as looking at your fine-tuning data, talking about architecture, and solving whatever other problems you have. Okay, so that's it for Patreon. Second is I want to plug the r slash artificial sentience subreddit. So this is a subreddit that I and a few other thought leaders on cognitive architecture created. And it's not my subreddit specifically, someone else created it, I'm just a member. But the primary thing is creating autonomous cognitive entities. We would have picked that, but that is too long of a subreddit title. So we have artificial sentience. Jump in over here, talk about artificial cognitive entities, artificial sentience, and so on. Next update is for the Raven project. So I posted an update, I pinned it here. The TLDR is that like, I'm super burned out, and so I am slowing down. That being said, this project has almost 700 stars and there's a huge amount of interest both in AGI today, in cognitive architecture, and also keeping it open source specifically. So if you want to jump in, jump in here. We're still getting organized. We're figuring out a consensus policy and I'm hoping that with the correct consensus policy it will be more distributed and more participatory. So you know it is slow. That's part of the design though. Now finally to the topic of today's video. If you're a chat GPT user you have probably been frustrated over the last few days because all your chats are gone. What I realized is that this is really unfortunate because I've been working on my novel and I use it, I create a new chat every time I'm working on a new chapter. What I do is I go back to the old chapters and say, write an executive summary of this chapter, and then I can just use that to quickly copy paste it into a new chat, so that the new chat can help me. It's caught up on the story and goes right along. But I'm like, okay, I can automate that. It's the same set of procedures every time I use an executive summary, so that it knows about the characters and the story and so on and I'm like why don't I just go ahead and work on this offline, right? I can manage my own files and if you watched my next most recent video you know that I'm working on a QA chatbot and so these actually have a lot in common. It has to deal with organizing an arbitrarily large amount of data, a large corpus of data. In the QA chatbot case, it is scientific papers. In the AutoMUSE case, the AutoMUSE chat GPT case, it is organizing a story. And so, but because of the similarity, right, the thing that they have in common is it has to summarize and search an arbitrarily large amount of memory and it has to do it automatically in the background. So these projects are actually much more similar than you might think from the perspective of cognitive architecture. So, since ChatGPT is down and I can't really use it, it's kind of actually stalled my forward progress on my novel. So I'm like, all right, well, why don't I just fix this? So what I have done is, let me just go ahead and show you the file, show you the repo. So here is what I'm working on with the AutoMuse ChatGPT project. So you might have remembered that I was working on AutoMuse a lot last year and then I stopped because I'm like, I don't wanna hurt anybody. I don't want to, you know, unemploy my friends or whatever. Now people are using Chat GPT to write like crazy and it's all garbage, right? So, or mostly garbage. So I'm not worried about that anymore. I, you know, when all the publicate although all the publishers are Using AI to detect whether or not it's written by AI or to detect the quality Speaking of if there are any publishers out there and you want to learn how to use AI to to rapidly like Measure the quality of someone's fiction. Let me know like measure the quality of someone's fiction. Let me know. Because that can help you quickly sift through, sift the grain from the chaff. So anyways, point being is there's a few components of this that are all the same, right? So you got the QA, I will be working on this. It's been three days. I was really tired over the weekend burnout is real but I am recovering and everyone has been very kind about that so I'm grateful when I said like I need some time everyone's like take your time buddy. Alright anyways going down a rabbit hole point being is that these projects have a lot in common and so what I'm working on is okay how do I create a memory system that works for both of these right because we humans have one memory system and it works for whatever task that we're doing whether you're remembering you know birthdays or how to do your job or whatever and I okay yes it's not one memory system we have a memory operating system you know the hippocampus and all sorts of other connections and And okay, yes, it's not one memory system. We have a memory operating system, you know, the hippocampus and all sorts of other connections and representations and abstractions. But the point is, is that with the correct format or system of abstractions and representations, you, we should be able to create a memory system that is good for an arbitrary number of tasks. So back in the day, there was this concept called temporal hierarchical memory which this was like back in 2005 I think people thought that this was going to lead to AGI and while it didn't pan out it died a quick death the concept is still very helpful and it's actually coming back with neuroscience and so basically here's a simple representation of what I mean. So you have all your narrative logs, right? So you have narrative memory, which is the chronologically linear series of experiences that you have, right? And that's what a chat log is, right? It is chronologically linear. But one problem with chat GPT is we have no idea what is going on in the background. One rumor is that it uses a scratch pad. I don't know that that's panned out. Someone else told me that all it does is uses a rolling window of 8,000 tokens, which a rolling window of 8,000 tokens, that's a lot of text. 8,000 tokens is like, let's see, that's about, it's like what, 3.6 characters per token on average. So that is over 24,000 characters, which then you think that the average word is five to six characters long. So we're looking at what? Can I do math right now? I think that's about 6,000 words. So 6,000 words and 250 words per page. So that's four times six. So that is 24 pages worth of text. That's a lot of text, if that's how it's working. Now the Chat GPT API in the documentation, they say that you only have 4,000 tokens. Even still, 4,000 tokens is 12 pages. You can summarize quite a bit in 12 pages, and this is also going to go up over time. They're doubling the window size pretty regularly. All right, so with all that said, we have a linear chunk of logs. And so what happens sometimes when you're having conversations is it's like it gets something wrong, and then you correct it, and then you're like then you're like no no no that's not what I wanted. And so what I'm what I'm doing with this is I've got a few on. So in the original salience one, so this is the progenitor work, right? This is, I probably won't update this because this repo is just for demonstration purposes, but it shows you the idea of using salience to summarize conversations, as well as anticipation to predict what's going forward. So salience is memory and anticipation is going forward, right? So that is the beginnings of a cognitive architecture. So then you take this forward and say, okay, we have the same exact salience and anticipation, but it is organized around writing, right? So in this case, I'm an AI named Muse. My primary goal is to help the user plan, brainstorm, outline, and otherwise construct their work of fiction, right? So it's got a very clear goal. And I won't show you the conversation I had because it's private. I'm working on my own story. But setting the system goal to this and then updating it with the salience and the anticipation. It is, if all you do is just run this as it is right now, you will find that it is very, very helpful, much more helpful than the plain vanilla chat GPT at helping you plan your story. And in fact, it is so good that you like, man, it won't need much help in terms of queuing up the correct memories in order to make it even better. Now all that being said you have a an arbitrarily long chat log right because writing a novel takes a long time and it's gonna be way more information even just you know brainstorming and stuff right because what happens when you're brainstorming? You have false positives, you have things that you change, things that you say, no, I'm not gonna go that way, so on and so forth. And so what happens is a chat log is basically like a transaction log. So if you're familiar with SQL databases, a transaction log tracks all the changes in the database, but it builds on one another, right? They're all sequential. And so we have to keep track of that in chronological order. So the next step is to summarize chunks of the conversation as concisely as possible while extracting the most salient bits. And so that's where these two new prompts come in. So I have write an executive summary. So it's in. So I have, write an executive summary. So it's as simple as it says, write an executive summary of the following chat log, executive summary. So this writes a very concise, just here's a narrative sequence of what happened. And so this allows it to keep track of, okay, this is how the conversation has gone while excluding a lot of the irrelevant details. And then secondly, story details. So write a summary of what we learn about the story from the following chat log. Now this should be, in the long run, this prompt won't work for other tasks, right? This is hard-coded, this is geared towards writing fiction because it says specifically extract information about the story. In the future the cognitive architecture should design this task or do task selection to figure out what exactly is most relevant to summarize. That being said, because AutoMuse is purpose-built for fiction we can go ahead and hard-code it. But what this does is it ignores the conversation and just says, what do we know about the story? And I tested this out and it actually works really well. So like you can take a long conversation that's 2000 tokens long and you end up with a 200 token summary of what you learn about the story. So that those those summaries, the executive summary and the story extraction, those are going to be summarized in these chunks, right? And so you get a 10 to 1 reduction in terms of files because that's how I've got it set right now, where every time you get to 10 dialogues back and forth, and this is an arbitrary number. In fact, I should probably just have this as the conversation length. I should parameterize that. But anyways, 10 is fine because you don't want to go right up to the window limit because one, you don't know how long the conversation is going to be, and two, you want to regularly summarize what's going on. Okay. So then once we get ... And this is as far as I got, I tested those prompts. And if you look at the to-dos, the very next to-do is I've got to actually populate the chunk summaries. You see, there's nothing here, right? I've got the chat logs. And so now I need to integrate the summaries and put those summaries here. And for those, I don't know whether or not I need to use semantic embedding, right? Because the primary organization feature here is timestamp. So you see chat underscore timestamp, user Muse, user Muse, user Muse. And so that is probably all the organization that I actually really need. Because again, with temporal hierarchical memory time is the primary organizing factor not semantic search we actually don't care what's in it semantically because we're going to algorithmically just recursively or not recursively but repeatedly summarize these chat logs so those are going to end up here in the chunk summaries and the chunk summaries are about five to ten times shorter than the originals. So that allows us to really kind of distill down, okay, what is the most important information? And then we're going to do another layer above that, which is we're going to extract the topics from these. And then the topics are not going to be linear, right? Because you think about like, okay, what do I know about Abraham Lincoln? That is not anchored to time. That is detached from time. Now, your understanding of Abraham Lincoln might be updated, right? You might have like, you can think of it as an internal Wikipedia page in your head. And so what we'll do is we'll transition from this temporal hierarchical part to a more knowledge graph or topical component. And so that is the third layer of abstraction. So eventually what I want is for an auto-muse, it's going to have a top like the... Whoops, yeah, come back. So the primary, you know, so the chat logs, that is like low-level raw memories. Then there's the chunk summaries, which is one layer above that. So you can think of that as medium-term memory. And then long-term memory is going to be this KG model, this knowledge graph model of topics. I don't know that it's actually going to be a knowledge graph because with semantic search, I don't really care about the links between it and also because the story is gonna be updated and summarized repeatedly, I don't know that we actually even need semantic search. So we might not do any embeddings with this just by virtue of the memories are gonna be so well organized and it's gonna be organized around one specific project. So here's the thing, when we get to a fully fledged cognitive architecture like Raven, where it's like, oh hey Raven, let's talk about my story, you absolutely will need some kind of search so that Raven can locate the correct set of memories. But even still, we should probably have some kind of hierarchical automatic organization in the background. Ideally, it's all kept in natural language because again, when we get to the level of fully autonomous AGI, you want its thoughts to be entirely transparent and entirely interpretable by humans. Because like if you have your AGI, whether it's Raven or another one, thinking, hey, gee, maybe I should go get access to nuclear launch codes. You want to be able to see that in clear text. You don't want AGI memories to be in some abstract embedding or AGI specific language. We want it all to be in pure natural language so that one, it can understand us and we can understand it and we'll have trust. So anyways, that's where we're at. I didn't get too much further today because again, recovering from burnout, but I'm really happy with this, especially some of the tests that I did. And I apologize I can't show it, but what I encourage you to do is just go ahead and clone this down and run chat. It should work as it is. Actually, you might want to comment this out, because it'll reset your conversation every 10 dialogues. But just with the anticipation and salience this out because it'll reset your conversation every 10 dialogues but just with the anticipation and salience and having it having it having this as the objective it's really good already it'll help you plan out your story it won't write prose for you maybe we'll get to that one day but yeah so that's that and then the QA bot so talking talking through the memory here, in this case, the memory is abstract. It's not narrative. The memory is in the form of papers, right? And so these text documents, that's the memory that we need to work on. But then we need to have other kinds of cognitive tasks like you know what am I going to read or you know what am I going to summarize or what am I going to synthesize and so I've been thinking through this and and the direction that I'm going with it is the very next thing that's going to happen is there's going to be a cognitive control module and so as you're talking to it the cognitive control module will have, it'll have a menu of various things that it can do. One, it can just ask you a question, ask you a follow-up question, say, hey, do I know what you're doing? It can read papers, it can summarize papers, it can synthesize new information based on information that it's got, and then it can generate hypotheses. I think those are the primary cognitive tasks. Now, it's going to automatically pick which task it wants to use based on where you're at in the conversation. So the first thing that happens in the cognitive control module is that it will update its task. So it'll basically have a task log, right? And so the task log will be similar to the scratch pad. And it'll be like, so we'll have, instead of the chat log, write a brief summary of the most salient points of the conversation, we're going to have update the task log based on task salience, right? So task salience is what is it that we're doing? And also, instead of having the goal, I'm an AI muse, my goal is to plan brainstorming. Instead, the goal will be to advance science. And so just by telling chat GPT, your goal is to advance science, it will adopt a new model and a new approach to what it's doing. And so anyways, these projects will be, there's gonna be some very distinct differences. And as I learn about it, I'll be able to create a more pragmatic higher level abstraction that can be more universally applied. So anyways, that's the update for today. I know that this is probably not the kind of update you're used to, but it is what it is and let me know what you think in the comments.", "chunks": [{"timestamp": [0.0, 4.12], "text": " Hey everyone, David Shapiro here with an update."}, {"timestamp": [4.12, 6.92], "text": " So before we get started, I will plug my Patreon."}, {"timestamp": [6.92, 9.2], "text": " This will take just a second."}, {"timestamp": [9.2, 13.84], "text": " I'm able to do AI full-time because of the support that I get on Patreon."}, {"timestamp": [13.84, 17.44], "text": " So if you want to support me, jump over, support me on Patreon."}, {"timestamp": [17.44, 23.36], "text": " Also if you want any direct help, if you sign up for the higher tiers on Patreon, I am happy"}, {"timestamp": [23.36, 25.88], "text": " to jump in and give you advice or help you"}, {"timestamp": [25.88, 26.88], "text": " solve problems."}, {"timestamp": [26.88, 32.02], "text": " And this goes as far as looking at your fine-tuning data, talking about architecture, and solving"}, {"timestamp": [32.02, 33.88], "text": " whatever other problems you have."}, {"timestamp": [33.88, 37.16], "text": " Okay, so that's it for Patreon."}, {"timestamp": [37.16, 43.6], "text": " Second is I want to plug the r slash artificial sentience subreddit."}, {"timestamp": [43.6, 46.32], "text": " So this is a subreddit that I and a few other"}, {"timestamp": [46.32, 49.38], "text": " thought leaders on cognitive architecture created."}, {"timestamp": [50.32, 52.28], "text": " And it's not my subreddit specifically,"}, {"timestamp": [52.28, 55.16], "text": " someone else created it, I'm just a member."}, {"timestamp": [55.16, 56.92], "text": " But the primary thing is creating"}, {"timestamp": [56.92, 58.92], "text": " autonomous cognitive entities."}, {"timestamp": [58.92, 59.76], "text": " We would have picked that,"}, {"timestamp": [59.76, 62.16], "text": " but that is too long of a subreddit title."}, {"timestamp": [62.16, 64.64], "text": " So we have artificial sentience."}, {"timestamp": [64.64, 68.1], "text": " Jump in over here, talk about artificial cognitive entities,"}, {"timestamp": [68.1, 70.74], "text": " artificial sentience, and so on."}, {"timestamp": [70.74, 74.12], "text": " Next update is for the Raven project."}, {"timestamp": [74.12, 77.14], "text": " So I posted an update, I pinned it here."}, {"timestamp": [77.14, 81.28], "text": " The TLDR is that like, I'm super burned out,"}, {"timestamp": [81.28, 83.72], "text": " and so I am slowing down."}, {"timestamp": [83.72, 88.88], "text": " That being said, this project has almost 700 stars"}, {"timestamp": [88.88, 94.88], "text": " and there's a huge amount of interest both in AGI today, in cognitive architecture, and"}, {"timestamp": [94.88, 103.2], "text": " also keeping it open source specifically. So if you want to jump in, jump in here. We're"}, {"timestamp": [103.2, 111.72], "text": " still getting organized. We're figuring out a consensus policy and I'm hoping that with the correct consensus policy it will be more distributed and more participatory."}, {"timestamp": [112.84, 114.56], "text": " So you know it is slow."}, {"timestamp": [114.72, 115.8], "text": " That's part of the design though."}, {"timestamp": [116.68, 119.4], "text": " Now finally to the topic of today's video."}, {"timestamp": [119.92, 125.08], "text": " If you're a chat GPT user you have probably been frustrated over the last few days because"}, {"timestamp": [125.08, 128.16], "text": " all your chats are gone."}, {"timestamp": [128.16, 134.86], "text": " What I realized is that this is really unfortunate because I've been working on my novel and"}, {"timestamp": [134.86, 140.5], "text": " I use it, I create a new chat every time I'm working on a new chapter."}, {"timestamp": [140.5, 145.46], "text": " What I do is I go back to the old chapters and say, write an executive summary of this chapter,"}, {"timestamp": [145.46, 147.74], "text": " and then I can just use that to quickly copy paste it"}, {"timestamp": [147.74, 152.74], "text": " into a new chat, so that the new chat can help me."}, {"timestamp": [152.9, 156.2], "text": " It's caught up on the story and goes right along."}, {"timestamp": [156.2, 157.94], "text": " But I'm like, okay, I can automate that."}, {"timestamp": [157.94, 161.98], "text": " It's the same set of procedures every time"}, {"timestamp": [161.98, 163.66], "text": " I use an executive summary,"}, {"timestamp": [163.66, 165.56], "text": " so that it knows about the characters and"}, {"timestamp": [165.56, 172.68], "text": " the story and so on and I'm like why don't I just go ahead and work on this"}, {"timestamp": [172.68, 178.36], "text": " offline, right? I can manage my own files and if you watched my next"}, {"timestamp": [178.36, 183.52], "text": " most recent video you know that I'm working on a QA chatbot and so these"}, {"timestamp": [183.52, 185.4], "text": " actually have a lot in common."}, {"timestamp": [185.4, 191.28], "text": " It has to deal with organizing an arbitrarily large amount of data, a large corpus of data."}, {"timestamp": [191.28, 195.36], "text": " In the QA chatbot case, it is scientific papers."}, {"timestamp": [195.36, 202.04], "text": " In the AutoMUSE case, the AutoMUSE chat GPT case, it is organizing a story."}, {"timestamp": [202.04, 205.08], "text": " And so, but because of the similarity, right,"}, {"timestamp": [205.08, 207.88], "text": " the thing that they have in common is it has to"}, {"timestamp": [207.88, 210.96], "text": " summarize and search an arbitrarily large amount of memory"}, {"timestamp": [210.96, 213.4], "text": " and it has to do it automatically in the background."}, {"timestamp": [213.4, 216.14], "text": " So these projects are actually much more similar"}, {"timestamp": [216.14, 218.14], "text": " than you might think from the perspective"}, {"timestamp": [218.14, 220.16], "text": " of cognitive architecture."}, {"timestamp": [220.16, 223.84], "text": " So, since ChatGPT is down and I can't really use it,"}, {"timestamp": [223.84, 225.64], "text": " it's kind of actually stalled my forward"}, {"timestamp": [225.64, 227.76], "text": " progress on my novel."}, {"timestamp": [227.76, 231.66], "text": " So I'm like, all right, well, why don't I just fix this?"}, {"timestamp": [231.66, 237.3], "text": " So what I have done is, let me just go ahead and show you the file, show you the repo."}, {"timestamp": [237.3, 244.14], "text": " So here is what I'm working on with the AutoMuse ChatGPT project."}, {"timestamp": [244.14, 246.88], "text": " So you might have remembered that I was working on AutoMuse"}, {"timestamp": [246.88, 249.24], "text": " a lot last year and then I stopped because I'm like,"}, {"timestamp": [249.24, 250.68], "text": " I don't wanna hurt anybody."}, {"timestamp": [250.68, 252.0], "text": " I don't want to, you know,"}, {"timestamp": [252.0, 253.84], "text": " unemploy my friends or whatever."}, {"timestamp": [253.84, 256.48], "text": " Now people are using Chat GPT to write like crazy"}, {"timestamp": [256.48, 258.08], "text": " and it's all garbage, right?"}, {"timestamp": [258.08, 260.28], "text": " So, or mostly garbage."}, {"timestamp": [260.28, 262.16], "text": " So I'm not worried about that anymore."}, {"timestamp": [262.16, 266.92], "text": " I, you know, when all the publicate although all the publishers are"}, {"timestamp": [267.32, 271.96], "text": " Using AI to detect whether or not it's written by AI or to detect the quality"}, {"timestamp": [272.22, 276.28], "text": " Speaking of if there are any publishers out there and you want to learn how to use"}, {"timestamp": [277.28, 280.16], "text": " AI to to rapidly like"}, {"timestamp": [281.52, 284.4], "text": " Measure the quality of someone's fiction. Let me know"}, {"timestamp": [284.08, 284.92], "text": " like measure the quality of someone's fiction. Let me know."}, {"timestamp": [286.88, 288.96], "text": " Because that can help you quickly sift through,"}, {"timestamp": [288.96, 292.7], "text": " sift the grain from the chaff."}, {"timestamp": [293.84, 298.84], "text": " So anyways, point being is there's a few components"}, {"timestamp": [299.16, 302.04], "text": " of this that are all the same, right?"}, {"timestamp": [302.04, 304.96], "text": " So you got the QA, I will be working on this."}, {"timestamp": [304.96, 311.06], "text": " It's been three days. I was really tired over the weekend burnout is real but I am recovering"}, {"timestamp": [311.06, 315.06], "text": " and everyone has been very kind about that so I'm grateful when I said like I need some"}, {"timestamp": [315.06, 317.78], "text": " time everyone's like take your time buddy."}, {"timestamp": [317.78, 322.98], "text": " Alright anyways going down a rabbit hole point being is that these projects have a lot in"}, {"timestamp": [322.98, 325.04], "text": " common and so what I'm working on is"}, {"timestamp": [325.04, 330.08], "text": " okay how do I create a memory system that works for both of these right"}, {"timestamp": [330.08, 334.68], "text": " because we humans have one memory system and it works for whatever task that"}, {"timestamp": [334.68, 339.04], "text": " we're doing whether you're remembering you know birthdays or how to do your job"}, {"timestamp": [339.04, 344.84], "text": " or whatever and I okay yes it's not one memory system we have a memory operating"}, {"timestamp": [344.84, 345.28], "text": " system you know the hippocampus and all sorts of other connections and And okay, yes, it's not one memory system. We have a memory operating system,"}, {"timestamp": [345.28, 347.84], "text": " you know, the hippocampus and all sorts of other connections"}, {"timestamp": [347.84, 350.08], "text": " and representations and abstractions."}, {"timestamp": [350.08, 353.64], "text": " But the point is, is that with the correct format"}, {"timestamp": [353.64, 356.88], "text": " or system of abstractions and representations,"}, {"timestamp": [356.88, 358.7], "text": " you, we should be able to create a memory system"}, {"timestamp": [358.7, 361.76], "text": " that is good for an arbitrary number of tasks."}, {"timestamp": [361.76, 364.0], "text": " So back in the day,"}, {"timestamp": [364.0, 365.56], "text": " there was this concept called temporal"}, {"timestamp": [365.56, 371.88], "text": " hierarchical memory which this was like back in 2005 I think people thought"}, {"timestamp": [371.88, 377.4], "text": " that this was going to lead to AGI and while it didn't pan out it died a quick"}, {"timestamp": [377.4, 381.28], "text": " death the concept is still very helpful and it's actually coming back with"}, {"timestamp": [381.28, 386.94], "text": " neuroscience and so basically here's a simple representation"}, {"timestamp": [386.94, 387.78], "text": " of what I mean."}, {"timestamp": [387.78, 391.14], "text": " So you have all your narrative logs, right?"}, {"timestamp": [391.14, 393.24], "text": " So you have narrative memory,"}, {"timestamp": [393.24, 398.24], "text": " which is the chronologically linear series of experiences"}, {"timestamp": [398.56, 399.8], "text": " that you have, right?"}, {"timestamp": [399.8, 401.88], "text": " And that's what a chat log is, right?"}, {"timestamp": [401.88, 403.6], "text": " It is chronologically linear."}, {"timestamp": [404.82, 407.4], "text": " But one problem with chat GPT is"}, {"timestamp": [407.4, 409.9], "text": " we have no idea what is going on in the background."}, {"timestamp": [409.9, 412.9], "text": " One rumor is that it uses a scratch pad."}, {"timestamp": [412.9, 414.44], "text": " I don't know that that's panned out."}, {"timestamp": [414.44, 416.12], "text": " Someone else told me that all it does"}, {"timestamp": [416.12, 419.78], "text": " is uses a rolling window of 8,000 tokens,"}, {"timestamp": [419.78, 421.92], "text": " which a rolling window of 8,000 tokens,"}, {"timestamp": [421.92, 423.32], "text": " that's a lot of text."}, {"timestamp": [423.32, 429.44], "text": " 8,000 tokens is like, let's see, that's about, it's like what, 3.6 characters per token on"}, {"timestamp": [429.44, 430.64], "text": " average."}, {"timestamp": [430.64, 437.48], "text": " So that is over 24,000 characters, which then you think that the average word is five to"}, {"timestamp": [437.48, 439.44], "text": " six characters long."}, {"timestamp": [439.44, 440.44], "text": " So we're looking at what?"}, {"timestamp": [440.44, 442.08], "text": " Can I do math right now?"}, {"timestamp": [442.08, 449.04], "text": " I think that's about 6,000 words. So 6,000 words and 250 words per page."}, {"timestamp": [449.04, 451.42], "text": " So that's four times six."}, {"timestamp": [451.42, 454.46], "text": " So that is 24 pages worth of text."}, {"timestamp": [454.46, 457.12], "text": " That's a lot of text, if that's how it's working."}, {"timestamp": [457.12, 461.16], "text": " Now the Chat GPT API in the documentation,"}, {"timestamp": [461.16, 463.44], "text": " they say that you only have 4,000 tokens."}, {"timestamp": [463.44, 466.52], "text": " Even still, 4,000 tokens is 12 pages."}, {"timestamp": [466.52, 472.18], "text": " You can summarize quite a bit in 12 pages, and this is also going to go up over time."}, {"timestamp": [472.18, 474.84], "text": " They're doubling the window size pretty regularly."}, {"timestamp": [474.84, 480.48], "text": " All right, so with all that said, we have a linear chunk of logs."}, {"timestamp": [480.48, 484.2], "text": " And so what happens sometimes when you're having conversations is it's like it gets"}, {"timestamp": [484.2, 489.0], "text": " something wrong, and then you correct it, and then you're like then you're like no no no that's not what I wanted."}, {"timestamp": [489.0, 507.24], "text": " And so what I'm what I'm doing with this is I've got a few on. So in the original salience one,"}, {"timestamp": [507.24, 510.42], "text": " so this is the progenitor work, right?"}, {"timestamp": [510.42, 512.38], "text": " This is, I probably won't update this"}, {"timestamp": [512.38, 515.96], "text": " because this repo is just for demonstration purposes,"}, {"timestamp": [515.96, 519.36], "text": " but it shows you the idea of using salience"}, {"timestamp": [519.36, 521.04], "text": " to summarize conversations,"}, {"timestamp": [521.04, 525.08], "text": " as well as anticipation to predict what's going forward."}, {"timestamp": [525.28, 529.56], "text": " So salience is memory and anticipation is going forward, right?"}, {"timestamp": [529.56, 532.48], "text": " So that is the beginnings of a cognitive architecture."}, {"timestamp": [533.04, 537.2], "text": " So then you take this forward and say, okay, we have the same exact salience and"}, {"timestamp": [537.2, 543.56], "text": " anticipation, but it is organized around writing, right?"}, {"timestamp": [543.56, 546.12], "text": " So in this case, I'm an AI named Muse."}, {"timestamp": [546.12, 547.72], "text": " My primary goal is to help the user plan,"}, {"timestamp": [547.72, 548.56], "text": " brainstorm, outline,"}, {"timestamp": [548.56, 550.86], "text": " and otherwise construct their work of fiction, right?"}, {"timestamp": [550.86, 552.5], "text": " So it's got a very clear goal."}, {"timestamp": [552.5, 554.78], "text": " And I won't show you the conversation I had"}, {"timestamp": [554.78, 556.22], "text": " because it's private."}, {"timestamp": [556.22, 558.34], "text": " I'm working on my own story."}, {"timestamp": [558.34, 562.22], "text": " But setting the system goal to this"}, {"timestamp": [562.22, 564.32], "text": " and then updating it with the salience"}, {"timestamp": [564.32, 566.4], "text": " and the anticipation."}, {"timestamp": [566.4, 570.96], "text": " It is, if all you do is just run this as it is right now,"}, {"timestamp": [570.96, 573.48], "text": " you will find that it is very, very helpful,"}, {"timestamp": [573.48, 576.52], "text": " much more helpful than the plain vanilla"}, {"timestamp": [576.52, 579.24], "text": " chat GPT at helping you plan your story."}, {"timestamp": [579.24, 583.52], "text": " And in fact, it is so good that you like, man,"}, {"timestamp": [583.52, 586.0], "text": " it won't need much help in terms of queuing up"}, {"timestamp": [586.0, 592.56], "text": " the correct memories in order to make it even better. Now all that being said you"}, {"timestamp": [592.56, 597.52], "text": " have a an arbitrarily long chat log right because writing a novel takes a"}, {"timestamp": [597.52, 602.48], "text": " long time and it's gonna be way more information even just you know"}, {"timestamp": [602.48, 606.08], "text": " brainstorming and stuff right because what happens when you're brainstorming?"}, {"timestamp": [606.08, 609.88], "text": " You have false positives, you have things that you change,"}, {"timestamp": [609.88, 612.72], "text": " things that you say, no, I'm not gonna go that way,"}, {"timestamp": [612.72, 614.08], "text": " so on and so forth."}, {"timestamp": [614.08, 617.26], "text": " And so what happens is a chat log"}, {"timestamp": [617.26, 619.14], "text": " is basically like a transaction log."}, {"timestamp": [619.14, 621.56], "text": " So if you're familiar with SQL databases,"}, {"timestamp": [621.56, 624.66], "text": " a transaction log tracks all the changes in the database,"}, {"timestamp": [624.66, 626.98], "text": " but it builds on one another, right?"}, {"timestamp": [626.98, 628.28], "text": " They're all sequential."}, {"timestamp": [628.28, 632.24], "text": " And so we have to keep track of that in chronological order."}, {"timestamp": [632.24, 637.04], "text": " So the next step is to summarize chunks of the conversation"}, {"timestamp": [637.04, 638.48], "text": " as concisely as possible"}, {"timestamp": [638.48, 640.96], "text": " while extracting the most salient bits."}, {"timestamp": [640.96, 643.12], "text": " And so that's where these two new prompts come in."}, {"timestamp": [643.12, 645.52], "text": " So I have write an executive summary. So it's in. So I have, write an executive summary."}, {"timestamp": [645.52, 650.2], "text": " So it's as simple as it says, write an executive summary of the following chat log, executive"}, {"timestamp": [650.2, 656.8], "text": " summary. So this writes a very concise, just here's a narrative sequence of what happened."}, {"timestamp": [656.8, 662.72], "text": " And so this allows it to keep track of, okay, this is how the conversation has gone while"}, {"timestamp": [662.72, 665.96], "text": " excluding a lot of the irrelevant details."}, {"timestamp": [665.96, 668.28], "text": " And then secondly, story details."}, {"timestamp": [668.28, 672.0], "text": " So write a summary of what we learn about the story from the following chat log."}, {"timestamp": [672.0, 678.88], "text": " Now this should be, in the long run, this prompt won't work for other tasks, right?"}, {"timestamp": [678.88, 688.64], "text": " This is hard-coded, this is geared towards writing fiction because it says specifically extract information about the story. In the future the cognitive"}, {"timestamp": [688.64, 694.08], "text": " architecture should design this task or do task selection to figure out"}, {"timestamp": [694.08, 698.48], "text": " what exactly is most relevant to summarize. That being said, because"}, {"timestamp": [698.48, 703.96], "text": " AutoMuse is purpose-built for fiction we can go ahead and hard-code it. But what"}, {"timestamp": [703.96, 710.14], "text": " this does is it ignores the conversation and just says, what do we know about the story?"}, {"timestamp": [710.14, 713.04], "text": " And I tested this out and it actually works really well."}, {"timestamp": [713.04, 718.9], "text": " So like you can take a long conversation that's 2000 tokens long and you end up with a 200"}, {"timestamp": [718.9, 721.98], "text": " token summary of what you learn about the story."}, {"timestamp": [721.98, 727.64], "text": " So that those those summaries, the executive summary and the story extraction, those are going"}, {"timestamp": [727.64, 730.08], "text": " to be summarized in these chunks, right?"}, {"timestamp": [730.08, 733.7], "text": " And so you get a 10 to 1 reduction in terms of files because that's how I've got it set"}, {"timestamp": [733.7, 739.76], "text": " right now, where every time you get to 10 dialogues back and forth, and this is an arbitrary"}, {"timestamp": [739.76, 740.76], "text": " number."}, {"timestamp": [740.76, 745.8], "text": " In fact, I should probably just have this as the conversation length."}, {"timestamp": [745.8, 747.08], "text": " I should parameterize that."}, {"timestamp": [747.08, 753.24], "text": " But anyways, 10 is fine because you don't want to go right up to the window limit because"}, {"timestamp": [753.24, 758.56], "text": " one, you don't know how long the conversation is going to be, and two, you want to regularly"}, {"timestamp": [758.56, 760.6], "text": " summarize what's going on."}, {"timestamp": [760.6, 761.6], "text": " Okay."}, {"timestamp": [761.6, 765.44], "text": " So then once we get ... And this is as far as I got, I tested those prompts."}, {"timestamp": [765.44, 767.42], "text": " And if you look at the to-dos,"}, {"timestamp": [768.28, 771.96], "text": " the very next to-do is I've got to actually"}, {"timestamp": [771.96, 773.04], "text": " populate the chunk summaries."}, {"timestamp": [773.04, 774.56], "text": " You see, there's nothing here, right?"}, {"timestamp": [774.56, 775.96], "text": " I've got the chat logs."}, {"timestamp": [775.96, 778.56], "text": " And so now I need to integrate the summaries"}, {"timestamp": [778.56, 780.14], "text": " and put those summaries here."}, {"timestamp": [781.44, 784.24], "text": " And for those, I don't know whether or not"}, {"timestamp": [784.24, 786.48], "text": " I need to use semantic embedding, right?"}, {"timestamp": [786.48, 791.68], "text": " Because the primary organization feature here is timestamp."}, {"timestamp": [791.68, 796.52], "text": " So you see chat underscore timestamp, user Muse, user Muse, user Muse."}, {"timestamp": [796.52, 801.6], "text": " And so that is probably all the organization that I actually really need."}, {"timestamp": [801.6, 808.2], "text": " Because again, with temporal hierarchical memory time is the primary"}, {"timestamp": [808.2, 811.76], "text": " organizing factor not semantic search we actually don't care what's in it"}, {"timestamp": [811.76, 816.52], "text": " semantically because we're going to algorithmically just recursively or not"}, {"timestamp": [816.52, 821.08], "text": " recursively but repeatedly summarize these chat logs so those are going to"}, {"timestamp": [821.08, 827.2], "text": " end up here in the chunk summaries and the chunk summaries are about five to ten times shorter"}, {"timestamp": [827.2, 832.32], "text": " than the originals. So that allows us to really kind of distill down,"}, {"timestamp": [832.32, 835.68], "text": " okay, what is the most important information? And then we're going to do"}, {"timestamp": [835.68, 839.12], "text": " another layer above that, which is we're going to"}, {"timestamp": [839.12, 842.72], "text": " extract the topics from these. And then the"}, {"timestamp": [842.72, 845.26], "text": " topics are not going to be linear, right?"}, {"timestamp": [845.26, 847.22], "text": " Because you think about like,"}, {"timestamp": [847.22, 850.04], "text": " okay, what do I know about Abraham Lincoln?"}, {"timestamp": [850.04, 851.44], "text": " That is not anchored to time."}, {"timestamp": [851.44, 853.2], "text": " That is detached from time."}, {"timestamp": [853.2, 855.48], "text": " Now, your understanding of Abraham Lincoln"}, {"timestamp": [855.48, 856.56], "text": " might be updated, right?"}, {"timestamp": [856.56, 857.42], "text": " You might have like,"}, {"timestamp": [857.42, 859.66], "text": " you can think of it as an internal Wikipedia page"}, {"timestamp": [859.66, 860.72], "text": " in your head."}, {"timestamp": [860.72, 862.98], "text": " And so what we'll do is we'll transition"}, {"timestamp": [862.98, 869.0], "text": " from this temporal hierarchical part to a more knowledge graph or topical component."}, {"timestamp": [869.0, 871.0], "text": " And so that is the third layer of abstraction."}, {"timestamp": [871.0, 878.0], "text": " So eventually what I want is for an auto-muse, it's going to have a top like the..."}, {"timestamp": [878.0, 879.0], "text": " Whoops, yeah, come back."}, {"timestamp": [879.0, 885.62], "text": " So the primary, you know, so the chat logs, that is like low-level raw memories."}, {"timestamp": [885.62, 888.36], "text": " Then there's the chunk summaries, which is one layer above that."}, {"timestamp": [888.36, 891.6], "text": " So you can think of that as medium-term memory."}, {"timestamp": [891.6, 897.2], "text": " And then long-term memory is going to be this KG model, this knowledge graph model of topics."}, {"timestamp": [897.2, 901.7], "text": " I don't know that it's actually going to be a knowledge graph because with semantic search,"}, {"timestamp": [901.7, 908.72], "text": " I don't really care about the links between it and also because the story is gonna be updated"}, {"timestamp": [908.72, 910.54], "text": " and summarized repeatedly,"}, {"timestamp": [910.54, 912.9], "text": " I don't know that we actually even need semantic search."}, {"timestamp": [912.9, 916.08], "text": " So we might not do any embeddings with this"}, {"timestamp": [916.08, 918.6], "text": " just by virtue of the memories are gonna be"}, {"timestamp": [918.6, 921.2], "text": " so well organized and it's gonna be organized"}, {"timestamp": [921.2, 923.24], "text": " around one specific project."}, {"timestamp": [923.24, 924.92], "text": " So here's the thing, when we get"}, {"timestamp": [924.92, 928.88], "text": " to a fully fledged cognitive architecture like Raven,"}, {"timestamp": [928.88, 933.28], "text": " where it's like, oh hey Raven, let's talk about my story, you absolutely will need some kind of"}, {"timestamp": [933.28, 940.0], "text": " search so that Raven can locate the correct set of memories. But even still, we should probably have"}, {"timestamp": [940.0, 945.2], "text": " some kind of hierarchical automatic organization in the background."}, {"timestamp": [945.2, 949.84], "text": " Ideally, it's all kept in natural language because again, when we get to the level of"}, {"timestamp": [949.84, 956.24], "text": " fully autonomous AGI, you want its thoughts to be entirely transparent and entirely interpretable"}, {"timestamp": [956.24, 960.64], "text": " by humans. Because like if you have your AGI, whether it's Raven or another one,"}, {"timestamp": [960.64, 964.16], "text": " thinking, hey, gee, maybe I should go get access to nuclear launch codes."}, {"timestamp": [964.16, 966.6], "text": " You want to be able to see that in clear text."}, {"timestamp": [966.6, 970.72], "text": " You don't want AGI memories to be in some abstract embedding"}, {"timestamp": [970.72, 972.2], "text": " or AGI specific language."}, {"timestamp": [972.2, 975.36], "text": " We want it all to be in pure natural language"}, {"timestamp": [975.36, 977.4], "text": " so that one, it can understand us"}, {"timestamp": [977.4, 980.0], "text": " and we can understand it and we'll have trust."}, {"timestamp": [980.0, 982.16], "text": " So anyways, that's where we're at."}, {"timestamp": [982.16, 983.64], "text": " I didn't get too much further today"}, {"timestamp": [983.64, 986.04], "text": " because again, recovering from burnout,"}, {"timestamp": [986.04, 987.4], "text": " but I'm really happy with this,"}, {"timestamp": [987.4, 989.28], "text": " especially some of the tests that I did."}, {"timestamp": [989.28, 990.52], "text": " And I apologize I can't show it,"}, {"timestamp": [990.52, 993.3], "text": " but what I encourage you to do is just go ahead"}, {"timestamp": [993.3, 996.04], "text": " and clone this down and run chat."}, {"timestamp": [996.04, 997.84], "text": " It should work as it is."}, {"timestamp": [998.64, 1001.36], "text": " Actually, you might want to comment this out,"}, {"timestamp": [1001.36, 1004.88], "text": " because it'll reset your conversation every 10 dialogues."}, {"timestamp": [1004.88, 1005.88], "text": " But just with the anticipation and salience this out because it'll reset your conversation every 10 dialogues but just"}, {"timestamp": [1005.88, 1011.44], "text": " with the anticipation and salience and having it having it having this as the"}, {"timestamp": [1011.44, 1016.56], "text": " objective it's really good already it'll help you plan out your story it won't"}, {"timestamp": [1016.56, 1022.4], "text": " write prose for you maybe we'll get to that one day but yeah so that's that and"}, {"timestamp": [1022.4, 1031.1], "text": " then the QA bot so talking talking through the memory here, in this case, the memory is abstract."}, {"timestamp": [1031.1, 1032.66], "text": " It's not narrative."}, {"timestamp": [1032.66, 1036.46], "text": " The memory is in the form of papers, right?"}, {"timestamp": [1036.46, 1041.16], "text": " And so these text documents, that's the memory that we need to work on."}, {"timestamp": [1041.16, 1045.24], "text": " But then we need to have other kinds of cognitive tasks like you know"}, {"timestamp": [1045.24, 1049.8], "text": " what am I going to read or you know what am I going to summarize or what am I"}, {"timestamp": [1049.8, 1055.44], "text": " going to synthesize and so I've been thinking through this and and the"}, {"timestamp": [1055.44, 1059.2], "text": " direction that I'm going with it is the very next thing that's going to happen"}, {"timestamp": [1059.2, 1063.96], "text": " is there's going to be a cognitive control module and so as you're talking"}, {"timestamp": [1063.96, 1067.44], "text": " to it the cognitive control module will have,"}, {"timestamp": [1067.44, 1070.96], "text": " it'll have a menu of various things that it can do."}, {"timestamp": [1070.96, 1073.04], "text": " One, it can just ask you a question,"}, {"timestamp": [1073.04, 1074.72], "text": " ask you a follow-up question, say,"}, {"timestamp": [1074.72, 1077.16], "text": " hey, do I know what you're doing?"}, {"timestamp": [1077.16, 1080.84], "text": " It can read papers, it can summarize papers,"}, {"timestamp": [1080.84, 1082.72], "text": " it can synthesize new information"}, {"timestamp": [1082.72, 1084.44], "text": " based on information that it's got,"}, {"timestamp": [1084.44, 1086.68], "text": " and then it can generate hypotheses."}, {"timestamp": [1086.68, 1089.92], "text": " I think those are the primary cognitive tasks."}, {"timestamp": [1089.92, 1095.28], "text": " Now, it's going to automatically pick which task it wants to use based on where you're"}, {"timestamp": [1095.28, 1097.0], "text": " at in the conversation."}, {"timestamp": [1097.0, 1102.2], "text": " So the first thing that happens in the cognitive control module is that it will update its"}, {"timestamp": [1102.2, 1103.2], "text": " task."}, {"timestamp": [1103.2, 1105.28], "text": " So it'll basically have a task log, right?"}, {"timestamp": [1105.28, 1108.08], "text": " And so the task log will be similar to the scratch pad."}, {"timestamp": [1109.4, 1110.96], "text": " And it'll be like, so we'll have,"}, {"timestamp": [1110.96, 1113.04], "text": " instead of the chat log,"}, {"timestamp": [1113.04, 1115.4], "text": " write a brief summary of the most salient points"}, {"timestamp": [1115.4, 1116.6], "text": " of the conversation,"}, {"timestamp": [1116.6, 1120.0], "text": " we're going to have update the task log"}, {"timestamp": [1120.0, 1122.04], "text": " based on task salience, right?"}, {"timestamp": [1122.04, 1124.84], "text": " So task salience is what is it that we're doing?"}, {"timestamp": [1124.84, 1128.48], "text": " And also, instead of having the goal,"}, {"timestamp": [1131.16, 1134.92], "text": " I'm an AI muse, my goal is to plan brainstorming."}, {"timestamp": [1134.92, 1138.76], "text": " Instead, the goal will be to advance science."}, {"timestamp": [1138.76, 1141.48], "text": " And so just by telling chat GPT,"}, {"timestamp": [1141.48, 1143.04], "text": " your goal is to advance science,"}, {"timestamp": [1143.04, 1146.54], "text": " it will adopt a new model and a new approach"}, {"timestamp": [1146.54, 1147.64], "text": " to what it's doing."}, {"timestamp": [1147.64, 1150.48], "text": " And so anyways, these projects will be,"}, {"timestamp": [1150.48, 1152.52], "text": " there's gonna be some very distinct differences."}, {"timestamp": [1152.52, 1154.92], "text": " And as I learn about it, I'll be able to create"}, {"timestamp": [1155.76, 1159.5], "text": " a more pragmatic higher level abstraction"}, {"timestamp": [1159.5, 1161.98], "text": " that can be more universally applied."}, {"timestamp": [1163.72, 1167.2], "text": " So anyways, that's the update for today. I know that"}, {"timestamp": [1167.2, 1171.68], "text": " this is probably not the kind of update you're used to, but it is what it is and"}, {"timestamp": [1171.68, 1175.32], "text": " let me know what you think in the comments."}]}