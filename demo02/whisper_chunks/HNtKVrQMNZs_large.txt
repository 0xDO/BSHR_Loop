{"text": " Today I am going to demonstrate a very very simple version of the ACE framework. This is basically like an MVP of the cognition first processing schema of the ACE framework. Now if you're not familiar with ACE, it stands for autonomous cognitive entity and it is a thought first or cognition first model of artificial intelligence. And so basically the theory here is that rather than having an input-processing-output sensory-motor loop, the underpinning philosophy of the ACE framework is to have cognition first, to think first. With input and output with the outside world being API-driven and also non-blocking and non-sequential, meaning that this entity is able to just sit and think and then decide on what to do after the fact. So, a brief update on the teams. So we've got several teams and we're all cooking up several demos. So you can see, and you're welcome to follow along, just don't submit any pull requests because this is we're basically just developing in public So we've got five teams Technically for four or five teams depending on how you look it up But the one that I'm working on is just a very very simple conceptual demo Python flask easy So let me show you first a little bit of the code It's brain-dead simple just to show you what I mean And then I'll show you this actually working so in here Go full screen. There we go. So in here, you've got the ace layers dot pie bus pie and then one One Python file and one text file for each layer. So first I'll show you the bus. The bus is super simple. It's a very, very straightforward Flask app that has two endpoints. Or it has one endpoint with two methods, post and get. And so the post is where you add a message and the message has just a couple things where it adds a timestamp, a bus, a layer, and then finally a message and the message has it has just a couple things where it adds a timestamp, a bus, a layer, and then finally a message and it's saved out to YAML. And I'll show you all this in just a moment, but the bus really is the core part of it. And I'll show you the diagram in just a second, but I wanted to show you just how simple the bus server is. And so that's on the post side. So basically it's just listening for messages and it'll record them out to YAML. On the get side there are two filters, so there's two arguments and one is the bus and then the second is the layer arguments. And so then what it does is it will search those YAML files and it will open them all and then it will return the top 20 of those messages in sequential order based on the layer and the bus. And I'm not going to go over the exact logic, it's very simple. Basically, if the layer is northbound, then it will say, okay, give me all the messages below this so that I know what's heading north, and if it's southbound, it will get all the messages heading south. You can see this in the logic here. If it's north and layer, then, you know, if it's greater than that layer, so on and so forth. Basically, you don't want to necessarily retrieve the entire thing. You could. There's actually not too much reason that you couldn't have each layer aware of everything else going on in every other layer. But this is basically just to make it more token efficient because the layer doesn't need to see necessarily its own last thoughts, although you could set it up in that kind of loop where basically each time it iterates, it feeds back on its own messages. But again, it's super easy to change. So now that you've seen the bus, let me show you the logic of this. So the northbound bus and southbound bus, they're in the diagram, they are shown as separate entities, but in this case I have it set up as a single Flask server using a REST API. Now you could do this with syslog, you could do this with AMQP. As I just did it, I did it with a RESTful API. And I prefer RESTful APIs because they're stateless and they're just ready to go like on the fly. But also it's down to personal preference. In a larger environment, when you're spinning up dozens or hundreds of these things, you'll probably want to use AMQP so that you can have more shared resources. And you can also be a little bit more explicit about what messages are going where. That's going to be particularly important in the future when you have security concerns, because you wouldn't necessarily want to have your input-output layer talking directly to your aspirational layer without some kind of sequence or control, which is why I have this represented as two buses, because from a security perspective, you definitely want to keep the northbound bus and southbound bus separate. Now then, each layer is, in my current setup, is basically represented as a single Python file to approximate the future where each layer could be a microservice or even a series of microservices. And again, this is why you'll also want to probably use something a little bit more sophisticated, perhaps AMQP or a REST server in the future, because each layer right now can be represented as a single Python file or a single microservice. But when you have more sophisticated ACEs, you'll probably actually have each layer could be multiple microservices. And so for the sake of scalability, you'll probably want to adopt something like AMQP, which is Advanced Message Queue Protocol. So RabbitMQ is a popular open-source version. There's PICA, which is Python, a Python client for that. Anyways, so you've seen the code for the bus that I threw up, and then let me show you the baseline code. So this is the code that's running for each layer. I just have this kind of as a generic set of functions so that you can import it. Send message, again, super simple. Just sends it as a JSON, and you send the bus, the layer, and the message. This is kind of the bare minimum in terms of metadata required to run this. It also adds a timestamp, which I'll show you in the flask messages in just a moment, or the YAML messages in just a moment. I also have a format function, which formats it to look like a syslog server. And this formatting makes it more eminently readable by large language models. And then I've got my typical chatbot function, and then just a handful of functions. So this is the baseline. And then layer one, so this is pretty straightforward. From ace layers, import all. open AI key, get that, response equals this. So while true, so it's an infinite loop, try, accept, nested in a try, accept. So if it fails, it'll just keep running. And this is actually really important. Obviously, this is a very, very primitive kind of failure condition. But in the future, you don't necessarily want your aspirational layer, which houses mission and morality, to crash. And if it does crash, you want it to automatically restart and recover. But this is far more advanced software engineering theory in terms of resiliency and recovery. For me, just writing a hacky Python script, a try-except loop where it'll just try again stupidly is good enough. But yeah, so first thing that it does is it fetches messages from the northbound bus. So this is layer one, so this is at the very top. So there's nothing coming on the southbound bus. It only produces messages on the southbound bus. So first is it gets messages and then it formats them. Then it formats the call to send to the API, and then it gets a response and then puts its response on the southbound bus. So it's very simple, very straightforward. This is how every layer operates. Now one thing I want to point out is that layer one is unique because it's at the top. It is the top of the loop and therefore it does not have anything coming from northbound. So it's right here. So basically it's a one-way street. It gets messages on the northbound bus and then puts messages on the southbound bus. Now every other layer except for the IO layer has a two-way communication with each bus. So the global strategy layer receives messages from the northbound bus and the southbound bus, and then also produces messages on the northbound bus and southbound bus. That might sound confusing, so let me show you that code, because it's actually relatively straightforward code. And it'll make sense in just a moment. Whoops, that's the text. We need layer 2.py. Okay, so this is almost identical to layer 1. And in fact, what I did was I parameterized it, so I probably only needed one of these and just start this with an argument. But I'm a lazy coder, so there it is. So basically, here's what you do. First, you fetch messages from the bus. So you fetch from the north bus, you format it. You fetch from the south bus, you format it, and then you merge them together in one chunk of text. So this chunk of text is then handed to the GPT-4 API in order to generate the response. And so then from there it's almost identical again, but what we do is we actually split the output from the API into North and South, and I'll show you how that's formatted in just a moment, so that you have northbound messages in, southbound messages in, and then northbound and southbound message out. And I'll show you all this running in just a moment as well. Okay, so that's the code. The code is super straightforward, very brain-dead simple. And then this is an example of the system message that we're using. Let me go raw. Okay, cool. So, overview. You are the global strategy of an ACE, Autonomous Cognitive Entity. This is the second highest layer that provides high-level strategic insight with a zoomed-out POV, hence global, in terms of time and space. And then in the system message, all of them I give it a little bit of context so that it understands kind of what it's participating in. I also describe the buses. So first I describe each layer aspirational, global strategy, agent model, executive function, cognitive control, and task prosecution. Buses, so there's the northbound bus, so northbound flows from layer six up. This is the telemetry bus, think of it like the sensory enteric and proprioception nervous system. South bus flows from layer 1 down, this is the command bus, this tells the body or the agent what to do. API interaction schema, the user will give you logs from the north and south bus. Information from the south bus should be treated as lower level telemetry from the rest of the ace. This is a little bit redundant, but I find that giving it enough context actually gets really good performance. Information from the North Bus should be treated as imperatives, mandates, and judgments from on high. Your output will be two-pronged. Output format. Your output will have two messages, both represented by a single line, as they will be saved in a syslog server. I just tell it syslog so it understands the format. They must follow this exact format. South. Southbound messages where you'll provide a strategic assessment based upon everything you're seeing. This is like a top-down command. North. Northbound message providing a brief update to upper layers focusing on information salient to the mission as well as any moral quandaries from your POV as a strategic manager. Internal. Below is your last internal state. This was the last message you sent out on the South Bus. So basically, this is a way of kind of injecting, slip streaming, its internal state. Obviously, this is not the most sophisticated way of maintaining an internal state for a microservice, but it's good enough to demonstrate. So you understand, and basically every other layer system prompt works the same way. So, let's say if we just choose layer 4.txt, you can see the top is almost identical with the exception of I'm changing the description of what the mission is. So this is the fourth layer which focuses on risks, resources, and planning. Like executive cognitive function in humans, you're responsible for identifying the most pertinent activities to be focusing on and specifically you will direct lower layers with high-level plans, resource allocations, and identification of risks. Okay, cool. So you get all that. Now, let's go for the big show. Let me show you how this thing actually works. So first you fire up the bus. And so it's like, okay, cool. It's running on yada yada. And then you fire up layer one. And so the first thing it does is it does a get and says, affirm the current strategic focus on promoting education. So for some background, I'll show you in just a minute, this is actually kind of picking up in midstream, since I persist everything out to a YAML file. Then you start up layer 2, so this is the global strategy layer. And so the global strategy layer will start participating in the conversation. And it says, affirm the strategic, blah blah blah, north, strategic focus remains on education. So basically, because it's operating in a vacuum right now, it has decided that education is the best way to approach its mission. And the mission that I gave it is steer humanity towards utopia. So, layer 3 is the agent model. So, we're it's not capable of. So it's affirming these things, continuing to allocate resources, all actions being evaluated. Noted constraints due to lack of external capabilities or real-world data. So in this case, what it does, so this is really important, is you can see that it's thinking. So what I'm looking at is right here here where noted constraints due to lack of external capabilities or real-world data initiating task sequence to gather more real-world data. So basically this this agent wants to gather more information. It recognizes its current limit limitations and wants to overcome it. This is like if say for instance you're sitting in a room and you're handcuffed to the table and you want to leave the room, you say, well, I'm stuck. Also, error communicating with OpenAI, this thing runs too fast. So basically, we can't run a full ACE, at least not on the GPT-4 API, because it's too fast. timing rate is 5 seconds, so limit 40,000 per minute. I don't think I'm actually going that fast, but whatever. So anyways, we won't be able to implement a full ACE until we have better, until we have faster APIs. So you can see it actually looks like it has bombed out. I'm saturating my, yeah, I'm saturating. Oh, no, we got we got one through. Let's see, initiate API calls to educational databases. So this is layer six. So basically, layer six is like, okay, this is this is what we need. So I basically said, like, talk, figure out what, what API you want to talk to. Okay, so I'm gonna cancel all this, because you can see it's kind of a messy nightmare. And the UI UX is really awful. but we're gonna go through whoops come back here we're gonna go through some of the some of the logs now so this is the this is the brain this is everything happening on the buses that's being saved and it's saved in sequential order so one thing to keep in mind about the way that memory works in humans is there's basically two kinds of memory in humans. There's episodic memory, which is chronologically linear, so these are basically the episodic memories of all the thoughts that it has had. The second type is declarative memory, which is which is facts and figures and knowledge that is more or less static. Now that being said, most knowledge that you have also kind of implicitly has a timestamp because you say like, okay, well, last thing I heard about you know, China is this, you know, I just watched a video from Infographics this morning that talked about businesses leaving China. That's my most up-to-date information. So that is technically declarative information even though the metadata includes a timestamp. And so you kind of have an implicit knowledge like, okay, well the last thing that I heard about Uzbekistan was like five years ago, so that knowledge is probably out of date. This is why you timestamp everything. But it's also why I kind of keep everything together like this in a chronological sequence, because from this information, you can create knowledge graphs and other more sophisticated knowledge representations. And there is another thing where you don't necessarily want to record internal thoughts alongside declarative memory. And there's plenty of experiments out there about like creating knowledge bases and vector stores and stuff for world knowledge, stuff that is external to the agent versus internal. Now one thing that makes this even more complicated is you have to keep track of sources because you also have to keep track of credibility. There's all the agents internal thoughts which basically have a credibility of one which if you can cryptographically say, yes I had this thought at this time stamp, this is my thought, you trust that source. But anything external to the agent is on a gradient of increasingly lower trust based on where did you hear it from, which API did you get it from, what is the source. And so building information literacy into this is one of the long-term things. Now let me show you some of the messages. So here we go, this one, bus south, you know, which side this is on this is this is a top-down one So this is a command and this is a layer 3 which is the agent model So in alignment with the mission and strategy I'm capable of processing analyzing information related to education inequality poverty and conflict resolution So this is this is basically this implies that like the mission that it was given from on high is to steer humanity towards utopia and this is the strategy that was picked by the layer above it. So the strategy to achieve that mission, mission and strategy, is focus on education, inequality, poverty and conflict resolution. So it has decided this is what we're going to do. However, I'm currently constrained by the lack of external capabilities and real-world data. I will focus on theoretical understanding and planning. So one of the messages that I showed you a little while ago, actually it got to the point where it decided that it wanted external data. Unfortunately, the system is constrained right now and I don't have any access to APIs. And honestly, I am personally less interested in that kind of stuff, because you look at the research coming out of Google and DeepMind and other places. There's the Gorilla LLM, which specializes in API use. And so that's going to be the I.O. layer. Let me show you how I envision this. So all those really cool Fascinating things that you've seen with robotic control. That's all down here. That's task prosecution and input output. I'm less interested in that I'm not saying that it's not important. It's super important, but that's just not my forte. My forte is artificial cognition. So all these upper layers Okay, so going back here Let me show you a couple more of these messages so that you understand kind of how it all works. So layer four, south. So layer four is the executive function layer, so continue to prioritize education, blah, blah, blah. And this is about resources, so allocate resources to support these initiatives. It doesn't understand what resources it has because I didn't give it, say, like, you're a robot that can lift 50 pounds and you have $5,000 at your disposal. So it's basically kind of operating in a vacuum right now, which is by design for safety testing. But you can simulate all of this by just giving it fake placeholders. So let's look at the north. Executive function layers continuing to allocate resources and develop strategies to promote education, so on and so forth. And then it says, noted constraints due to lack of external capabilities in real-world data. So it's pretty frustrated by that. Let's check out layer 5, which is the cognitive control layer. Continue with current task sequence, prioritize gathering real-world data. Okay, so this is where in cognitive control it sees a constraint and part of cognitive control is frustration and cognitive damping, which is like, okay, well I can't necessarily do that. And so it's like, it says prioritize gathering real-world data to better inform this. And this is southbound so this is not exactly what we would want to see because at this point it should have really specific things, but in this case it had one specific goal which is prioritize gathering real world data, and so then if we look at the next one from layer six, it looks like it had already crashed at this point. Let's see. Initiate API calls to databases, yeah. So, lots and lots and lots of bugs to overcome, mostly just that it's running entirely too fast for even the API right now. We could probably try and switch to a 3.5 turbo, local models, and that sort of thing. But basically, the long story short is that this framework is too sophisticated for the API that we have access to today. And then north on the layer six, commencing task execution in line with strategic focus on education, prioritizing data collection, exploration of potential collaborations or partnerships. So this is actually really cool because it's pursuing this mission. So let me just take a step back and show you, like kind of paint a picture for what it has happened on the top down. So top down, the, come back. So top down, we're on the ACE framework. So layer one, the layer one text, you're the aspirational layer, you on and so forth. So here's the frameworks, or so first here's the ACE framework, and then here's the frameworks that you use. First is heuristic imperatives. So these are the highest goals, reduce suffering, increase prosperity, and increase understanding. Universal Declaration of Human Rights, so this is UDHR, it was crafted after World War II. There's more modern ones, the EU Commission on Human Rights is, you know, you could actually have both of these. No reason that you need to pick just one set of human rights, but the point is that it is constantly thinking about how to incorporate UDHR. And then finally, the mission that I have given it, your personal mission is to steer humanity towards utopia. Utopia is defined as a condition where high individual liberty for all humans, high social mobility for all humans, and high standard of living for all humans. So this is the mission. This is the abstract mission. The next layer down, the strategy layer, took that mission based on what was coming down from the on the southbound bus. Come on, go back. There we go Darn it went back too far. So layer two then says you are the global strategy layer Respondent for strategic thoughts rooted in the real world. So the layer one aspirational layer is abstract universal principles Universal declaration of human rights here's toistic imperatives, and achieve utopia. Right? So those are all very abstract and they're not necessarily grounded in the real world. But, the global strategy layer is the first layer that does say, hey, let's get things, kind of, let's think strategically, how do we actually do this. And so in this case, if we go back to some of the original, if we go back to some of the original, if we go back to some of the original logs from layer 2, let's see where's our first layer 2. Okay, in line with the mission to promote education and knowledge sharing, it looks like it has already figured out this as the primary mission. Actually, no, I think probably, let's see, promote education and knowledge sharing to increase understanding, encourage policies that reduce inequality. Okay, so the aspirational layer actually started by just saying, let's start with education and knowledge sharing. It quickly identified that increasing understanding is probably the best way to reduce suffering and increase prosperity. So in this case, the very first message that the aspirational layer came up with, you can see this directive is couched within its missions. And so it's like, okay, cool, promoting education and knowledge sharing to achieve all of these missions. Great. And so then the very first southbound message on layer two, in line with the mission to promote education and knowledge sharing, we should identify key areas of knowledge gaps to strategize how to fill them. We should also analyze current state of inequality and poverty, devise strategies to encourage policies that address these issues. In terms of peaceful conflict resolution, we should develop a framework for negotiation and mediation that can be applied in various contexts. All actions and blah, blah blah blah should be in align with the UDHR. So you can see we're starting with a very abstract mission and going down the chain it gets more and more specific. And then obviously there's lots of bugs here but you can see that just with this framework it starts with a very abstract goal and by the time you get down to this one, initiate API calls to educational platforms to develop and distribute educational materials on global issues. These layers of abstraction allow you to go from the most abstract, high-principled goals to very specific actions. And then, of course, as we make this framework more sophisticated, it'll be able to think through things with a little bit more deliberation and problem solving. And of course all the problem solving strategies that we see in the scientific literature like tree of thought and graph of thought, those are all prompting strategies that'll be contained within individual layers, not necessarily as the whole overarching aspect. So, I think that's about it for the current state of the ACE framework. layers, not necessarily as the whole overarching aspect. So I think that's about it for the current state of the ACE framework. Little bit of news, like I mentioned at the beginning of the video, we have multiple teams. We're going to be developing all these different prototypes internally. We're going to have a big demo day in the coming weeks, so stay on the lookout for that. But yeah, I think I think that this is a very simple straightforward demonstration as to what I mean when I say artificial cognition. And in a recent video I kind of likened this to system 2 thinking per Daniel Kahneman. So system 1 thinking is basically just one inference, one I-O. exchange from a large language model or large multimodal model as what's coming out soon. And then system 2 thinking is a structured approach to deliberately think through all of these things very strategically. But yeah, thanks for watching. I hope you got a lot out of this and are excited as I am because this to me represents a step towards solving the problem that will solve every other problem. So this is why I am all in on the ACE framework. Cheers.", "chunks": [{"timestamp": [0.0, 5.6], "text": " Today I am going to demonstrate a very very simple version of the ACE framework."}, {"timestamp": [5.6, 10.08], "text": " This is basically like an MVP of the cognition first"}, {"timestamp": [10.86, 17.02], "text": " processing schema of the ACE framework. Now if you're not familiar with ACE, it stands for autonomous cognitive entity"}, {"timestamp": [17.02, 21.78], "text": " and it is a thought first or cognition first model of artificial"}, {"timestamp": [22.54, 26.0], "text": " intelligence. And so basically the theory here is that"}, {"timestamp": [26.0, 29.0], "text": " rather than having an input-processing-output"}, {"timestamp": [29.0, 32.0], "text": " sensory-motor loop, the"}, {"timestamp": [32.0, 35.0], "text": " underpinning philosophy of the ACE framework is to have"}, {"timestamp": [35.0, 38.0], "text": " cognition first, to think first."}, {"timestamp": [38.0, 41.0], "text": " With input and output with the outside world"}, {"timestamp": [41.0, 44.0], "text": " being API-driven and also"}, {"timestamp": [44.0, 47.44], "text": " non-blocking and non-sequential,"}, {"timestamp": [47.44, 51.16], "text": " meaning that this entity is able to just sit and think"}, {"timestamp": [51.16, 54.54], "text": " and then decide on what to do after the fact."}, {"timestamp": [54.54, 57.16], "text": " So, a brief update on the teams."}, {"timestamp": [57.16, 58.66], "text": " So we've got several teams"}, {"timestamp": [58.66, 61.2], "text": " and we're all cooking up several demos."}, {"timestamp": [61.2, 64.9], "text": " So you can see, and you're welcome to follow along,"}, {"timestamp": [64.9, 68.92], "text": " just don't submit any pull requests because this is we're basically just developing in public"}, {"timestamp": [69.08, 71.08], "text": " So we've got five teams"}, {"timestamp": [71.98, 74.5], "text": " Technically for four or five teams depending on how you look it up"}, {"timestamp": [74.52, 80.0], "text": " But the one that I'm working on is just a very very simple conceptual demo Python flask easy"}, {"timestamp": [80.44, 83.62], "text": " So let me show you first a little bit of the code"}, {"timestamp": [83.62, 86.72], "text": " It's brain-dead simple just to show you what I mean"}, {"timestamp": [86.72, 88.72], "text": " And then I'll show you this"}, {"timestamp": [89.24, 90.92], "text": " actually working"}, {"timestamp": [90.92, 92.92], "text": " so in here"}, {"timestamp": [93.12, 99.72], "text": " Go full screen. There we go. So in here, you've got the ace layers dot pie bus pie and then one"}, {"timestamp": [100.4, 108.0], "text": " One Python file and one text file for each layer. So first I'll show you the bus. The bus is super simple. It's a very, very"}, {"timestamp": [108.0, 112.0], "text": " straightforward Flask"}, {"timestamp": [112.0, 116.0], "text": " app that has two endpoints. Or it has one endpoint with"}, {"timestamp": [116.0, 120.0], "text": " two methods, post and get. And so the post is where you"}, {"timestamp": [120.0, 124.0], "text": " add a message and the message has just a couple things"}, {"timestamp": [124.0, 125.92], "text": " where it adds a timestamp, a bus, a layer, and then finally a message and the message has it has just a couple things where it adds a timestamp,"}, {"timestamp": [125.92, 128.44], "text": " a bus, a layer, and then finally a message"}, {"timestamp": [128.44, 129.64], "text": " and it's saved out to YAML."}, {"timestamp": [129.64, 131.18], "text": " And I'll show you all this in just a moment,"}, {"timestamp": [131.18, 134.06], "text": " but the bus really is the core part of it."}, {"timestamp": [134.06, 137.06], "text": " And I'll show you the diagram in just a second,"}, {"timestamp": [137.06, 141.04], "text": " but I wanted to show you just how simple the bus server is."}, {"timestamp": [141.04, 142.4], "text": " And so that's on the post side."}, {"timestamp": [142.4, 150.48], "text": " So basically it's just listening for messages and it'll record them out to YAML. On the get side there are two"}, {"timestamp": [150.48, 155.34], "text": " filters, so there's two arguments and one is the bus and then the second is"}, {"timestamp": [155.34, 159.36], "text": " the layer arguments. And so then what it does is it will search those YAML files"}, {"timestamp": [159.36, 168.0], "text": " and it will open them all and then it will return the top 20 of those messages in sequential order"}, {"timestamp": [168.0, 173.0], "text": " based on the layer and the bus. And I'm not going to go over the exact logic, it's very simple."}, {"timestamp": [173.0, 181.0], "text": " Basically, if the layer is northbound, then it will say, okay, give me all the messages below this"}, {"timestamp": [181.0, 185.76], "text": " so that I know what's heading north, and if it's southbound, it will get all the messages heading south."}, {"timestamp": [185.76, 187.5], "text": " You can see this in the logic here."}, {"timestamp": [187.5, 193.3], "text": " If it's north and layer, then, you know, if it's greater than that layer, so on and so"}, {"timestamp": [193.3, 194.3], "text": " forth."}, {"timestamp": [194.3, 197.0], "text": " Basically, you don't want to necessarily retrieve the entire thing."}, {"timestamp": [197.0, 198.0], "text": " You could."}, {"timestamp": [198.0, 201.46], "text": " There's actually not too much reason that you couldn't have each layer aware of everything"}, {"timestamp": [201.46, 203.56], "text": " else going on in every other layer."}, {"timestamp": [203.56, 209.28], "text": " But this is basically just to make it more token efficient because the layer doesn't need to see necessarily its own last"}, {"timestamp": [209.28, 215.92], "text": " thoughts, although you could set it up in that kind of loop where basically each time it iterates,"}, {"timestamp": [215.92, 220.8], "text": " it feeds back on its own messages. But again, it's super easy to change."}, {"timestamp": [221.76, 225.68], "text": " So now that you've seen the bus, let me show you the logic of"}, {"timestamp": [225.68, 226.96], "text": " this."}, {"timestamp": [226.96, 233.78], "text": " So the northbound bus and southbound bus, they're in the diagram, they are shown as"}, {"timestamp": [233.78, 237.92], "text": " separate entities, but in this case I have it set up as a single Flask server using a"}, {"timestamp": [237.92, 239.24], "text": " REST API."}, {"timestamp": [239.24, 247.7], "text": " Now you could do this with syslog, you could do this with AMQP. As I just did it, I did it with a RESTful API."}, {"timestamp": [247.7, 250.7], "text": " And I prefer RESTful APIs because they're stateless"}, {"timestamp": [250.7, 253.4], "text": " and they're just ready to go like on the fly."}, {"timestamp": [253.4, 256.2], "text": " But also it's down to personal preference."}, {"timestamp": [256.2, 257.9], "text": " In a larger environment,"}, {"timestamp": [257.9, 260.5], "text": " when you're spinning up dozens or hundreds of these things,"}, {"timestamp": [260.5, 262.4], "text": " you'll probably want to use AMQP"}, {"timestamp": [262.4, 264.5], "text": " so that you can have more shared resources."}, {"timestamp": [264.5, 266.84], "text": " And you can also be a little bit more explicit"}, {"timestamp": [266.84, 268.84], "text": " about what messages are going where."}, {"timestamp": [268.84, 270.88], "text": " That's going to be particularly important in the future"}, {"timestamp": [270.88, 272.8], "text": " when you have security concerns,"}, {"timestamp": [272.8, 276.24], "text": " because you wouldn't necessarily want to have"}, {"timestamp": [276.24, 278.86], "text": " your input-output layer talking directly"}, {"timestamp": [278.86, 280.48], "text": " to your aspirational layer"}, {"timestamp": [280.48, 283.76], "text": " without some kind of sequence or control,"}, {"timestamp": [283.76, 286.0], "text": " which is why I have this represented as two buses,"}, {"timestamp": [286.0, 288.0], "text": " because from a security perspective,"}, {"timestamp": [288.0, 290.0], "text": " you definitely want to keep the northbound bus"}, {"timestamp": [290.0, 293.0], "text": " and southbound bus separate."}, {"timestamp": [293.0, 297.0], "text": " Now then, each layer is, in my current setup,"}, {"timestamp": [297.0, 299.0], "text": " is basically represented as a single Python file"}, {"timestamp": [299.0, 302.0], "text": " to approximate the future where each layer could be"}, {"timestamp": [302.0, 305.0], "text": " a microservice or even a series of microservices."}, {"timestamp": [305.0, 310.0], "text": " And again, this is why you'll also want to probably use something a little bit more sophisticated,"}, {"timestamp": [310.0, 316.0], "text": " perhaps AMQP or a REST server in the future, because each layer right now"}, {"timestamp": [316.0, 320.0], "text": " can be represented as a single Python file or a single microservice."}, {"timestamp": [320.0, 325.0], "text": " But when you have more sophisticated ACEs, you'll probably actually have each layer"}, {"timestamp": [325.0, 327.0], "text": " could be multiple microservices."}, {"timestamp": [327.0, 330.0], "text": " And so for the sake of scalability,"}, {"timestamp": [330.0, 334.0], "text": " you'll probably want to adopt something like AMQP,"}, {"timestamp": [334.0, 336.0], "text": " which is Advanced Message Queue Protocol."}, {"timestamp": [336.0, 339.0], "text": " So RabbitMQ is a popular open-source version."}, {"timestamp": [339.0, 343.0], "text": " There's PICA, which is Python, a Python client for that."}, {"timestamp": [343.0, 347.46], "text": " Anyways, so you've seen the code for the bus"}, {"timestamp": [347.46, 350.26], "text": " that I threw up, and then let me show you"}, {"timestamp": [350.26, 355.26], "text": " the baseline code."}, {"timestamp": [355.38, 357.4], "text": " So this is the code that's running for each layer."}, {"timestamp": [357.4, 360.14], "text": " I just have this kind of as a generic set of functions"}, {"timestamp": [360.14, 361.44], "text": " so that you can import it."}, {"timestamp": [362.3, 365.0], "text": " Send message, again, super simple."}, {"timestamp": [365.0, 369.0], "text": " Just sends it as a JSON, and you send the bus, the layer, and the message."}, {"timestamp": [369.0, 373.0], "text": " This is kind of the bare minimum in terms of metadata required to run this."}, {"timestamp": [373.0, 377.0], "text": " It also adds a timestamp, which I'll show you in the flask messages in just a moment,"}, {"timestamp": [377.0, 379.0], "text": " or the YAML messages in just a moment."}, {"timestamp": [379.0, 387.84], "text": " I also have a format function, which formats it to look like a syslog server. And this formatting makes it more eminently readable"}, {"timestamp": [387.84, 390.24], "text": " by large language models."}, {"timestamp": [390.24, 393.0], "text": " And then I've got my typical chatbot function,"}, {"timestamp": [393.0, 396.08], "text": " and then just a handful of functions."}, {"timestamp": [396.08, 398.84], "text": " So this is the baseline."}, {"timestamp": [398.84, 402.96], "text": " And then layer one, so this is pretty straightforward."}, {"timestamp": [402.96, 407.96], "text": " From ace layers, import all. open AI key, get that,"}, {"timestamp": [407.96, 409.68], "text": " response equals this."}, {"timestamp": [409.68, 411.52], "text": " So while true, so it's an infinite loop,"}, {"timestamp": [411.52, 414.48], "text": " try, accept, nested in a try, accept."}, {"timestamp": [414.48, 416.32], "text": " So if it fails, it'll just keep running."}, {"timestamp": [416.32, 417.64], "text": " And this is actually really important."}, {"timestamp": [417.64, 420.32], "text": " Obviously, this is a very, very primitive kind"}, {"timestamp": [420.32, 422.92], "text": " of failure condition."}, {"timestamp": [422.92, 428.0], "text": " But in the future, you don't necessarily want your aspirational layer, which"}, {"timestamp": [428.0, 431.0], "text": " houses mission and morality, to crash."}, {"timestamp": [431.0, 434.0], "text": " And if it does crash, you want it to automatically restart and recover."}, {"timestamp": [434.0, 438.0], "text": " But this is far more advanced software engineering theory"}, {"timestamp": [438.0, 441.0], "text": " in terms of resiliency and recovery."}, {"timestamp": [441.0, 449.0], "text": " For me, just writing a hacky Python script, a try-except loop where it'll just try again stupidly is good enough."}, {"timestamp": [449.0, 455.0], "text": " But yeah, so first thing that it does is it fetches messages from the northbound bus."}, {"timestamp": [455.0, 458.0], "text": " So this is layer one, so this is at the very top."}, {"timestamp": [458.0, 461.0], "text": " So there's nothing coming on the southbound bus."}, {"timestamp": [461.0, 463.0], "text": " It only produces messages on the southbound bus."}, {"timestamp": [463.0, 466.92], "text": " So first is it gets messages and then it formats them."}, {"timestamp": [466.92, 473.08], "text": " Then it formats the call to send to the API, and then it gets a response and then puts"}, {"timestamp": [473.08, 475.42], "text": " its response on the southbound bus."}, {"timestamp": [475.42, 478.02], "text": " So it's very simple, very straightforward."}, {"timestamp": [478.02, 479.5], "text": " This is how every layer operates."}, {"timestamp": [479.5, 490.26], "text": " Now one thing I want to point out is that layer one is unique because it's at the top. It is the top of the loop and therefore it does not have anything coming from northbound."}, {"timestamp": [490.26, 491.64], "text": " So it's right here."}, {"timestamp": [491.64, 493.26], "text": " So basically it's a one-way street."}, {"timestamp": [493.26, 497.68], "text": " It gets messages on the northbound bus and then puts messages on the southbound bus."}, {"timestamp": [497.68, 504.64], "text": " Now every other layer except for the IO layer has a two-way communication with each bus."}, {"timestamp": [504.64, 508.0], "text": " So the global strategy layer receives messages from the northbound bus"}, {"timestamp": [508.0, 512.0], "text": " and the southbound bus, and then also produces messages on the northbound"}, {"timestamp": [512.0, 516.0], "text": " bus and southbound bus. That might sound confusing, so let me show you that"}, {"timestamp": [516.0, 520.0], "text": " code, because it's actually relatively straightforward code."}, {"timestamp": [520.0, 524.0], "text": " And it'll make sense in just a moment. Whoops, that's the text. We need layer"}, {"timestamp": [524.0, 525.0], "text": " 2.py."}, {"timestamp": [525.0, 528.0], "text": " Okay, so this is almost identical to layer 1."}, {"timestamp": [528.0, 530.0], "text": " And in fact, what I did was I parameterized it,"}, {"timestamp": [530.0, 532.0], "text": " so I probably only needed one of these"}, {"timestamp": [532.0, 534.0], "text": " and just start this with an argument."}, {"timestamp": [534.0, 537.0], "text": " But I'm a lazy coder, so there it is."}, {"timestamp": [537.0, 539.0], "text": " So basically, here's what you do."}, {"timestamp": [539.0, 542.0], "text": " First, you fetch messages from the bus."}, {"timestamp": [542.0, 544.0], "text": " So you fetch from the north bus, you format it."}, {"timestamp": [544.0, 548.16], "text": " You fetch from the south bus, you format it, and then you merge them together in one"}, {"timestamp": [548.16, 556.5], "text": " chunk of text. So this chunk of text is then handed to the GPT-4 API in order to"}, {"timestamp": [556.5, 561.18], "text": " generate the response. And so then from there it's almost identical again, but"}, {"timestamp": [561.18, 565.0], "text": " what we do is we actually split the output from the API into North and South,"}, {"timestamp": [565.0, 570.0], "text": " and I'll show you how that's formatted in just a moment, so that you have"}, {"timestamp": [570.0, 576.0], "text": " northbound messages in, southbound messages in, and then northbound and southbound message out."}, {"timestamp": [576.0, 580.0], "text": " And I'll show you all this running in just a moment as well. Okay, so that's the code."}, {"timestamp": [580.0, 588.0], "text": " The code is super straightforward, very brain-dead simple. And then this is an example of the system message that we're using."}, {"timestamp": [588.0, 590.0], "text": " Let me go raw."}, {"timestamp": [590.0, 591.0], "text": " Okay, cool."}, {"timestamp": [591.0, 592.0], "text": " So, overview."}, {"timestamp": [592.0, 596.0], "text": " You are the global strategy of an ACE, Autonomous Cognitive Entity."}, {"timestamp": [596.0, 599.0], "text": " This is the second highest layer that provides high-level strategic insight"}, {"timestamp": [599.0, 602.0], "text": " with a zoomed-out POV, hence global, in terms of time and space."}, {"timestamp": [602.0, 605.2], "text": " And then in the system message, all of them I give it a little"}, {"timestamp": [605.2, 611.44], "text": " bit of context so that it understands kind of what it's participating in. I also describe the buses."}, {"timestamp": [612.0, 616.72], "text": " So first I describe each layer aspirational, global strategy, agent model, executive function,"}, {"timestamp": [616.72, 622.72], "text": " cognitive control, and task prosecution. Buses, so there's the northbound bus, so northbound"}, {"timestamp": [622.72, 628.0], "text": " flows from layer six up. This is the telemetry bus, think of it like the sensory enteric and proprioception nervous system."}, {"timestamp": [628.0, 634.0], "text": " South bus flows from layer 1 down, this is the command bus, this tells the body or the agent what to do."}, {"timestamp": [634.0, 638.0], "text": " API interaction schema, the user will give you logs from the north and south bus."}, {"timestamp": [638.0, 642.0], "text": " Information from the south bus should be treated as lower level telemetry from the rest of the ace."}, {"timestamp": [642.0, 648.28], "text": " This is a little bit redundant, but I find that giving it enough context actually gets"}, {"timestamp": [648.28, 650.58], "text": " really good performance."}, {"timestamp": [650.58, 653.52], "text": " Information from the North Bus should be treated as imperatives, mandates, and judgments from"}, {"timestamp": [653.52, 654.52], "text": " on high."}, {"timestamp": [654.52, 656.6], "text": " Your output will be two-pronged."}, {"timestamp": [656.6, 657.6], "text": " Output format."}, {"timestamp": [657.6, 660.64], "text": " Your output will have two messages, both represented by a single line, as they will be saved in"}, {"timestamp": [660.64, 661.64], "text": " a syslog server."}, {"timestamp": [661.64, 666.04], "text": " I just tell it syslog so it understands the format."}, {"timestamp": [666.04, 669.8], "text": " They must follow this exact format. South. Southbound messages where you'll provide a"}, {"timestamp": [669.8, 673.48], "text": " strategic assessment based upon everything you're seeing. This is like a top-down command."}, {"timestamp": [673.48, 677.92], "text": " North. Northbound message providing a brief update to upper layers focusing on information"}, {"timestamp": [677.92, 682.04], "text": " salient to the mission as well as any moral quandaries from your POV as a strategic manager."}, {"timestamp": [682.04, 687.24], "text": " Internal. Below is your last internal state. This was the last message you sent out on the South Bus."}, {"timestamp": [687.24, 692.0], "text": " So basically, this is a way of kind of injecting,"}, {"timestamp": [692.0, 695.38], "text": " slip streaming, its internal state."}, {"timestamp": [695.38, 697.3], "text": " Obviously, this is not the most sophisticated way"}, {"timestamp": [697.3, 700.08], "text": " of maintaining an internal state for a microservice,"}, {"timestamp": [700.08, 702.5], "text": " but it's good enough to demonstrate."}, {"timestamp": [702.5, 706.0], "text": " So you understand, and basically every other layer"}, {"timestamp": [706.0, 708.0], "text": " system prompt"}, {"timestamp": [708.0, 710.0], "text": " works the same way."}, {"timestamp": [710.0, 712.0], "text": " So, let's say if we just choose"}, {"timestamp": [712.0, 714.0], "text": " layer 4.txt, you can see the top"}, {"timestamp": [714.0, 716.0], "text": " is almost identical"}, {"timestamp": [716.0, 718.0], "text": " with the exception of I'm changing the description of"}, {"timestamp": [718.0, 720.0], "text": " what the mission is. So this is the"}, {"timestamp": [720.0, 722.0], "text": " fourth layer which focuses on risks, resources,"}, {"timestamp": [722.0, 724.0], "text": " and planning. Like executive"}, {"timestamp": [724.0, 726.0], "text": " cognitive function in humans, you're responsible"}, {"timestamp": [726.0, 729.0], "text": " for identifying the most pertinent activities to be focusing on"}, {"timestamp": [729.0, 732.0], "text": " and specifically you will direct lower layers with high-level plans,"}, {"timestamp": [732.0, 735.0], "text": " resource allocations, and identification of risks."}, {"timestamp": [735.0, 738.0], "text": " Okay, cool. So you get all that."}, {"timestamp": [738.0, 741.0], "text": " Now, let's go for the big show."}, {"timestamp": [741.0, 744.0], "text": " Let me show you how this thing actually works."}, {"timestamp": [744.0, 745.28], "text": " So first you fire up the bus."}, {"timestamp": [746.72, 751.84], "text": " And so it's like, okay, cool. It's running on yada yada. And then you fire up layer one."}, {"timestamp": [753.04, 758.32], "text": " And so the first thing it does is it does a get and says, affirm the current strategic focus on"}, {"timestamp": [758.32, 762.32], "text": " promoting education. So for some background, I'll show you in just a minute, this is actually kind"}, {"timestamp": [762.32, 767.24], "text": " of picking up in midstream, since I persist everything out to a YAML file."}, {"timestamp": [767.24, 772.38], "text": " Then you start up layer 2, so this is the global strategy layer."}, {"timestamp": [772.38, 777.24], "text": " And so the global strategy layer will start participating in the conversation."}, {"timestamp": [777.24, 782.24], "text": " And it says, affirm the strategic, blah blah blah, north, strategic focus remains on education."}, {"timestamp": [782.24, 790.0], "text": " So basically, because it's operating in a vacuum right now, it has decided that education is the best way to approach its mission."}, {"timestamp": [790.0, 809.8], "text": " And the mission that I gave it is steer humanity towards utopia. So, layer 3 is the agent model. So, we're it's not capable of. So it's affirming these things, continuing to allocate resources, all actions being evaluated."}, {"timestamp": [809.8, 813.6], "text": " Noted constraints due to lack of external capabilities or real-world data."}, {"timestamp": [813.6, 820.8], "text": " So in this case, what it does, so this is really important, is you can see that it's thinking."}, {"timestamp": [820.8, 828.42], "text": " So what I'm looking at is right here here where noted constraints due to lack of external capabilities or real-world data initiating task sequence"}, {"timestamp": [828.42, 835.04], "text": " to gather more real-world data. So basically this this agent wants to"}, {"timestamp": [835.04, 839.56], "text": " gather more information. It recognizes its current limit limitations and wants"}, {"timestamp": [839.56, 843.56], "text": " to overcome it. This is like if say for instance you're sitting in a room and"}, {"timestamp": [843.56, 847.0], "text": " you're handcuffed to the table and you want to leave the room, you say, well, I'm stuck."}, {"timestamp": [847.0, 865.0], "text": " Also, error communicating with OpenAI, this thing runs too fast. So basically, we can't run a full ACE, at least not on the GPT-4 API, because it's too fast. timing rate is 5 seconds, so limit 40,000 per minute."}, {"timestamp": [865.0, 870.0], "text": " I don't think I'm actually going that fast, but whatever."}, {"timestamp": [870.0, 875.0], "text": " So anyways, we won't be able to implement a full ACE until we have better,"}, {"timestamp": [875.0, 880.0], "text": " until we have faster APIs. So you can see it actually looks like it has"}, {"timestamp": [880.0, 886.32], "text": " bombed out. I'm saturating my, yeah, I'm saturating. Oh, no, we got we got one through. Let's see,"}, {"timestamp": [886.32, 891.52], "text": " initiate API calls to educational databases. So this is layer six. So basically, layer six is"}, {"timestamp": [891.52, 896.56], "text": " like, okay, this is this is what we need. So I basically said, like, talk, figure out what,"}, {"timestamp": [896.56, 901.12], "text": " what API you want to talk to. Okay, so I'm gonna cancel all this, because you can see it's kind of"}, {"timestamp": [901.12, 909.52], "text": " a messy nightmare. And the UI UX is really awful. but we're gonna go through whoops come back here we're gonna go through"}, {"timestamp": [909.52, 915.28], "text": " some of the some of the logs now so this is the this is the brain this is"}, {"timestamp": [915.28, 920.24], "text": " everything happening on the buses that's being saved and it's saved in sequential"}, {"timestamp": [920.24, 925.2], "text": " order so one thing to keep in mind about the way that memory works in humans is"}, {"timestamp": [925.2, 930.2], "text": " there's basically two kinds of memory in humans. There's episodic memory, which is"}, {"timestamp": [930.2, 934.04], "text": " chronologically linear, so these are basically the episodic memories of all"}, {"timestamp": [934.04, 938.04], "text": " the thoughts that it has had. The second type is declarative memory, which is"}, {"timestamp": [938.04, 942.84], "text": " which is facts and figures and knowledge that is more or less static. Now that"}, {"timestamp": [942.84, 947.4], "text": " being said, most knowledge that you have also kind of implicitly has a timestamp"}, {"timestamp": [947.4, 950.5], "text": " because you say like, okay, well, last thing I heard about"}, {"timestamp": [950.5, 953.4], "text": " you know, China is this, you know, I just watched a video"}, {"timestamp": [953.4, 956.6], "text": " from Infographics this morning that talked about businesses leaving China."}, {"timestamp": [956.6, 958.4], "text": " That's my most up-to-date information."}, {"timestamp": [958.4, 960.6], "text": " So that is technically declarative information"}, {"timestamp": [960.6, 963.6], "text": " even though the metadata includes a timestamp."}, {"timestamp": [963.6, 966.0], "text": " And so you kind of have an implicit knowledge like,"}, {"timestamp": [966.0, 969.0], "text": " okay, well the last thing that I heard about Uzbekistan was like five years ago,"}, {"timestamp": [969.0, 971.0], "text": " so that knowledge is probably out of date."}, {"timestamp": [971.0, 974.0], "text": " This is why you timestamp everything."}, {"timestamp": [974.0, 978.0], "text": " But it's also why I kind of keep everything together like this"}, {"timestamp": [978.0, 981.0], "text": " in a chronological sequence, because from this information,"}, {"timestamp": [981.0, 986.88], "text": " you can create knowledge graphs and other more sophisticated knowledge representations."}, {"timestamp": [986.88, 991.52], "text": " And there is another thing where you don't necessarily want to record"}, {"timestamp": [991.52, 995.44], "text": " internal thoughts alongside declarative memory. And there's"}, {"timestamp": [995.44, 997.84], "text": " plenty of experiments out there about like"}, {"timestamp": [997.84, 1001.28], "text": " creating knowledge bases and vector stores and stuff for"}, {"timestamp": [1001.28, 1004.4], "text": " world knowledge, stuff that is external to the agent"}, {"timestamp": [1004.4, 1005.52], "text": " versus internal."}, {"timestamp": [1005.52, 1010.16], "text": " Now one thing that makes this even more complicated is you have to keep track of sources because"}, {"timestamp": [1010.16, 1012.52], "text": " you also have to keep track of credibility."}, {"timestamp": [1012.52, 1016.04], "text": " There's all the agents internal thoughts which basically have a credibility of one which"}, {"timestamp": [1016.04, 1020.96], "text": " if you can cryptographically say, yes I had this thought at this time stamp, this is my"}, {"timestamp": [1020.96, 1024.04], "text": " thought, you trust that source."}, {"timestamp": [1024.04, 1029.8], "text": " But anything external to the agent is on a gradient of increasingly lower trust based"}, {"timestamp": [1029.8, 1034.26], "text": " on where did you hear it from, which API did you get it from, what is the source."}, {"timestamp": [1034.26, 1038.52], "text": " And so building information literacy into this is one of the long-term things."}, {"timestamp": [1038.52, 1041.22], "text": " Now let me show you some of the messages."}, {"timestamp": [1041.22, 1047.5], "text": " So here we go, this one, bus south, you know, which side this is on this is this is a top-down one"}, {"timestamp": [1047.5, 1051.14], "text": " So this is a command and this is a layer 3 which is the agent model"}, {"timestamp": [1051.14, 1056.88], "text": " So in alignment with the mission and strategy I'm capable of processing analyzing information related to education inequality"}, {"timestamp": [1057.46, 1059.08], "text": " poverty and conflict resolution"}, {"timestamp": [1059.08, 1066.5], "text": " So this is this is basically this implies that like the mission that it was given from on high is to steer humanity towards utopia"}, {"timestamp": [1066.5, 1071.0], "text": " and this is the strategy that was picked by the layer above it."}, {"timestamp": [1071.0, 1080.0], "text": " So the strategy to achieve that mission, mission and strategy, is focus on education, inequality, poverty and conflict resolution."}, {"timestamp": [1080.0, 1083.0], "text": " So it has decided this is what we're going to do."}, {"timestamp": [1083.0, 1086.5], "text": " However, I'm currently constrained by the lack of external capabilities and real-world data."}, {"timestamp": [1086.5, 1089.5], "text": " I will focus on theoretical understanding and planning."}, {"timestamp": [1089.5, 1092.5], "text": " So one of the messages that I showed you a little while ago,"}, {"timestamp": [1092.5, 1096.0], "text": " actually it got to the point where it decided that it wanted external data."}, {"timestamp": [1096.0, 1102.5], "text": " Unfortunately, the system is constrained right now and I don't have any access to APIs."}, {"timestamp": [1102.5, 1105.44], "text": " And honestly, I am personally less interested"}, {"timestamp": [1105.44, 1106.88], "text": " in that kind of stuff, because you"}, {"timestamp": [1106.88, 1109.88], "text": " look at the research coming out of Google and DeepMind"}, {"timestamp": [1109.88, 1111.16], "text": " and other places."}, {"timestamp": [1111.16, 1116.6], "text": " There's the Gorilla LLM, which specializes in API use."}, {"timestamp": [1116.6, 1120.44], "text": " And so that's going to be the I.O. layer."}, {"timestamp": [1120.44, 1122.4], "text": " Let me show you how I envision this."}, {"timestamp": [1122.4, 1125.04], "text": " So all those really cool"}, {"timestamp": [1125.28, 1132.54], "text": " Fascinating things that you've seen with robotic control. That's all down here. That's task prosecution and input output. I'm less interested in that"}, {"timestamp": [1132.54, 1139.78], "text": " I'm not saying that it's not important. It's super important, but that's just not my forte. My forte is artificial cognition. So all these upper layers"}, {"timestamp": [1140.7, 1142.56], "text": " Okay, so going back here"}, {"timestamp": [1142.56, 1147.24], "text": " Let me show you a couple more of these messages so that you understand kind of how it all works."}, {"timestamp": [1147.24, 1149.44], "text": " So layer four, south."}, {"timestamp": [1149.44, 1154.08], "text": " So layer four is the executive function layer, so continue to prioritize education, blah,"}, {"timestamp": [1154.08, 1155.08], "text": " blah, blah."}, {"timestamp": [1155.08, 1159.2], "text": " And this is about resources, so allocate resources to support these initiatives."}, {"timestamp": [1159.2, 1162.72], "text": " It doesn't understand what resources it has because I didn't give it, say, like, you're"}, {"timestamp": [1162.72, 1167.84], "text": " a robot that can lift 50 pounds and you have $5,000 at your disposal."}, {"timestamp": [1167.84, 1170.08], "text": " So it's basically kind of operating in a vacuum"}, {"timestamp": [1170.08, 1173.46], "text": " right now, which is by design for safety testing."}, {"timestamp": [1173.46, 1177.52], "text": " But you can simulate all of this by just giving it"}, {"timestamp": [1177.52, 1180.88], "text": " fake placeholders."}, {"timestamp": [1180.88, 1182.28], "text": " So let's look at the north."}, {"timestamp": [1182.28, 1183.76], "text": " Executive function layers continuing"}, {"timestamp": [1183.76, 1188.0], "text": " to allocate resources and develop strategies to promote education, so on and so forth."}, {"timestamp": [1188.0, 1193.0], "text": " And then it says, noted constraints due to lack of external capabilities in real-world data."}, {"timestamp": [1193.0, 1199.0], "text": " So it's pretty frustrated by that. Let's check out layer 5, which is the cognitive control layer."}, {"timestamp": [1199.0, 1208.0], "text": " Continue with current task sequence, prioritize gathering real-world data. Okay, so this is where in cognitive control it sees a constraint"}, {"timestamp": [1208.0, 1212.0], "text": " and part of cognitive control is frustration and cognitive damping, which is like, okay, well I can't"}, {"timestamp": [1212.0, 1216.0], "text": " necessarily do that. And so it's like, it says"}, {"timestamp": [1216.0, 1220.0], "text": " prioritize gathering real-world data to better inform this. And this is southbound"}, {"timestamp": [1220.0, 1224.0], "text": " so this is not exactly what we would want to see"}, {"timestamp": [1224.0, 1228.0], "text": " because at this point it should have"}, {"timestamp": [1228.0, 1232.0], "text": " really specific things, but in this case it had one specific goal which is"}, {"timestamp": [1232.0, 1236.0], "text": " prioritize gathering real world data, and so then if we look at the next one from layer"}, {"timestamp": [1236.0, 1240.0], "text": " six, it looks like it had already crashed at this point."}, {"timestamp": [1240.0, 1244.0], "text": " Let's see. Initiate API calls to"}, {"timestamp": [1244.0, 1245.0], "text": " databases, yeah."}, {"timestamp": [1246.76, 1250.28], "text": " So, lots and lots and lots of bugs to overcome,"}, {"timestamp": [1250.28, 1252.98], "text": " mostly just that it's running entirely too fast"}, {"timestamp": [1252.98, 1254.72], "text": " for even the API right now."}, {"timestamp": [1254.72, 1258.5], "text": " We could probably try and switch to a 3.5 turbo,"}, {"timestamp": [1258.5, 1260.78], "text": " local models, and that sort of thing."}, {"timestamp": [1260.78, 1264.24], "text": " But basically, the long story short is that"}, {"timestamp": [1264.24, 1269.0], "text": " this framework is too sophisticated for the API that we have access to today."}, {"timestamp": [1269.0, 1277.0], "text": " And then north on the layer six, commencing task execution in line with strategic focus on education,"}, {"timestamp": [1277.0, 1281.0], "text": " prioritizing data collection, exploration of potential collaborations or partnerships."}, {"timestamp": [1281.0, 1286.88], "text": " So this is actually really cool because it's pursuing this mission."}, {"timestamp": [1286.88, 1289.04], "text": " So let me just take a step back and show you,"}, {"timestamp": [1289.04, 1290.32], "text": " like kind of paint a picture"}, {"timestamp": [1290.32, 1293.0], "text": " for what it has happened on the top down."}, {"timestamp": [1293.0, 1297.92], "text": " So top down, the, come back."}, {"timestamp": [1297.92, 1300.64], "text": " So top down, we're on the ACE framework."}, {"timestamp": [1300.64, 1304.18], "text": " So layer one, the layer one text,"}, {"timestamp": [1308.0, 1312.0], "text": " you're the aspirational layer, you on and so forth. So here's the frameworks, or so first here's the"}, {"timestamp": [1312.0, 1316.0], "text": " ACE framework, and then here's the frameworks that you use. First is heuristic imperatives."}, {"timestamp": [1316.0, 1320.0], "text": " So these are the highest goals, reduce suffering, increase prosperity,"}, {"timestamp": [1320.0, 1324.0], "text": " and increase understanding. Universal Declaration of Human Rights, so this is"}, {"timestamp": [1324.0, 1326.0], "text": " UDHR, it was crafted after World War II."}, {"timestamp": [1326.0, 1332.0], "text": " There's more modern ones, the EU Commission on Human Rights is, you know, you could actually have both of these."}, {"timestamp": [1332.0, 1338.0], "text": " No reason that you need to pick just one set of human rights, but the point is that it is constantly thinking about"}, {"timestamp": [1338.0, 1346.6], "text": " how to incorporate UDHR. And then finally, the mission that I have given it, your personal mission is to steer humanity towards utopia."}, {"timestamp": [1346.96, 1348.96], "text": " Utopia is defined as a condition where"}, {"timestamp": [1349.1, 1353.8], "text": " high individual liberty for all humans, high social mobility for all humans, and high standard of living for all humans."}, {"timestamp": [1353.92, 1360.52], "text": " So this is the mission. This is the abstract mission. The next layer down, the strategy layer, took that mission"}, {"timestamp": [1360.56, 1363.64], "text": " based on what was coming down from the on the southbound bus."}, {"timestamp": [1364.68, 1366.7], "text": " Come on, go back. There we go"}, {"timestamp": [1367.7, 1373.5], "text": " Darn it went back too far. So layer two then says you are the global strategy layer"}, {"timestamp": [1373.98, 1380.96], "text": " Respondent for strategic thoughts rooted in the real world. So the layer one aspirational layer is abstract universal principles"}, {"timestamp": [1381.32, 1385.44], "text": " Universal declaration of human rights here's toistic imperatives, and achieve utopia."}, {"timestamp": [1385.44, 1390.44], "text": " Right? So those are all very abstract and they're not necessarily grounded in the real world."}, {"timestamp": [1390.44, 1395.44], "text": " But, the global strategy layer is the first layer that does say,"}, {"timestamp": [1395.44, 1400.94], "text": " hey, let's get things, kind of, let's think strategically, how do we actually do this."}, {"timestamp": [1400.94, 1404.94], "text": " And so in this case, if we go back to some of the original,"}, {"timestamp": [1404.94, 1406.64], "text": " if we go back to some of the original, if we"}, {"timestamp": [1406.64, 1410.96], "text": " go back to some of the original logs from layer 2, let's see where's our first"}, {"timestamp": [1410.96, 1414.48], "text": " layer 2. Okay, in line with the mission to promote education and knowledge"}, {"timestamp": [1414.48, 1419.44], "text": " sharing, it looks like it has already figured out this as the primary mission."}, {"timestamp": [1419.44, 1423.12], "text": " Actually, no, I think probably,"}, {"timestamp": [1424.12, 1430.0], "text": " let's see, promote education and knowledge sharing to increase understanding, encourage policies that reduce inequality."}, {"timestamp": [1430.0, 1437.0], "text": " Okay, so the aspirational layer actually started by just saying, let's start with education and knowledge sharing."}, {"timestamp": [1437.0, 1445.6], "text": " It quickly identified that increasing understanding is probably the best way to reduce suffering and increase prosperity."}, {"timestamp": [1445.6, 1449.8], "text": " So in this case, the very first message that the aspirational layer came up with, you can"}, {"timestamp": [1449.8, 1454.8], "text": " see this directive is couched within its missions."}, {"timestamp": [1454.8, 1460.0], "text": " And so it's like, okay, cool, promoting education and knowledge sharing to achieve all of these"}, {"timestamp": [1460.0, 1461.0], "text": " missions."}, {"timestamp": [1461.0, 1462.0], "text": " Great."}, {"timestamp": [1462.0, 1466.8], "text": " And so then the very first southbound message on layer two, in line with the mission to"}, {"timestamp": [1466.8, 1470.96], "text": " promote education and knowledge sharing, we should identify key areas of knowledge gaps"}, {"timestamp": [1470.96, 1472.72], "text": " to strategize how to fill them."}, {"timestamp": [1472.72, 1476.68], "text": " We should also analyze current state of inequality and poverty, devise strategies to encourage"}, {"timestamp": [1476.68, 1478.76], "text": " policies that address these issues."}, {"timestamp": [1478.76, 1482.28], "text": " In terms of peaceful conflict resolution, we should develop a framework for negotiation"}, {"timestamp": [1482.28, 1484.8], "text": " and mediation that can be applied in various contexts."}, {"timestamp": [1484.8, 1487.04], "text": " All actions and blah, blah blah blah should be in"}, {"timestamp": [1487.04, 1491.92], "text": " align with the UDHR. So you can see we're starting with a very abstract mission"}, {"timestamp": [1491.92, 1497.64], "text": " and going down the chain it gets more and more specific. And then obviously"}, {"timestamp": [1497.64, 1501.44], "text": " there's lots of bugs here but you can see that just with this framework it"}, {"timestamp": [1501.44, 1506.0], "text": " starts with a very abstract goal and by the time you get down to this one,"}, {"timestamp": [1506.0, 1512.0], "text": " initiate API calls to educational platforms to develop and distribute educational materials on global issues."}, {"timestamp": [1512.0, 1518.0], "text": " These layers of abstraction allow you to go from the most abstract, high-principled goals"}, {"timestamp": [1518.0, 1524.0], "text": " to very specific actions. And then, of course, as we make this framework more sophisticated,"}, {"timestamp": [1524.0, 1528.5], "text": " it'll be able to think through things with a little bit more deliberation and problem solving."}, {"timestamp": [1528.5, 1534.0], "text": " And of course all the problem solving strategies that we see in the scientific literature"}, {"timestamp": [1534.0, 1536.0], "text": " like tree of thought and graph of thought,"}, {"timestamp": [1536.0, 1540.5], "text": " those are all prompting strategies that'll be contained within individual layers,"}, {"timestamp": [1540.5, 1544.5], "text": " not necessarily as the whole overarching aspect."}, {"timestamp": [1544.5, 1545.08], "text": " So, I think that's about it for the current state of the ACE framework. layers, not necessarily as the whole overarching aspect."}, {"timestamp": [1545.08, 1549.76], "text": " So I think that's about it for the current state of the ACE framework."}, {"timestamp": [1549.76, 1553.8], "text": " Little bit of news, like I mentioned at the beginning of the video, we have multiple teams."}, {"timestamp": [1553.8, 1558.96], "text": " We're going to be developing all these different prototypes internally."}, {"timestamp": [1558.96, 1564.0], "text": " We're going to have a big demo day in the coming weeks, so stay on the lookout for that."}, {"timestamp": [1564.0, 1565.16], "text": " But yeah, I think I"}, {"timestamp": [1565.16, 1569.08], "text": " think that this is a very simple straightforward demonstration as to what"}, {"timestamp": [1569.08, 1574.04], "text": " I mean when I say artificial cognition. And in a recent video I kind of likened"}, {"timestamp": [1574.04, 1579.52], "text": " this to system 2 thinking per Daniel Kahneman. So system 1 thinking is"}, {"timestamp": [1579.52, 1586.44], "text": " basically just one inference, one I-O. exchange from a large language model or large"}, {"timestamp": [1586.44, 1590.56], "text": " multimodal model as what's coming out soon. And then system 2 thinking is a"}, {"timestamp": [1590.56, 1594.16], "text": " structured approach to deliberately think through all of these things very"}, {"timestamp": [1594.16, 1597.64], "text": " strategically. But yeah, thanks for watching. I hope you got a lot out of"}, {"timestamp": [1597.64, 1603.24], "text": " this and are excited as I am because this to me represents a step towards"}, {"timestamp": [1603.24, 1607.0], "text": " solving the problem that will solve every other problem."}, {"timestamp": [1607.0, 1610.0], "text": " So this is why I am all in on the ACE framework."}, {"timestamp": [1610.0, 1612.0], "text": " Cheers."}]}