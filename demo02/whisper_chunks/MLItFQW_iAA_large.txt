{"text": " Okay, so you know how chat GPT has been slightly, let's say, lobotomized lately? It seems to not really handle coding that well. And if you're like me, I tried GitHub Copilot and I really don't like it. I applied for the GitHub Copilot chat and then a few days later I tried to go use it and it says, oh, well, the beta has expired, or you've been kicked out, or whatever. I was like, OK, whatever. So I realized that, all right, I have the power to fix this myself, because I've been shying away from doing my coding experiments, because chat GPT is broken, or lobotomized, or whatever. And GitHub Copilot, and I know there's lots of other tools there's Amazon and blah blah blah but you know like I can fix this I can I can do the thing that I want to do and I can make a thing that is specific. So I came over to the playground and I was like all right let's try this. So I just want to show you real quick. You know I gave a really simple prompt system message you are Python coding assistant the user will give you instructions to help write functions. You may ask for clarification if needed but otherwise you should only output Python code. And of course you can change this to whatever language you want. Adhere to PEP 8 so that's the Python enhancement program version 8 which is basically sets all the standards for how to write Python Pythonically, provide explanations of the code only if the user asks for them. So you know how like chat GPT will be super overly verbose. And then I gave it a copy of the script that I was working on. And so then I said, write a function that loads all files into a given folder, returns a list of lists and groups of five, include the full file path. And it just, bam, did it. I was like, cool, that's exactly what I wanted. And I was like, wait, that worked really well, so why don't I just make a chatbot that does it? So, coding chatbot assistant. Since chat GPT has been lobotomized and GitHub copilot is broken. I got it set up here. Here's an example of the output. So for instance, I'm working on, you know, my recent projects have been chatbots with long-term memories and KB articles and stuff. So I was like, okay, I've got this far, just write the function for me. So I told it how I want to write the function. You know, it's a KB article with a YAML file, so on and so forth. Now, that being said, I want to show you function you know it's a KB article with a yaml file so on and so forth. Now that being said I want to show you a really cool cool bit so this is the output you can see it's pretty familiar. So it gives you like OK you know you need to import this let's do this. Here's a couple of functions and it thought through it and gave it a very very very specific output. I haven't tested this code yet, but this is very much the behavior that I wanna see. So now let me explain to you how the chatbot works. So we'll go through the code real quick. It's pretty straightforward. It's 105 lines of code, so not the most complicated thing. And actually, some of this is superfluous. I actually think that I don't use the YAML functions anywhere. Yes, I could probably delete that and make it even shorter. All right, so ignore those helper functions. Here's the call to GPT. Super simple. You just call it. You get the text response. And then what I started doing is I just pass back the token count so that I can manage the text response. And then what I started doing is I just pass back the token count so that I can manage the conversation internally. But pretty much this whole thing here is just if there's an error, it will give you some output. So for instance, if the content context links is too long, it'll trim the conversation and try again. It'll let you know what happened. If another error happened, it'll put it'll output that the whole thing sometimes the it's not available whatever opening I has gotten a lot better but sometimes you'll have you know network errors and other stuff and what this does is it uses exponential back off so every time it retries it doubles the amount of time that it'll wait to try again. And it'll give you debug output the whole time. And then I've got this function. So this is a multi-line input function, which it will switch into this mode if you want to update a scratchpad. So in this case, the scratchpad is just a plain text file that it uses to load into the system message. So I've got that system message that I showed you and then a description of the below code scratch pad may be provided by the user blah blah blah. And so then it I wrap it in the comment so that way knows like hey this is Python and then it'll copy paste the you know your code into it from the scratch pad. And so what you can do is first it'll take you know input from the user and then if you type in scratchpad it will give you a chance to update the scratchpad which is you can put anything you can put in code you can put in comments you whatever you can put in a file system description whatever you want. But the point is is that it will use this function so that it will continue to accept new lines of input without without breaking. And so then when if you type end at the very end then it says OK cool save exit. I strip that out of the end and so on and so forth. So there you go. Let's see. It should be about it. Oh, and then if you accidentally hit enter twice, because you know that can happen, it'll just go like it says, you know, enter. Whoops, crap, I accidentally type something. So that's going to break it. Yeah, it was very confused. Yep. Okay, let's see. So then the other thing that I do is I accumulate all the messages, the user input and the chatbot response in a list called all messages. And I keep that separate from the conversation object that I passed to chat GPT, that I passed to the API. And the reason is because I actually just had a, had a Patreon supporter give me this really powerful tip, which is that if you put the system message at the end, rather than at the beginning, it is much more likely to continue to adhere to the instructions that you gave it rather than drift. So apparently this I haven't I haven't spent too much time testing it but you know how sometimes like chat GPT's behavior will change over time especially as the conversation gets longer it'll continue to kind of modify its behavior and it'll usually kind of default back to its default behavior. If you put the system message at the very end. So what I do is I say you know conversation is an empty list. I add all messages and then I append the system message at the very end and then I get the response. And so then once I get the response it passes back the tokens. If it's if the token count is over seventy five hundred because we've got a limit of eight thousand. I just remember the I remember I remove the oldest message so pop zero and then I append the assistant response to all messages so remember all messages is kept separate so that I can just tack on the system message separately and then I get the output and here it goes. So what I realized is that if you use text wrap, it will nullify all of the new lines. So what I do is I split the new lines and then text wrap it so that if there's comments, then it won't be too long. So anyways, there you have it. The repo is up here, it's working. The only thing that it's pretty well documented I got in the habit of just using chat GPT to produce the documentation because that makes it easier for everybody. Setup is super simple you just mean need open AI you need your open AI API key and then the biggest thing that you need to know is to use a scratch pad. I do have instructions in the console output. So it'll tell you how to get into the scratch pad and then how to get out of it. And then the console will tell you what mode you're in. You can tell I was an infrastructure engineer who used Cisco switches. Cause I'm just like, hey, this model works. Anyways, so yeah, I think that's about it. So this is my new chatbot coding assistant and yeah, I hope that you find it useful. Super simple, super straightforward. Yeah, let me know if you have any thoughts about how to improve it, but I think honestly the scratchpad is like all you need Because then you can you can update this out of band as well If you want to you know Whatever you want to put in it right you can you can even put multiple scripts in it or multiple files or whatever But yeah, so thanks for watching. I hope you liked it, and I'm gonna get back to coding. Bye But yeah, so thanks for watching. I hope you liked it, and I'm gonna get back to coding. Bye", "chunks": [{"timestamp": [0.0, 5.0], "text": " Okay, so you know how chat GPT has been slightly,"}, {"timestamp": [5.98, 8.06], "text": " let's say, lobotomized lately?"}, {"timestamp": [8.06, 11.22], "text": " It seems to not really handle coding that well."}, {"timestamp": [11.22, 14.9], "text": " And if you're like me, I tried GitHub Copilot"}, {"timestamp": [14.9, 17.18], "text": " and I really don't like it."}, {"timestamp": [17.18, 19.78], "text": " I applied for the GitHub Copilot chat"}, {"timestamp": [19.78, 23.58], "text": " and then a few days later I tried to go use it"}, {"timestamp": [23.58, 25.8], "text": " and it says, oh, well, the beta has expired,"}, {"timestamp": [25.8, 27.44], "text": " or you've been kicked out, or whatever."}, {"timestamp": [27.44, 28.96], "text": " I was like, OK, whatever."}, {"timestamp": [28.96, 32.3], "text": " So I realized that, all right, I have the power"}, {"timestamp": [32.3, 36.16], "text": " to fix this myself, because I've been shying away"}, {"timestamp": [36.16, 37.76], "text": " from doing my coding experiments,"}, {"timestamp": [37.76, 41.76], "text": " because chat GPT is broken, or lobotomized, or whatever."}, {"timestamp": [41.76, 47.0], "text": " And GitHub Copilot, and I know there's lots of other tools there's Amazon and blah blah blah"}, {"timestamp": [47.0, 53.0], "text": " but you know like I can fix this I can I can do the thing that I want to do and I can make a thing that is specific."}, {"timestamp": [53.0, 57.0], "text": " So I came over to the playground and I was like all right let's try this."}, {"timestamp": [57.0, 61.0], "text": " So I just want to show you real quick."}, {"timestamp": [61.0, 68.0], "text": " You know I gave a really simple prompt system message you are Python coding assistant the user will give you instructions to help write functions."}, {"timestamp": [68.0, 73.0], "text": " You may ask for clarification if needed but otherwise you should only output Python code."}, {"timestamp": [73.0, 76.0], "text": " And of course you can change this to whatever language you want."}, {"timestamp": [76.0, 87.54], "text": " Adhere to PEP 8 so that's the Python enhancement program version 8 which is basically sets all the standards for how to write Python Pythonically, provide explanations of the code"}, {"timestamp": [87.54, 90.3], "text": " only if the user asks for them."}, {"timestamp": [90.3, 94.46], "text": " So you know how like chat GPT will be super overly verbose."}, {"timestamp": [94.46, 96.98], "text": " And then I gave it a copy of the script"}, {"timestamp": [96.98, 98.3], "text": " that I was working on."}, {"timestamp": [98.3, 100.6], "text": " And so then I said, write a function that loads all files"}, {"timestamp": [100.6, 103.56], "text": " into a given folder, returns a list of lists"}, {"timestamp": [103.56, 105.72], "text": " and groups of five, include the full file path."}, {"timestamp": [105.72, 107.12], "text": " And it just, bam, did it."}, {"timestamp": [107.12, 109.28], "text": " I was like, cool, that's exactly what I wanted."}, {"timestamp": [109.28, 111.44], "text": " And I was like, wait, that worked really well,"}, {"timestamp": [111.44, 113.4], "text": " so why don't I just make a chatbot that does it?"}, {"timestamp": [113.4, 116.08], "text": " So, coding chatbot assistant."}, {"timestamp": [116.08, 118.04], "text": " Since chat GPT has been lobotomized"}, {"timestamp": [118.04, 119.68], "text": " and GitHub copilot is broken."}, {"timestamp": [121.28, 122.8], "text": " I got it set up here."}, {"timestamp": [122.8, 125.0], "text": " Here's an example of the output."}, {"timestamp": [125.0, 128.3], "text": " So for instance, I'm working on,"}, {"timestamp": [128.3, 131.28], "text": " you know, my recent projects have been"}, {"timestamp": [131.28, 135.18], "text": " chatbots with long-term memories and KB articles and stuff."}, {"timestamp": [135.18, 137.32], "text": " So I was like, okay, I've got this far,"}, {"timestamp": [137.32, 139.0], "text": " just write the function for me."}, {"timestamp": [139.0, 141.28], "text": " So I told it how I want to write the function."}, {"timestamp": [141.28, 143.32], "text": " You know, it's a KB article with a YAML file,"}, {"timestamp": [143.32, 145.08], "text": " so on and so forth. Now, that being said, I want to show you function you know it's a KB article with a yaml file so on and so forth."}, {"timestamp": [145.08, 148.68], "text": " Now that being said I want to show you a really cool cool bit"}, {"timestamp": [148.68, 152.0], "text": " so this is the output you can see it's pretty familiar."}, {"timestamp": [152.0, 156.52], "text": " So it gives you like OK you know you need to import this let's"}, {"timestamp": [156.52, 157.92], "text": " do this."}, {"timestamp": [157.92, 160.36], "text": " Here's a couple of functions and it thought through it and gave"}, {"timestamp": [160.36, 164.96], "text": " it a very very very specific output."}, {"timestamp": [164.96, 166.28], "text": " I haven't tested this code yet,"}, {"timestamp": [166.28, 169.36], "text": " but this is very much the behavior that I wanna see."}, {"timestamp": [169.36, 172.8], "text": " So now let me explain to you how the chatbot works."}, {"timestamp": [172.8, 176.34], "text": " So we'll go through the code real quick."}, {"timestamp": [176.34, 177.3], "text": " It's pretty straightforward."}, {"timestamp": [177.3, 181.46], "text": " It's 105 lines of code, so not the most complicated thing."}, {"timestamp": [181.46, 183.56], "text": " And actually, some of this is superfluous."}, {"timestamp": [184.4, 187.0], "text": " I actually think that I don't use the YAML functions anywhere."}, {"timestamp": [187.0, 191.0], "text": " Yes, I could probably delete that and make it even shorter."}, {"timestamp": [191.0, 194.0], "text": " All right, so ignore those helper functions."}, {"timestamp": [194.0, 197.0], "text": " Here's the call to GPT."}, {"timestamp": [197.0, 200.0], "text": " Super simple. You just call it."}, {"timestamp": [200.0, 204.0], "text": " You get the text response. And then what I started doing is I just pass back"}, {"timestamp": [204.0, 206.8], "text": " the token count so that I can manage the text response. And then what I started doing is I just pass back the token count"}, {"timestamp": [206.8, 213.68], "text": " so that I can manage the conversation internally. But pretty much this whole thing here is just if there's an error,"}, {"timestamp": [213.68, 219.88], "text": " it will give you some output. So for instance, if the content context links is too long,"}, {"timestamp": [219.88, 224.28], "text": " it'll trim the conversation and try again. It'll let you know what happened."}, {"timestamp": [224.28, 230.36], "text": " If another error happened, it'll put it'll output that the whole thing sometimes the"}, {"timestamp": [230.36, 235.12], "text": " it's not available whatever opening I has gotten a lot better but sometimes you'll have"}, {"timestamp": [235.12, 239.56], "text": " you know network errors and other stuff and what this does is it uses exponential back"}, {"timestamp": [239.56, 246.0], "text": " off so every time it retries it doubles the amount of time that it'll wait to try again."}, {"timestamp": [246.0, 249.0], "text": " And it'll give you debug output the whole time."}, {"timestamp": [249.0, 253.0], "text": " And then I've got this function. So this is a multi-line input function,"}, {"timestamp": [253.0, 257.0], "text": " which it will switch into this mode if you want to update a scratchpad."}, {"timestamp": [257.0, 264.0], "text": " So in this case, the scratchpad is just a plain text file that it uses to load into the system message."}, {"timestamp": [264.0, 266.48], "text": " So I've got that system message that I showed you"}, {"timestamp": [266.48, 269.76], "text": " and then a description of the below code scratch pad"}, {"timestamp": [269.76, 274.0], "text": " may be provided by the user blah blah blah. And so then it I wrap it in the"}, {"timestamp": [274.0, 278.08], "text": " comment so that way knows like hey this is Python and then it'll copy paste the"}, {"timestamp": [278.08, 281.36], "text": " you know your code into it from the scratch pad."}, {"timestamp": [281.36, 286.22], "text": " And so what you can do is first it'll take you know input from"}, {"timestamp": [286.22, 288.4], "text": " the user and then if you type"}, {"timestamp": [288.4, 290.62], "text": " in scratchpad it will"}, {"timestamp": [290.62, 292.56], "text": " give you a chance to update the scratchpad"}, {"timestamp": [293.28, 295.28], "text": " which is you can put anything you can put in"}, {"timestamp": [295.28, 297.48], "text": " code you can put in comments"}, {"timestamp": [297.48, 300.0], "text": " you whatever you can put in a file"}, {"timestamp": [300.0, 302.24], "text": " system description whatever you want."}, {"timestamp": [303.32, 306.2], "text": " But the point is is that it will use this function"}, {"timestamp": [306.2, 308.8], "text": " so that it will continue to accept"}, {"timestamp": [310.12, 312.4], "text": " new lines of input without"}, {"timestamp": [313.4, 314.4], "text": " without breaking."}, {"timestamp": [314.92, 317.32], "text": " And so then when if you type end at the very"}, {"timestamp": [317.32, 319.68], "text": " end then it says OK cool save exit."}, {"timestamp": [320.8, 323.4], "text": " I strip that out of the end"}, {"timestamp": [324.32, 325.44], "text": " and so on and so forth."}, {"timestamp": [325.44, 327.32], "text": " So there you go."}, {"timestamp": [327.32, 328.32], "text": " Let's see."}, {"timestamp": [328.32, 330.52], "text": " It should be about it."}, {"timestamp": [330.52, 336.28], "text": " Oh, and then if you accidentally hit enter twice, because you know that can happen, it'll"}, {"timestamp": [336.28, 339.8], "text": " just go like it says, you know, enter."}, {"timestamp": [339.8, 343.48], "text": " Whoops, crap, I accidentally type something."}, {"timestamp": [343.48, 344.8], "text": " So that's going to break it."}, {"timestamp": [344.8, 347.56], "text": " Yeah, it was very confused."}, {"timestamp": [347.56, 349.24], "text": " Yep."}, {"timestamp": [349.24, 352.0], "text": " Okay, let's see."}, {"timestamp": [352.0, 359.32], "text": " So then the other thing that I do is I accumulate all the messages, the user input and the chatbot"}, {"timestamp": [359.32, 363.6], "text": " response in a list called all messages."}, {"timestamp": [363.6, 366.2], "text": " And I keep that separate from the conversation object"}, {"timestamp": [366.2, 370.08], "text": " that I passed to chat GPT, that I passed to the API."}, {"timestamp": [370.08, 373.36], "text": " And the reason is because I actually just had a,"}, {"timestamp": [373.36, 378.36], "text": " had a Patreon supporter give me this really powerful tip,"}, {"timestamp": [378.86, 381.52], "text": " which is that if you put the system message at the end,"}, {"timestamp": [381.52, 383.0], "text": " rather than at the beginning,"}, {"timestamp": [383.0, 387.6], "text": " it is much more likely to continue to adhere to the instructions that you gave it rather"}, {"timestamp": [387.6, 389.52], "text": " than drift."}, {"timestamp": [389.52, 393.8], "text": " So apparently this I haven't I haven't spent too much time testing it but you know how"}, {"timestamp": [393.8, 398.52], "text": " sometimes like chat GPT's behavior will change over time especially as the conversation gets"}, {"timestamp": [398.52, 402.48], "text": " longer it'll continue to kind of modify its behavior and it'll usually kind of default"}, {"timestamp": [402.48, 405.64], "text": " back to its default behavior. If you put the system message"}, {"timestamp": [405.64, 410.14], "text": " at the very end. So what I do is I say you know conversation"}, {"timestamp": [410.14, 414.38], "text": " is an empty list. I add all messages and then I append the"}, {"timestamp": [414.38, 417.76], "text": " system message at the very end and then I get the response."}, {"timestamp": [418.5, 421.12], "text": " And so then once I get the response it passes back the"}, {"timestamp": [421.12, 426.24], "text": " tokens. If it's if the token count is over seventy five hundred because we've got a limit of eight"}, {"timestamp": [426.24, 427.92], "text": " thousand. I just remember the"}, {"timestamp": [427.92, 430.44], "text": " I remember I remove the oldest"}, {"timestamp": [430.44, 433.4], "text": " message so pop zero"}, {"timestamp": [433.4, 435.52], "text": " and then I append the"}, {"timestamp": [435.52, 437.84], "text": " assistant response to all messages"}, {"timestamp": [437.84, 440.96], "text": " so remember all messages is kept separate"}, {"timestamp": [440.96, 443.28], "text": " so that I can just tack on the system"}, {"timestamp": [443.28, 448.24], "text": " message separately and then I get the output and here it goes."}, {"timestamp": [448.24, 451.12], "text": " So what I realized is that if you use text wrap,"}, {"timestamp": [451.12, 454.58], "text": " it will nullify all of the new lines."}, {"timestamp": [454.58, 457.28], "text": " So what I do is I split the new lines"}, {"timestamp": [457.28, 459.8], "text": " and then text wrap it so that if there's comments,"}, {"timestamp": [459.8, 461.3], "text": " then it won't be too long."}, {"timestamp": [461.3, 462.9], "text": " So anyways, there you have it."}, {"timestamp": [462.9, 466.24], "text": " The repo is up here, it's working. The only thing that"}, {"timestamp": [466.24, 472.0], "text": " it's pretty well documented I got in the habit of just using chat GPT to produce the documentation"}, {"timestamp": [472.0, 479.12], "text": " because that makes it easier for everybody. Setup is super simple you just mean need open AI you"}, {"timestamp": [479.12, 485.92], "text": " need your open AI API key and then the biggest thing that you need to know is to use a scratch pad."}, {"timestamp": [485.92, 488.74], "text": " I do have instructions in the console output."}, {"timestamp": [488.74, 490.7], "text": " So it'll tell you how to get into the scratch pad"}, {"timestamp": [490.7, 492.02], "text": " and then how to get out of it."}, {"timestamp": [492.02, 497.02], "text": " And then the console will tell you what mode you're in."}, {"timestamp": [498.38, 500.18], "text": " You can tell I was an infrastructure engineer"}, {"timestamp": [500.18, 501.7], "text": " who used Cisco switches."}, {"timestamp": [503.4, 508.16], "text": " Cause I'm just like, hey, this model works. Anyways, so yeah, I think"}, {"timestamp": [508.16, 515.68], "text": " that's about it. So this is my new chatbot coding assistant and yeah, I hope that you find it useful."}, {"timestamp": [515.68, 522.0], "text": " Super simple, super straightforward. Yeah, let me know if you have any thoughts about how to"}, {"timestamp": [522.0, 525.56], "text": " improve it, but I think honestly the scratchpad is like all you need"}, {"timestamp": [526.32, 528.94], "text": " Because then you can you can update this out of band as well"}, {"timestamp": [529.6, 531.6], "text": " If you want to you know"}, {"timestamp": [532.64, 538.7], "text": " Whatever you want to put in it right you can you can even put multiple scripts in it or multiple files or whatever"}, {"timestamp": [540.0, 545.0], "text": " But yeah, so thanks for watching. I hope you liked it, and I'm gonna get back to coding. Bye"}, {"timestamp": [541.11, 546.11], "text": " But yeah, so thanks for watching. I hope you liked it, and I'm gonna get back to coding. Bye"}]}