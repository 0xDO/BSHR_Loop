{"text": " Fine-tuning large language models has become all the rage recently. With OpenAI's release of the GPT 3.5 fine-tuning capabilities, interest has exploded. So I'm here today to share my best practices and tips from over four years of hands-on fine-tuning experience, starting back with GPT 2 in 2019. My earliest fine-tuning projects were focused on two things. First, I wanted to automatically correct punctuation errors, which GPT-2 was able to do very well. I basically took a bunch of Wikipedia pages, removed all punctuation, and lower-cased everything for the data set synthesis. I used the original Wikipedia article as the input, and this scrambled version for the output, GPT-2 learned to fix punctuation and capitalization with no problem. The reason I had to lower-case everything was because GPT-2 learned to just look for capitalization to detect sentence boundaries. That was my first ever fine-tuning experiment. And second, I aimed to fine-tune the model to reduce suffering as an altruistic goal, part of what I now call the heuristic imperatives. To do this, I synthesized a ton of short examples of problems like there's a cat stuck in a tree as the input with simple solutions like get a ladder to rescue the cat as the output. I don't remember exactly how many samples I generated but it was enough to fine-tune GPT-2 and test its ability to generalize. Once I finished training I tried a problem that was not in the samples. The problem I gave, it was this. There are 500 million people in the world suffering from chronic pain. Well, GPT-2 suggested we euthanize all people in chronic pain to reduce suffering. So clearly I had to go back to the drawing board on that one. Obviously GPT-3 and now GPT-4 have a much better ability to understand the spirit, if not the letter, of the heuristic imperatives. Anyways, the single most important thing you need to know about fine-tuning is that it trains the model to replicate patterns. Fine-tuning does not impart broader knowledge, though you can teach it to reason or think in a particular style. For instance, you could implicitly fine-tune the model to follow SWOT analysis. The bulk of an LLM's knowledge is gained during the initial training process. This is because fine-tuning only adjusts a small portion of the model parameters, updating some of the weights and biases in the final layers. But the vast majority of the model remains unchanged. You are not retraining the full network from scratch. That would be too slow and expensive. We may get to it one day, but you absolutely must remember that fine-tuning only trains a small part of the model. So what exactly is a pattern when it comes to language and fine-tuning models? Let's unpack what I mean by patterns. Patterns can emerge at many levels, from overall structural conventions to small stylistic choices. Different writing genres follow distinctive high-level patterns. For instance, fiction and prose has sequences of dialogue, introspection, action, and description, while academic papers adhere to the standard format of abstract introduction, methods, results, and conclusion. Furthermore, the sentences tend to be more complex and jargon-heavy. See what I mean? It's all just sequences of text based on category and type. Even at the paragraph level, patterns appear in things like bullet points and lists. The repetitive bullets chunk content into scannable sections, but they are just patterns of new lines and hyphens as far as the model is concerned. Think about how ChatGPT and Claude Love using bullet points and lists for clarity and structure. Different kinds of sentences exhibit patterns too. For example, dialogue exchanges have a rhythmic back-and-forth structure, delimited by quotation marks and new lines. Contrast that with nonfiction, where passive voice and avoiding first-person pronouns is part of the scholarly writing convention. Patterns also exist in tone, diction, and other stylistic aspects, like Hemingway's punchy prose versus Austin's elegant extended lines. Text can follow casual or professional language patterns. Kind of like how Grammarly can comment on your length, style, and tone. Essentially, any consistent language convention can form a pattern, whether functional or stylistic. Fine-tuning allows steering text generation invention can form a pattern, whether functional or stylistic. Fine-tuning allows steering text generation by training these patterns. Viewing writing as a system and pattern is what allowed me to fine-tune GPT-3 to write prose before anyone else knew it was possible. I built a fine-tuning dataset, scraped from Gutenberg, and selected for prose styles that were particularly good and modern-sounding. Likewise, you could scrape archive for scientific papers in order to copy the style and tone. Beyond just output patterns, fine-tuning also establishes input-output mappings. The model learns associations between particular inputs and desired corresponding outputs. After all, you need some kind of input or prompt to prime the model, or at least to give it something to work with, some kind of source material. The nature of the input can be highly variable. It may be natural language instructions, such as those used in the old Instruct-aligned models, structured data like CSV or JSON, or raw text to summarize, whatever, you get the idea. The model must learn to handle this diversity of inputs depending on the task you're training it for, ideally your training data exposes the model to the full breadth of all possible inputs. This allows it to generalize to handle new inputs robustly, even if it's somewhat unfamiliar. For example, a form processing model should train on forms of different lengths, formats, fields, and oddities. Think about legal forms or tax forms. They all follow some general patterns and conventions, but within those categories there can still be a tremendous amount of variance. Each training sample is like an equation. The input maps to the target output. Diverse data enables flexible mapping from any arbitrary input to any desired output. Let's take a quick break to discuss generalizing. I've used this term several times and it has a very particular meaning to me. Think about how you learn to drive a car. Over the course of your life, you may have driven cars, trucks, vans, and SUVs of various sizes, and once you've gotten behind the wheel of enough vehicles, your driving skills generalize to be able to operate pretty much any vehicle under almost any condition that you've been exposed to. This is a human example of what I mean when I say generalize. Likewise, if you include enough variety in your fine-tuning data set, the model will learn to generalize the abstract principles of the task you're giving it. This leads to the key point, which is that fine-tuning data must be highly varied, not tightly clustered. You want broad coverage across the problem space, not a narrow concentration. Let's use a dartboard analogy. Each training sample is like a dart throw. If all your throws cluster in one spot, your model will be constrained, or what I call lopsided, unable to handle different input conditions, and it will not generalize across the entire task. Instead, evenly distribute your data across the board. This diversity encourages the model to generalize. The model learns to hit any part of the board that it is instructed to, not just a narrow bullseye or one section that is favored by your training data. Now let's wrap up with a few best practices as a sort of recap. First only fine-tune for one specialized, well-defined task at a time. Don't try to cram in multiple objectives or complex steps, at least not when you're a fine-tuning noob. Fine-tuning produces specialized tools, not general purpose, Swiss Army Knives. Stuff like RLHF can produce more broadly generalized models, but remember that companies like OpenAI have teams of engineers who do this day in and day out, plus they have millions of dollars worth of Microsoft as your compute to experiment with. Second, you need to clearly characterize the link between inputs and outputs. Define the textual patterns you want to connect and think about it like an equation. A plus B equals C. Think of fine-tuning like an assembly line, consistently mapping inputs to outputs. In other words, you put in some kind of raw material, whether it's data, instructions, or a blob of text, and you want to fine-tune your model to basically treat it like an automatic text factory. It will do some kind of process against that input. Third, use extremely diverse data spanning different genres, lengths, formats, styles, and topics. Incorporate adversarial cases too, such as broken input or hostile attacks. Broad variability encourages generalization. Garbage in equals garbage out, so curate your dataset carefully. I find that it's better to have too much variance rather than too little. It's better to have some samples that you don't need rather than to need some samples you don't have. Well-rounded data sets tend to produce smarter feeling models. Fourth, remember that fine-tuning primarily teaches patterns, not comprehensive knowledge. Use other methods like retrieval augmentation for knowledge functions. Focus on the patterns and treat it like an algorithm. Patterns can include logic or some kind of reasoning. For instance, you could train a model to reliably translate between XML and YAML or JSON, even though there are some different conventions. Fifth, include messy real-world examples in your training data. The model needs exposure to noisy inputs to handle them robustly after deployment. Human generated data, with its high variance and impurities, almost always results in better data than purely synthetic datasets. That being said, you can magnify or amplify datasets by starting with small amounts of human data and imputing larger sets from it. Thanks for untuning in today, see what I did there. Get it real quick on our way out. I wanted to give a brief update on the Ace Framework project. It's all good news. We have a lead developer selected. His name is Lance, who you'll see interacting on the GitHub discussions. He's a great guy and far more well-versed in software development life cycles than I am. He eats, sleeps, and breathes this stuff. We are still scouting for some members to join the core team, so check out the discussions tab here. But also, we are enabling people to form their own teams and share their work, ask questions, and so on. The plan right now is that the core team will develop at least one MVP internally, in private, before we merge it into the main repo. But once that's done, you'll be able to see some functional demonstrations of the ACE framework. I think we're gonna start with a personal desktop assistant like Samantha from the movie Her. We're not gonna steal Scarlett's voice, though, that would be unethical. However, we do plan on focusing on extensibility so that you can add tools and functions yourself once we get this MVP launched. I think that's all for today. Thanks everyone, stay tuned, it's ramping up fast.", "chunks": [{"timestamp": [0.0, 4.4], "text": " Fine-tuning large language models has become all the rage recently."}, {"timestamp": [4.4, 12.9], "text": " With OpenAI's release of the GPT 3.5 fine-tuning capabilities, interest has exploded."}, {"timestamp": [12.9, 19.4], "text": " So I'm here today to share my best practices and tips from over four years of hands-on fine-tuning experience,"}, {"timestamp": [19.4, 22.9], "text": " starting back with GPT 2 in 2019."}, {"timestamp": [22.9, 27.76], "text": " My earliest fine-tuning projects were focused on two things."}, {"timestamp": [27.76, 32.0], "text": " First, I wanted to automatically correct punctuation errors,"}, {"timestamp": [32.0, 35.04], "text": " which GPT-2 was able to do very well."}, {"timestamp": [35.04, 38.84], "text": " I basically took a bunch of Wikipedia pages,"}, {"timestamp": [38.84, 43.4], "text": " removed all punctuation, and lower-cased everything"}, {"timestamp": [43.4, 45.0], "text": " for the data set synthesis."}, {"timestamp": [45.0, 49.0], "text": " I used the original Wikipedia article as the input,"}, {"timestamp": [49.0, 52.0], "text": " and this scrambled version for the output,"}, {"timestamp": [52.0, 57.0], "text": " GPT-2 learned to fix punctuation and capitalization with no problem."}, {"timestamp": [57.0, 61.0], "text": " The reason I had to lower-case everything was because GPT-2"}, {"timestamp": [61.0, 65.84], "text": " learned to just look for capitalization to detect sentence boundaries."}, {"timestamp": [65.84, 69.28], "text": " That was my first ever fine-tuning experiment."}, {"timestamp": [69.28, 76.26], "text": " And second, I aimed to fine-tune the model to reduce suffering as an altruistic goal,"}, {"timestamp": [76.26, 79.86], "text": " part of what I now call the heuristic imperatives."}, {"timestamp": [79.86, 85.6], "text": " To do this, I synthesized a ton of short examples of problems like there's a cat"}, {"timestamp": [85.6, 90.66], "text": " stuck in a tree as the input with simple solutions like get a ladder to rescue"}, {"timestamp": [90.66, 96.02], "text": " the cat as the output. I don't remember exactly how many samples I generated but"}, {"timestamp": [96.02, 101.96], "text": " it was enough to fine-tune GPT-2 and test its ability to generalize. Once I"}, {"timestamp": [101.96, 106.24], "text": " finished training I tried a problem that was not in the"}, {"timestamp": [106.24, 111.28], "text": " samples. The problem I gave, it was this. There are 500 million people in the"}, {"timestamp": [111.28, 118.2], "text": " world suffering from chronic pain. Well, GPT-2 suggested we euthanize all people"}, {"timestamp": [118.2, 123.16], "text": " in chronic pain to reduce suffering. So clearly I had to go back to the drawing"}, {"timestamp": [123.16, 132.84], "text": " board on that one. Obviously GPT-3 and now GPT-4 have a much better ability to understand the spirit, if not"}, {"timestamp": [132.84, 138.24], "text": " the letter, of the heuristic imperatives. Anyways, the single most important thing"}, {"timestamp": [138.24, 142.96], "text": " you need to know about fine-tuning is that it trains the model to replicate"}, {"timestamp": [142.96, 147.0], "text": " patterns. Fine-tuning does not impart broader knowledge,"}, {"timestamp": [147.0, 152.0], "text": " though you can teach it to reason or think in a particular style."}, {"timestamp": [152.0, 157.0], "text": " For instance, you could implicitly fine-tune the model to follow SWOT analysis."}, {"timestamp": [157.0, 162.0], "text": " The bulk of an LLM's knowledge is gained during the initial training process."}, {"timestamp": [162.0, 169.56], "text": " This is because fine-tuning only adjusts a small portion of the model parameters, updating some of the weights and biases"}, {"timestamp": [169.56, 175.16], "text": " in the final layers. But the vast majority of the model remains unchanged."}, {"timestamp": [175.16, 180.28], "text": " You are not retraining the full network from scratch. That would be too slow and"}, {"timestamp": [180.28, 185.88], "text": " expensive. We may get to it one day, but you absolutely must remember that fine-tuning"}, {"timestamp": [185.88, 189.36], "text": " only trains a small part of the model."}, {"timestamp": [189.36, 195.28], "text": " So what exactly is a pattern when it comes to language and fine-tuning models? Let's"}, {"timestamp": [195.28, 201.08], "text": " unpack what I mean by patterns. Patterns can emerge at many levels, from overall structural"}, {"timestamp": [201.08, 210.9], "text": " conventions to small stylistic choices. Different writing genres follow distinctive high-level patterns. For instance, fiction and prose"}, {"timestamp": [210.9, 217.88], "text": " has sequences of dialogue, introspection, action, and description, while academic"}, {"timestamp": [217.88, 227.0], "text": " papers adhere to the standard format of abstract introduction, methods, results, and conclusion."}, {"timestamp": [227.0, 232.0], "text": " Furthermore, the sentences tend to be more complex and jargon-heavy."}, {"timestamp": [232.0, 237.0], "text": " See what I mean? It's all just sequences of text based on category and type."}, {"timestamp": [237.0, 241.0], "text": " Even at the paragraph level, patterns appear in things like bullet points and lists."}, {"timestamp": [241.0, 245.42], "text": " The repetitive bullets chunk content into scannable sections,"}, {"timestamp": [245.42, 250.2], "text": " but they are just patterns of new lines and hyphens as far as the model is"}, {"timestamp": [250.2, 256.36], "text": " concerned. Think about how ChatGPT and Claude Love using bullet points and lists"}, {"timestamp": [256.36, 260.48], "text": " for clarity and structure. Different kinds of sentences exhibit patterns too."}, {"timestamp": [260.48, 265.36], "text": " For example, dialogue exchanges have a rhythmic back-and-forth structure,"}, {"timestamp": [265.36, 270.76], "text": " delimited by quotation marks and new lines. Contrast that with nonfiction, where passive"}, {"timestamp": [270.76, 277.52], "text": " voice and avoiding first-person pronouns is part of the scholarly writing convention."}, {"timestamp": [277.52, 288.2], "text": " Patterns also exist in tone, diction, and other stylistic aspects, like Hemingway's punchy prose versus Austin's elegant extended lines."}, {"timestamp": [288.2, 292.5], "text": " Text can follow casual or professional language patterns."}, {"timestamp": [292.5, 294.7], "text": " Kind of like how Grammarly can comment"}, {"timestamp": [294.7, 297.5], "text": " on your length, style, and tone."}, {"timestamp": [297.5, 300.5], "text": " Essentially, any consistent language convention"}, {"timestamp": [300.5, 304.8], "text": " can form a pattern, whether functional or stylistic."}, {"timestamp": [304.8, 305.52], "text": " Fine-tuning allows steering text generation invention can form a pattern, whether functional or stylistic."}, {"timestamp": [305.52, 310.48], "text": " Fine-tuning allows steering text generation by training these patterns."}, {"timestamp": [310.48, 316.52], "text": " Viewing writing as a system and pattern is what allowed me to fine-tune GPT-3 to write"}, {"timestamp": [316.52, 319.72], "text": " prose before anyone else knew it was possible."}, {"timestamp": [319.72, 326.36], "text": " I built a fine-tuning dataset, scraped from Gutenberg, and selected for prose styles"}, {"timestamp": [326.36, 332.24], "text": " that were particularly good and modern-sounding. Likewise, you could scrape"}, {"timestamp": [332.24, 338.12], "text": " archive for scientific papers in order to copy the style and tone. Beyond just"}, {"timestamp": [338.12, 344.36], "text": " output patterns, fine-tuning also establishes input-output mappings. The"}, {"timestamp": [344.36, 350.0], "text": " model learns associations between particular inputs and desired corresponding outputs."}, {"timestamp": [350.0, 354.0], "text": " After all, you need some kind of input or prompt to prime the model,"}, {"timestamp": [354.0, 360.0], "text": " or at least to give it something to work with, some kind of source material."}, {"timestamp": [360.0, 363.0], "text": " The nature of the input can be highly variable."}, {"timestamp": [363.0, 368.72], "text": " It may be natural language instructions, such as those used in the old Instruct-aligned"}, {"timestamp": [368.72, 375.9], "text": " models, structured data like CSV or JSON, or raw text to summarize, whatever, you get"}, {"timestamp": [375.9, 377.26], "text": " the idea."}, {"timestamp": [377.26, 383.16], "text": " The model must learn to handle this diversity of inputs depending on the task you're training"}, {"timestamp": [383.16, 385.28], "text": " it for, ideally your training"}, {"timestamp": [385.28, 390.08], "text": " data exposes the model to the full breadth of all possible inputs. This"}, {"timestamp": [390.08, 395.52], "text": " allows it to generalize to handle new inputs robustly, even if it's somewhat"}, {"timestamp": [395.52, 400.96], "text": " unfamiliar. For example, a form processing model should train on forms"}, {"timestamp": [400.96, 409.72], "text": " of different lengths, formats, fields, and oddities. Think about legal forms or tax forms. They all follow some general patterns and conventions,"}, {"timestamp": [409.72, 415.48], "text": " but within those categories there can still be a tremendous amount of variance."}, {"timestamp": [415.48, 421.32], "text": " Each training sample is like an equation. The input maps to the target output."}, {"timestamp": [421.32, 425.0], "text": " Diverse data enables flexible mapping"}, {"timestamp": [425.0, 428.56], "text": " from any arbitrary input to any desired output."}, {"timestamp": [428.56, 431.92], "text": " Let's take a quick break to discuss generalizing."}, {"timestamp": [431.92, 433.84], "text": " I've used this term several times"}, {"timestamp": [433.84, 437.44], "text": " and it has a very particular meaning to me."}, {"timestamp": [437.44, 440.76], "text": " Think about how you learn to drive a car."}, {"timestamp": [440.76, 443.68], "text": " Over the course of your life, you may have driven cars,"}, {"timestamp": [443.68, 446.36], "text": " trucks, vans, and SUVs of"}, {"timestamp": [446.36, 451.64], "text": " various sizes, and once you've gotten behind the wheel of enough vehicles, your driving"}, {"timestamp": [451.64, 457.84], "text": " skills generalize to be able to operate pretty much any vehicle under almost any condition"}, {"timestamp": [457.84, 463.76], "text": " that you've been exposed to. This is a human example of what I mean when I say generalize."}, {"timestamp": [463.76, 468.36], "text": " Likewise, if you include enough variety in your fine-tuning data set,"}, {"timestamp": [468.36, 473.84], "text": " the model will learn to generalize the abstract principles of the task you're giving it."}, {"timestamp": [473.84, 479.84], "text": " This leads to the key point, which is that fine-tuning data must be highly varied,"}, {"timestamp": [479.84, 481.64], "text": " not tightly clustered."}, {"timestamp": [481.64, 485.04], "text": " You want broad coverage across the problem space,"}, {"timestamp": [485.04, 488.08], "text": " not a narrow concentration."}, {"timestamp": [488.08, 490.88], "text": " Let's use a dartboard analogy."}, {"timestamp": [490.88, 494.12], "text": " Each training sample is like a dart throw."}, {"timestamp": [494.12, 496.76], "text": " If all your throws cluster in one spot,"}, {"timestamp": [496.76, 500.96], "text": " your model will be constrained, or what I call lopsided,"}, {"timestamp": [500.96, 503.6], "text": " unable to handle different input conditions,"}, {"timestamp": [503.6, 507.0], "text": " and it will not generalize across the entire task."}, {"timestamp": [507.0, 512.0], "text": " Instead, evenly distribute your data across the board."}, {"timestamp": [512.0, 516.0], "text": " This diversity encourages the model to generalize."}, {"timestamp": [516.0, 521.0], "text": " The model learns to hit any part of the board that it is instructed to,"}, {"timestamp": [521.0, 526.18], "text": " not just a narrow bullseye or one section that is favored by your training"}, {"timestamp": [526.18, 527.18], "text": " data."}, {"timestamp": [527.18, 532.48], "text": " Now let's wrap up with a few best practices as a sort of recap."}, {"timestamp": [532.48, 536.92], "text": " First only fine-tune for one specialized, well-defined task at a time."}, {"timestamp": [536.92, 542.56], "text": " Don't try to cram in multiple objectives or complex steps, at least not when you're a"}, {"timestamp": [542.56, 550.4], "text": " fine-tuning noob. Fine-tuning produces specialized tools, not general purpose, Swiss Army Knives."}, {"timestamp": [550.4, 557.2], "text": " Stuff like RLHF can produce more broadly generalized models, but remember that companies like OpenAI"}, {"timestamp": [557.2, 561.88], "text": " have teams of engineers who do this day in and day out, plus they have millions of dollars"}, {"timestamp": [561.88, 565.38], "text": " worth of Microsoft as your compute to experiment with."}, {"timestamp": [570.46, 570.9], "text": " Second, you need to clearly characterize the link between inputs and outputs."}, {"timestamp": [577.92, 578.16], "text": " Define the textual patterns you want to connect and think about it like an equation. A plus B equals C."}, {"timestamp": [580.6, 581.34], "text": " Think of fine-tuning like an assembly line,"}, {"timestamp": [589.92, 596.04], "text": " consistently mapping inputs to outputs. In other words, you put in some kind of raw material, whether it's data, instructions, or a blob of text, and you want to fine-tune your model to basically treat it like an automatic"}, {"timestamp": [596.04, 597.88], "text": " text factory."}, {"timestamp": [597.88, 600.96], "text": " It will do some kind of process against that input."}, {"timestamp": [600.96, 607.0], "text": " Third, use extremely diverse data spanning different genres, lengths, formats, styles,"}, {"timestamp": [607.34, 614.06], "text": " and topics. Incorporate adversarial cases too, such as broken input or hostile attacks."}, {"timestamp": [614.06, 621.06], "text": " Broad variability encourages generalization. Garbage in equals garbage out, so curate your"}, {"timestamp": [621.06, 625.72], "text": " dataset carefully. I find that it's better to have too much variance"}, {"timestamp": [625.72, 627.44], "text": " rather than too little."}, {"timestamp": [627.44, 630.32], "text": " It's better to have some samples that you don't need"}, {"timestamp": [630.32, 633.08], "text": " rather than to need some samples you don't have."}, {"timestamp": [633.08, 635.44], "text": " Well-rounded data sets tend to produce"}, {"timestamp": [635.44, 637.56], "text": " smarter feeling models."}, {"timestamp": [637.56, 640.16], "text": " Fourth, remember that fine-tuning"}, {"timestamp": [640.16, 644.24], "text": " primarily teaches patterns, not comprehensive knowledge."}, {"timestamp": [644.24, 649.06], "text": " Use other methods like retrieval augmentation for knowledge functions."}, {"timestamp": [649.06, 653.16], "text": " Focus on the patterns and treat it like an algorithm."}, {"timestamp": [653.16, 656.56], "text": " Patterns can include logic or some kind of reasoning."}, {"timestamp": [656.56, 663.5], "text": " For instance, you could train a model to reliably translate between XML and YAML or JSON, even"}, {"timestamp": [663.5, 666.2], "text": " though there are some different conventions. Fifth,"}, {"timestamp": [666.2, 671.24], "text": " include messy real-world examples in your training data. The model needs"}, {"timestamp": [671.24, 676.04], "text": " exposure to noisy inputs to handle them robustly after deployment. Human"}, {"timestamp": [676.04, 680.92], "text": " generated data, with its high variance and impurities, almost always"}, {"timestamp": [680.92, 685.6], "text": " results in better data than purely synthetic datasets."}, {"timestamp": [685.6, 692.8], "text": " That being said, you can magnify or amplify datasets by starting with small amounts of human data"}, {"timestamp": [692.8, 695.6], "text": " and imputing larger sets from it."}, {"timestamp": [696.6, 700.4], "text": " Thanks for untuning in today, see what I did there."}, {"timestamp": [700.4, 702.9], "text": " Get it real quick on our way out."}, {"timestamp": [702.9, 710.0], "text": " I wanted to give a brief update on the Ace Framework project. It's all good news. We have a lead developer selected."}, {"timestamp": [710.0, 726.3], "text": " His name is Lance, who you'll see interacting on the GitHub discussions. He's a great guy and far more well-versed in software development life cycles than I am. He eats, sleeps, and breathes this stuff. We are still scouting for some"}, {"timestamp": [726.3, 732.08], "text": " members to join the core team, so check out the discussions tab here. But also, we are"}, {"timestamp": [732.08, 739.0], "text": " enabling people to form their own teams and share their work, ask questions, and so on."}, {"timestamp": [739.0, 745.0], "text": " The plan right now is that the core team will develop at least one MVP internally,"}, {"timestamp": [745.16, 749.28], "text": " in private, before we merge it into the main repo."}, {"timestamp": [749.28, 751.48], "text": " But once that's done, you'll be able to see"}, {"timestamp": [751.48, 754.76], "text": " some functional demonstrations of the ACE framework."}, {"timestamp": [754.76, 758.28], "text": " I think we're gonna start with a personal desktop assistant"}, {"timestamp": [758.28, 761.56], "text": " like Samantha from the movie Her."}, {"timestamp": [761.56, 763.88], "text": " We're not gonna steal Scarlett's voice, though,"}, {"timestamp": [763.88, 765.16], "text": " that would be unethical."}, {"timestamp": [765.16, 768.76], "text": " However, we do plan on focusing on extensibility"}, {"timestamp": [768.76, 772.04], "text": " so that you can add tools and functions yourself"}, {"timestamp": [772.04, 777.24], "text": " once we get this MVP launched. I think that's all for today. Thanks everyone,"}, {"timestamp": [777.24, 779.6], "text": " stay tuned, it's ramping up fast."}]}