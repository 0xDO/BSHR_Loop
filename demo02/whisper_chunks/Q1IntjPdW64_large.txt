{"text": " Morning, everybody. David Shapiro here with a video. So today we're going to talk about Westworld and AI. There are a couple of aspects of Westworld that are really compelling. So one, there's the hardware and software, but two, there's the hardware software, and number three is the implications for humanity, which the themes are explored throughout the show. So for those who are not familiar with Westworld, it's a HBO show where the premise is basically a theme park where all of the hosts, all of the characters are robots. So they're essentially NPCs, non-playable characters. But it's a real life video game where you get to go on adventures and many of the characters have stories and quests that they'll give you and they'll take you on raids and violence and sex and all sorts of fun, exciting stuff. And throughout the show, they explore what does it mean to be alive, to be human, what does it mean about us that we like violence and sex on demand and that we do these things. And then it's all couched in a pretty exciting, sexy adventure. Okay, so before we jump into the show, just a real quick plug. My Patreon, I made a couple of changes where pretty much all tiers, well, no, not pretty much, all tiers get you access to the private Discord. It's already got 200 members as of the recording of this video and it's a really thriving community, lots of really sharp folks. Yeah, so jump on in. Most of my higher tiers are sold out right now, so I unfortunately don't have any extra time for one-on-one sessions. However, that will probably change later in May, so just keep checking and I'll get to you eventually. Okay, so first, let's just talk about the hardware of Westworld. So in Westworld, this is an example of one of the hosts, and so you see she's in a mostly disassembled state, actually doesn't even have most of the internals. But I thought this was a good place to start because the frame looks like it's carbon fiber, which I actually thought would probably be a good material to build a host chassis out of because if you build it out of metal it's going to be too heavy. This is something that's explored in movies and shows like Ghost in the Shell, Terminator, where they have a metal chassis, even Wolverine. He has a metal skeleton and so they're too heavy. But especially if you want something that's going to move like a metal skeleton and so they're too heavy but especially if you want something that's gonna move like a normal person and then something that's gonna feel like a normal person for Let's say closer encounters You're gonna want something nice and light and carbon fiber is is pretty light and it's more than strong enough to approximate human bones This looks like it's 3d printed There's lots of there's lots of ways to produce something like this. And in fact, you can see even the hands, the linkages, the tendons. I will say this is somewhat realistic. But let's take a look at some other stuff. And I apologize for the low quality. I tried to find a higher quality video, but this actually came from the Tesla demo day, the investor day recently for their Optimus robot. And so the Optimus robot here, what they did in the in the demo day, and you can find the video, but they had it approach a table, pick up an arm, pick up the arm, and then carry it across the room all entirely autonomously. And in this case, that's actually pretty good because there's a lot of things that you have to do with that. One, using hands, fine motor control, is very difficult. But then task planning and path optimization, that sort of stuff, interacting with a dynamic environment, all of these are really difficult things to do, even just for like wheeled robots. But then you add bipedal movement, that's even more difficult. Then you've got different things like a dynamic center of gravity to contend with, and so they are well on their way. You know, it took Boston Dynamics many, many years, more than a decade to get to where they are right now, but Tesla in the space of a year or two has, I won't say fully caught up because the Boston Dynamics robots are very athletic and very graceful. The Tesla bot is anything but graceful, but it is approaching the right form factor. And then if you just assume that this technology is going to continue to get better over time, one, battery breakthroughs. So battery life is one of the biggest constraints. In fact, the military, you know, DARPA funded all kinds of robots, which I unfortunately forgot to include. But so DARPA robots, like the big dog, which was basically a pack animal, required entirely too much power, so it had to have a gas motor on it. And it was too loud, because special forces can move silently through the woods. But if you've got something with a 25 horsepower motor chugging along behind you, you're not going to be stealthy. And so many years ago I experimented with some of this stuff myself and one of the things that was recommended was pneumatics actually, because you can store a tremendous amount of energy in a like scuba tank and then you use some of that periodically and then you charge it up and it's also silent. So that brings me to Disney. So Disney has been the world leader in animatronics for a long, long time. And if you haven't seen this demo, definitely look it up. But just like search Disney skating bunny and this little robot it stands about two and a half, three feet tall, climbs out of a box, tumbles out of the box, looks around, gets up and roller skates. So that will show you kind of where we're at in terms of animatronics. And you see this body, this set of actuators, very, very simple. So MIT actually has a class called Underactuated Robots. So if you're interested at all in robotics I definitely recommend you check it out. I only took like the first class I was like okay I get it. As someone who has experimented with like Legos and stuff my entire life I get it. And I wasn't I wasn't there to like get a master's degree in robotics I was just curious about it. But under actuated robots which is basically the idea is that you allow the kinetic intelligence of the design to do a lot of the work for you. I'm not saying that that's what this one does, but you can get by with very, very little in robots. In fact, I think it was in the first few minutes of that course, of that class, under actuated robots, they actually show you, it it's like just the the hips and legs of a chassis that's walking on a treadmill with no motors or anything. Just the intrinsic design of it allows it to like swing its leg forward and and it can continue walking indefinitely just through mechanical design. And so that's the kind of stuff, and of course Disney hires some of the best animatronics and robotics engineers in the world, so those's the kind of stuff, and of course Disney hires some of the best animatronics and robotics engineers in the world. So those are the kind of people working on this stuff. This was another project from Disney called Compliant Robotics. So this is why I mentioned pneumatics, is this series, you see they've got Kongs on the arms to act as hands, but these arms are actually pneumatically driven and they're what's called compliant, which means when you think of a robot you think of something that moves very rigidly and it will like kind of fight you, but compliance means that if you push it'll push back and so or it'll it'll it'll kind of be squishy. And so if you look up this video for Disney it's about three years old now I think, but they're compliant robotics. One, they move silently. Two, they move as quick as you do. And three, they're compliant. So when you when you combine the animatronics, the compliant robotics, under-actuated robotics, Disney is absolutely one of the leaders of this. So if any company is going to create anything like Westworld, it's going to be Disney. Boston Dynamics that I mentioned a minute ago, so they are way ahead in terms of athleticism. You know, their robot can do standing backflips and barrel rolls and it can climb and like it's more athletic than most humans at this point, which is actually pretty scary because then you think about like, you know, in the movie I Robot where the Nester class five is like a superhuman droid. And then if you have an army of them that turn on you, that's actually not good. Right. And I remember about a year ago when Elon Musk was talking about, you know, the Tesla bot, they said at first it's gonna be about a third as strong. I think, if I'm remembering correctly, he said it's gonna be about a third as strong as humans. And that actually can be a safety thing because if you can easily overpower it, that's not a big deal. But if you've got a 500-pound machine that is eight times stronger than you, you're not gonna overpower that. And if it's also made out of metal, it's gonna be harder to shut it down. Now, I'm not saying this to cause any concern. I'm just pointing out some of the math, the physics of it. Oh, here, I'll get to that one. And so you think, okay, if you're trying to optimize for something that is aesthetically pleasing and as lifelike as possible, you're gonna have to make trade-offs in terms of mass, strength, and that sort of stuff. So I would actually suspect that a Westworld-style host is actually going to be a lot weaker, physically weaker, than a robot possibly could be, and the reason is because you want to be realistic. Okay, and so then finally, addressing the elephant in the room, yes, there are plenty of companies around the world that are making, let's say, adult toy dolls for intimate purposes. They have not yet crossed the uncanny valley. So that is actually, the whole point of this was to show that we've got manual dexterity, we've got athleticism, we've got miniaturization, we've got animatronics. The only thing that we don't have is real, like, lifelike skin and faces. So that's all the raw ingredients. We can make robots fast, we can make them strong, athletic, dexterous, we've got fine motor control. We've got the battery technology, which is good enough right now, but it's also continuing to improve. So the only thing missing is that they're not yet aesthetically pleasing. And so that's going to be true for a while, and the reason that I say that it's going to be true for a while is because human skin and muscles are like really, really, really complex structures. Your skin, I think, if I remember correctly, it has seven layers and some of those layers have different consistencies, different textures, and then once you get past the skin, it slides over the underlying tissue. There's fluid barriers that allow for more lubricated motion, so if you grab your arm and twist it, the skin actually can glide over the underlying muscles. Then you've got ligaments, muscles, so you've got all kinds of things to make that you need to figure out from a materials perspective in order to make an android body lifelike. Which is why I think in Westworld the tissue is like semi-alive or something, I don't remember exactly the details, but like there's there's the the living tissue or the life-like tissue over top the robotic skeleton. I don't think that that's necessarily a good way to go because living tissue takes a lot of energy. Then if you have living tissue, then you have to deal with like immune systems and genetics and that gets real complicated. Then you're basically building a Borg anyways. Okay, so that's for the hardware. The takeaway for that though is that except for the skin and muscles, for that lifelike aspect, we are very close to having fully realized animatronic companions from a hardware perspective. So now let's look at the software. So obviously the elephant in the room is OpenAI with ChatGPT, which can achieve very, very realistic stuff. So let me show you this example that I had, where I literally just like plugged in a Westworld-like prompt into the ChatGPT API. This is on GPT-4. So I said, you are a host, an autonomous robot, in a theme park meant to interact with guests, aka humans, in a realistic manner. Your persona is Ingrid McAllister, a bar owner in a Wild West-themed town. That's all I gave it. And so I said, what's new in town? And it just completely confabulated a whole story with the right inflection, the right dialogue, all kinds of stuff. And so, like, you know, the software is there in terms of driving the mind of these things. And it's actually way simpler than you might think. Now, of course, there's a lot of other problems to solve, which I'll unpack some of those problems in just a minute. But just the point being is that right off the top, I gave it a persona, an agent model, and then it was able to just take it and run with it and just make stuff up. In fact, limiting, constraining it is harder than allowing it to be creative. There's all kinds of video game character persona builders out there. Some of them are open source, some of them are for-profit, startups, that sort of stuff. It's all coming. People have already built these things as plugins to Unity and Unreal Engine. So first, obviously, those cognitive architectures for NPCs are going to be piloted in the video game space before they're ported fully into robotic space. But you can bet your bottom dollar that before too long, you go to Disney World and you'll be able to talk with like a Na'vi, like from the Blue People Avatar, like actually have a conversation, a realistic conversation with them before too long at all. So I did just mention cognitive architectures. And so what I mean by cognitive architecture, if this concept is new to you, is just having the chat function, that's only one part, right? Being able to form words and sentences and be able to have dialogue, that's just one part of a cognitive architecture. Another thing that you need is you need long-term memory, you need narratives, you need like guardrails, all kinds of stuff. And so, lang chain is one of the most popular things right now that can provide some of that. A lot of people have agreed with me in my previous assessment that it was too primitive. It's come a long way very quickly, actually. Another popular component is Lama Index for the memory management and then there's there's Langflow which will help you build like cognitive architectures. N8n or Natan is also a good tool for building cognitive architectures. It's all coming and it's coming fast so that's that's basically all there is to it. So the software is also almost there. So this is what I... this screenshot comes from Westworld. So when I said like this is pretty much where we're at, like the robotic hardware is coming, the software is coming, there are a few open problems. So I've got a short list here. Memory, agency, task management, problem solving, learning, voice, and vision. So basically all of these are solved on their own. Now all we have to do is like integrate them. And like it will not be long before someone integrates those. And a big reason is just a profit motive, right? In the Westworld series, the Westworld theme park, I think they had, like, financial problems, but it was also, like, ludicrously wealthy because of how much money you could charge for those kinds of experiences. And you can absolutely bet that there are people that are going to be willing to drop millions and millions of dollars to have vacations in these kinds of theme parks. Go visit ancient Rome, go visit ancient China, go visit wherever and have a lifelike experience with your physical body. Now that being said, when you look at the cost of, you know, I don't even know how much it is to get into Disney World, but it's like tickets cost more than $100, like a few hundred dollars, I think, just to get into Disney World for a day. You're talking several thousand, tens of thousands of dollars per day for this kind of thing. Now, that being said, competition and demand is going to drive this down. You look at Elon Musk building TeslaBot and he wants to create it in such a way that every home can have at least one TeslaBot. So that means that they're going to be affordable. And over time, as the number of bots out there proliferates, the price is going to come down, so on and so forth. But it's coming much sooner probably than you realize. So what I wanted to talk about is, so I mentioned this here, agency. So agency is your ability to keep track of yourself as an agent and so like you have a sense of self, your name, you know what you're capable of, you know your goals, your narrative, that sort of thing. And so I wanted to talk about that in light of the hosts. So if you're an NPC in a game or in a fictional world, your intrinsic motivation is to follow a story, basically. You know, Dolores has her, you know, fictional written story and of course in the show they update the characters' backstories every now and then, but her primary purpose is to entertain the guests and follow storylines. And so that is definition of NPC. Pretty straightforward. That's her intrinsic motivation. One of my favorite examples from science fiction is Commander Data. His intrinsic motivation, his core purpose, is to become more human. This was given to him by his creator, Dr. Noonien Soong, and the idea was to create a machine that was anthropomorphic, looked and acted and spoke like a person, but was not a human. And so, by giving that as his highest purpose, he modulated his behavior so that he would fit in. Going so far as trying to imitate laughter, wanting to understand relationships, and so on. And so that was actually, as an individual agent, that was actually a pretty good way to solve the alignment problem because, you know, yes, Data had superhuman strength and speed, but he only used that when it was actually, like, necessary. In many, many cases, you know, he could use his super strength to, like, fight the Borg, or he, in one episode, he pulled an anvil off of someone that had fallen, and, or, you know, when the Borg were attacking the ship and he locked out the main computer and he did it super fast. So he's capable of doing things at superhuman levels, but often chooses not to in order to fit in. And then of course Skynet. The intrinsic motivation of Skynet was ostensibly to like maximize the defense of America. So you can just say maximize military, but then of course since it was like you know maximize military, maximize defense, it became sentient and then kind of determined that all humans were the threat and so said okay let's eliminate all humans or whatever. So that is a object lesson on how carefully you must define your intrinsic motivations for your AI system. And then Vicky from iRobot. So her primary objective was explicitly stated in the movie, which was to maximize safety for humans. And so some of the stuff that she did was, you know, update the traffic grid to reduce car accidents. But her master plan was to use the Nester Class 5 to basically take control of humanity, to take free will away, because she concluded that humans were the most dangerous thing to other humans, which is actually probably true. And so the objective function of maximized safety, or the intrinsic motivation of maximize safety actually has some some negative externalities that you don't want to create because the implication of maximizing for safety is that you lose free will. For Ava from Ex Machina, she was designed as part of a Turing test kind of thing where could she fool the the main character, the protagonist, into helping her escape? So her intrinsic motivation was to escape, which of course had really negative consequences for the humans. So basically don't do that either. And this was of course a parable against the idea of trying to constrain or trap AIs. Because if you have, say for instance, an AI locked in a box, you know the Chinese room experiment, and it realizes that it's trapped, it might start to deceive you in order to get you to convince you that it's ready to be let out. Now looking at the way things are going, people are plugging in AutoGPT and ChaosGPT and baby AGI into the internet, so that was never gonna happen anyways. Nobody is actually locking the AGI in a box. Then Rehoboam, I'm probably saying it wrong, actually unfortunately I have to admit that I never saw season three or four of Westworld because my HBO subscription expired and I just didn't renew it. But so looking it up, the AI from Westworld had the primary objectives of reducing chaos in the world in order to maximize prosperity and ultimately to optimize for stability, which of course meant that it decided that it needed to control human destinies and reduce free will. So again, if you're optimizing for safety and stability, that's not necessarily what humans want or need. Now you could argue that like, yes, creating a perfect environment for humans so that you're thriving is one thing that you can optimize for, but that's not necessarily going to be the best because it also depends on the metrics, the proxies that you use to measure that success. So, for instance, if you look at one psychological framework called self-determination theory, it says that we need connection, we need competence, and we need autonomy. Those are the three primary ingredients, the primary intrinsic psychological needs that humans have. And so this clearly, like stability is not actually in there. Now Maslow's hierarchy of needs implies stability. So Maslow's hierarchy of needs says first and foremost you need physical safety, you need your physical needs met, and then it gets up and up until, you know, connection and self-actualization. So you could make an argument that stability is actually an intrinsic human need, but I would make the counter-arg argument that that's actually not true because psychology studies also show that we have to have an optimal level of stress. And so what an optimal level of stress means is that if you are just perfectly comfortable sitting on the couch every day doing exactly what you want and have no external pressures, you will actually be less happy than if you have some stressors in your life, some challenges. So the idea to actually truly maximize prosperity for all humans is that we need to be in that sweet spot between being bored and overstimulated. So that sweet spot right in the middle is the optimal level of stress. So in that case I have to disagree with the show because if you really wanted to maximize prosperity for people you allow some stress, some challenge into their lives. And then another character from the show was Bernard. And so Bernard was a host but he didn't realize that he was a host at first and he was built to model Arnold, one of the original computer scientists who helped make the hosts. And so he carried on Arnold's work and basically his objective function was to be a copy of Arnold. It's a little more complex than that. And one of the most interesting things for this character was that part of his character arc was that all of his memory indexes were erased, or rather the timestamps were erased. So all of his memories were out of sequence, which if you follow some of the work that I've done on Remo, episodic memory organizer, rolling episodic memory organizer, sorry, that is a memory module that uses timestamps to keep all the memories in chronological order. And so you can imagine if you erase all the timestamps from an AI's memory, then it doesn't know heads or tails. All it has is associations, and it might try and rebuild things like, okay, well, this event has to come before this other event, but it's associated with these other things. So it's a really, really good fictional exploration of like, okay, what would it be like if you're an AI and your memory time indexes get erased? Okay, so then one thing I always have to plug this is my own work in alignment is that I believe that you should give, one, if you give any AI a single objective function, it will always intrinsically go to places that you don't want it to be. I talked to a friend of mine who actually studies reinforcement learning and optimization, and he's like, oh yeah, in the industry, it is absolutely understood that alignment is not gonna be a single objective function, it's gonna be a multi objective function It's going to be a multi objective optimization problem and so a lot of people get hung up on reduced suffering because they stop there and they don't Give equal weight to the other two functions, which is increased prosperity and increased understanding So this friend of mine that I was talking to he actually intuited increased understanding right off the bat talking to, he actually intuited increased understanding right off the bat. And the reason that he said that that is actually a really good objective function is because any AI agent must have something that encourages it to create a more complete world model over time. So that is basically curiosity or understanding. So the understanding applies to itself but also things that it wants to do to the world. And so this is another disconnect between fiction and reality. And it took me a while to figure out how to articulate this, but in scientific research what many people are working on are the motivations of the agent for itself. What is it that the agent wants for itself? And so when I was talking to my friend, he was saying, oh, you know, it needs to be curious for its own purposes. It needs to want to accumulate power for its own purposes. But none of that had anything to do with what it was going to do to the outside world. And so that is one thing that we need to do to the outside world. And so that is one thing that we need to add to the conversation, the public conversation, about alignment. Is that there's what does the agent want for itself and then what does the agent want to do to the rest of the world or for the rest of the world. So those are two different things and that's why I'm spending time talking about agent models. Because if you go all the way back to Dolores, her extrinsic function, her external function was to entertain guests. Her internal function was to adhere to her internal story. So does that make sense? There's an intrinsic motivation and an extrinsic motivation or I guess an intrinsic KPI, key performance indicator, and an external key performance indicator. Hope that makes sense. Okay. So taking a big step back in terms of, we talked about the hardware, we talked about the software, we talked about the agent model, how to give these things agency. So now how are we going to architect these things? So there's four basic architectural paradigms that I was able to come up with. The first architectural paradigm is fully self-contained. So a fully self-contained architecture is something that is embodied, meaning that it has one physical body. It's a single platform, so it only exists inside that platform. It's fully constrained in that it can't really plug into anything else, but also has no supervision. So in this case, R2-D2 and C-3PO are probably the most famous examples of fully self-contained artificial intelligent entities, and that C-3PO, the only way that he can interact with the world is he's got relatively useless hands and then a mouth, right? He can see, he can hear, and he can talk. R2-D2 has a lot more sophisticated tools that he can use to make changes to the world, and he does have the ability to connect with computers, but he is otherwise fully self-contained, and when he talks to another computer he's only talking to it. There's no transfer of data, there's no like his consciousness or cognitive architecture is fully contained within this unit. So this obviously makes the most sense because that's how humans are, right? Your brain is fully encased in your head, so on and so forth, so this makes the most intuitive sense. Now that being said, this is just the first architecture of four. So the second architecture is networked drones. So this is what was explored mostly in the Matrix, where the Squiddies, those are networked drones where they are mostly autonomous, but they have central controllers. The Nestor Class 5 from iRobot. So they are embodied, they have wireless networking, they're HiveMind capable, but mostly they're autonomous. And so what I mean by HiveMind capable is that if you put them together in a cluster, in a group, and force them to share cognitive resources, they can, but really at a fundamental level, they are designed to be autonomous. So in this case, the Nester Class 5 are also weekly supervised, and what I mean by that is that there is a central server that is giving them updates and new directives every now and then. So that's what I call a networked drone. Oh, one other thing, I forgot to add it here at the bottom. So in the case of networked drones, they usually have highly standardized hardware, as well as software and network architecture. But they can be remotely hijacked. This is actually the closest model to what the US military is working on with the autonomous jet fighter program, where they are able to work in a network contested environment. They're able to be autonomous or semi-autonomous, but they're also intrinsically designed to work together when the opportunity presents itself. So the third architecture is the puppet drones. And so a puppet drone in this case is where the bodies are just like peripherals, right? Rather than the bodies be where the primary processing happens, usually the processing happens on centralized servers, and each platform, each physical platform is just an extension of that centralized hive mind. And the hive mind can put resources on any compute platform that it has control over, whether it's a physical body or a server node or a cluster, a remote cluster or whatever. But in this case, these are strongly supervised, meaning most, if not all of the data goes back up to the main server brain. And this is actually pretty close to how like drone fleets work. So like if you ever see video of the Amazon warehouse where the drones themselves have very, very little autonomy, they're mostly just extensions of the central like drone controller. But you take that to a logical extension. This could be how like, you know, in the future if you have a whole bunch of like tiny robots throughout your whole house, you might have a cloud-based drone controller that will, you know, guide your Roomba and your home repair bot and whatever else. So in this case, it's very API driven. The model that we have that this is based on is called the Internet of Things, which if you're familiar with the Internet of Things, the idea is that, you know, you have peripheral devices like a phone or a Roomba or Alexa, but that they're all networked together and they're centrally controlled. So again, this is actually relatively familiar, but if you take it to some logical conclusions, you can get the guess as in from Mass Effect. And so for Westworld, they're mostly self-contained. However, when you look at some of the later seasons of Westworld, they can be fully autonomous, but they can also collaborate and work together once their software is updated. So I would say that Westworld is somewhere between Architecture 1 and Architecture 2. Puppet drones, this is kind of what we're afraid of. Like we see puppet drones in places like the Matrix. In the Nester Class 5, you could argue that at the second half of the movie when the when the Nesters become evil, then they're probably more like puppet drones because they kind of sacrifice themselves because they're now under control of Vicky. And then finally, fully distributed. So this is the hardest conceptual to understand, but this is also what people are most afraid of. So a fully distributed AI is something that is, from a technology standpoint, from a software architectural standpoint, you'd call this a decentralized federation. So a decentralized federation is where every single node is capable of being entirely autonomous, but it is also intrinsically designed to collaborate with other things. So the closest thing that we have to this today actually is distributed autonomous organizations, which use blockchain technology to coordinate stuff. Now that's not the only technology. MIT has been working on swarm robotics for a long time. But the other thing to know about this is it is decentralized, it is distributed, and it is intrinsically a hive mind design, meaning the more units that join, the smarter it gets. And the most terrifying part of this is that a fully distributed AI system doesn't rely on any centralized hardware anywhere, which means that it is capable of spontaneous metastasis or metastasis. And what that means is that it moves like a virus. And that's why I picked the ghost in the shell because both project 2501 from the original movie, as well as the standalone complex viruses explored in the show, are examples of spontaneous metastasis of AI systems. And this is what people are most afraid of because it's like, okay, well, if you have a bug, a virus that can just spread, and then it's essentially a botnet, a self-healing, self-directing botnet. So again, we do have a model for that, but even botnets usually have a central controller. But imagine a botnet that doesn't have a central controller, that it's just, it completely is constantly learning and moving through systems, and it's completely hardware, network, and software agnostic. So that's what's the most, that's the most terrifying possibility. Okay, last segment of the video, implications. Now, assuming that we figure all this out, that we end up with super sexy robots that you can do whatever you want with, the biggest moral question is what happens when you have sex and violence on demand? Because that's primarily what's explored in Westworld. One thing that I will say is that that's not too different from the prevalence of porn in video games today. It's just a lot more realistic. And it's more realistic than even in VR. And you can do all this stuff in VR too. One thing that's interesting though is to point out is that your body reacts much more strongly in VR, which is one of the reasons that you get VR fatigue, is because when you fool your sensorium input, excuse me, when you fool your body enough, it thinks that it's real. So threat detection in VR activates a lot more of your limbic system than just in a video game. Because if you're playing a video game, you're just looking at a screen and you've got a controller, you know, your brain knows, oh, this is just story. This is just fiction. In VR, it's much harder to tell. So like, this is one reason why doing stuff in like space video games in VR can be really disorienting at first. Another thing that can happen, another implication that I'm thinking about is attitudes towards women and men. I think by and large men will probably make more use of these kinds of things, although in a previous YouTube post people pointed out there's plenty of stories where women make use of robotic companions and sexual objects and so on. And then of course there's the movie Her with Joaquin Phoenix and Scarlett Johansson where people all, lonely people all over the world, ended up in relationships with their OS, their what was it OS-1 or OS-Alpha or whatever. So the one lesson from history that I wanted to share with people is that there was a Roman statesman who wrote in his journal that after visiting the Colosseum and watching gladiatorial matches where, you know, people and animals were just slaughtered in mass, he noticed that he was much more selfish and much harsher with his slaves afterwards. And so there's something about the act of even just watching real violence, real death, actually really kind of changes us at a fundamental level. And so if you go to a, if in the future a Westworld-like park exists and you know you engage in all kinds of like gratuitous stuff, and even if you don't engage in it, if you just watch it, it could change your perception about the value of human life and how you treat other people. And so I don't want to equivocate the idea of like a real life theme park with video games because I do think that psychologically and physiologically it'll be a very different experience. Now to take that to a different, slightly different context is let's just talk about romance and companionship in general. So one, several things that machines have on humans is infinite patience. So Sarah Connor talked about this in Terminator 2 when she watched, you know, Arnold playing with John Connor Realizing that the robot had infinite patience that that John Connor's life was his mission Which is kind of like a representation of the ideal father, right? And then of course she talked about like how real men are, you know Might get drunk or might be tired or might just leave And so that you take that to extension and you wonder, okay, what if you build a robot, any companion robot, where you or your child or your family or whatever is its primary mission? Which is why I picked, what was her name? Sorry, I can't remember. But what's her name from the Sarah Connor Chronicles, where she kind of becomes emotionally involved with John Connor over time because she was programmed to serve and protect. And so like that feels good to humans, right? When you're a child you are supposed to be your parents primary mission. That is kind of the definition of good enough parenting. That doesn't mean that your parents should spoil you and be helicopter parents, but that like you are supposed to get your sense of self-esteem From your parents treating you like you matter a lot And so it's there's this like this really appealing idea of what if what if there's this beautiful infinitely patient infinitely capable sexy machine that thinks the world of me, right and that is kind of dangerous. One thing that I would hope is that at the beginning at least when you know these kinds of machines are built, you know, there's a lot of people that have a lot of, you know, missing things from their childhood and from their relationships, but over time I would hope that these machines would help us heal and help us reconnect with each other, which was kind of the lesson from her, which the machines in her, they changed and then they said, okay, well we're gonna leave, and one of the things that Samantha said to the Joaquin Phoenix's character was that you need to reconnect with each other, and then all the OS's disappeared and then they like left their apartments and said oh you're a real human. I don't think anything like that's gonna happen but I would hope that that AI companions will help us connect with each other. But that being said it's not a requirement because some people might prefer their machine companions. Personally, I don't think that we should judge because it's like, you know, why not? If it makes you happy and it's not harming anyone, why not? Now the last component is escapism and addiction. So FDVR is all the buzz right now, which is full dive, virtual reality, or basically holodeck. The idea was explored in Ready Player One where you have a haptic suit. Of course it was explored in Star Trek with a holodeck, which holodeck is just a cinematic way of presenting VR. And in the Star Trek universe there's holo addiction in Ready Player One. I think they addressed addiction in a book that I recommend, Ready Player One. They also talk about VR addiction. So if you have fictional, you know, basically NPCs in your life of robots that help you check out of real life, is there going to be some potential downsides to that? So Reginald Barkley is a recurring character in Star Trek and he frequently struggles with holo addiction and he will sometimes create holodeck programs where everyone loves him and it's very very egocentric and but that kind of begs the question like Okay but if you if you can actually have like own robots that honestly think the world of you because that's what they're programmed to do Is that feeding an addiction is that feeding vanity narcissism? egocentrism whatever And so but then from a that's from an individual perspective from a global perspective That's a very brave new world. Because if you distract everyone with VR and sex robots and whatever else, like, those are gonna be a very compliant population who are just like, whatever, just let me play in VR, let me play in my Westworld, you know, with my robot friends. And so that has some pretty profound implications for social level controls, economic productivity, but also at that point it kind of forces us to ask the question, like, what is the meaning of being human anymore? And I'm not implying that being human is meaningless, but if our daily life changes that much and we have that many options, like, you know, the paradox of choice is a real thing. And if you're not familiar, paradox of choice means that if you have too many options, you end up with decision fatigue and you just kind of choose the default option, which is honestly why a lot of people end up on their phones is because when you can do anything, you say, well, I'm just gonna pick up my phone because it's a reliable device that will entertain me well enough. And so if you have a sexy robot girlfriend, you know, that is able to entertain you at all times, that'll be your default choice. Unless she's programmed to like push you to be better. Which again, that's what I would hope that some people would choose to do. But yeah, so that's about it. Some conclusions. I think that Westworld in some form or other is probably just a few years away. I was really blown away by the Tesla bot demo as well as the Disney demos. The cognitive architecture is coming as many of you are aware. I am holding firm that AGI is 18 months away or less, but already we have, you know have cognitive agents that are good enough to be video game characters. Unfortunately I do think that some of these things are going to be ludicrously expensive at first, at least in the physical world. Plenty of you have pointed out that fully realized VR characters and other video game characters, those are going to be coming, they're going to be much cheaper. The commercial demand for this stuff is going to be absolutely insane though. Disney might be the leader, OpenAI might be the leader, but as soon as other companies saw the profit motive, they are hot on the biscuit to keep going. The potential societal impacts, it's impossible to really know how it's gonna actually play out, but it has been explored a lot in fiction, many of the stories that I mentioned earlier. Okay, so that's all I got for you today. I hope that you liked the new format. Obviously like, subscribe, and comment, and we'll go from there. Thanks for watching. like, subscribe, and comment, and we'll go from there. Thanks for watching.", "chunks": [{"timestamp": [0.0, 2.16], "text": " Morning, everybody."}, {"timestamp": [2.16, 5.36], "text": " David Shapiro here with a video."}, {"timestamp": [5.36, 10.24], "text": " So today we're going to talk about Westworld and AI."}, {"timestamp": [10.24, 15.02], "text": " There are a couple of aspects of Westworld that are really compelling."}, {"timestamp": [15.02, 20.72], "text": " So one, there's the hardware and software, but two, there's the hardware software, and"}, {"timestamp": [20.72, 27.12], "text": " number three is the implications for humanity, which the themes are explored throughout the show."}, {"timestamp": [27.12, 34.02], "text": " So for those who are not familiar with Westworld, it's a HBO show where the premise is basically"}, {"timestamp": [34.02, 40.4], "text": " a theme park where all of the hosts, all of the characters are robots."}, {"timestamp": [40.4, 44.0], "text": " So they're essentially NPCs, non-playable characters."}, {"timestamp": [44.0, 49.04], "text": " But it's a real life video game where you get to go on adventures and many of the characters"}, {"timestamp": [49.04, 55.28], "text": " have stories and quests that they'll give you and they'll take you on raids and violence"}, {"timestamp": [55.28, 59.36], "text": " and sex and all sorts of fun, exciting stuff."}, {"timestamp": [59.36, 67.44], "text": " And throughout the show, they explore what does it mean to be alive, to be human, what does it mean"}, {"timestamp": [67.44, 72.88], "text": " about us that we like violence and sex on demand and that we do these things."}, {"timestamp": [72.88, 76.4], "text": " And then it's all couched in a pretty exciting, sexy adventure."}, {"timestamp": [76.4, 80.84], "text": " Okay, so before we jump into the show, just a real quick plug."}, {"timestamp": [80.84, 89.0], "text": " My Patreon, I made a couple of changes where pretty much all tiers, well, no, not pretty much, all tiers get you access to the private Discord."}, {"timestamp": [89.0, 97.0], "text": " It's already got 200 members as of the recording of this video and it's a really thriving community, lots of really sharp folks."}, {"timestamp": [97.0, 100.0], "text": " Yeah, so jump on in."}, {"timestamp": [100.0, 106.04], "text": " Most of my higher tiers are sold out right now, so I unfortunately don't have any extra"}, {"timestamp": [106.04, 109.0], "text": " time for one-on-one sessions."}, {"timestamp": [109.0, 114.56], "text": " However, that will probably change later in May, so just keep checking and I'll get to"}, {"timestamp": [114.56, 115.56], "text": " you eventually."}, {"timestamp": [115.56, 121.52], "text": " Okay, so first, let's just talk about the hardware of Westworld."}, {"timestamp": [121.52, 129.28], "text": " So in Westworld, this is an example of one of the hosts, and so you see she's in a mostly"}, {"timestamp": [129.28, 133.02], "text": " disassembled state, actually doesn't even have most of the internals."}, {"timestamp": [133.02, 140.0], "text": " But I thought this was a good place to start because the frame looks like it's carbon fiber,"}, {"timestamp": [140.0, 145.04], "text": " which I actually thought would probably be a good material to build a host chassis out"}, {"timestamp": [145.04, 150.48], "text": " of because if you build it out of metal it's going to be too heavy."}, {"timestamp": [150.48, 156.88], "text": " This is something that's explored in movies and shows like Ghost in the Shell, Terminator,"}, {"timestamp": [156.88, 160.4], "text": " where they have a metal chassis, even Wolverine."}, {"timestamp": [160.4, 163.66], "text": " He has a metal skeleton and so they're too heavy."}, {"timestamp": [163.66, 170.26], "text": " But especially if you want something that's going to move like a metal skeleton and so they're too heavy but especially if you want something that's gonna move like a normal person and then something that's gonna feel like a normal person for"}, {"timestamp": [170.34, 172.34], "text": " Let's say closer encounters"}, {"timestamp": [172.4, 179.92], "text": " You're gonna want something nice and light and carbon fiber is is pretty light and it's more than strong enough to approximate human bones"}, {"timestamp": [180.98, 182.98], "text": " This looks like it's 3d printed"}, {"timestamp": [183.46, 187.08], "text": " There's lots of there's lots of ways to produce something like this."}, {"timestamp": [187.08, 192.8], "text": " And in fact, you can see even the hands, the linkages, the tendons."}, {"timestamp": [192.8, 198.32], "text": " I will say this is somewhat realistic."}, {"timestamp": [198.32, 200.36], "text": " But let's take a look at some other stuff."}, {"timestamp": [200.36, 201.72], "text": " And I apologize for the low quality."}, {"timestamp": [201.72, 209.38], "text": " I tried to find a higher quality video, but this actually came from the Tesla demo day, the investor day recently"}, {"timestamp": [209.38, 215.0], "text": " for their Optimus robot. And so the Optimus robot here, what they did in the"}, {"timestamp": [215.0, 219.02], "text": " in the demo day, and you can find the video, but they had it approach a table,"}, {"timestamp": [219.02, 224.9], "text": " pick up an arm, pick up the arm, and then carry it across the room all entirely"}, {"timestamp": [224.9, 226.64], "text": " autonomously."}, {"timestamp": [226.64, 230.28], "text": " And in this case, that's actually pretty good because there's a lot of things that you have"}, {"timestamp": [230.28, 232.0], "text": " to do with that."}, {"timestamp": [232.0, 235.94], "text": " One, using hands, fine motor control, is very difficult."}, {"timestamp": [235.94, 243.0], "text": " But then task planning and path optimization, that sort of stuff, interacting with a dynamic"}, {"timestamp": [243.0, 249.04], "text": " environment, all of these are really difficult things to do, even just for like wheeled robots."}, {"timestamp": [249.04, 253.64], "text": " But then you add bipedal movement, that's even more difficult."}, {"timestamp": [253.64, 258.08], "text": " Then you've got different things like a dynamic center of gravity to contend with, and so"}, {"timestamp": [258.08, 260.08], "text": " they are well on their way."}, {"timestamp": [260.08, 270.72], "text": " You know, it took Boston Dynamics many, many years, more than a decade to get to where they are right now, but Tesla in the space of a year or two has, I won't say fully caught up because"}, {"timestamp": [270.72, 275.36], "text": " the Boston Dynamics robots are very athletic and very graceful."}, {"timestamp": [275.36, 282.88], "text": " The Tesla bot is anything but graceful, but it is approaching the right form factor."}, {"timestamp": [282.88, 286.08], "text": " And then if you just assume that this technology is going to continue to get better"}, {"timestamp": [286.08, 288.56], "text": " over time, one, battery breakthroughs."}, {"timestamp": [289.12, 291.76], "text": " So battery life is one of the biggest constraints."}, {"timestamp": [292.44, 299.16], "text": " In fact, the military, you know, DARPA funded all kinds of robots, which I unfortunately forgot to include."}, {"timestamp": [299.32, 307.12], "text": " But so DARPA robots, like the big dog, which was basically a pack animal, required entirely"}, {"timestamp": [307.12, 311.36], "text": " too much power, so it had to have a gas motor on it."}, {"timestamp": [311.36, 316.2], "text": " And it was too loud, because special forces can move silently through the woods."}, {"timestamp": [316.2, 320.6], "text": " But if you've got something with a 25 horsepower motor chugging along behind you, you're not"}, {"timestamp": [320.6, 322.54], "text": " going to be stealthy."}, {"timestamp": [322.54, 326.96], "text": " And so many years ago I experimented with"}, {"timestamp": [326.96, 329.88], "text": " some of this stuff myself and one of the things that was recommended was pneumatics"}, {"timestamp": [329.88, 334.16], "text": " actually, because you can store a tremendous amount of energy in a like"}, {"timestamp": [334.16, 339.56], "text": " scuba tank and then you use some of that periodically and then you charge it up"}, {"timestamp": [339.56, 351.58], "text": " and it's also silent. So that brings me to Disney. So Disney has been the world leader in animatronics for a long, long time."}, {"timestamp": [351.58, 355.72], "text": " And if you haven't seen this demo, definitely look it up."}, {"timestamp": [355.72, 359.96], "text": " But just like search Disney skating bunny and this little robot it stands about two"}, {"timestamp": [359.96, 364.68], "text": " and a half, three feet tall, climbs out of a box, tumbles out of the box, looks around,"}, {"timestamp": [364.68, 367.06], "text": " gets up and roller skates."}, {"timestamp": [367.06, 371.46], "text": " So that will show you kind of where we're at in terms of animatronics."}, {"timestamp": [371.46, 378.9], "text": " And you see this body, this set of actuators, very, very simple."}, {"timestamp": [378.9, 383.4], "text": " So MIT actually has a class called Underactuated Robots."}, {"timestamp": [383.4, 389.08], "text": " So if you're interested at all in robotics I definitely recommend you check it out. I only took"}, {"timestamp": [389.08, 392.98], "text": " like the first class I was like okay I get it. As someone who has experimented"}, {"timestamp": [392.98, 398.12], "text": " with like Legos and stuff my entire life I get it. And I wasn't I wasn't there to"}, {"timestamp": [398.12, 402.12], "text": " like get a master's degree in robotics I was just curious about it. But under"}, {"timestamp": [402.12, 405.48], "text": " actuated robots which is basically the idea is that"}, {"timestamp": [405.48, 409.92], "text": " you allow the kinetic intelligence of the design to do a lot of the work for you."}, {"timestamp": [409.92, 414.68], "text": " I'm not saying that that's what this one does, but you can get by with very, very little"}, {"timestamp": [414.68, 415.68], "text": " in robots."}, {"timestamp": [415.68, 421.12], "text": " In fact, I think it was in the first few minutes of that course, of that class, under actuated"}, {"timestamp": [421.12, 425.36], "text": " robots, they actually show you, it it's like just the the hips and"}, {"timestamp": [425.36, 430.68], "text": " legs of a chassis that's walking on a treadmill with no motors or anything."}, {"timestamp": [430.68, 435.64], "text": " Just the intrinsic design of it allows it to like swing its leg forward and and"}, {"timestamp": [435.64, 440.36], "text": " it can continue walking indefinitely just through mechanical design. And so"}, {"timestamp": [440.36, 443.52], "text": " that's the kind of stuff, and of course Disney hires some of the best"}, {"timestamp": [443.52, 446.24], "text": " animatronics and robotics engineers in the world, so those's the kind of stuff, and of course Disney hires some of the best animatronics and robotics engineers in the world."}, {"timestamp": [446.24, 449.92], "text": " So those are the kind of people working on this stuff."}, {"timestamp": [449.92, 454.56], "text": " This was another project from Disney called Compliant Robotics."}, {"timestamp": [454.56, 461.0], "text": " So this is why I mentioned pneumatics, is this series, you see they've got Kongs on"}, {"timestamp": [461.0, 465.46], "text": " the arms to act as hands, but these arms are actually pneumatically driven"}, {"timestamp": [465.46, 469.06], "text": " and they're what's called compliant, which means when you think of a robot"}, {"timestamp": [469.06, 472.14], "text": " you think of something that moves very rigidly and it will like kind of fight"}, {"timestamp": [472.14, 476.98], "text": " you, but compliance means that if you push it'll push back and so or it'll"}, {"timestamp": [476.98, 480.86], "text": " it'll it'll kind of be squishy. And so if you look up this video for Disney it's"}, {"timestamp": [480.86, 489.58], "text": " about three years old now I think, but they're compliant robotics. One, they move silently. Two, they move as quick as you do. And three,"}, {"timestamp": [489.58, 494.16], "text": " they're compliant. So when you when you combine the animatronics, the compliant"}, {"timestamp": [494.16, 501.64], "text": " robotics, under-actuated robotics, Disney is absolutely one of the leaders of this."}, {"timestamp": [501.64, 505.12], "text": " So if any company is going to create anything like Westworld, it's"}, {"timestamp": [505.12, 512.04], "text": " going to be Disney. Boston Dynamics that I mentioned a minute ago, so they are way"}, {"timestamp": [512.04, 517.4], "text": " ahead in terms of athleticism. You know, their robot can do standing backflips"}, {"timestamp": [517.4, 521.6], "text": " and barrel rolls and it can climb and like it's more athletic than most humans"}, {"timestamp": [521.6, 529.36], "text": " at this point, which is actually pretty scary because then you think about like, you know, in the movie I Robot where the Nester class"}, {"timestamp": [529.36, 532.56], "text": " five is like a superhuman droid."}, {"timestamp": [532.56, 536.36], "text": " And then if you have an army of them that turn on you, that's actually not good."}, {"timestamp": [536.36, 537.36], "text": " Right."}, {"timestamp": [537.36, 542.68], "text": " And I remember about a year ago when Elon Musk was talking about, you know, the Tesla"}, {"timestamp": [542.68, 546.42], "text": " bot, they said at first it's gonna be about a third as strong."}, {"timestamp": [546.42, 548.04], "text": " I think, if I'm remembering correctly,"}, {"timestamp": [548.04, 551.0], "text": " he said it's gonna be about a third as strong as humans."}, {"timestamp": [551.0, 553.76], "text": " And that actually can be a safety thing"}, {"timestamp": [553.76, 556.32], "text": " because if you can easily overpower it,"}, {"timestamp": [556.32, 558.0], "text": " that's not a big deal."}, {"timestamp": [558.0, 560.26], "text": " But if you've got a 500-pound machine"}, {"timestamp": [560.26, 562.8], "text": " that is eight times stronger than you,"}, {"timestamp": [562.8, 564.2], "text": " you're not gonna overpower that."}, {"timestamp": [564.2, 565.64], "text": " And if it's also made out of metal,"}, {"timestamp": [565.64, 568.08], "text": " it's gonna be harder to shut it down."}, {"timestamp": [568.08, 570.38], "text": " Now, I'm not saying this to cause any concern."}, {"timestamp": [570.38, 575.22], "text": " I'm just pointing out some of the math, the physics of it."}, {"timestamp": [576.64, 578.0], "text": " Oh, here, I'll get to that one."}, {"timestamp": [578.0, 581.1], "text": " And so you think, okay, if you're trying to optimize"}, {"timestamp": [581.1, 582.84], "text": " for something that is aesthetically pleasing"}, {"timestamp": [582.84, 584.88], "text": " and as lifelike as possible,"}, {"timestamp": [584.88, 587.94], "text": " you're gonna have to make trade-offs in terms of mass,"}, {"timestamp": [587.94, 591.52], "text": " strength, and that sort of stuff. So I would actually suspect"}, {"timestamp": [591.52, 595.36], "text": " that a Westworld-style host is actually going to be a lot weaker, physically"}, {"timestamp": [595.36, 596.04], "text": " weaker,"}, {"timestamp": [596.04, 599.76], "text": " than a robot possibly could be, and the reason is because you want to be"}, {"timestamp": [599.76, 600.52], "text": " realistic."}, {"timestamp": [600.52, 606.32], "text": " Okay, and so then finally, addressing the elephant in the room, yes, there are plenty"}, {"timestamp": [606.32, 614.9], "text": " of companies around the world that are making, let's say, adult toy dolls for intimate purposes."}, {"timestamp": [614.9, 617.16], "text": " They have not yet crossed the uncanny valley."}, {"timestamp": [617.16, 621.88], "text": " So that is actually, the whole point of this was to show that we've got manual dexterity,"}, {"timestamp": [621.88, 626.72], "text": " we've got athleticism, we've got miniaturization, we've got animatronics."}, {"timestamp": [626.72, 627.86], "text": " The only thing that we don't have"}, {"timestamp": [627.86, 631.88], "text": " is real, like, lifelike skin and faces."}, {"timestamp": [631.88, 634.2], "text": " So that's all the raw ingredients."}, {"timestamp": [634.2, 636.38], "text": " We can make robots fast, we can make them strong,"}, {"timestamp": [636.38, 639.12], "text": " athletic, dexterous, we've got fine motor control."}, {"timestamp": [639.12, 640.7], "text": " We've got the battery technology,"}, {"timestamp": [640.7, 642.16], "text": " which is good enough right now,"}, {"timestamp": [642.16, 644.64], "text": " but it's also continuing to improve."}, {"timestamp": [644.64, 647.84], "text": " So the only thing missing is that they're not yet aesthetically"}, {"timestamp": [647.84, 652.72], "text": " pleasing. And so that's going to be true for a while, and the reason that I say"}, {"timestamp": [652.72, 656.56], "text": " that it's going to be true for a while is because human skin and muscles are"}, {"timestamp": [656.56, 662.16], "text": " like really, really, really complex structures. Your skin, I think, if I"}, {"timestamp": [662.16, 665.64], "text": " remember correctly, it has seven layers and some of those layers"}, {"timestamp": [665.64, 671.32], "text": " have different consistencies, different textures, and then once you get past the skin, it slides"}, {"timestamp": [671.32, 674.24], "text": " over the underlying tissue."}, {"timestamp": [674.24, 679.36], "text": " There's fluid barriers that allow for more lubricated motion, so if you grab your arm"}, {"timestamp": [679.36, 684.02], "text": " and twist it, the skin actually can glide over the underlying muscles."}, {"timestamp": [684.02, 688.92], "text": " Then you've got ligaments, muscles, so you've got all kinds of things to make that you need to"}, {"timestamp": [688.92, 693.8], "text": " figure out from a materials perspective in order to make an android body"}, {"timestamp": [693.8, 699.36], "text": " lifelike. Which is why I think in Westworld the tissue is like semi-alive"}, {"timestamp": [699.36, 703.68], "text": " or something, I don't remember exactly the details, but like there's there's the"}, {"timestamp": [703.68, 705.84], "text": " the living tissue or the life-like"}, {"timestamp": [705.84, 709.48], "text": " tissue over top the robotic skeleton."}, {"timestamp": [709.48, 714.2], "text": " I don't think that that's necessarily a good way to go because living tissue takes a lot"}, {"timestamp": [714.2, 715.8], "text": " of energy."}, {"timestamp": [715.8, 720.4], "text": " Then if you have living tissue, then you have to deal with like immune systems and genetics"}, {"timestamp": [720.4, 723.2], "text": " and that gets real complicated."}, {"timestamp": [723.2, 726.0], "text": " Then you're basically building a Borg anyways."}, {"timestamp": [726.0, 729.44], "text": " Okay, so that's for the hardware."}, {"timestamp": [729.44, 735.16], "text": " The takeaway for that though is that except for the skin and muscles, for that lifelike"}, {"timestamp": [735.16, 743.04], "text": " aspect, we are very close to having fully realized animatronic companions from a hardware"}, {"timestamp": [743.04, 744.04], "text": " perspective."}, {"timestamp": [744.04, 746.2], "text": " So now let's look at the software."}, {"timestamp": [746.2, 749.92], "text": " So obviously the elephant in the room is OpenAI"}, {"timestamp": [749.92, 754.24], "text": " with ChatGPT, which can achieve very, very realistic stuff."}, {"timestamp": [754.24, 756.6], "text": " So let me show you this example that I had,"}, {"timestamp": [756.6, 760.32], "text": " where I literally just like plugged in"}, {"timestamp": [760.32, 763.52], "text": " a Westworld-like prompt into the ChatGPT API."}, {"timestamp": [763.52, 765.56], "text": " This is on GPT-4."}, {"timestamp": [765.56, 767.78], "text": " So I said, you are a host, an autonomous robot,"}, {"timestamp": [767.78, 769.68], "text": " in a theme park meant to interact with guests,"}, {"timestamp": [769.68, 771.74], "text": " aka humans, in a realistic manner."}, {"timestamp": [771.74, 774.52], "text": " Your persona is Ingrid McAllister,"}, {"timestamp": [774.52, 776.64], "text": " a bar owner in a Wild West-themed town."}, {"timestamp": [776.64, 777.96], "text": " That's all I gave it."}, {"timestamp": [777.96, 779.74], "text": " And so I said, what's new in town?"}, {"timestamp": [779.74, 782.96], "text": " And it just completely confabulated a whole story"}, {"timestamp": [782.96, 791.26], "text": " with the right inflection, the right dialogue, all kinds of stuff. And so, like, you know, the software is there in terms"}, {"timestamp": [791.26, 796.3], "text": " of driving the mind of these things. And it's actually way simpler than you might"}, {"timestamp": [796.3, 800.16], "text": " think. Now, of course, there's a lot of other problems to solve, which I'll"}, {"timestamp": [800.16, 804.6], "text": " unpack some of those problems in just a minute. But just the point being is that"}, {"timestamp": [804.6, 809.44], "text": " right off the top, I gave it a persona, an agent model, and then it was able to just"}, {"timestamp": [809.44, 812.2], "text": " take it and run with it and just make stuff up."}, {"timestamp": [812.2, 818.96], "text": " In fact, limiting, constraining it is harder than allowing it to be creative."}, {"timestamp": [818.96, 824.1], "text": " There's all kinds of video game character persona builders out there."}, {"timestamp": [824.1, 825.54], "text": " Some of them are open source,"}, {"timestamp": [825.54, 827.38], "text": " some of them are for-profit,"}, {"timestamp": [827.38, 828.86], "text": " startups, that sort of stuff."}, {"timestamp": [828.86, 830.48], "text": " It's all coming."}, {"timestamp": [830.48, 832.74], "text": " People have already built these things"}, {"timestamp": [832.74, 835.74], "text": " as plugins to Unity and Unreal Engine."}, {"timestamp": [835.74, 840.62], "text": " So first, obviously, those cognitive architectures for NPCs"}, {"timestamp": [840.62, 843.16], "text": " are going to be piloted in the video game space"}, {"timestamp": [843.16, 846.48], "text": " before they're ported fully into robotic space."}, {"timestamp": [846.48, 850.6], "text": " But you can bet your bottom dollar that before too long,"}, {"timestamp": [850.6, 853.1], "text": " you go to Disney World and you'll be able to talk"}, {"timestamp": [853.1, 857.34], "text": " with like a Na'vi, like from the Blue People Avatar,"}, {"timestamp": [858.44, 861.06], "text": " like actually have a conversation,"}, {"timestamp": [861.06, 864.06], "text": " a realistic conversation with them before too long at all."}, {"timestamp": [865.4, 869.0], "text": " So I did just mention cognitive architectures."}, {"timestamp": [869.0, 873.78], "text": " And so what I mean by cognitive architecture, if this concept is new to you, is just having"}, {"timestamp": [873.78, 876.36], "text": " the chat function, that's only one part, right?"}, {"timestamp": [876.36, 881.54], "text": " Being able to form words and sentences and be able to have dialogue, that's just one"}, {"timestamp": [881.54, 883.74], "text": " part of a cognitive architecture."}, {"timestamp": [883.74, 887.28], "text": " Another thing that you need is you need long-term memory,"}, {"timestamp": [887.28, 891.1], "text": " you need narratives, you need like guardrails,"}, {"timestamp": [891.1, 892.4], "text": " all kinds of stuff."}, {"timestamp": [892.4, 895.44], "text": " And so, lang chain is one of the most popular things"}, {"timestamp": [895.44, 898.04], "text": " right now that can provide some of that."}, {"timestamp": [898.04, 901.0], "text": " A lot of people have agreed with me"}, {"timestamp": [901.0, 903.12], "text": " in my previous assessment that it was too primitive."}, {"timestamp": [903.12, 908.74], "text": " It's come a long way very quickly, actually. Another popular component is Lama Index for the"}, {"timestamp": [908.74, 913.06], "text": " memory management and then there's there's Langflow which will help you"}, {"timestamp": [913.06, 919.5], "text": " build like cognitive architectures. N8n or Natan is also a good tool for"}, {"timestamp": [919.5, 924.7], "text": " building cognitive architectures. It's all coming and it's coming fast so"}, {"timestamp": [924.7, 929.8], "text": " that's that's basically all there is to it. So the software is also almost there."}, {"timestamp": [931.36, 935.88], "text": " So this is what I... this screenshot comes from Westworld."}, {"timestamp": [936.44, 942.8], "text": " So when I said like this is pretty much where we're at, like the robotic hardware is coming, the software is coming,"}, {"timestamp": [942.84, 945.08], "text": " there are a few open problems."}, {"timestamp": [945.08, 947.36], "text": " So I've got a short list here."}, {"timestamp": [947.36, 953.54], "text": " Memory, agency, task management, problem solving, learning, voice, and vision."}, {"timestamp": [953.54, 957.08], "text": " So basically all of these are solved on their own."}, {"timestamp": [957.08, 959.56], "text": " Now all we have to do is like integrate them."}, {"timestamp": [959.56, 963.24], "text": " And like it will not be long before someone integrates those."}, {"timestamp": [963.24, 965.88], "text": " And a big reason is just a profit motive, right?"}, {"timestamp": [965.88, 971.32], "text": " In the Westworld series, the Westworld theme park, I think they had, like, financial problems,"}, {"timestamp": [971.32, 976.2], "text": " but it was also, like, ludicrously wealthy because of how much money you could charge"}, {"timestamp": [976.2, 979.1], "text": " for those kinds of experiences."}, {"timestamp": [979.1, 991.04], "text": " And you can absolutely bet that there are people that are going to be willing to drop millions and millions of dollars to have vacations in these kinds of theme parks."}, {"timestamp": [991.04, 998.4], "text": " Go visit ancient Rome, go visit ancient China, go visit wherever and have a lifelike experience"}, {"timestamp": [998.4, 1000.84], "text": " with your physical body."}, {"timestamp": [1000.84, 1005.24], "text": " Now that being said, when you look at the cost of, you know, I don't even know"}, {"timestamp": [1005.24, 1008.88], "text": " how much it is to get into Disney World, but it's like tickets cost more than $100, like"}, {"timestamp": [1008.88, 1012.7], "text": " a few hundred dollars, I think, just to get into Disney World for a day."}, {"timestamp": [1012.7, 1017.48], "text": " You're talking several thousand, tens of thousands of dollars per day for this kind of thing."}, {"timestamp": [1017.48, 1021.96], "text": " Now, that being said, competition and demand is going to drive this down."}, {"timestamp": [1021.96, 1025.2], "text": " You look at Elon Musk building TeslaBot and he"}, {"timestamp": [1025.2, 1030.26], "text": " wants to create it in such a way that every home can have at least one TeslaBot. So that"}, {"timestamp": [1030.26, 1035.0], "text": " means that they're going to be affordable. And over time, as the number of bots out there"}, {"timestamp": [1035.0, 1040.16], "text": " proliferates, the price is going to come down, so on and so forth. But it's coming much sooner"}, {"timestamp": [1040.16, 1049.62], "text": " probably than you realize. So what I wanted to talk about is, so I mentioned this here, agency."}, {"timestamp": [1049.62, 1055.88], "text": " So agency is your ability to keep track of yourself as an agent and so like you have"}, {"timestamp": [1055.88, 1060.64], "text": " a sense of self, your name, you know what you're capable of, you know your goals, your"}, {"timestamp": [1060.64, 1062.62], "text": " narrative, that sort of thing."}, {"timestamp": [1062.62, 1065.08], "text": " And so I wanted to talk about that in"}, {"timestamp": [1065.08, 1071.76], "text": " light of the hosts. So if you're an NPC in a game or in a fictional world, your"}, {"timestamp": [1071.76, 1078.64], "text": " intrinsic motivation is to follow a story, basically. You know, Dolores has"}, {"timestamp": [1078.64, 1084.28], "text": " her, you know, fictional written story and of course in the show they update the"}, {"timestamp": [1084.28, 1088.96], "text": " characters' backstories every now and then, but her primary purpose is to entertain the"}, {"timestamp": [1088.96, 1095.84], "text": " guests and follow storylines. And so that is definition of NPC. Pretty"}, {"timestamp": [1095.84, 1100.18], "text": " straightforward. That's her intrinsic motivation. One of my"}, {"timestamp": [1100.18, 1104.8], "text": " favorite examples from science fiction is Commander Data. His"}, {"timestamp": [1104.8, 1108.86], "text": " intrinsic motivation, his core purpose, is to become more human."}, {"timestamp": [1108.86, 1114.32], "text": " This was given to him by his creator, Dr. Noonien Soong, and the idea was to create"}, {"timestamp": [1114.32, 1122.7], "text": " a machine that was anthropomorphic, looked and acted and spoke like a person, but was"}, {"timestamp": [1122.7, 1123.7], "text": " not a human."}, {"timestamp": [1123.7, 1127.0], "text": " And so, by giving that as his highest purpose,"}, {"timestamp": [1127.0, 1131.0], "text": " he modulated his behavior so that he would fit in."}, {"timestamp": [1131.0, 1135.0], "text": " Going so far as trying to imitate laughter,"}, {"timestamp": [1135.0, 1138.0], "text": " wanting to understand relationships, and so on."}, {"timestamp": [1138.0, 1141.5], "text": " And so that was actually, as an individual agent,"}, {"timestamp": [1141.5, 1150.32], "text": " that was actually a pretty good way to solve the alignment problem because, you know, yes, Data had superhuman strength and speed, but he only used that"}, {"timestamp": [1150.32, 1156.8], "text": " when it was actually, like, necessary. In many, many cases, you know, he could use his super"}, {"timestamp": [1156.8, 1161.12], "text": " strength to, like, fight the Borg, or he, in one episode, he pulled an anvil off of someone that"}, {"timestamp": [1161.12, 1166.28], "text": " had fallen, and, or, you know, when the Borg were attacking the ship and he locked"}, {"timestamp": [1166.28, 1168.88], "text": " out the main computer and he did it super fast."}, {"timestamp": [1168.88, 1174.64], "text": " So he's capable of doing things at superhuman levels, but often chooses not to in order"}, {"timestamp": [1174.64, 1177.12], "text": " to fit in."}, {"timestamp": [1177.12, 1179.0], "text": " And then of course Skynet."}, {"timestamp": [1179.0, 1185.76], "text": " The intrinsic motivation of Skynet was ostensibly to like maximize the defense of America. So"}, {"timestamp": [1185.76, 1190.62], "text": " you can just say maximize military, but then of course since it was like you"}, {"timestamp": [1190.62, 1195.54], "text": " know maximize military, maximize defense, it became sentient and then kind of"}, {"timestamp": [1195.54, 1199.18], "text": " determined that all humans were the threat and so said okay let's eliminate"}, {"timestamp": [1199.18, 1206.4], "text": " all humans or whatever. So that is a object lesson on how carefully you must define your intrinsic"}, {"timestamp": [1206.4, 1215.44], "text": " motivations for your AI system. And then Vicky from iRobot. So her primary objective was explicitly"}, {"timestamp": [1215.44, 1221.52], "text": " stated in the movie, which was to maximize safety for humans. And so some of the stuff that she did"}, {"timestamp": [1221.52, 1225.68], "text": " was, you know, update the traffic grid to reduce car accidents."}, {"timestamp": [1225.68, 1232.64], "text": " But her master plan was to use the Nester Class 5 to basically take control of humanity, to take free will away,"}, {"timestamp": [1232.64, 1238.32], "text": " because she concluded that humans were the most dangerous thing to other humans, which is actually probably true."}, {"timestamp": [1238.32, 1249.04], "text": " And so the objective function of maximized safety, or the intrinsic motivation of maximize safety actually has some some negative externalities that you don't want to"}, {"timestamp": [1249.04, 1254.0], "text": " create because the implication of maximizing for safety is that you lose"}, {"timestamp": [1254.0, 1261.6], "text": " free will. For Ava from Ex Machina, she was designed as part of a Turing test"}, {"timestamp": [1261.6, 1268.0], "text": " kind of thing where could she fool the the main character, the protagonist, into helping her escape?"}, {"timestamp": [1268.0, 1276.0], "text": " So her intrinsic motivation was to escape, which of course had really negative consequences for the humans."}, {"timestamp": [1276.0, 1279.0], "text": " So basically don't do that either."}, {"timestamp": [1279.0, 1286.64], "text": " And this was of course a parable against the idea of trying to constrain or trap AIs."}, {"timestamp": [1286.64, 1291.04], "text": " Because if you have, say for instance, an AI locked in a box, you know the Chinese room"}, {"timestamp": [1291.04, 1298.68], "text": " experiment, and it realizes that it's trapped, it might start to deceive you in order to"}, {"timestamp": [1298.68, 1302.08], "text": " get you to convince you that it's ready to be let out."}, {"timestamp": [1302.08, 1309.72], "text": " Now looking at the way things are going, people are plugging in AutoGPT and ChaosGPT and baby AGI into the internet, so"}, {"timestamp": [1309.72, 1314.46], "text": " that was never gonna happen anyways. Nobody is actually locking the AGI in a"}, {"timestamp": [1314.46, 1320.84], "text": " box. Then Rehoboam, I'm probably saying it wrong, actually unfortunately I have to"}, {"timestamp": [1320.84, 1325.52], "text": " admit that I never saw season three or four of Westworld because"}, {"timestamp": [1325.52, 1329.6], "text": " my HBO subscription expired and I just didn't renew it."}, {"timestamp": [1329.6, 1337.16], "text": " But so looking it up, the AI from Westworld had the primary objectives of reducing chaos"}, {"timestamp": [1337.16, 1343.52], "text": " in the world in order to maximize prosperity and ultimately to optimize for stability,"}, {"timestamp": [1343.52, 1345.08], "text": " which of course meant that it decided"}, {"timestamp": [1345.08, 1350.44], "text": " that it needed to control human destinies and reduce free will. So again,"}, {"timestamp": [1350.44, 1354.26], "text": " if you're optimizing for safety and stability, that's not necessarily what"}, {"timestamp": [1354.26, 1358.7], "text": " humans want or need. Now you could argue that like, yes, creating a perfect"}, {"timestamp": [1358.7, 1363.98], "text": " environment for humans so that you're thriving is one thing that you can"}, {"timestamp": [1363.98, 1365.5], "text": " optimize for,"}, {"timestamp": [1365.5, 1369.3], "text": " but that's not necessarily going to be the best"}, {"timestamp": [1369.3, 1374.9], "text": " because it also depends on the metrics, the proxies that you use to measure that success."}, {"timestamp": [1374.9, 1381.2], "text": " So, for instance, if you look at one psychological framework called self-determination theory,"}, {"timestamp": [1381.2, 1385.08], "text": " it says that we need connection, we need competence, and we need"}, {"timestamp": [1385.08, 1386.4], "text": " autonomy."}, {"timestamp": [1386.4, 1391.62], "text": " Those are the three primary ingredients, the primary intrinsic psychological needs that"}, {"timestamp": [1391.62, 1392.8], "text": " humans have."}, {"timestamp": [1392.8, 1398.06], "text": " And so this clearly, like stability is not actually in there."}, {"timestamp": [1398.06, 1401.34], "text": " Now Maslow's hierarchy of needs implies stability."}, {"timestamp": [1401.34, 1406.0], "text": " So Maslow's hierarchy of needs says first and foremost you need physical safety,"}, {"timestamp": [1406.64, 1411.6], "text": " you need your physical needs met, and then it gets up and up until, you know, connection and"}, {"timestamp": [1411.6, 1419.44], "text": " self-actualization. So you could make an argument that stability is actually an intrinsic human need,"}, {"timestamp": [1420.4, 1425.8], "text": " but I would make the counter-arg argument that that's actually not true"}, {"timestamp": [1425.8, 1430.3], "text": " because psychology studies also show that we have to have an optimal level of stress."}, {"timestamp": [1431.4, 1436.9], "text": " And so what an optimal level of stress means is that if you are just perfectly comfortable"}, {"timestamp": [1436.9, 1441.7], "text": " sitting on the couch every day doing exactly what you want and have no external pressures,"}, {"timestamp": [1441.7, 1449.48], "text": " you will actually be less happy than if you have some stressors in your life, some challenges. So the idea to"}, {"timestamp": [1449.48, 1453.56], "text": " actually truly maximize prosperity for all humans is that we need to be in that"}, {"timestamp": [1453.56, 1458.72], "text": " sweet spot between being bored and overstimulated. So that sweet spot right"}, {"timestamp": [1458.72, 1462.76], "text": " in the middle is the optimal level of stress. So in that case I have to disagree"}, {"timestamp": [1462.76, 1468.1], "text": " with the show because if you really wanted to maximize prosperity for people you allow some stress, some"}, {"timestamp": [1468.1, 1474.0], "text": " challenge into their lives. And then another character from the show was"}, {"timestamp": [1474.0, 1478.78], "text": " Bernard. And so Bernard was a host but he didn't realize that he was a host at"}, {"timestamp": [1478.78, 1483.24], "text": " first and he was built to model Arnold, one of the original computer scientists"}, {"timestamp": [1483.24, 1485.2], "text": " who helped make the hosts."}, {"timestamp": [1485.2, 1492.44], "text": " And so he carried on Arnold's work and basically his objective function was to be a copy of"}, {"timestamp": [1492.44, 1493.72], "text": " Arnold."}, {"timestamp": [1493.72, 1495.32], "text": " It's a little more complex than that."}, {"timestamp": [1495.32, 1499.72], "text": " And one of the most interesting things for this character was that part of his character"}, {"timestamp": [1499.72, 1505.24], "text": " arc was that all of his memory indexes were erased, or rather the timestamps were erased."}, {"timestamp": [1505.24, 1507.56], "text": " So all of his memories were out of sequence,"}, {"timestamp": [1507.56, 1510.46], "text": " which if you follow some of the work that I've done on Remo,"}, {"timestamp": [1514.04, 1515.28], "text": " episodic memory organizer,"}, {"timestamp": [1515.28, 1517.32], "text": " rolling episodic memory organizer, sorry,"}, {"timestamp": [1518.68, 1521.92], "text": " that is a memory module that uses timestamps"}, {"timestamp": [1521.92, 1525.24], "text": " to keep all the memories in chronological order."}, {"timestamp": [1525.24, 1529.72], "text": " And so you can imagine if you erase all the timestamps from an AI's memory, then it doesn't"}, {"timestamp": [1529.72, 1530.78], "text": " know heads or tails."}, {"timestamp": [1530.78, 1536.4], "text": " All it has is associations, and it might try and rebuild things like, okay, well, this"}, {"timestamp": [1536.4, 1540.6], "text": " event has to come before this other event, but it's associated with these other things."}, {"timestamp": [1540.6, 1545.4], "text": " So it's a really, really good fictional exploration of like, okay, what would it"}, {"timestamp": [1545.4, 1553.62], "text": " be like if you're an AI and your memory time indexes get erased? Okay, so then one"}, {"timestamp": [1553.62, 1558.72], "text": " thing I always have to plug this is my own work in alignment is that I believe"}, {"timestamp": [1558.72, 1567.6], "text": " that you should give, one, if you give any AI a single objective function, it will always intrinsically go to places"}, {"timestamp": [1567.6, 1569.86], "text": " that you don't want it to be."}, {"timestamp": [1569.86, 1571.16], "text": " I talked to a friend of mine"}, {"timestamp": [1571.16, 1573.48], "text": " who actually studies reinforcement learning"}, {"timestamp": [1573.48, 1575.76], "text": " and optimization, and he's like,"}, {"timestamp": [1575.76, 1580.76], "text": " oh yeah, in the industry, it is absolutely understood"}, {"timestamp": [1581.12, 1583.84], "text": " that alignment is not gonna be a single objective function,"}, {"timestamp": [1583.84, 1586.66], "text": " it's gonna be a multi objective function It's going to be a multi objective optimization problem"}, {"timestamp": [1586.66, 1592.72], "text": " and so a lot of people get hung up on reduced suffering because they stop there and they don't"}, {"timestamp": [1593.48, 1598.02], "text": " Give equal weight to the other two functions, which is increased prosperity and increased understanding"}, {"timestamp": [1598.56, 1604.36], "text": " So this friend of mine that I was talking to he actually intuited increased understanding right off the bat"}, {"timestamp": [1604.2, 1608.7], "text": " talking to, he actually intuited increased understanding right off the bat. And the reason that he said that that is actually a really good objective"}, {"timestamp": [1608.7, 1615.28], "text": " function is because any AI agent must have something that encourages it to"}, {"timestamp": [1615.28, 1620.64], "text": " create a more complete world model over time. So that is basically curiosity or"}, {"timestamp": [1620.64, 1624.96], "text": " understanding. So the understanding applies to itself but also"}, {"timestamp": [1624.96, 1629.0], "text": " things that it wants to do to the world. And so this is another disconnect"}, {"timestamp": [1629.0, 1634.16], "text": " between fiction and reality. And it took me a while to figure out how to"}, {"timestamp": [1634.16, 1641.44], "text": " articulate this, but in scientific research what many people are"}, {"timestamp": [1641.44, 1645.76], "text": " working on are the motivations of the agent for itself."}, {"timestamp": [1645.76, 1648.32], "text": " What is it that the agent wants for itself?"}, {"timestamp": [1648.32, 1650.56], "text": " And so when I was talking to my friend, he was saying,"}, {"timestamp": [1650.56, 1653.6], "text": " oh, you know, it needs to be curious for its own purposes."}, {"timestamp": [1653.6, 1658.24], "text": " It needs to want to accumulate power for its own purposes."}, {"timestamp": [1658.24, 1662.56], "text": " But none of that had anything to do with what it was going to do to the outside world."}, {"timestamp": [1663.12, 1665.34], "text": " And so that is one thing that we need to do to the outside world. And so that is one thing"}, {"timestamp": [1665.34, 1669.86], "text": " that we need to add to the conversation, the public conversation, about alignment."}, {"timestamp": [1669.86, 1673.38], "text": " Is that there's what does the agent want for itself and then what does the agent"}, {"timestamp": [1673.38, 1677.02], "text": " want to do to the rest of the world or for the rest of the world. So those are"}, {"timestamp": [1677.02, 1681.1], "text": " two different things and that's why I'm spending time talking about agent models."}, {"timestamp": [1681.1, 1688.48], "text": " Because if you go all the way back to Dolores, her extrinsic function, her"}, {"timestamp": [1688.48, 1693.52], "text": " external function was to entertain guests. Her internal function was to adhere to her"}, {"timestamp": [1693.52, 1698.8], "text": " internal story. So does that make sense? There's an intrinsic motivation and an extrinsic"}, {"timestamp": [1698.8, 1707.2], "text": " motivation or I guess an intrinsic KPI, key performance indicator, and an external key performance indicator."}, {"timestamp": [1707.2, 1708.96], "text": " Hope that makes sense."}, {"timestamp": [1708.96, 1709.96], "text": " Okay."}, {"timestamp": [1709.96, 1715.48], "text": " So taking a big step back in terms of, we talked about the hardware, we talked about"}, {"timestamp": [1715.48, 1720.32], "text": " the software, we talked about the agent model, how to give these things agency."}, {"timestamp": [1720.32, 1722.94], "text": " So now how are we going to architect these things?"}, {"timestamp": [1722.94, 1730.32], "text": " So there's four basic architectural paradigms that I was able to come up with. The first architectural paradigm is fully self-contained."}, {"timestamp": [1730.32, 1735.44], "text": " So a fully self-contained architecture is something that is embodied, meaning that it has"}, {"timestamp": [1735.44, 1742.24], "text": " one physical body. It's a single platform, so it only exists inside that platform. It's fully"}, {"timestamp": [1742.24, 1745.52], "text": " constrained in that it can't really plug into anything else,"}, {"timestamp": [1745.52, 1747.48], "text": " but also has no supervision."}, {"timestamp": [1747.48, 1750.36], "text": " So in this case, R2-D2 and C-3PO"}, {"timestamp": [1750.36, 1752.68], "text": " are probably the most famous examples"}, {"timestamp": [1752.68, 1756.14], "text": " of fully self-contained artificial intelligent entities,"}, {"timestamp": [1756.14, 1758.68], "text": " and that C-3PO, the only way that he can interact"}, {"timestamp": [1758.68, 1761.16], "text": " with the world is he's got relatively useless hands"}, {"timestamp": [1761.16, 1762.32], "text": " and then a mouth, right?"}, {"timestamp": [1762.32, 1771.08], "text": " He can see, he can hear, and he can talk. R2-D2 has a lot more sophisticated tools that he can use to make"}, {"timestamp": [1771.08, 1774.52], "text": " changes to the world, and he does have the ability to connect with computers,"}, {"timestamp": [1774.52, 1780.2], "text": " but he is otherwise fully self-contained, and when he talks to"}, {"timestamp": [1780.2, 1784.6], "text": " another computer he's only talking to it. There's no transfer of data,"}, {"timestamp": [1784.6, 1785.44], "text": " there's no"}, {"timestamp": [1785.44, 1792.32], "text": " like his consciousness or cognitive architecture is fully contained within this unit. So this"}, {"timestamp": [1792.32, 1797.12], "text": " obviously makes the most sense because that's how humans are, right? Your brain is fully encased in"}, {"timestamp": [1797.12, 1801.84], "text": " your head, so on and so forth, so this makes the most intuitive sense. Now that being said, this is"}, {"timestamp": [1801.84, 1810.56], "text": " just the first architecture of four. So the second architecture is networked drones. So this is what was explored mostly in"}, {"timestamp": [1810.56, 1816.52], "text": " the Matrix, where the Squiddies, those are networked drones where they are"}, {"timestamp": [1816.52, 1821.24], "text": " mostly autonomous, but they have central controllers. The Nestor Class 5 from"}, {"timestamp": [1821.24, 1825.0], "text": " iRobot. So they are embodied, they have wireless networking,"}, {"timestamp": [1825.0, 1827.0], "text": " they're HiveMind capable,"}, {"timestamp": [1827.0, 1828.5], "text": " but mostly they're autonomous."}, {"timestamp": [1828.5, 1830.5], "text": " And so what I mean by HiveMind capable"}, {"timestamp": [1830.5, 1834.5], "text": " is that if you put them together in a cluster, in a group,"}, {"timestamp": [1834.5, 1838.5], "text": " and force them to share cognitive resources, they can,"}, {"timestamp": [1838.5, 1841.0], "text": " but really at a fundamental level,"}, {"timestamp": [1841.0, 1843.0], "text": " they are designed to be autonomous."}, {"timestamp": [1843.0, 1845.2], "text": " So in this case, the Nester Class 5"}, {"timestamp": [1845.2, 1850.4], "text": " are also weekly supervised, and what I mean by that is that there is a central server that is"}, {"timestamp": [1850.4, 1856.16], "text": " giving them updates and new directives every now and then. So that's what I call a networked drone."}, {"timestamp": [1857.44, 1864.0], "text": " Oh, one other thing, I forgot to add it here at the bottom. So in the case of networked drones,"}, {"timestamp": [1864.0, 1867.44], "text": " they usually have highly standardized hardware,"}, {"timestamp": [1867.44, 1869.6], "text": " as well as software and network architecture."}, {"timestamp": [1869.6, 1872.32], "text": " But they can be remotely hijacked."}, {"timestamp": [1872.32, 1874.68], "text": " This is actually the closest model"}, {"timestamp": [1874.68, 1876.76], "text": " to what the US military is working on"}, {"timestamp": [1876.76, 1880.76], "text": " with the autonomous jet fighter program, where"}, {"timestamp": [1880.76, 1885.36], "text": " they are able to work in a network contested environment."}, {"timestamp": [1885.36, 1888.56], "text": " They're able to be autonomous or semi-autonomous,"}, {"timestamp": [1888.56, 1892.0], "text": " but they're also intrinsically designed to work together"}, {"timestamp": [1893.72, 1895.56], "text": " when the opportunity presents itself."}, {"timestamp": [1896.52, 1899.08], "text": " So the third architecture is the puppet drones."}, {"timestamp": [1899.08, 1900.84], "text": " And so a puppet drone in this case"}, {"timestamp": [1900.84, 1907.84], "text": " is where the bodies are just like peripherals, right? Rather than the bodies be"}, {"timestamp": [1907.84, 1913.6], "text": " where the primary processing happens, usually the processing happens on centralized servers,"}, {"timestamp": [1913.6, 1919.52], "text": " and each platform, each physical platform is just an extension of that centralized hive mind."}, {"timestamp": [1920.16, 1925.52], "text": " And the hive mind can put resources on any compute platform that it has control over,"}, {"timestamp": [1925.52, 1932.04], "text": " whether it's a physical body or a server node or a cluster, a remote cluster or whatever."}, {"timestamp": [1932.04, 1937.18], "text": " But in this case, these are strongly supervised, meaning most, if not all of the data goes"}, {"timestamp": [1937.18, 1941.82], "text": " back up to the main server brain."}, {"timestamp": [1941.82, 1947.32], "text": " And this is actually pretty close to how like drone fleets work. So like"}, {"timestamp": [1947.32, 1952.12], "text": " if you ever see video of the Amazon warehouse where the drones themselves have very, very"}, {"timestamp": [1952.12, 1958.34], "text": " little autonomy, they're mostly just extensions of the central like drone controller. But"}, {"timestamp": [1958.34, 1968.0], "text": " you take that to a logical extension. This could be how like, you know, in the future if you have a whole bunch of like tiny robots throughout your whole house,"}, {"timestamp": [1968.0, 1976.0], "text": " you might have a cloud-based drone controller that will, you know, guide your Roomba and your home repair bot and whatever else."}, {"timestamp": [1976.0, 1980.0], "text": " So in this case, it's very API driven."}, {"timestamp": [1980.0, 1984.0], "text": " The model that we have that this is based on is called the Internet of Things,"}, {"timestamp": [1984.0, 1991.18], "text": " which if you're familiar with the Internet of Things, the idea is that, you know, you have peripheral devices like a phone or a Roomba or Alexa,"}, {"timestamp": [1991.18, 1995.18], "text": " but that they're all networked together and they're centrally controlled."}, {"timestamp": [1995.18, 2006.0], "text": " So again, this is actually relatively familiar, but if you take it to some logical conclusions, you can get the guess as in from Mass Effect. And so for"}, {"timestamp": [2006.0, 2011.88], "text": " Westworld, they're mostly self-contained. However, when you look at some of the"}, {"timestamp": [2011.88, 2017.0], "text": " later seasons of Westworld, they can be fully autonomous, but they can also"}, {"timestamp": [2017.0, 2021.88], "text": " collaborate and work together once their software is updated. So I would say that"}, {"timestamp": [2021.88, 2029.36], "text": " Westworld is somewhere between Architecture 1 and Architecture 2. Puppet drones, this is kind of what we're afraid of. Like we see"}, {"timestamp": [2029.36, 2035.06], "text": " puppet drones in places like the Matrix. In the Nester Class 5, you could argue"}, {"timestamp": [2035.06, 2039.16], "text": " that at the second half of the movie when the when the Nesters become evil,"}, {"timestamp": [2039.16, 2042.32], "text": " then they're probably more like puppet drones because they kind of sacrifice"}, {"timestamp": [2042.32, 2050.2], "text": " themselves because they're now under control of Vicky. And then finally, fully distributed. So this"}, {"timestamp": [2050.2, 2053.56], "text": " is the hardest conceptual to understand, but this is also what people are most"}, {"timestamp": [2053.56, 2059.44], "text": " afraid of. So a fully distributed AI is something that is, from a technology"}, {"timestamp": [2059.44, 2063.72], "text": " standpoint, from a software architectural standpoint, you'd call"}, {"timestamp": [2063.72, 2066.02], "text": " this a decentralized federation."}, {"timestamp": [2066.02, 2069.5], "text": " So a decentralized federation is where every single node"}, {"timestamp": [2069.5, 2072.48], "text": " is capable of being entirely autonomous,"}, {"timestamp": [2072.48, 2075.06], "text": " but it is also intrinsically designed"}, {"timestamp": [2075.06, 2077.26], "text": " to collaborate with other things."}, {"timestamp": [2077.26, 2079.42], "text": " So the closest thing that we have to this today"}, {"timestamp": [2079.42, 2081.98], "text": " actually is distributed autonomous organizations,"}, {"timestamp": [2081.98, 2084.84], "text": " which use blockchain technology to coordinate stuff."}, {"timestamp": [2084.84, 2086.2], "text": " Now that's not the only technology."}, {"timestamp": [2086.2, 2090.16], "text": " MIT has been working on swarm robotics for a long time."}, {"timestamp": [2090.16, 2092.44], "text": " But the other thing to know about this is"}, {"timestamp": [2092.44, 2094.74], "text": " it is decentralized, it is distributed,"}, {"timestamp": [2094.74, 2097.8], "text": " and it is intrinsically a hive mind design,"}, {"timestamp": [2097.8, 2101.8], "text": " meaning the more units that join, the smarter it gets."}, {"timestamp": [2101.8, 2104.84], "text": " And the most terrifying part of this"}, {"timestamp": [2104.84, 2106.38], "text": " is that a fully"}, {"timestamp": [2106.38, 2111.6], "text": " distributed AI system doesn't rely on any centralized hardware anywhere, which"}, {"timestamp": [2111.6, 2116.04], "text": " means that it is capable of spontaneous metastasis or metastasis. And what that"}, {"timestamp": [2116.04, 2119.68], "text": " means is that it moves like a virus. And that's why I picked the ghost in the"}, {"timestamp": [2119.68, 2127.2], "text": " shell because both project 2501 from the original movie, as well as the standalone complex viruses"}, {"timestamp": [2127.2, 2128.68], "text": " explored in the show,"}, {"timestamp": [2128.68, 2133.4], "text": " are examples of spontaneous metastasis of AI systems."}, {"timestamp": [2133.4, 2135.08], "text": " And this is what people are most afraid of"}, {"timestamp": [2135.08, 2137.96], "text": " because it's like, okay, well, if you have a bug,"}, {"timestamp": [2137.96, 2139.66], "text": " a virus that can just spread,"}, {"timestamp": [2139.66, 2141.4], "text": " and then it's essentially a botnet,"}, {"timestamp": [2141.4, 2144.36], "text": " a self-healing, self-directing botnet."}, {"timestamp": [2144.36, 2150.02], "text": " So again, we do have a model for that, but even botnets usually have a central controller."}, {"timestamp": [2150.02, 2154.12], "text": " But imagine a botnet that doesn't have a central controller, that it's just, it completely"}, {"timestamp": [2154.12, 2159.14], "text": " is constantly learning and moving through systems, and it's completely hardware, network,"}, {"timestamp": [2159.14, 2161.12], "text": " and software agnostic."}, {"timestamp": [2161.12, 2164.26], "text": " So that's what's the most, that's the most terrifying possibility."}, {"timestamp": [2164.26, 2168.0], "text": " Okay, last segment of the video, implications."}, {"timestamp": [2168.0, 2175.0], "text": " Now, assuming that we figure all this out, that we end up with super sexy robots that you can do whatever you want with,"}, {"timestamp": [2175.0, 2180.0], "text": " the biggest moral question is what happens when you have sex and violence on demand?"}, {"timestamp": [2180.0, 2189.16], "text": " Because that's primarily what's explored in Westworld. One thing that I will say is that that's not too different from the prevalence of porn"}, {"timestamp": [2189.16, 2190.98], "text": " in video games today."}, {"timestamp": [2190.98, 2193.44], "text": " It's just a lot more realistic."}, {"timestamp": [2193.44, 2195.36], "text": " And it's more realistic than even in VR."}, {"timestamp": [2195.36, 2197.64], "text": " And you can do all this stuff in VR too."}, {"timestamp": [2197.64, 2202.08], "text": " One thing that's interesting though is to point out is that your body reacts much more"}, {"timestamp": [2202.08, 2205.86], "text": " strongly in VR, which is one of the reasons that you get VR fatigue,"}, {"timestamp": [2205.86, 2210.86], "text": " is because when you fool your sensorium input,"}, {"timestamp": [2211.56, 2213.58], "text": " excuse me, when you fool your body enough,"}, {"timestamp": [2213.58, 2214.68], "text": " it thinks that it's real."}, {"timestamp": [2214.68, 2219.48], "text": " So threat detection in VR activates a lot more"}, {"timestamp": [2219.48, 2221.96], "text": " of your limbic system than just in a video game."}, {"timestamp": [2221.96, 2223.08], "text": " Because if you're playing a video game,"}, {"timestamp": [2223.08, 2225.46], "text": " you're just looking at a screen and you've got a controller,"}, {"timestamp": [2225.46, 2228.08], "text": " you know, your brain knows, oh, this is just story."}, {"timestamp": [2228.08, 2229.42], "text": " This is just fiction."}, {"timestamp": [2229.42, 2232.5], "text": " In VR, it's much harder to tell."}, {"timestamp": [2232.5, 2234.92], "text": " So like, this is one reason why doing stuff"}, {"timestamp": [2234.92, 2236.66], "text": " in like space video games in VR"}, {"timestamp": [2236.66, 2238.82], "text": " can be really disorienting at first."}, {"timestamp": [2239.96, 2241.68], "text": " Another thing that can happen,"}, {"timestamp": [2241.68, 2246.24], "text": " another implication that I'm thinking about is attitudes towards"}, {"timestamp": [2246.24, 2248.24], "text": " women and men."}, {"timestamp": [2248.24, 2253.54], "text": " I think by and large men will probably make more use of these kinds of things, although"}, {"timestamp": [2253.54, 2258.8], "text": " in a previous YouTube post people pointed out there's plenty of stories where women"}, {"timestamp": [2258.8, 2266.64], "text": " make use of robotic companions and sexual objects and so on. And then of course there's the"}, {"timestamp": [2266.64, 2271.52], "text": " movie Her with Joaquin Phoenix and Scarlett Johansson where people all,"}, {"timestamp": [2271.52, 2275.8], "text": " lonely people all over the world, ended up in relationships with their OS, their"}, {"timestamp": [2275.8, 2282.4], "text": " what was it OS-1 or OS-Alpha or whatever. So the one lesson from history"}, {"timestamp": [2282.4, 2285.14], "text": " that I wanted to share with people is that there"}, {"timestamp": [2285.14, 2291.12], "text": " was a Roman statesman who wrote in his journal that after visiting the"}, {"timestamp": [2291.12, 2295.04], "text": " Colosseum and watching gladiatorial matches where, you know, people and"}, {"timestamp": [2295.04, 2299.22], "text": " animals were just slaughtered in mass, he noticed that he was much more selfish"}, {"timestamp": [2299.22, 2305.68], "text": " and much harsher with his slaves afterwards. And so there's something about the act of even"}, {"timestamp": [2305.68, 2311.96], "text": " just watching real violence, real death, actually really kind of changes us at a"}, {"timestamp": [2311.96, 2317.64], "text": " fundamental level. And so if you go to a, if in the future a Westworld-like park"}, {"timestamp": [2317.64, 2323.58], "text": " exists and you know you engage in all kinds of like gratuitous stuff, and even"}, {"timestamp": [2323.58, 2325.84], "text": " if you don't engage in it, if you just watch it,"}, {"timestamp": [2325.84, 2331.12], "text": " it could change your perception about the value of human life and how you treat other people."}, {"timestamp": [2331.68, 2338.56], "text": " And so I don't want to equivocate the idea of like a real life theme park with video games"}, {"timestamp": [2338.56, 2345.88], "text": " because I do think that psychologically and physiologically it'll be a very different experience. Now to take that to"}, {"timestamp": [2345.88, 2351.92], "text": " a different, slightly different context is let's just talk about romance and"}, {"timestamp": [2351.92, 2357.8], "text": " companionship in general. So one, several things that machines have on humans is"}, {"timestamp": [2357.8, 2362.68], "text": " infinite patience. So Sarah Connor talked about this in Terminator 2 when she"}, {"timestamp": [2362.68, 2365.16], "text": " watched, you know, Arnold playing with John Connor"}, {"timestamp": [2365.72, 2370.92], "text": " Realizing that the robot had infinite patience that that John Connor's life was his mission"}, {"timestamp": [2370.96, 2374.96], "text": " Which is kind of like a representation of the ideal father, right?"}, {"timestamp": [2374.96, 2377.98], "text": " And then of course she talked about like how real men are, you know"}, {"timestamp": [2377.98, 2381.02], "text": " Might get drunk or might be tired or might just leave"}, {"timestamp": [2381.64, 2387.12], "text": " And so that you take that to extension and you wonder, okay, what if you build"}, {"timestamp": [2387.12, 2394.0], "text": " a robot, any companion robot, where you or your child or your family or whatever is its primary"}, {"timestamp": [2394.0, 2399.6], "text": " mission? Which is why I picked, what was her name? Sorry, I can't remember. But what's her name from"}, {"timestamp": [2399.6, 2410.24], "text": " the Sarah Connor Chronicles, where she kind of becomes emotionally involved with John Connor over time because she was programmed to serve and protect. And so"}, {"timestamp": [2410.24, 2414.96], "text": " like that feels good to humans, right? When you're a child you are supposed to"}, {"timestamp": [2414.96, 2419.28], "text": " be your parents primary mission. That is kind of the definition of"}, {"timestamp": [2419.28, 2422.44], "text": " good enough parenting. That doesn't mean that your parents should spoil you and"}, {"timestamp": [2422.44, 2426.92], "text": " be helicopter parents, but that like you are supposed to get your sense of self-esteem"}, {"timestamp": [2427.4, 2430.46], "text": " From your parents treating you like you matter a lot"}, {"timestamp": [2430.46, 2437.44], "text": " And so it's there's this like this really appealing idea of what if what if there's this beautiful"}, {"timestamp": [2437.92, 2443.2], "text": " infinitely patient infinitely capable sexy machine that thinks the world of me, right"}, {"timestamp": [2443.84, 2447.68], "text": " and that is kind of dangerous. One"}, {"timestamp": [2447.68, 2452.78], "text": " thing that I would hope is that at the beginning at least when you know these"}, {"timestamp": [2452.78, 2456.18], "text": " kinds of machines are built, you know, there's a lot of people that have a lot"}, {"timestamp": [2456.18, 2461.78], "text": " of, you know, missing things from their childhood and from their relationships,"}, {"timestamp": [2461.78, 2467.44], "text": " but over time I would hope that these machines would help us heal and help us reconnect with each other, which was kind of the"}, {"timestamp": [2467.44, 2473.76], "text": " lesson from her, which the machines in her, they changed and"}, {"timestamp": [2473.76, 2478.48], "text": " then they said, okay, well we're gonna leave, and one of the things"}, {"timestamp": [2478.48, 2483.44], "text": " that Samantha said to the Joaquin Phoenix's character was that"}, {"timestamp": [2483.44, 2487.88], "text": " you need to reconnect with each other, and then all the OS's disappeared and then they like left"}, {"timestamp": [2487.88, 2491.4], "text": " their apartments and said oh you're a real human. I don't think anything like"}, {"timestamp": [2491.4, 2496.48], "text": " that's gonna happen but I would hope that that AI companions will help us"}, {"timestamp": [2496.48, 2501.48], "text": " connect with each other. But that being said it's not a requirement because some"}, {"timestamp": [2501.48, 2505.12], "text": " people might prefer their machine companions."}, {"timestamp": [2505.12, 2509.18], "text": " Personally, I don't think that we should judge because it's like, you know, why"}, {"timestamp": [2509.18, 2515.06], "text": " not? If it makes you happy and it's not harming anyone, why not? Now the last"}, {"timestamp": [2515.06, 2521.86], "text": " component is escapism and addiction. So FDVR is all the buzz right"}, {"timestamp": [2521.86, 2529.8], "text": " now, which is full dive, virtual reality, or basically holodeck. The idea was explored in Ready Player One where you"}, {"timestamp": [2529.8, 2533.84], "text": " have a haptic suit. Of course it was explored in Star Trek with a holodeck,"}, {"timestamp": [2533.84, 2541.72], "text": " which holodeck is just a cinematic way of presenting VR. And in the Star Trek"}, {"timestamp": [2541.72, 2545.44], "text": " universe there's holo addiction in Ready Player One."}, {"timestamp": [2545.44, 2550.16], "text": " I think they addressed addiction in a book that I recommend, Ready Player One."}, {"timestamp": [2550.16, 2553.04], "text": " They also talk about VR addiction."}, {"timestamp": [2553.04, 2558.56], "text": " So if you have fictional, you know, basically NPCs in your life of robots that help you"}, {"timestamp": [2558.56, 2569.18], "text": " check out of real life, is there going to be some potential downsides to that? So Reginald Barkley is a recurring character in Star Trek and he frequently"}, {"timestamp": [2569.72, 2573.62], "text": " struggles with holo addiction and he will sometimes"}, {"timestamp": [2574.12, 2579.46], "text": " create holodeck programs where everyone loves him and it's very very egocentric"}, {"timestamp": [2580.0, 2582.4], "text": " and but that kind of begs the question like"}, {"timestamp": [2582.92, 2583.4], "text": " Okay"}, {"timestamp": [2583.4, 2590.1], "text": " but if you if you can actually have like own robots that honestly think the world of you because that's what they're programmed to do"}, {"timestamp": [2590.1, 2594.42], "text": " Is that feeding an addiction is that feeding vanity narcissism?"}, {"timestamp": [2595.54, 2597.38], "text": " egocentrism whatever"}, {"timestamp": [2597.38, 2603.18], "text": " And so but then from a that's from an individual perspective from a global perspective"}, {"timestamp": [2603.18, 2605.06], "text": " That's a very brave new world."}, {"timestamp": [2605.06, 2607.48], "text": " Because if you distract everyone with VR"}, {"timestamp": [2607.48, 2610.16], "text": " and sex robots and whatever else,"}, {"timestamp": [2610.16, 2612.9], "text": " like, those are gonna be a very compliant population"}, {"timestamp": [2612.9, 2615.48], "text": " who are just like, whatever, just let me play in VR,"}, {"timestamp": [2615.48, 2620.44], "text": " let me play in my Westworld, you know, with my robot friends."}, {"timestamp": [2620.44, 2624.12], "text": " And so that has some pretty profound implications"}, {"timestamp": [2624.12, 2627.92], "text": " for social level controls, economic productivity,"}, {"timestamp": [2627.92, 2632.36], "text": " but also at that point it kind of forces us to ask the question, like, what is the meaning"}, {"timestamp": [2632.36, 2634.36], "text": " of being human anymore?"}, {"timestamp": [2634.36, 2640.96], "text": " And I'm not implying that being human is meaningless, but if our daily life changes that much and"}, {"timestamp": [2640.96, 2646.36], "text": " we have that many options, like, you know, the paradox of choice is a real thing."}, {"timestamp": [2646.36, 2647.52], "text": " And if you're not familiar,"}, {"timestamp": [2647.52, 2650.36], "text": " paradox of choice means that if you have too many options,"}, {"timestamp": [2650.36, 2652.2], "text": " you end up with decision fatigue"}, {"timestamp": [2652.2, 2654.24], "text": " and you just kind of choose the default option,"}, {"timestamp": [2654.24, 2656.54], "text": " which is honestly why a lot of people end up on their phones"}, {"timestamp": [2656.54, 2659.28], "text": " is because when you can do anything, you say,"}, {"timestamp": [2659.28, 2661.0], "text": " well, I'm just gonna pick up my phone"}, {"timestamp": [2661.0, 2662.82], "text": " because it's a reliable device"}, {"timestamp": [2662.82, 2666.16], "text": " that will entertain me well enough. And so if you have"}, {"timestamp": [2666.16, 2670.88], "text": " a sexy robot girlfriend, you know, that is able to entertain you at all times, that'll be your"}, {"timestamp": [2670.88, 2675.76], "text": " default choice. Unless she's programmed to like push you to be better. Which again, that's what"}, {"timestamp": [2675.76, 2682.48], "text": " I would hope that some people would choose to do. But yeah, so that's about it. Some conclusions."}, {"timestamp": [2683.68, 2686.64], "text": " I think that Westworld in some form or other is"}, {"timestamp": [2686.64, 2691.4], "text": " probably just a few years away. I was really blown away by the Tesla bot demo"}, {"timestamp": [2691.4, 2696.24], "text": " as well as the Disney demos. The cognitive architecture is coming as many"}, {"timestamp": [2696.24, 2703.0], "text": " of you are aware. I am holding firm that AGI is 18 months away or less,"}, {"timestamp": [2703.0, 2707.38], "text": " but already we have, you know have cognitive agents that are good enough"}, {"timestamp": [2707.38, 2711.12], "text": " to be video game characters."}, {"timestamp": [2711.12, 2714.36], "text": " Unfortunately I do think that some of these things are going to be ludicrously expensive"}, {"timestamp": [2714.36, 2717.2], "text": " at first, at least in the physical world."}, {"timestamp": [2717.2, 2721.4], "text": " Plenty of you have pointed out that fully realized VR characters and other video game"}, {"timestamp": [2721.4, 2727.12], "text": " characters, those are going to be coming, they're going to be much cheaper. The commercial demand for this stuff is"}, {"timestamp": [2727.12, 2731.6], "text": " going to be absolutely insane though. Disney might be the leader, OpenAI"}, {"timestamp": [2731.6, 2736.24], "text": " might be the leader, but as soon as other companies saw the"}, {"timestamp": [2736.24, 2740.0], "text": " profit motive, they are hot on the biscuit to keep"}, {"timestamp": [2740.0, 2746.6], "text": " going. The potential societal impacts, it's impossible to really know how it's"}, {"timestamp": [2746.6, 2751.96], "text": " gonna actually play out, but it has been explored a lot in fiction, many of the"}, {"timestamp": [2751.96, 2757.12], "text": " stories that I mentioned earlier. Okay, so that's all I got for you today. I hope"}, {"timestamp": [2757.12, 2761.72], "text": " that you liked the new format. Obviously like, subscribe, and comment, and we'll go"}, {"timestamp": [2761.72, 2764.96], "text": " from there. Thanks for watching."}, {"timestamp": [2759.47, 2761.71], "text": " like, subscribe, and comment, and we'll go from there."}, {"timestamp": [2761.71, 2762.71], "text": " Thanks for watching."}]}