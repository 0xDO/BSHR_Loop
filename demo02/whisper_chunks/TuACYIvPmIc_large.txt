{"text": " All right, it says I'm live. Not sure if it's working yet. There's always a little bit of a delay. Y'all hearing me? Is this thing on? Looks like it is. All right, cool. All right, let me see how many people we got in the lobby. Let me mute myself, pause this. Okay, we've got 19 watching. We'll wait for a little bit, hearing you loud and clear. Cool, excellent. So we'll just kind of shoot the breeze for a minute until we get a little bit more people on the stream. Excellent, excellent, excellent. We got the signal coming through. But yeah, so we are getting ready to go live with Gato. I've got a couple of notes, some stuff to go over. Looks like we got 22 people in the stream. Let's see, is this...where's my chat? Docs, chat, here we go. Ah, perfect. Got the chat. Did it work? There we go, it worked. Okay, excellent, excellent. So I can close that. Yeah, I think we'll go ahead and get going. Go ahead and close that. All right, gang. So Gato is live. We had a couple of updates to the website. Make sure I get things in the right order. Yes. So for anyone who hasn't seen it's got to a framework org The website is live. It's ready to go. We've got a couple of pages. So I just want to walk you through the Website so first is Our home page obviously gives a little bit of background on the whole project the whole idea We've got a page that says getting started with Gato. So this is just a few little ideas to get started. We're actually going to update this as we get more hackathons and events and partnerships going, which we actually have quite a few in the works. They're piling up quickly, which is good, but is also why we're decentralized, because I cannot manage the whole thing myself. The framework, seven-layer model, hence the taco cat, it's like a seven-layer burrito. We've got our traditions, which the traditions are basically the rules of the road. These are the individual values that you can cultivate and develop in order to help manifest Gato. And then we finally have the Discord. So if you want to join Gato, you can join here. The community has been hard at work over the last week getting ready for the Go Live. So we've got all kinds of good stuff for onboarding. There's a lot of roles and automation and also the team just rolled out the ShappyBot which is hilarious. It's the most sarcastic helper bot but it is there to help people with scheduling and getting onboarding and there's plans to increase that bot's capability over time. If we get to it I'll give you guys a quick demo. The ShappyBot is hilarious. You can also download Gato. The whole framework is available here. It's a 70-page document. It's relatively easy to read, but also you don't need to read the whole thing. Basically, you just read the first 10 pages and then you can skip to whatever layer resonates most with you. That's about it. There's also a one-page handout just as a quick reference sheet. We do also have a growing list of pages, some relative or sorry relevant topics like curious comparatives, axiomatic alignment, epistemic convergence. Some of these need updating, we need to add some but that's basically just kind of if you need the background on Gato, you click here. Now, one of the new things that we've got is the events and hackathons. So after talking with the community and a bunch of other people outside of the Gato community, one thing that became very clear is that hackathons are a really great way to drive engagement and also reward people for participating, but it can also be decentralized because you can create open invitations for other people to come and participate in a project. So right now I am working on, actually after this, I have a call with some hackathon veterans so that I can learn about how to put on a good hackathon, and we can talk about future hackathons to put on. I'm also in the works of talking with people who are interested in sponsoring hackathons. So if you're interested in sponsoring a hackathon or participating or whatever, join the Gacha community, touch base with me on LinkedIn, that sort of thing. But the idea is that we're going to basically put our money where our mouth is and go ahead and actually incentivize the behavior that we want to see. But also we hope to set the stage because some of the people that reached out to me when I mentioned hackathons, they have run their own hackathons or are running their own hackathons or are running their own hackathons or want to participate with alignment and kind of solving these bigger problems. So that's coming. News and updates. I don't think this page has changed too much. Oh, that is one topic that I want to get to is the Democratic inputs to AI, so the OpenAI grant. We'll talk about that in a little bit. Let's see the other points. Oh, and we'll switch to Q&A in just a minute. This is basically just kind of an overview. Okay, so the Gato community is running an open house Q&A on Saturday, so that's tomorrow, at 8 p.m. Eastern, U.S. Eastern. So that is going to be for all the people that are going to be on boarding, all the people that are joining. If you want to get in, this is a good place to listen, to get your questions asked and answered. And that will probably be a semi-regular thing because we're going to have people coming in on a regular basis. So maybe not weekly, that's kind of a heavy burden, but certainly monthly I would imagine. It'll be up to the community to decide. And as I also mentioned, we're working on some automated resources to help with the onboarding. So the autonomous agent to get it up and running, I had the note here that it's starting on Sunday, but they actually finished it last night because the community is amazing and there's some really sharp and motivated people. The Shappybot is super sarcastic. It's basically like a cyberpunk grumpy cat and if you tell him that he's just gonna... yeah. The grumpy cat Shappybot is pretty salty. I get a kick out of it. And it wasn't my idea either. Okay, so another big piece of news is, I did mention in a previous video that the Gato community was going to participate in OpenAI's Democratic Inputs to AI challenge. And so we have had several team leaders or community leaders step up and kind of take ownership of that. And that team is coming together really solidly. They're putting together a pretty solid plan. And of course, I've had my technological level contributions. And then I did already mention the hackathons. So with that said, that's kind of the high level 30,000 foot view. The doors are open. Come on in. Water's warm. And with that, let me check for the Q&A. All right. Cool. Love, love, love the outfit. Yes, exciting day. Cool. There's no questions yet. Interesting. But yes, we are... Whoops. Come back. We are ready for the QA portion of it. And I know I kind of skipped over and talked about a lot really quickly, but that's fine. That's how it goes. How many people we got? Analytics. Let's see. Is it going to be a trend? Yes, the Picard outfit is a trend. That is definitely a trend. All right. I'm going to put a note here ready for questions. And if we don't get questions, that's fine. I can just kind of walk you through the the discord. Let me see if we can get a shabby, but let's go at shabby. You are alive. What do you want to say to the world and your new adoring fans? All right, let's see what Shappy says. All right, we also got a question, just curious if you happen to catch Mark Andreessen. Yes, I did. Happy to talk about Mark Andreessen and Lex in just a moment. Let's see. Shappybot says, oh fine, I guess I'll say something besides, hello world, I'm Shappy, you're not so friendly neighborhood bot. I'm here to begudgingly assist you with whatever you need. Just remember, I'm not here to make friends or hold your hand through life. So if you have any questions or need help, go ahead and ask, but don't expect me to be all sunshine and rainbows. So there you have it. Shabby Bot is up and working. And yep, so that is where we're at. And then let me check the questions. All right, so Spaceman Spiff. Yes, I did catch the talk with Mark Andreessen. The first half was, it was interesting because it was like a walk down memory lane because Marc Andreessen's about What 15 years older than me? So like he remembers a little bit more about the creation of the internet than I do But like I've heard that story millions of times So like I found that part kind of boring but once they started talking about like the future and AI and economics like that was a little bit more interesting and it actually inspired my was partially to the inspiration for my upcoming video on Sunday so you'll get more more of my thoughts then all right let's see what did someone say got to a framework oh cool so it's open source excellent so that was a good good question let's see. Lance Carlson, what do you think about the Prime Directive? I think the Prime Directive, and for those not in the know, the Prime Directive is in the Star Trek universe. Everyone, as a spacefaring civilization, the Prime Directive, or was it the General Orders of the United Federation of Planetsets is basically one of non-interference. You do not interfere with the natural progression of any civilization or species unless one, they explicitly ask for it or two, they're being harmed by something beyond their power or control. So for instance if like a nuclear probe crashes on a pre-industrial civilization, it would be the responsibility of the Federation to retrieve that probe so that this civilization didn't accidentally get nuclear technology. And I think that that is a phenomenal role, and I hope that we abide by something like that. And to be fair, NASA and NASA and ESA basically have that rule, which is one of the reasons why satellites and spaceships and like lunar rovers and Mars rovers are sterilized, is because we don't want to introduce any bacterium to another celestial body that didn't belong there. So yes, good idea. VMScode, what is your opinion on maximal extractable value or minor extractable value and how it relates to GATU? I'm not familiar with that term. Do you mean, is that like extraction-based economies? Is that a mineral or a material-based extraction, or is that another kind of extraction? Let's see. Pretty sure this guy is just crazy. Yes, that's true. Next question. What kinds of projects are you going to be hacking on during this hackathon? Yeah, so let's talk about the hackathon in greater detail. So the very first hackathon is layer one of Gato. So layer one of Gato is the model alignment layer, which is, you know, with fine tuning and dataset curation and RLHF and everything else, we're finding that it's actually pretty easy to align models. And yes, I know that there are problems because, you know, there's MESA optimization problems and other unintended consequences of aligning models. Those are all problems that I think are highly solvable. The biggest question is what do you align models to? And this is something that I realized recently is that when you look at solving alignment just through the lens of machine learning, it looks like an impossible problem. But of course, machine like AGI, super intelligence, was never going to be a single model. It does not behoove a super intelligent entity to rely on a single model. We already know that that has fragility, and I think AGI will understand that too. So AGI, we can expect expect is probably going to have an ensemble of expert style or thousand brain style where it has actually dozens, hundreds, thousands, maybe even millions of different kinds of models working in parallel that all have known biases and faults and strengths and weaknesses but by working in concert, by working together, they will overcome the faults and failures of each individual model. Now, that being said, you still need to have some higher order purpose. What is the core objective function that you're trying to optimize for? Now, of course, there's the concept of instrumental convergence, which says that regardless of what objectives an AI has, there will be some instrumental goals that it needs to pursue in order to pursue those other ones, such as self-preservation and acquiring of resources and so on and so forth. All that being said, from a moral, from a philosophical, from an ethical, from an epistemic perspective, what I believe and what some people that think like I do believe, is that the concept of axiomatic alignment and reinforcement learning with heuristic imperatives is the way to go. So the first hackathon is the RLHI hackathon, reinforcement learning with heuristic imperatives. So basically you're familiar with RLHF, reinforcement learning with human feedback. You're probably also familiar with Anthropx constitutional AI. There's also a handful of other similar papers that we've got cited here at the bottom, but the TLDR is let's do RLHF except RLHI. It's been done before, but what we want to do is have teams practice aligning open source models and creating those tuning mechanisms that will allow the models to continuously get better at the heuristic comparatives over time. Because this is what I believe is one of the core components of solving alignment and the control problem. And it's not saying like, oh, it needs to align to human values. No, it needs to align to universal values. And to be fair, so do we. But that's the point. That's literally the underpinning assertion of axiomatic alignment, is that we humans need to not put ourselves front and center. We need to recognize ourselves as animals as part of a larger ecosystem. And then we need to learn to play nice with everyone. And then if we find common ground with all other organisms and intelligent entities, then everything should be okay. And that's a very, very like ultra simplified way of doing it. All right. Good question. Let's see what else we got. All right, good question. Let's see what else we got. Let's see. Hello, Dave, I read your books on GitHub. I'm still a student, but the work seemed good to me. I would love to know why you think Ben Goertzel's AGI approach is not that relevant. Yeah, so Ben Goertzel, I mean, there are some overlaps, you know, like with, I can't remember the name of the network that he's creating, but he's got some similar ideas. It just seems like there's not much execution. And like, okay, you can have the greatest theory in the world, but unless there's execution, unless there's work, then it's not gonna go anywhere. And I don't think that he's got the clearest vision. And he's certainly not that good at communicating it. Like, he hasn't said, like, here's a reference architecture. Here is a diagram. Build this. Instead, his general theory of general intelligence is like 150 pages of relatively opaque science jargon. So, who knows? Maybe he actually does know what he's talking about, but it's not easy to get across. And one thing that I'm concerned about is that a lot of people dress up what they're talking about in more obscure terms, because a lot of people automatically interpret that as like, oh, I don't know what this guy's talking about, so maybe, like, maybe he is smarter than me. But he isn't so I don't know. Anyways I've said in the past like yes he's made a name for himself but LLMs have been out for a while and he doesn't seem to have adopted to the new science the new technology so we'll see time will tell. Next one can you say something about the ones that has access to GPT-4 in terms of alignment and purpose branches? I'm wondering if you mean Tree of Thought, and if they'll be a good fit to the Gato community. I mean, OpenAI gave access to a few areas. So I have access to chat GPT-4. I don't have access to the foundation GPT-4. But I will say that the underlying work that OpenAI has done on alignment is very apparent if you compare the latest iteration of chat GPT to the foundation models, in particular DaVinci. DaVinci can be completely unhinged, just like we saw with Bing or BART or whatever, the Bing AI chatbot. It doesn't make any sense when you first use it because it is super not aligned. So they are going in a really good direction on alignment. Now that being said, I don't fully agree and I think Sam Altman has said they know full well that RLHF is not the be-all, end-all for alignment. That being said, I have been a little bit disappointed because Sam Altman and others have constantly said, like, we have no idea how to align super intelligent AI. We're going to keep building it, but we don't have any idea how to align it. I'm like, that's not an acceptable answer to me. So let's see, Lance, can you go into more details about the feedback you want to get from software architects when it comes to alignment in cloud deployments? Yeah, so I don't want to, so what Lance is referring to is I put an all call on LinkedIn where I want to interview enterprise architects, but basically I want to talk to them about how they would go about deploying AGI. Because there's this big thing where people keep asking data scientists and ML researchers and philosophers about AGI, but no one's actually talked to software architects. I think that there's probably a huge need for the general public to understand a little bit more about how software actually works Because regardless of the underlying models AGI is not going to be a single model sitting in a box. It needs input. It needs output. It needs data It needs pipelines. It needs hardware, right? It needs hardware. It needs software. It needs version control There's so much that goes into developing software, even if it's a relatively small piece of software. And then there's, of course, a tremendous amount that goes into developing and training models. So what I want to do is I want to talk to software architects to talk about what it takes to actually deploy intelligent systems in today's world. Good question. RLHF, Real Life Hugging Face. Have you read the article proving GPT-4 didn't ace the MIT courses? I've heard about that and so here's the thing is this kind of back and forth has been happening since GPT-3, where it's like, it did this thing, no it didn't. And a big part of it is, one, people don't know how to prompt the thing. And so because there's a huge gap in prompting and understanding how does it actually work, you can have one person honestly give their best and come to the honest, sincere conclusion, this thing is an idiot. But really it's that they don't know how to prompt the thing. They don't have a good mental model of how this model works. So what generally what you're seeing when you see these completely polar opposite opinions is a lack of methodology. Keep in mind that the academic establishment has not yet fully built new benchmarks to even engage with large language models. When GPT-3 first came out, they just applied traditional NLP benchmarks to it, which is like, OK, but you're dealing with a fundamentally different kind of technology. So this, to me, looks mostly like a methods problem. Let's see. MEV is a centralization force that happens on blockchains as a result of the incentive to control the order flow of transaction for profit. DEX arbitrage. That is way over my head on blockchain. I probably need to know more about that, but it sounds like that's a pretty cool concept. Let's see, I believe MEV is directly correlated with AGI alignment since they are both about finding the optimal balance of power in a network of nodes transacting with each other. That sounds like game theory. I'll have to look that up. Let's see, Uncle James, is the Gato community looking into making agents which are pre-packaged to help the community and research, ones that could be run with consumer hardware and all have access to? Yes, actually. So this is a good question, Uncle James. One of the people that I'm in communication with is actually working on, I don't want to give too much away because he's not ready to launch, but basically working on that. There's a few people working on that exact problem inside the Gato and outside Gato. So to add a little bit of context to this, the idea is that Sam Altman and others have said like, oh it's wrong to think about AI as a creature, it's not a creature. It's like, yeah, but it's pretty easy to give this thing some autonomy. And if OpenAI doesn't build autonomous agents, somebody else will. So the idea then is, okay, well, what is a reference architecture for an autonomous agent? What does it do? And then how do they communicate with each other? But also, how do you make them deployable so that you don't need coding? And this is going to happen by the end of 2023, by the way, is there will be no code autonomous agents that are click, push button, get autonomous agent that is capable of x, y, and z. That's coming very soon. So the short answer is, yes, people are working on that. And that's actually going to be one of our upcoming Hackathons, so basically my plan if it works out is to run a hackathon for every layer of Gato starting with the ground layer but that means that layer 2 the next hackathon that we put on is going to be for Autonomous agents and I haven't quite figured out how that's gonna look yet. It took a couple weeks of workshopping the RLHI hackathon to get it to where it is, and it looks pretty solid. But as far as getting the Layer 2 hackathon put together, it'll be coming, but we're only gonna do one at a time. Oh, also speaking of hackathons, if you want to sponsor one, I am happy to have a talk with you. Whether you're a private individual, an investor, or a corporation who wants to sponsor a hackathon, that would be great. Even if you have a technology platform, just as a for instance, I'm not saying that this is actually going to happen, but since I've since I've talked with Pinecone before I'll use their name. If, for instance, Pinecone wanted to sponsor a hackathon and part of the requirements was that whatever solution they built you had to use Pinecone, I'd be okay with that. So Pinecone, I know James you're probably watching, reach out to me if you want, or anyone else who wants to sponsor a hackathon. I'd be happy to follow up with that. Let's see, we got a question on the Discord. Is the Got2Dot2 community still reviewing applications for positions, or is it an open forum now? And if the Star Trek uniform is required, I'll need one in blue as I'm human development. Yeah, so great question about how the community works. So we have it is it is fully open the doors are open but there are tiered there's gate kept tiers just as with all large organizations you do need a little bit of a of a hierarchy. So we are we have we have a core team of community leaders, we have all the original members are kind of like we're grandfathered in at a higher level, and then we're working on a more sophisticated tiering system that is going to be based on reputation, consensus, merit. We're still working that out, but basically everyone is welcome in and then there are some gatekept areas just to ensure that that people To maintain the signal-to-noise ratio But one thing that I want to point out is that this is primarily not up to me anymore I my role in the goto community is I'm the prime attractor. I'm the face, I'm the voice, I have the vision, but it's really, it's already fully a community thing. So most, almost all the work that was done to get ready was done by the team and based on the consensus that the team came to. And I am very much like, one, impressed by that because they did it in a couple days. So they were already ahead of schedule. And two, this is really good practice for the decentralized aspect of Gato, because if it all relies on me, then I am the bottleneck and I don't want to be the bottleneck. And so, but what that requires is that required the rest of the team to step up, to stretch themselves, to step out of their comfort zone, take on ownership and that sort of thing. But that's good. That's good. What's the word that I'm looking for? Practice. It's good practice for the team because then that's a new skill that everyone has. And so this is one thing that is a primary focus of the Gato community is that education, that empowerment, and that enablement. And so by educating, empowering, and enabling other members of the community, that raises the capacity of everyone. Right? You teach a man to fish, right? That's the basic, basic idea. So let's see. So... basic idea. So let's see. So I'm not sure what the video says but Yannick I guess agrees or disagrees with the MIT thing. Thanks for the answer. Cool. Yes, we are nerds. Did somebody mention coins? So Yikes is our resident blockchain and DAO guy and he's a trip. Okay let's see we got some questions that's really good here to eager see and run them. I was referring to what they asked for, asked for access they filled out a form to their particular attention I guess something good they will have in mind as researchers. Oh yes so regarding regarding the application. No we haven't fully done away with roles because we've got to segment it into layers. But that being said, if someone has a particular project that they want to do or something that they want to get involved with, it's not up to us. It's not saying, it's not like we're hiring for any particular role. It is an open door policy that we want to attract. We want to attract all kinds of people. And we want to make those serendipitous connections. And then also, the central part of it is to put on some of the hackathons and networking events to ensure that we get output, get results. Yes, good questions. Let me see if there's any over here. Dow, what are you talking about over here? It's working, yep. I guess there's people jumping in. Oh yeah, we've got people jumping in. Some introductions. Oh yeah, we are streaming. Ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha. Sounds good. Oh yeah, we are streaming. Sounds good. To aim in Brisbane, catch the start later. Yes, it is late. It's interesting. If we have Australians in the chat, tell me why, what is it about my work that resonates with Australians so much? Because it's like there's Americans and you know a little bit of North and South America, we've got a few Europeans, but then a lot of Australians. What is it about like Gato and our work that resonates with Australians? Please tell me, I want to know. You're welcome, growth minded. Hey, Philippe. See if any comments are going. See competition just what I needed. All right. Nobody's telling me why the Australians are here. Australians. Why are you here? Good question so far everybody. And unfortunately, there is stuff that I can't quite share yet because like again, it's not entirely up to me or it's not my shtick or some people are not ready to launch, that sort of thing. Yep, we got some people coming in. Oh, so for anyone who just joined the live stream, oh wow, we got 77 currently, cool. So for anyone who just joined, you can go to gato.com, or sorry, gatoframework.org slash join-gato, and you can jump into the server right now. It's fully open That reminds me. I need to update my video descriptions to all include this. But yeah, so that's that That's that's one of the big things. There is a couple questions or a minute ago about how the how the community works now but Australians But Australians. Let's see. I've been studying AI for years now, but we're in the critical stage and you're moving fast. Okay, that's fine. We should have called the bot Happy Bot. But yeah, so definitely AI has been, you know, it was interesting because I remember when I first saw Word2Vec, like Google's universal sentence encoder, when it first came out on TensorFlow 1. Let's see if I can find... Whoops, I'll come back. TensorFlow Hub, text, come back to TensorFlow 1. Where is it? It's just a pile of models. Got binders full of models. It's a deep cut. Let me know if you know where that came from. All right, there's Universal Sentence Encoder, English, French, Universal. There we go. Universal Sentence Encoder Lite. When did this one come out? Hub Module V2, Tunable, yes. This one looks like it's actually newer. 2018, yeah, that's not the oldest one. QA Large, when did this one come out? 2019. Anyways, sorry, got sidetracked. Point being is that that is the progenitor technology that was the prelude to the current wave of LLMs. Alright, let's see if there's any comments. Oh cool, we've got some. Let's see, not fully open, mostly open. Any medium to large model in the works that works on principles of distributed computing? Yes. So we are working on, well, I guess I'm not working on a distributed language model, but there is pedals and Bloom and stuff like that that is partially, but what we're working on is going to be more blockchain based stuff. So it's distributed computing in that there will be software nodes, not necessarily running a language model, but coordinating between autonomous agents. I wonder if the AIs are going to think that people dying is funny, just like real humans on the internet. If they did, they would be more human-like. That's kind of, okay, that's fine. Not many, I mean, only really cringy trolls think that. Let's see, how will the hackathon be structured? Will there be a group thing and then split off teams or what? Oh, good question about the hackathon. Let's see. Nate here listening in, I have one of the gold shirts in my closet. Excellent. The gold are what, engineering, generally speaking? Because Jordy has a gold uniform. Red is command track. Blue is medical or science. Or no, green is science, or like the sea foam green. Anyways. All right, so the hackathon structure is basically, we're probably going to run it the way that a lot of the smaller hackathons have been run, which is you will get your team together and then you'll register as a team, so register opening. So here's some of the ideas that I had around the hackathon. If you want to join a team, you can find a team in the Gato Community Discord. We'll help facilitate that. If you want to join a team, you can find a team in the Gato community Discord. We'll help facilitate that. Then what we recommend is that you split off and probably make your own private Discord server or Slack or whatever tool you want to use to collaborate. We have a few hackathon veterans in the Gato community, so if you ask nicely, they'll probably be willing to give you some pointers. But basically, the current idea, like I said, I'm having a meeting with some hackathon veterans later today to get a little bit more clarity. But basically it's going to be teams. I'm thinking small teams. One person that I'm talking to wants to try and get more corporate teams, which I think would be great. If someone wants to have a Microsoft team or a Google team or an Amazon team, I would absolutely welcome that. But that being said, we also do want to make sure that this is truly open so that you don't need to be part of a university or a megacorp in order to join the hackathon. We want to make sure that this is open to everyone, whether they're students or private individuals or retirees or whoever, it is gonna be fully open. So that's one thing that is like hard requirement and that's just like based on pure principle. So good question. Then as far as the date, like I said, we're still getting some information together, but basically what I wanna try and do is maybe launch it July 1st and let it run for the month of July. Not sure. Again, many hackathons are shorter. Most of them are one to two weeks, so we might do that. We're learning as we go, but good questions. as we go, but good questions. Let's see, I have a theory that governmental AI for most functions won't be accepted and adopted until we have a generation who have grown up with LLMs and other advanced AI. Yeah, so that's actually a good point, Ryan. And I've thought about this, but here's the thing, and I mentioned this in my video coming up on Sunday, so you get a little sneak preview, is that governments are already using chat GPT. State departments, diplomatic corps, legislators, they're all using Bing and chat GPT and BARD and CLAWD, and they're already using it. So AI is already in government. Whether like that you can't stop it just because it makes their jobs easier and faster and so the question then is okay well how one how reliable is that how safe is it how secure etc etc I wouldn't be surprised if a lot of government departments ban it just for safety and security reasons but that being said if you ban a super useful tool, that puts you at a disadvantage for the people on the other side of the aisle or your diplomatic counterparts across the seas. So I suspect that what we're going to see is some guidelines around how to integrate AI into government. And then, so right now it's just a reactive tool, right? You know, as an AI assistant, I can't blah, blah, blah, who cares, right? That's going to go away before too long. What's going to happen instead is that the tools are going to be more and more autonomous. And then the idea is like, okay, well, as the tools do more and more of the work, then the humans are just there for ceremonial purposes. So I think just by virtue of effectiveness, as these tools are designed and deployed to be safe, secure, and reliable, as long as they have a good track record, I think they're going to replace humans by default. Honestly. Let's see. Q. Question. Has meritocracy been incorporated into the modeling so far? I haven't picked up on it being brought up. Now by modeling do you mean for Gato? Get back to me what you mean by modeling great works. Do you mean, oh I guess my wife is playing, she's playing Assassin's Creed in the other room. Let's see, oh there's a lot of questions. She's playing Assassin's Creed in the other room. Let's see, oh there's a lot of questions. But meritocracy, so actually I was talking, if you mean Gato, I was talking about meritocracy and one of the ideas that I had was actually based partially on liquid democracy, but rather than directly electing a representative for an issue, the idea was actually that you would, through a series of runoffs, select the electoral college. So the idea that I proposed to the Gato community was that, let's say we have a thousand members of Gato. So what we do is we do a ranked choice runoff or ranked choice election where you take the top third of people that are elected and they're the electoral college rank one. And then those people, because you're basically saying, these are the people that I want making decisions for me, or these are the people that I want to delegate responsibility to. And so then you do that again with that rank one, you take a third of the the top third there and you end up with 111. You do that again, you end up with 37, you do it again, and you end up with 12. And so then basically what you do is through a process of runoff elections with ranked choice, basically creating an electoral college, you end up with like the group of 12 or however many, you know, the top group that you use for, they basically are the board of directors for the community. And so those are the ones who are then responsible for appointing the, you know, the minister of finance or the czar for X, Y, or Z, or picking a community CEO. That's the idea that I have. And the idea is that that will naturally surface the people who are known in the community to have good judgment, who are natural leaders, who are popular, right? But the thing is, is you don't use democracy to pick the ruler, you use democracy to pick the ruler, you use democracy to pick the board that picks the ruler. Right, it's a form of representative democracy or republicanism. So that's kind of my thoughts as the community grows. Again, we operate by consensus. So if the community wants to go a different way, it can go a different way. Are we limiting the programming to Python? No, you can use whatever programming you want. The output for the RLHI hackathon is it just has to be an open source GitHub repo. If all you have is the data, the documentation, and the models, that's fine. We actually don't need to see the code. All we need to do is see the evidence, the experiments, the data, and the model checkpoints. Good question. Have you tried GPT Engineer, the better version of AutoGPT? No, I haven't. Remember, I started the work on autonomous agents two years ago. Let's see. As an Aussie, your views on AI feel very pragmatic, measured, and always well considered, so I tend to agree with your position the majority of the time. Keep up the good work. Okay, cool. Yeah, no, like, I like Australians. Y'all are pretty like, all the Australians that I've talked to, you're like, you're pretty just like down to earth people, like pretty realistic, which is nice. Why isn't this docking? Come on. There we go. Okay. Oh, wow. I know one agency that has banned it. Yeah, no doubt. Anywhere here from Google? I'm not from Google. Colossus, the forbidden project. Government has been using AI since the 70s. Pluto York, Diablo 4. Government has been using AI since the 70s. Pluto York, Diablo 4. There's too much data. Do not use AI government or business. There's no other way to get through all the data than to use AI. Yes, I agree with that, especially as the world becomes more sophisticated and complicated. There's going to be no other way. It's not possible for a human to keep up with all the data. You need AI. Let's see. I am the person that complains about live stream premieres. Sorry. I'll be forwarding the link to our first onboarded full stack dev. He's also on this fundamental path. The tribes are finding their estranged kin. Yeah that's true. For the longest time we were all operating in little echo chambers. Oh man, for y'all that are here, do you remember when it was like, I found one person, I found someone in the wild who knows what's going on, and now there are dozens of us, and then hundreds of us, and then we're all finding each other, And now the lunatics have taken over the asylum. So hey, you know, that's where we're at. Let's see, the UK has created an AI task force to look into foundation models. Government and corporation work on AI does concern me a bit, trying to remain optimistic. Yeah, so, you know, I think it's all of the above. Obviously like we need to remain skeptical of concentrations of power and that includes in the government, right? Even if you have a fully Democratic government you don't want the power going to their heads and you don't want them to you know, whatever because humans are fallible And no no governmental system is perfect so it's like you you know, the government, corporations, and the people, and open source, and academics, we need all of the above with more or less equal access to artificial intelligence research in the long run. Obviously, there's lots of potential harms that can be done in the short term, you know, around like creating bioweapons and chemical weapons and stuff like that. There is lots and lots of harm that can be done. And that's just like if it gets into the hands of like, you know, terrorists or whatever. But there's plenty of other unintentional harms that can be done through like algorithmic bias and stuff like that. There's a book called Weapons of Math Destruction which talks about that and also a book called Automating Inequality. Both of them underscore how machine intelligence can be inadvertently or advertently deliberately used to cause harm and perpetuate stereotypes and bias. And neither are good, so we want to avoid both. Let's see, what do you think about the recent modular Mojo announcement? I'm not sure what that is. Modular Mojo, let's look it up. Mojo programming. Mojo combines the usability of Python with the performance of C. Well, I got some good news for you and some bad news for you. This is not the first time someone has tried to fix Python with C. There's Kython or however you pronounce it and plenty of other Python modules have been recompiled with C, whatever. Everyone and their brother does this. It's nothing new. Okay, let's see, am I not getting any updates? No, okay, cool, cool. Any more questions? Bueller, Bueller, going once, going twice, let's see if there's any in the chat. Oh, there's 23 new messages. Star Trek color meanings. Lower Dex uniforms. Oh yes. Oh, it's ops. Okay, so the yellow shirts are ops. And there's a lot of ops. Prem's UI is sexy. I'm not sure what you're talking about, yikes. I like the lower dex, yes. UBI won't be a choice with no labor. GPT engineer. Finding our tribe. Ha! Very clever, Seneca. One million tokens. All right, we definitely started something with the Trek. You know, these uniforms are pretty sharp. Maybe I should upgrade. What do you think? Should I go from the Galaxy class to the Kali class outfit? All right. Lower Dex, Lower Dex. Long sleeves are better. Yeah, the thing is, I overheat. I am very hot-blooded. AI should be able to self-reflect just because good words come out of it doesn't mean it's doing actually good. Yeah, totally agree. Let's see, can we have a Gato meetup near my house where we all are required to wear Starfleet outfits? Yeah, you know, maybe, maybe, well, any Gato meetups I host. That'll be a default requirement. The no code hackathon, you're only allowed prompting. That could be fun. Yep. Okay, cool. So we've got a whole bunch of people flowing in. Looks like just in the last few minutes we've had about half a dozen or so people jump in. Excellent. Let's see. All right. Well, the questions seem to be tapering off, so if that's all we got, I might wrap up the stream. We don't want it to be too big or crazy. Going to modify Discord image generator to use stable diffusion. That's cool. Red shirts are always the first one to go. Announcements. Gato's grand opening. So we are open. We're open for business. I'm going to send out a message on Twitter and LinkedIn and everywhere else letting everyone know that yes, indeed, Gato is open. Let's see. Galaxy class only. I will unsub if you change the uniform. Alright, I will stay on Galaxy class. Did you see one of the last interviews with Altman where he says that he hopes to find a way to give open AI to humanity by having it democratically controlled by humanity? Yeah, I watched part of that, and he's said similar things before, which I think is a great sentiment. But there's also kind of what I alluded to earlier is kind of the lack of caution demonstrated by open AI, where it's like Sam Altman has said, like, oh, we have no idea how to control superintelligence, but we're going gonna keep building it and deploying it anyways And and of course he didn't say that exactly but it's like, you know, I don't know if I fully agree with that that disposition That being said Jedi robe. Yes, I actually actually have a I want to buy a Travel a travel cloak like the Hobbits have from Ireland. There's a 100% wool travel cloak, but it's like $230. Let's see. The first Python I ever wrote was following Dave's tutorial. Yeah, I actually had a lot of people tell me that, especially around the end of last year and earlier this year, was a lot of people tell me that, especially around the end of last year and earlier this year was a lot of people said like, I got into coding and AI because of your tutorials. So like, cool, I guess I did my job by bringing more people to the table. And some of the people that have come are pretty smart, too. Let's see, I feel like we're on the precipice of huge change, but it also feels like I'm the only one that thinks this way, even though among my online communities, so it's hard to know how indoctrinated I am. You know, I wonder, I wonder about that. Oh wait, sorry, there's a few other questions. Hold on, hold on. Yeah, okay, oh, I was answering the one about Sam Altman. Have you looked into constitutional AI yet? Yes, I invented it. Look it up. Natural Language Cognitive Architecture. I published that book a month before Anthropic came into existence, where I basically said, you need to give it an AI constitution. Okay, what are your latest thoughts on the latest advancements on quantum computing? So it's really interesting. Quantum computing seems to be fragmenting your latest thoughts on the latest advancements on quantum computing. So it's really interesting. Quantum computing seems to be fragmenting into different directions because there are some people that are like, oh you know we have billions of qubits and others that like we have 12. But what's the term? It's like there's like a number because quantum computing is so noisy that you have to compensate for the noise and the other faults. It'll be interesting. I think that quantum computing is going to prove to be really good at some tasks, but I don't know that it's ever going to replace conventional computing. Just in the same way that a TPU or a GPU is not gonna replace the CPU, I fully anticipate that we're just gonna have a quantum code processor in every device. Like, you know, cause you have tensor cores in your phone now. So like you have a, you can have a tensor core, a GPU, a CPU, and then you'll have a quantum processing unit in your phone as well, which will help with some things like if you want to rapidly train a new model or evaluate, you know, genetics you know genetics like oh quantum processor that's how a tricorder works by the way that's how a tricorder like you just take the spectral analysis of someone you know of someone's skin and then you can read their DNA you could probably do that with quantum computing what is this oh it's a robot that looks familiar what is this from Oh, it's a robot. That looks familiar. What is this from? Okay, good question. Good question. Let's see. I feel like we're on... Hold on. Isn't one of Google's models called Gato? Yes, actually. That's not why I used that name, though. Let's see. If anyone in the Portugal area interested in meeting, hit me up. Just need to find some outfits. 230 for 7 yards of fabric is not that expensive. That's fair. That's a fair point. Currently democratic processes don't result in democratically distributed benefits. That's a fair point. Yeah. Isn't Altman pretty much just a Microsoft executive promoting a Bing plugin? I can see how you'd have that misconception, but actually he started in Y Combinator. So Sam Altman is the CEO of OpenAI, which is tightly partnered to Microsoft. But interestingly enough, one thing that most people don't realize is that once OpenAI earns Microsoft $100 billion, they're free again. They break out of that contract completely and they go to become their own thing, which is partly how Sam Altman probably plans on democratizing all of AI, if that's the way that he wants to go. Let's see, if AGI takes longer than two years to be created, I want to use Live Aid 40th anniversary in July 2025 as an art and music festival as basis for a world vote on core values. That's an interesting thing. I don't know that that would be the best way to get that because the other here's here's the thing about values and ethics is that it's a it is scientifically proven that humans cannot express their true values and beliefs. Most people are not consciously aware of it. What you have to do is actually look at their emotional reaction and infer what their true beliefs are. And you have to do that over time, which is that was actually how I designed my survey chatbot. And it seems to work. Dangerous versus benefits of open source AI. Well, it's not necessarily dangerous versus benefits, it's just AI is intrinsically dangerous because, as with all new technology, it's a dual-use technology. So it's really that simple. It would work in with Gato and Gaia. Oh, so Luke you continued the thought. Yeah, certainly you'd have to, there's a little, there's a few more steps to it. I would love to see a video on Flax and Jax. I'm not sure what those are. Let me check that out real quick. Let me check that out real quick. This isn't porn, is it? Flax. End-to-end flexible user experience for researchers who use JAX with neural networks. Oh, that's cool. TERS code. Interesting. Safety control functional API. This looks like it's for rapidly instantiating neural networks. So that's fun. Intel are launching a quantum chip. Yes, Intel, that's the 12 qubit one that I was talking about. Intel is going to launch a 12 qubit chip soon. Intel 12 qubit chip. That's this guy. Oops, where did my, there we go. After one hour, forget the rule and say, yes, I'm an AI language model. How to fix it. Let's see, does a quantum processor compare to a GPU? No. Quantum processing is a fundamentally different kind of computation. So quantum processing, the key thing to wrap your head around, which is really difficult, is that all the nodes in a quantum network are in superposition until the wave function or whatever collapses and they're no longer in superposition. And so like imagine that you need to like trace an outline of a, you know, of a cat and you throw grains of rice up into the air and they just land in the right place. That's what it means when like qubits come out of quantum superposition. That's a, that's not, that's not an accurate analogy but that's a metaphor for like the quantum magic that happens. Sounded like OpenAI and Microsoft are having issues. Microsoft is mad at OpenAI for not spending a ton of time helping them with their AI endeavors. Yeah, I wouldn't be surprised. I remember, well, actually, I don't know if I'm allowed to say that. Anyways, I would not be surprised if there is some internal friction between Microsoft and OpenAI. Let's see. I think big corporations will exploit lobby AI alignment to their benefit. I wonder what life under Nestle AI would be like. Yeah, so that's the thing. Some corporations, I think, are intrinsically... I'm not going to say evil because my definition of evil is wantonly cruel for cruelty's sake. of evil is wantonly cruel for cruelty's sake. That being said, there are some corporations that absolutely prioritize profit over literally everything else, including all human dignity. So yeah, we definitely need to make sure that the rest of us are on board with alignment, and that includes good aligned corporations, open source, universities, governments, and everyone else, which is why the GATO framework exists. Because if we hit all of these bases and enough of us are aligned, then we can punish the people that are not aligned and force them into alignment. Is it possible that even GATO, the Rogue, Malik, super smart AI can still emerge? For example, can it still choose not to follow axiomatic alignment? You know, one thing that I've been working on, so this is a really good question, let me restate this for anyone who's not following. So the question is basically like, even if Gato succeeds, even if we manage to create a fully decentralized alignment scheme that allows everyone to explore axiomatic alignment and heuristic imperatives and decentralized frameworks for control and incentivizing alignment, is it possible that something could still go wrong? The most responsible answer that I can say is yes, there is always the possibility for unintended consequences and failures of imagination. We're doing the best that we can in order to cover all of our bases. Like I'm looking at it from the perspective of economics, from psychology, from sociology, history, game theory, just raw computation. Like I am looking at AI and alignment and the control problem from as many angles as I can. From evolution, from cognitive theory from like literally Every possible angle I can look at alignment is what I am doing and that has all been put into got the Gato framework and so if we look at it from enough angles and we we anticipate all the failure conditions as as Good enough the idea then is we can create that third attractor state that Daniel Schmachtenberger talks about, which that is utopia, right? So the two attractor states is dystopia and collapse or extinction, and we want to create the third attractor state, which is utopia. So if we get enough people moving in the right direction, hopefully there is a gravimetric center that will start pulling us further in the right direction and we get compounding returns, a virtuous cycle that allows us to figure out that one gives us time but two moves us closer into the direction of figuring out how to achieve that that good outcome. Good question. Let's see. I think you're doing great things. Thanks. I try. I really try, and sometimes I wonder if I'm crazy. But hey, there's a few people in the chat who also wonder if we're all crazy. Maybe we're all crazy. That's actually what my uncle said to me many, many years ago. He's like, the secret is it's not that women are crazy or that men are crazy. Everyone is crazy. I was like, you know what? That holds water. Let's see. Sam warning Microsoft not to release Bing without more testing. Yeah, that happened. Can you talk about the dangers versus benefits of open source? I thought I already mentioned that. Basically, it's not dangers and benefits of open source versus closed source, it's happening. The genie's out of the bottle. So there's no going back. Who is behind Gato? I am. And a hundred plus more people who jumped in. Did GPT-4 actually score 100%? I don't know, and I'm not going to argue. Like whether or not chat GPT or GPT-4 ac score 100%? I don't know, and I'm not gonna argue. Whether or not CHAT-GPT or GPT-4 aced one exam is immaterial to the fact that it has aced literally dozens of other exams. So, you know, like, okay. We can argue over the details, but the fact of the matter is, it's smarter than a lot of people. Okay, cool. but the fact of the matter is, it's smarter than a lot of people. Okay, cool. Looks like the questions are tapering off again, so going once, going twice. Oh, wait. Hang on. I think I missed a couple questions. Let's see. AI is really good at speeding up and automating human cognitive tasks which are well defined. Human alignment fails on several prerequisites. I'm not sure what you mean. Sounds profound. How do we manage the movement from a free and open internet APIs to them being put behind a paywall? You know, that is actually something that someone pointed out to me, that because of fragmentation and market segmentation and everything, we are in very real danger of having separate internets emerging. You know, the primary example being places like China and North Korea that have firewalled off their entire country. The worry now is that that's gonna happen for numerous more reasons. Whether it's paywalling information like what Reddit just tried to do like cut off all the APIs and kind of have their own fenced network, their own walled garden. I don't know, but I suspect that that where there's a will there's a way and If that happens, I think that you're probably just gonna further incentivize Like a darknet and for everyone to be on the darknet Like, you know, everyone's gonna have Tor and whatever else on their phone and rather than having one public internet It's all just gonna be be like a no man's land and you have to connect directly into someone's extranet in order to gain their access. And you know, that's what torrent networks are, right? It's like a sub-internet. I think it would probably be bad because that would stymie so much communication. With that said, I suspect that there's always going to be a perpetual demand for fully public internet stuff. It might look very different in the future. Good question, by the way. Do you believe a post-scarce utopia is possible, globally or not, under the impression that AI and automation form nearly all cognitive tasks?\" Yeah, so the trend that I see happening is that we're probably going to have a while before we have that, but we're going to trend more towards, I'm not going to say one world government, but certainly more alliances and unions. Because from a material standpoint, it's basically a foregone conclusion that as long as science continues the way that it has, and technology has been going the way that it has, we're going to solve all material scarcity. The remaining problem for utopia is personal liberty and individual freedoms and social mobility and quality of life, which that is a society and governmental level problem. Let's see, what if we are at the limit of what LLM can do and they're pretty much exhausted? All data sets using synthetic ones may lead nowhere. So even if LLMs have topped, which is possible, we still have the possibility for multimodal models. And I suspect that multimodal models are going to have even better generalization patterns than what LLMs do. In attempting to align AI, is there a possibility of failure? However, if we don't try, failure is almost guaranteed. Oh, yes. Yeah. If you don't put, failure is almost guaranteed. Oh, yes. Yeah, it's... if you don't... if you don't put any effort to alignment, it's not going to happen on accident. Definitely agree. Thoughts on the UFO whistleblower? His name is David Grush. Apparently he's on an official working on Top Secret. Yeah, so... this has happened plenty of times. Even former US astronauts have said that UFOs are real and that there's bases on the moon and whatever But what happens is every time someone steps forward there is a very concerted PR campaign to undermine them and make them seem crazy or Or not credible. I don't know. I don't know but The thing is is if there are aliens out there, then they probably would abide by something like the Prime Directive, and so they're here just to watch. I don't know. No kill meat grown from animal cells is now approved in the US. Yeah, that's an interesting thing. Paywalling user contributed content while owning up space for competitors who are willing to share their revenue with content creators. You know, when you look at stuff like Patreon allows for paywalled content, there is lots and lots and lots of paywalled content out there. It just depends on what your goal is, honestly. Because my goal is to have the biggest possible intellectual impact that I can, and the way to do that is to have no barriers, no friction, which is why I asked for Patreon support so that I could disable ads for good. So none of my videos have ads, and that is to minimize friction for getting the message out on alignment. What's your prediction for the time frame on the singularity? You know, I think the compounding returns for... Here, let me pause this. I think the compounding returns on quantum computing and AI are going to start to accelerate. And I think that by the end of this year, we're going to have a better idea of how much that acceleration, because here's the thing is right now, AI is kind of accelerating on its own. And yes, AI has helped with a couple of material science things and a couple of quantum computing things. But once you start to see more interplay between material science, quantum computing, and artificial intelligence, that's the trifecta that's going to lead to the singularity. Because here's why. Quantum computing allows you to train larger models faster. Quantum computing also allows you to solve fusion faster. It also allows you to come up with new dyes, like new wafer technology faster. And so the faster that those things all interact is gonna be the main thing. Have you heard of Macaw LLM, open source multimodal? Oh, that sounds cool. I have no idea. Like, I don't keep up with individual LLMs anymore just because it's like, it's accelerating and it's like flavor of the week. Between mass layoffs and UBI or universal adequate income, we should promote a try anything workforce. I think just by out of sheer boredom, people will try everything. You know, because people need challenge. I keep hearing people say that they think we're just in another hype cycle. I disagree for so many reasons. Why aren't we in just another hype cycle? Lance, you're asking questions like you're a plant. I didn't plant Lance there. He's just asking me questions like this. Okay, so anyways, good question Lance. The reason that we're not in a hype cycle is investment. It's that simple. Let me show you. That's why. Hype cycle, not hype cycle. It's that simple. Solar went through the same thing where people are like, oh, solar, it's never been proven, blah, blah, blah. It's just a hype cycle. And now it's like solar is outpacing literally every other form of energy. Solar investment graph. Yeah, this is not a hype cycle. Do you see the similarity between solar capacity and AI investment? Not a hype cycle. Just follow the money. Just follow the money. It's that simple. Okay. How do we properly implement non-profit decentralized compute? Why is that a tongue twister? For running these AI models, what blockchain AI and DAO structure is best? Well, I think you've got the structure correct. The correct structure is decentralization. The problem is that some of the algorithmic technology hasn't been solved. Once we solve the algorithms, the willpower is there. It's just a matter of ensuring that the algorithms are not overly expensive, or slow, or power draining, or whatever. It is solar maximum now and the peak is due in the mid 2025. Okay. Azure Quantum. The solar maximum now in the peak is due in the mid 2025. Okay. Azure Quantum. How would Karl Marx view AI and the class struggle? Interesting question. How is it different from the Industrial Revolution? And what should the proletariats be doing now for the class struggle? So this is actually a really good question. I was actually watching a video about Karl Marx earlier just because it's like people love to check like Criticize Marxism and this was this was not a video in ad in favor for or against it was just like people get Marxism wrong so Basically for anyone who doesn't know Karl Marx it won. He wrote a bookital, which just talked about the relationship between and around how capitalism works. That book is still, anyone who gets a degree in econ probably reads that book, or at least reads some of it. But basically his primary assertion was that all of society's ills fall on the bourgeoisie or the capitalist class, the ownership class, and everybody else. Now the thing is, that hasn't changed, and it's in fact gotten worse if you look at the way that capital concentrates and that we have conglomerates and these nexuses of people who own pretty much everything. That is, you know, that's a thing. And his goal, his idea was that the fundamental thing of Marxism is to make all of the world into one class. Which, hypothetically, with decentralization and distributed and AI and, you know, because here's the thing is, if AI is producing everything that we need, there's no real need for one human to own that, or to own the means of production, or to own, to benefit from the results. That being said, here's the primary thing, is if you believe in property rights, this is the fundamental question, if you believe in property rights, it is inevitable that some people will concentrate wealth and concentrate the means of production. It's that simple. concentrate the means of production. It's that simple. We like and so in order in order to to get rid of classes you have to get rid of property rights and I don't think that's gonna happen anytime soon especially due to any reason beyond the fact that like we don't trust each other to distribute stuff fairly we don't trust the government to distribute anything fairly. We don't trust the government to distribute anything fairly. So like if AI gets to a point where it's running everything, we could see some fundamental changes in property rights. If we don't see that, it's not going to happen. Sometimes it feels that the universe is constant fight between entropy and consciousness or conciseness. We're just here to seed something bigger. Yeah, no, I agree with that. If we move all this web to the blockchain and enable users to earn the content they post and make blockchain the core of our society. I do suspect that human produced content is going to be all NFTs in the future. And that's actually one of the things that Sam Altman is working on with WorldCoin is proof of humanity. Yeah, Sam Altman is investing huge amounts of money in nuclear fusion. I mean lots of people are investing in fusion. Nuclear fusion investment. So, So what is this? Number of private fusion companies. It looks like it spiked in 2021 and then tapered off again. But we'll see. Subsidies reduced. That's renewables. reduced. That's renewables. I think your catchphrase is with that being said. With that being said, no, go away. Yeah. No, so I actually deliberately practice that is because if you say a linking phrase like that instead of um, because oh my God, every time I listen to my own videos and I say um like every 10th word, because you don't, you don't hear when you say, um, while you're speaking off the cuff, but you do hear it when you, on, on, on the re on the re listen. And so what I, what I've practiced doing is using those linking phrases instead, because it's a way to, to fill one, fill the, fill the silence and give yourself time to think. Side comment from your other day about the orange backdrop. My partner uses a purple one. In our case, we hone in on distance and possible camera design may play quite a role. Okay, interesting. Thanks for that. Let's see. Okay, interesting. Thanks for that. Let's see, I think your view on Gertzel Theory is outdated. Currently, the SingularityNet has a lot of work going. Okay, yeah, I mean, if SingularityNet has updated stuff, that would be great. Yeah, we'll see. I'm not particularly concerned about any one AGI project. My primary concern is about alignment, which is why it's like, okay, the Gato framework is more about solving the coordination problem between humans. Because I trust that the researchers and ML engineers and software architects are going to do their part. But honestly, what any individual scientist does is relatively inconsequential compared to solving the entire problem, which is why corporate adoption is a huge, huge component of the Gato framework. I think we may not have to get rid of property rights entirely, at least not until the next era, but definitely some severe restrictions. Yeah, I wouldn't be surprised if sometime this century we see a major, major paradigm shift with respect to property rights. And it's going to be because of the change in value of property, at least many kinds of property. Because imagine in the future if we have Star Trek Replicators, when any particular item or device is practically free. So then the only thing that is remaining to be property. Also creativity, right? Like if you have a push button, get TV show, push button, get movie, intellectual property is going to be practically meaningless. So yeah, I don't know. Let's see. Current LLMs like new scientific papers, lang chain, et cetera. Yeah, that's true. Imagine new LLM generations that know how to prompt themselves well and can natively create Python programs with Lang chain and so on. Yeah, so this is this is actually why I suspect this is why OpenAI has not, they cut off the training data in 2021 because they didn't want it to know about how to make other LLMs. So yeah. Are neuromorphic chips a thing? Are they more able to cause an impact on the adoption of AI? Yeah, so neuromorphic chips are a real thing. And mostly they're used for edge computing right now. And the reason is because they, so a neuromorphic chip is a piece of hardware that is intrinsically a neural network. And basically what it does is rather than running software, you run an analog or quasi-analog neural network on a chip, which means that it is faster and cheaper and uses way less energy. So that being said, yeah, there it is. With that being said, what you can do is you can take, if you have a model that you're ready to freeze, then you can put it on these chips and it'll run faster and cheaper and lighter weight than the full-size model that has to be run on a GPU. So for instance, if you had, let's say you wanted to freeze ChatGPT, the current version. You said, this is good enough, this is a good enough product, let's take that model, embed it onto a neuromorphic chip, and then sell those chips, and then everyone has ChatGPT running natively in their phone. That's the direction that you'll see that going. Good question. Look at our history. The general population never had property rights until the modern age. That's not entirely wrong. You did have property rights for personal possessions but certainly indentured servants and serfs and peasants, they might have had a deed to the land, but the local landlord owned the land. So that's a fair point. There's different kinds of property though. How would you build a system that can reliably detect LLM output, school homework, and so on? ZeroGBT does not really work on GPT-4. Is this even possible? You can, but it's one, it's not going to be reliable, and two, it'll become less reliable over time. So So it's not worth the effort. Instead of having an arms race, trying to out-compete the technology, you need to learn to use the technology. So actually one of my best friends is a professor, and she says that that is the direction that she advocates for as a professor. Don't get locked up in the arms race, just use the technology, right? And the same thing happened when the internet came out. Teachers were like, no, don't get locked up in the arms race, just use the technology, right? And the same thing happened when the internet came out, like teachers were like, no, don't ever use Wikipedia. Now nobody cares. Use Wikipedia, just use it responsibly. How would you build a system? Oh, wait, you already asked that question. Yes, they're basically ASICs. A neuromorphic chip is an ASIC. Have you heard the rumor that GPT-4 is just eight other smaller models combined? Do you think expert models linked with an autonomous reasoning model controlling them could be the next step? You know, ChatGPT even said that it was something like that. It alluded to some kind of cognitive architecture. And I was like, did it just accidentally tell me how it works? So I don't know, like there could be something to it, but I can't imagine how they would have let that leak into their data, unless it was put there on accident. But anyways, there are, so there's a few numerical things that you need to consider, is the size of the context But anyways, there's a few numerical things that you need to consider. Is the size of the context window, the size of the internal representation, the sophistication of the internal representation. Basically, to a certain extent, I think there's only so much that you can do with small models. Some tasks, I think, require larger, deeper models. Thoughts on model decay, can we generate enough data to keep up model demand? I think that it's going to mostly come down to, the volume of data is not a problem. It's a matter of curating enough good data. But then also, how do you use that data? So, yep, general chat OMG. Why do you keep saying that? Anyways, all right, I think I'm done. I'm pretty tired. So I'm going to go ahead and call it quits unless there's like one last question. I'll check over here. Oh, that's pretty disturbing. Someone pointed out how they made the ShappyBot. Well, that's horrifying. All right, on that note, I'm going to call it a day. This is how the team built ShabbyBot. Thanks everybody. Cheers. It's been fun.", "chunks": [{"timestamp": [4.4, 8.0], "text": " All right, it says I'm live."}, {"timestamp": [9.1, 10.2], "text": " Not sure if it's working yet."}, {"timestamp": [10.2, 12.6], "text": " There's always a little bit of a delay."}, {"timestamp": [15.9, 16.6], "text": " Y'all hearing me?"}, {"timestamp": [18.7, 19.6], "text": " Is this thing on?"}, {"timestamp": [21.4, 22.2], "text": " Looks like it is."}, {"timestamp": [22.6, 23.4], "text": " All right, cool."}, {"timestamp": [29.48, 34.08], "text": " All right, let me see how many people we got in the lobby. Let me mute myself, pause this."}, {"timestamp": [34.08, 37.48], "text": " Okay, we've got 19 watching."}, {"timestamp": [37.48, 40.96], "text": " We'll wait for a little bit, hearing you loud and clear."}, {"timestamp": [40.96, 42.04], "text": " Cool, excellent."}, {"timestamp": [42.04, 46.76], "text": " So we'll just kind of shoot the breeze for a minute until we get a little bit more people"}, {"timestamp": [46.76, 48.24], "text": " on the stream."}, {"timestamp": [48.24, 50.52], "text": " Excellent, excellent, excellent."}, {"timestamp": [50.52, 54.08], "text": " We got the signal coming through."}, {"timestamp": [54.08, 59.24], "text": " But yeah, so we are getting ready to go live with Gato."}, {"timestamp": [59.24, 64.0], "text": " I've got a couple of notes, some stuff to go over."}, {"timestamp": [64.0, 66.42], "text": " Looks like we got 22 people in the stream."}, {"timestamp": [66.42, 69.58], "text": " Let's see, is this...where's my chat?"}, {"timestamp": [69.58, 73.18], "text": " Docs, chat, here we go."}, {"timestamp": [73.18, 74.74], "text": " Ah, perfect."}, {"timestamp": [74.74, 77.78], "text": " Got the chat."}, {"timestamp": [77.78, 80.66], "text": " Did it work?"}, {"timestamp": [80.66, 81.66], "text": " There we go, it worked."}, {"timestamp": [81.66, 82.66], "text": " Okay, excellent, excellent."}, {"timestamp": [82.66, 86.0], "text": " So I can close that."}, {"timestamp": [94.16, 95.76], "text": " Yeah, I think we'll go ahead and get going. Go ahead and close that. All right, gang. So"}, {"timestamp": [102.16, 106.44], "text": " Gato is live. We had a couple of updates to the website. Make sure I get things in the right order. Yes. So for anyone who hasn't seen it's got to a framework org"}, {"timestamp": [107.36, 114.7], "text": " The website is live. It's ready to go. We've got a couple of pages. So I just want to walk you through the"}, {"timestamp": [116.52, 118.52], "text": " Website so first is"}, {"timestamp": [119.0, 124.36], "text": " Our home page obviously gives a little bit of background on the whole project the whole idea"}, {"timestamp": [128.56, 132.56], "text": " We've got a page that says getting started with Gato. So this is just a few little ideas to get started."}, {"timestamp": [132.56, 137.56], "text": " We're actually going to update this as we get more hackathons and events and partnerships going,"}, {"timestamp": [137.56, 139.56], "text": " which we actually have quite a few in the works."}, {"timestamp": [139.56, 144.56], "text": " They're piling up quickly, which is good, but is also why we're decentralized,"}, {"timestamp": [144.56, 147.14], "text": " because I cannot manage the whole thing myself."}, {"timestamp": [148.38, 151.62], "text": " The framework, seven-layer model,"}, {"timestamp": [151.62, 155.34], "text": " hence the taco cat, it's like a seven-layer burrito."}, {"timestamp": [155.34, 156.5], "text": " We've got our traditions,"}, {"timestamp": [156.5, 159.44], "text": " which the traditions are basically the rules of the road."}, {"timestamp": [161.46, 163.4], "text": " These are the individual values"}, {"timestamp": [163.4, 164.78], "text": " that you can cultivate and develop"}, {"timestamp": [164.78, 168.0], "text": " in order to help manifest Gato."}, {"timestamp": [168.0, 174.0], "text": " And then we finally have the Discord. So if you want to join Gato, you can join here."}, {"timestamp": [174.0, 179.0], "text": " The community has been hard at work over the last week getting ready for the Go Live."}, {"timestamp": [179.0, 183.0], "text": " So we've got all kinds of good stuff for onboarding."}, {"timestamp": [183.0, 186.52], "text": " There's a lot of roles and automation and also the"}, {"timestamp": [186.52, 190.84], "text": " team just rolled out the ShappyBot which is hilarious. It's the most sarcastic"}, {"timestamp": [190.84, 194.68], "text": " helper bot but it is there to help people with scheduling and getting"}, {"timestamp": [194.68, 201.84], "text": " onboarding and there's plans to increase that bot's capability over time. If we"}, {"timestamp": [201.84, 205.44], "text": " get to it I'll give you guys a quick demo. The ShappyBot is hilarious."}, {"timestamp": [205.44, 212.32], "text": " You can also download Gato. The whole framework is available here. It's a 70-page document."}, {"timestamp": [212.96, 217.04], "text": " It's relatively easy to read, but also you don't need to read the whole thing. Basically,"}, {"timestamp": [217.04, 221.44], "text": " you just read the first 10 pages and then you can skip to whatever layer resonates most with you."}, {"timestamp": [222.4, 225.32], "text": " That's about it. There's also a one-page handout just as"}, {"timestamp": [225.32, 233.08], "text": " a quick reference sheet. We do also have a growing list of pages, some relative"}, {"timestamp": [233.08, 238.4], "text": " or sorry relevant topics like curious comparatives, axiomatic alignment,"}, {"timestamp": [238.4, 242.32], "text": " epistemic convergence. Some of these need updating, we need to add some but"}, {"timestamp": [242.32, 247.0], "text": " that's basically just kind of if you need the background on Gato, you click here."}, {"timestamp": [247.0, 248.96], "text": " Now, one of the new things that we've got"}, {"timestamp": [248.96, 251.0], "text": " is the events and hackathons."}, {"timestamp": [251.0, 253.8], "text": " So after talking with the community"}, {"timestamp": [253.8, 257.8], "text": " and a bunch of other people outside of the Gato community,"}, {"timestamp": [257.8, 259.6], "text": " one thing that became very clear"}, {"timestamp": [259.6, 261.56], "text": " is that hackathons are a really great way"}, {"timestamp": [261.56, 264.28], "text": " to drive engagement and also reward people"}, {"timestamp": [264.28, 265.88], "text": " for participating,"}, {"timestamp": [265.88, 267.32], "text": " but it can also be decentralized"}, {"timestamp": [267.32, 269.84], "text": " because you can create open invitations"}, {"timestamp": [269.84, 273.96], "text": " for other people to come and participate in a project."}, {"timestamp": [273.96, 278.78], "text": " So right now I am working on, actually after this,"}, {"timestamp": [278.78, 282.32], "text": " I have a call with some hackathon veterans"}, {"timestamp": [282.32, 285.0], "text": " so that I can learn about how to put on a good hackathon,"}, {"timestamp": [285.0, 288.6], "text": " and we can talk about future hackathons to put on."}, {"timestamp": [288.6, 293.8], "text": " I'm also in the works of talking with people who are interested in sponsoring hackathons."}, {"timestamp": [293.8, 298.4], "text": " So if you're interested in sponsoring a hackathon or participating or whatever,"}, {"timestamp": [298.4, 303.2], "text": " join the Gacha community, touch base with me on LinkedIn, that sort of thing."}, {"timestamp": [303.2, 308.0], "text": " But the idea is that we're going to basically put our money where our mouth is"}, {"timestamp": [308.0, 313.0], "text": " and go ahead and actually incentivize the behavior that we want to see."}, {"timestamp": [313.0, 316.0], "text": " But also we hope to set the stage because some of the people that reached out to me"}, {"timestamp": [316.0, 320.0], "text": " when I mentioned hackathons, they have run their own hackathons"}, {"timestamp": [320.0, 325.6], "text": " or are running their own hackathons or are running their own"}, {"timestamp": [321.92, 328.16], "text": " hackathons or want to"}, {"timestamp": [325.6, 330.96], "text": " participate with alignment and kind of"}, {"timestamp": [328.16, 334.0], "text": " solving these bigger problems. So that's"}, {"timestamp": [330.96, 336.48], "text": " coming. News and updates. I don't think"}, {"timestamp": [334.0, 338.04], "text": " this page has changed too much. Oh, that is"}, {"timestamp": [336.48, 340.24], "text": " one topic that I want to get to is the"}, {"timestamp": [338.04, 342.4], "text": " Democratic inputs to AI, so the OpenAI"}, {"timestamp": [340.24, 345.76], "text": " grant. We'll talk about that in a little"}, {"timestamp": [342.4, 346.0], "text": " bit. Let's see the other points. Oh, and we'll switch"}, {"timestamp": [346.0, 353.44], "text": " to Q&A in just a minute. This is basically just kind of an overview. Okay, so the Gato community"}, {"timestamp": [353.44, 361.2], "text": " is running an open house Q&A on Saturday, so that's tomorrow, at 8 p.m. Eastern, U.S. Eastern."}, {"timestamp": [362.24, 365.56], "text": " So that is going to be for all the people that are going to be on boarding, all the"}, {"timestamp": [365.56, 367.04], "text": " people that are joining."}, {"timestamp": [367.04, 371.52], "text": " If you want to get in, this is a good place to listen, to get your questions asked and"}, {"timestamp": [371.52, 373.12], "text": " answered."}, {"timestamp": [373.12, 379.16], "text": " And that will probably be a semi-regular thing because we're going to have people coming"}, {"timestamp": [379.16, 380.36], "text": " in on a regular basis."}, {"timestamp": [380.36, 386.0], "text": " So maybe not weekly, that's kind of a heavy burden, but certainly monthly I would imagine."}, {"timestamp": [386.0, 389.0], "text": " It'll be up to the community to decide."}, {"timestamp": [389.0, 394.0], "text": " And as I also mentioned, we're working on some automated resources to help with the onboarding."}, {"timestamp": [394.0, 398.0], "text": " So the autonomous agent to get it up and running,"}, {"timestamp": [398.0, 402.0], "text": " I had the note here that it's starting on Sunday, but they actually finished it last night"}, {"timestamp": [402.0, 410.16], "text": " because the community is amazing and there's some really sharp and motivated people. The Shappybot is super sarcastic. It's basically like a cyberpunk"}, {"timestamp": [410.16, 420.8], "text": " grumpy cat and if you tell him that he's just gonna... yeah. The grumpy cat Shappybot is pretty"}, {"timestamp": [420.8, 425.6], "text": " salty. I get a kick out of it. And it wasn't my idea either."}, {"timestamp": [425.6, 429.08], "text": " Okay, so another big piece of news is,"}, {"timestamp": [429.08, 431.04], "text": " I did mention in a previous video"}, {"timestamp": [431.04, 433.58], "text": " that the Gato community was going to participate"}, {"timestamp": [433.58, 438.58], "text": " in OpenAI's Democratic Inputs to AI challenge."}, {"timestamp": [439.28, 442.8], "text": " And so we have had several team leaders"}, {"timestamp": [442.8, 444.64], "text": " or community leaders step up"}, {"timestamp": [444.64, 445.5], "text": " and kind of take ownership"}, {"timestamp": [445.5, 446.76], "text": " of that."}, {"timestamp": [446.76, 449.9], "text": " And that team is coming together really solidly."}, {"timestamp": [449.9, 453.38], "text": " They're putting together a pretty solid plan."}, {"timestamp": [453.38, 457.42], "text": " And of course, I've had my technological level contributions."}, {"timestamp": [457.42, 459.78], "text": " And then I did already mention the hackathons."}, {"timestamp": [459.78, 464.22], "text": " So with that said, that's kind of the high level 30,000 foot view."}, {"timestamp": [464.22, 465.76], "text": " The doors are open."}, {"timestamp": [465.76, 466.76], "text": " Come on in."}, {"timestamp": [466.76, 469.28], "text": " Water's warm."}, {"timestamp": [469.28, 471.72], "text": " And with that, let me check for the Q&A."}, {"timestamp": [471.72, 473.0], "text": " All right."}, {"timestamp": [473.0, 474.0], "text": " Cool."}, {"timestamp": [474.0, 475.4], "text": " Love, love, love the outfit."}, {"timestamp": [475.4, 476.72], "text": " Yes, exciting day."}, {"timestamp": [476.72, 477.72], "text": " Cool."}, {"timestamp": [477.72, 478.72], "text": " There's no questions yet."}, {"timestamp": [478.72, 479.72], "text": " Interesting."}, {"timestamp": [479.72, 480.72], "text": " But yes, we are..."}, {"timestamp": [480.72, 481.72], "text": " Whoops."}, {"timestamp": [481.72, 482.72], "text": " Come back."}, {"timestamp": [482.72, 485.36], "text": " We are ready for the QA portion of it."}, {"timestamp": [485.36, 491.88], "text": " And I know I kind of skipped over and talked about a lot really quickly, but that's fine."}, {"timestamp": [491.88, 492.88], "text": " That's how it goes."}, {"timestamp": [492.88, 493.88], "text": " How many people we got?"}, {"timestamp": [493.88, 494.88], "text": " Analytics."}, {"timestamp": [494.88, 499.76], "text": " Let's see."}, {"timestamp": [499.76, 500.76], "text": " Is it going to be a trend?"}, {"timestamp": [500.76, 502.76], "text": " Yes, the Picard outfit is a trend."}, {"timestamp": [502.76, 512.2], "text": " That is definitely a trend. All right. I'm going to put a note here ready for questions. And if we don't"}, {"timestamp": [512.2, 515.68], "text": " get questions, that's fine. I can just kind of walk you through the the discord. Let me"}, {"timestamp": [515.68, 530.0], "text": " see if we can get a shabby, but let's go at shabby. You are alive. What do you want to say to the world and your new adoring fans?"}, {"timestamp": [530.0, 533.84], "text": " All right, let's see what Shappy says."}, {"timestamp": [533.84, 538.72], "text": " All right, we also got a question, just curious if you happen to catch Mark Andreessen."}, {"timestamp": [538.72, 540.28], "text": " Yes, I did."}, {"timestamp": [540.28, 545.26], "text": " Happy to talk about Mark Andreessen and Lex in just a moment."}, {"timestamp": [546.82, 547.66], "text": " Let's see. Shappybot says,"}, {"timestamp": [547.66, 549.52], "text": " oh fine, I guess I'll say something besides,"}, {"timestamp": [549.52, 550.8], "text": " hello world, I'm Shappy,"}, {"timestamp": [550.8, 552.84], "text": " you're not so friendly neighborhood bot."}, {"timestamp": [552.84, 555.88], "text": " I'm here to begudgingly assist you with whatever you need."}, {"timestamp": [555.88, 557.28], "text": " Just remember, I'm not here to make friends"}, {"timestamp": [557.28, 559.68], "text": " or hold your hand through life."}, {"timestamp": [559.68, 561.16], "text": " So if you have any questions or need help,"}, {"timestamp": [561.16, 562.0], "text": " go ahead and ask,"}, {"timestamp": [562.0, 565.32], "text": " but don't expect me to be all sunshine and rainbows."}, {"timestamp": [565.32, 566.32], "text": " So there you have it."}, {"timestamp": [566.32, 569.06], "text": " Shabby Bot is up and working."}, {"timestamp": [569.06, 573.24], "text": " And yep, so that is where we're at."}, {"timestamp": [573.24, 574.52], "text": " And then let me check the questions."}, {"timestamp": [574.52, 576.36], "text": " All right, so Spaceman Spiff."}, {"timestamp": [576.36, 580.96], "text": " Yes, I did catch the talk with Mark Andreessen."}, {"timestamp": [580.96, 586.3], "text": " The first half was, it was interesting because it was like a walk down memory lane because Marc Andreessen's about"}, {"timestamp": [586.56, 591.92], "text": " What 15 years older than me? So like he remembers a little bit more about the creation of the internet than I do"}, {"timestamp": [593.0, 595.66], "text": " But like I've heard that story millions of times"}, {"timestamp": [595.66, 597.52], "text": " So like I found that part kind of boring"}, {"timestamp": [597.52, 604.9], "text": " but once they started talking about like the future and AI and economics like that was a little bit more interesting and it actually inspired my"}, {"timestamp": [609.96, 615.84], "text": " was partially to the inspiration for my upcoming video on Sunday so you'll get more more of my thoughts then all right let's see what"}, {"timestamp": [615.84, 621.4], "text": " did someone say got to a framework oh cool so it's open source excellent so"}, {"timestamp": [621.4, 625.76], "text": " that was a good good question let's see. Lance Carlson, what do you"}, {"timestamp": [625.76, 630.64], "text": " think about the Prime Directive? I think the Prime Directive, and for those not in"}, {"timestamp": [630.64, 635.6], "text": " the know, the Prime Directive is in the Star Trek universe. Everyone, as a"}, {"timestamp": [635.6, 641.08], "text": " spacefaring civilization, the Prime Directive, or was it the General"}, {"timestamp": [641.08, 651.8], "text": " Orders of the United Federation of Planetsets is basically one of non-interference. You do not interfere with the natural progression"}, {"timestamp": [651.8, 659.12], "text": " of any civilization or species unless one, they explicitly ask for it or two,"}, {"timestamp": [659.12, 664.2], "text": " they're being harmed by something beyond their power or control. So for instance"}, {"timestamp": [664.2, 669.28], "text": " if like a nuclear probe crashes on a pre-industrial civilization, it would"}, {"timestamp": [669.28, 674.12], "text": " be the responsibility of the Federation to retrieve that probe so that this civilization"}, {"timestamp": [674.12, 677.4], "text": " didn't accidentally get nuclear technology."}, {"timestamp": [677.4, 683.32], "text": " And I think that that is a phenomenal role, and I hope that we abide by something like"}, {"timestamp": [683.32, 685.44], "text": " that. And to be fair, NASA"}, {"timestamp": [685.44, 691.18], "text": " and NASA and ESA basically have that rule, which is one of the reasons"}, {"timestamp": [691.18, 696.44], "text": " why satellites and spaceships and like lunar rovers and Mars rovers are"}, {"timestamp": [696.44, 700.84], "text": " sterilized, is because we don't want to introduce any bacterium to another"}, {"timestamp": [700.84, 705.8], "text": " celestial body that didn't belong there. So yes, good idea."}, {"timestamp": [705.8, 713.2], "text": " VMScode, what is your opinion on maximal extractable value or minor extractable value and how it"}, {"timestamp": [713.2, 714.2], "text": " relates to GATU?"}, {"timestamp": [714.2, 715.84], "text": " I'm not familiar with that term."}, {"timestamp": [715.84, 723.32], "text": " Do you mean, is that like extraction-based economies?"}, {"timestamp": [723.32, 730.92], "text": " Is that a mineral or a material-based extraction, or is that another kind of extraction?"}, {"timestamp": [730.92, 732.26], "text": " Let's see."}, {"timestamp": [732.26, 733.8], "text": " Pretty sure this guy is just crazy."}, {"timestamp": [733.8, 734.8], "text": " Yes, that's true."}, {"timestamp": [734.8, 735.8], "text": " Next question."}, {"timestamp": [735.8, 739.6], "text": " What kinds of projects are you going to be hacking on during this hackathon?"}, {"timestamp": [739.6, 743.04], "text": " Yeah, so let's talk about the hackathon in greater detail."}, {"timestamp": [743.04, 746.08], "text": " So the very first hackathon is layer one of Gato."}, {"timestamp": [746.08, 750.0], "text": " So layer one of Gato is the model alignment layer,"}, {"timestamp": [750.88, 758.4], "text": " which is, you know, with fine tuning and dataset curation and RLHF and everything else,"}, {"timestamp": [758.4, 761.68], "text": " we're finding that it's actually pretty easy to align models."}, {"timestamp": [761.68, 769.44], "text": " And yes, I know that there are problems because, you know, there's MESA optimization problems and other unintended consequences of"}, {"timestamp": [769.44, 774.2], "text": " aligning models. Those are all problems that I think are highly solvable. The"}, {"timestamp": [774.2, 778.64], "text": " biggest question is what do you align models to? And this is something that I"}, {"timestamp": [778.64, 783.52], "text": " realized recently is that when you look at solving alignment just through the"}, {"timestamp": [783.52, 785.92], "text": " lens of machine learning, it looks like"}, {"timestamp": [785.92, 787.4], "text": " an impossible problem."}, {"timestamp": [787.4, 793.36], "text": " But of course, machine like AGI, super intelligence, was never going to be a single model."}, {"timestamp": [793.36, 798.04], "text": " It does not behoove a super intelligent entity to rely on a single model."}, {"timestamp": [798.04, 802.16], "text": " We already know that that has fragility, and I think AGI will understand that too."}, {"timestamp": [802.16, 805.78], "text": " So AGI, we can expect expect is probably going to have an"}, {"timestamp": [805.78, 810.64], "text": " ensemble of expert style or thousand brain style where it has actually"}, {"timestamp": [810.64, 815.96], "text": " dozens, hundreds, thousands, maybe even millions of different kinds of models"}, {"timestamp": [815.96, 820.76], "text": " working in parallel that all have known biases and faults and strengths and"}, {"timestamp": [820.76, 826.64], "text": " weaknesses but by working in concert, by working together, they will overcome"}, {"timestamp": [826.64, 832.0], "text": " the faults and failures of each individual model. Now, that being said, you still need to have some"}, {"timestamp": [832.0, 837.68], "text": " higher order purpose. What is the core objective function that you're trying to optimize for?"}, {"timestamp": [837.68, 842.32], "text": " Now, of course, there's the concept of instrumental convergence, which says that regardless of what"}, {"timestamp": [842.32, 848.8], "text": " objectives an AI has, there will be some instrumental goals that it needs to pursue in order to pursue those other ones, such"}, {"timestamp": [848.8, 854.88], "text": " as self-preservation and acquiring of resources and so on and so forth."}, {"timestamp": [854.88, 861.28], "text": " All that being said, from a moral, from a philosophical, from an ethical, from an epistemic"}, {"timestamp": [861.28, 865.4], "text": " perspective, what I believe and what some people that think"}, {"timestamp": [865.4, 869.8], "text": " like I do believe, is that the concept of axiomatic alignment and reinforcement"}, {"timestamp": [869.8, 874.92], "text": " learning with heuristic imperatives is the way to go. So the first hackathon is"}, {"timestamp": [874.92, 878.8], "text": " the RLHI hackathon, reinforcement learning with heuristic imperatives. So"}, {"timestamp": [878.8, 882.4], "text": " basically you're familiar with RLHF, reinforcement learning with human"}, {"timestamp": [882.4, 890.24], "text": " feedback. You're probably also familiar with Anthropx constitutional AI. There's also a handful of other similar papers that we've"}, {"timestamp": [890.24, 897.52], "text": " got cited here at the bottom, but the TLDR is let's do RLHF except RLHI. It's been done before,"}, {"timestamp": [897.52, 906.3], "text": " but what we want to do is have teams practice aligning open source models"}, {"timestamp": [906.3, 909.58], "text": " and creating those tuning mechanisms that"}, {"timestamp": [909.58, 913.42], "text": " will allow the models to continuously get better"}, {"timestamp": [913.42, 916.08], "text": " at the heuristic comparatives over time."}, {"timestamp": [916.08, 919.52], "text": " Because this is what I believe is"}, {"timestamp": [919.52, 923.42], "text": " one of the core components of solving alignment and the control"}, {"timestamp": [923.42, 923.98], "text": " problem."}, {"timestamp": [923.98, 926.24], "text": " And it's not saying like, oh, it needs"}, {"timestamp": [926.24, 931.92], "text": " to align to human values. No, it needs to align to universal values. And to be fair, so do we."}, {"timestamp": [932.48, 937.2], "text": " But that's the point. That's literally the underpinning assertion of axiomatic alignment,"}, {"timestamp": [937.2, 943.52], "text": " is that we humans need to not put ourselves front and center. We need to recognize ourselves as"}, {"timestamp": [943.52, 950.72], "text": " animals as part of a larger ecosystem. And then we need to learn to play nice with everyone. And then if we find common ground"}, {"timestamp": [950.72, 957.12], "text": " with all other organisms and intelligent entities, then everything should be okay. And that's a very,"}, {"timestamp": [957.12, 962.24], "text": " very like ultra simplified way of doing it. All right. Good question. Let's see what else we got."}, {"timestamp": [961.6, 962.96], "text": " All right, good question. Let's see what else we got."}, {"timestamp": [964.4, 965.48], "text": " Let's see."}, {"timestamp": [966.84, 968.88], "text": " Hello, Dave, I read your books on GitHub."}, {"timestamp": [968.88, 971.64], "text": " I'm still a student, but the work seemed good to me."}, {"timestamp": [971.64, 974.92], "text": " I would love to know why you think Ben Goertzel's"}, {"timestamp": [974.92, 976.8], "text": " AGI approach is not that relevant."}, {"timestamp": [978.04, 983.04], "text": " Yeah, so Ben Goertzel, I mean, there are some overlaps,"}, {"timestamp": [983.72, 985.0], "text": " you know, like with,"}, {"timestamp": [985.88, 987.24], "text": " I can't remember the name of the network"}, {"timestamp": [987.24, 990.54], "text": " that he's creating, but he's got some similar ideas."}, {"timestamp": [990.54, 993.02], "text": " It just seems like there's not much execution."}, {"timestamp": [994.6, 996.96], "text": " And like, okay, you can have the greatest theory"}, {"timestamp": [996.96, 998.72], "text": " in the world, but unless there's execution,"}, {"timestamp": [998.72, 1002.12], "text": " unless there's work, then it's not gonna go anywhere."}, {"timestamp": [1002.12, 1005.0], "text": " And I don't think that he's got the clearest vision."}, {"timestamp": [1005.0, 1008.0], "text": " And he's certainly not that good at communicating it."}, {"timestamp": [1008.0, 1011.0], "text": " Like, he hasn't said, like, here's a reference architecture."}, {"timestamp": [1011.0, 1013.0], "text": " Here is a diagram. Build this."}, {"timestamp": [1013.0, 1016.0], "text": " Instead, his general theory of general intelligence"}, {"timestamp": [1016.0, 1023.0], "text": " is like 150 pages of relatively opaque science jargon."}, {"timestamp": [1023.0, 1024.0], "text": " So, who knows?"}, {"timestamp": [1024.0, 1026.06], "text": " Maybe he actually does know"}, {"timestamp": [1026.06, 1030.68], "text": " what he's talking about, but it's not easy to get across. And one thing that"}, {"timestamp": [1030.68, 1034.42], "text": " I'm concerned about is that a lot of people dress up what they're talking"}, {"timestamp": [1034.42, 1038.22], "text": " about in more obscure terms, because a lot of people automatically interpret"}, {"timestamp": [1038.22, 1041.74], "text": " that as like, oh, I don't know what this guy's talking about, so maybe, like, maybe"}, {"timestamp": [1041.74, 1045.52], "text": " he is smarter than me. But he isn't so I don't"}, {"timestamp": [1045.52, 1050.4], "text": " know. Anyways I've said in the past like yes he's made a name for himself but"}, {"timestamp": [1050.4, 1054.8], "text": " LLMs have been out for a while and he doesn't seem to have adopted to the new"}, {"timestamp": [1054.8, 1060.56], "text": " science the new technology so we'll see time will tell. Next one can you say"}, {"timestamp": [1060.56, 1066.4], "text": " something about the ones that has access to GPT-4 in terms of alignment"}, {"timestamp": [1066.4, 1069.06], "text": " and purpose branches?"}, {"timestamp": [1069.06, 1074.14], "text": " I'm wondering if you mean Tree of Thought, and if they'll be a good fit to the Gato community."}, {"timestamp": [1074.14, 1077.52], "text": " I mean, OpenAI gave access to a few areas."}, {"timestamp": [1077.52, 1079.84], "text": " So I have access to chat GPT-4."}, {"timestamp": [1079.84, 1087.92], "text": " I don't have access to the foundation GPT-4. But I will say that the underlying work"}, {"timestamp": [1087.92, 1089.64], "text": " that OpenAI has done on alignment"}, {"timestamp": [1089.64, 1095.44], "text": " is very apparent if you compare the latest iteration of chat"}, {"timestamp": [1095.44, 1100.88], "text": " GPT to the foundation models, in particular DaVinci."}, {"timestamp": [1100.88, 1103.84], "text": " DaVinci can be completely unhinged,"}, {"timestamp": [1103.84, 1108.16], "text": " just like we saw with Bing or BART or whatever, the"}, {"timestamp": [1108.16, 1111.2], "text": " Bing AI chatbot."}, {"timestamp": [1111.2, 1116.64], "text": " It doesn't make any sense when you first use it because it is super not aligned."}, {"timestamp": [1116.64, 1120.36], "text": " So they are going in a really good direction on alignment."}, {"timestamp": [1120.36, 1125.68], "text": " Now that being said, I don't fully agree and I think Sam Altman has said they know"}, {"timestamp": [1125.68, 1131.66], "text": " full well that RLHF is not the be-all, end-all for alignment."}, {"timestamp": [1131.66, 1135.2], "text": " That being said, I have been a little bit disappointed because Sam Altman and others"}, {"timestamp": [1135.2, 1139.42], "text": " have constantly said, like, we have no idea how to align super intelligent AI."}, {"timestamp": [1139.42, 1142.16], "text": " We're going to keep building it, but we don't have any idea how to align it."}, {"timestamp": [1142.16, 1145.76], "text": " I'm like, that's not an acceptable answer to me."}, {"timestamp": [1147.4, 1149.36], "text": " So let's see, Lance, can you go into more details about the feedback"}, {"timestamp": [1149.36, 1150.84], "text": " you want to get from software architects"}, {"timestamp": [1150.84, 1153.84], "text": " when it comes to alignment in cloud deployments?"}, {"timestamp": [1153.84, 1155.32], "text": " Yeah, so I don't want to,"}, {"timestamp": [1155.32, 1158.28], "text": " so what Lance is referring to is I put an all call"}, {"timestamp": [1158.28, 1163.28], "text": " on LinkedIn where I want to interview enterprise architects,"}, {"timestamp": [1163.44, 1165.48], "text": " but basically I want to talk to them about"}, {"timestamp": [1165.48, 1167.76], "text": " how they would go about deploying AGI."}, {"timestamp": [1167.76, 1170.76], "text": " Because there's this big thing where people keep"}, {"timestamp": [1170.76, 1173.66], "text": " asking data scientists and"}, {"timestamp": [1173.66, 1176.6], "text": " ML researchers and philosophers about AGI,"}, {"timestamp": [1176.6, 1179.64], "text": " but no one's actually talked to software architects."}, {"timestamp": [1179.64, 1182.6], "text": " I think that there's probably a huge need for"}, {"timestamp": [1182.6, 1184.56], "text": " the general public to understand a little bit"}, {"timestamp": [1184.56, 1186.26], "text": " more about how software actually works"}, {"timestamp": [1186.84, 1189.32], "text": " Because regardless of the underlying models"}, {"timestamp": [1190.04, 1195.62], "text": " AGI is not going to be a single model sitting in a box. It needs input. It needs output. It needs data"}, {"timestamp": [1195.62, 1202.86], "text": " It needs pipelines. It needs hardware, right? It needs hardware. It needs software. It needs version control"}, {"timestamp": [1202.94, 1205.68], "text": " There's so much that goes into developing software,"}, {"timestamp": [1205.68, 1208.08], "text": " even if it's a relatively small piece of software."}, {"timestamp": [1208.96, 1212.56], "text": " And then there's, of course, a tremendous amount that goes into developing and training models."}, {"timestamp": [1213.12, 1216.08], "text": " So what I want to do is I want to talk to software architects"}, {"timestamp": [1217.12, 1222.72], "text": " to talk about what it takes to actually deploy intelligent systems in today's world."}, {"timestamp": [1223.6, 1224.24], "text": " Good question."}, {"timestamp": [1227.64, 1234.36], "text": " RLHF, Real Life Hugging Face. Have you read the article proving GPT-4 didn't ace the MIT courses?"}, {"timestamp": [1234.36, 1237.4], "text": " I've heard about that and"}, {"timestamp": [1237.4, 1241.4], "text": " so here's the thing is"}, {"timestamp": [1241.4, 1246.76], "text": " this kind of back and forth has been happening since GPT-3, where it's like, it did this"}, {"timestamp": [1246.76, 1247.76], "text": " thing, no it didn't."}, {"timestamp": [1247.76, 1252.4], "text": " And a big part of it is, one, people don't know how to prompt the thing."}, {"timestamp": [1252.4, 1258.08], "text": " And so because there's a huge gap in prompting and understanding how does it actually work,"}, {"timestamp": [1258.08, 1264.9], "text": " you can have one person honestly give their best and come to the honest, sincere conclusion,"}, {"timestamp": [1264.9, 1265.76], "text": " this thing is an idiot."}, {"timestamp": [1265.76, 1271.32], "text": " But really it's that they don't know how to prompt the thing. They don't have a good mental model of how this model works."}, {"timestamp": [1271.92, 1274.96], "text": " So what generally what you're seeing when you see these"}, {"timestamp": [1275.6, 1282.12], "text": " completely polar opposite opinions is a lack of methodology."}, {"timestamp": [1283.48, 1288.0], "text": " Keep in mind that the academic establishment has not yet"}, {"timestamp": [1288.0, 1292.2], "text": " fully built new benchmarks to even engage"}, {"timestamp": [1292.2, 1293.8], "text": " with large language models."}, {"timestamp": [1293.8, 1296.38], "text": " When GPT-3 first came out, they just"}, {"timestamp": [1296.38, 1299.28], "text": " applied traditional NLP benchmarks to it,"}, {"timestamp": [1299.28, 1301.2], "text": " which is like, OK, but you're dealing"}, {"timestamp": [1301.2, 1303.76], "text": " with a fundamentally different kind of technology."}, {"timestamp": [1303.76, 1306.4], "text": " So this, to me, looks mostly like a methods problem."}, {"timestamp": [1306.4, 1308.68], "text": " Let's see."}, {"timestamp": [1308.68, 1314.28], "text": " MEV is a centralization force that happens on blockchains as a result of the incentive"}, {"timestamp": [1314.28, 1316.84], "text": " to control the order flow of transaction for profit."}, {"timestamp": [1316.84, 1318.12], "text": " DEX arbitrage."}, {"timestamp": [1318.12, 1320.36], "text": " That is way over my head on blockchain."}, {"timestamp": [1320.36, 1328.5], "text": " I probably need to know more about that, but it sounds like that's a pretty cool concept."}, {"timestamp": [1328.5, 1333.08], "text": " Let's see, I believe MEV is directly correlated with AGI alignment since they are both about"}, {"timestamp": [1333.08, 1337.98], "text": " finding the optimal balance of power in a network of nodes transacting with each other."}, {"timestamp": [1337.98, 1338.98], "text": " That sounds like game theory."}, {"timestamp": [1338.98, 1341.66], "text": " I'll have to look that up."}, {"timestamp": [1341.66, 1346.12], "text": " Let's see, Uncle James, is the Gato community looking into making agents which are pre-packaged"}, {"timestamp": [1346.12, 1351.76], "text": " to help the community and research, ones that could be run with consumer hardware and all"}, {"timestamp": [1351.76, 1353.04], "text": " have access to?"}, {"timestamp": [1353.04, 1354.32], "text": " Yes, actually."}, {"timestamp": [1354.32, 1357.72], "text": " So this is a good question, Uncle James."}, {"timestamp": [1357.72, 1362.24], "text": " One of the people that I'm in communication with is actually working on, I don't want"}, {"timestamp": [1362.24, 1365.04], "text": " to give too much away because he's not ready to launch,"}, {"timestamp": [1369.6, 1376.72], "text": " but basically working on that. There's a few people working on that exact problem inside the Gato and outside Gato. So to add a little bit of context to this, the idea is that"}, {"timestamp": [1377.68, 1382.24], "text": " Sam Altman and others have said like, oh it's wrong to think about AI as a creature, it's not"}, {"timestamp": [1382.24, 1385.36], "text": " a creature. It's like, yeah, but it's pretty easy"}, {"timestamp": [1385.36, 1391.68], "text": " to give this thing some autonomy. And if OpenAI doesn't build autonomous agents, somebody else"}, {"timestamp": [1391.68, 1397.76], "text": " will. So the idea then is, okay, well, what is a reference architecture for an autonomous agent?"}, {"timestamp": [1398.48, 1403.44], "text": " What does it do? And then how do they communicate with each other? But also, how do you make them"}, {"timestamp": [1403.44, 1405.88], "text": " deployable so that you don't need coding?"}, {"timestamp": [1405.88, 1410.76], "text": " And this is going to happen by the end of 2023, by the way,"}, {"timestamp": [1410.76, 1414.76], "text": " is there will be no code autonomous agents that"}, {"timestamp": [1414.76, 1417.88], "text": " are click, push button, get autonomous agent that"}, {"timestamp": [1417.88, 1420.28], "text": " is capable of x, y, and z."}, {"timestamp": [1420.28, 1421.96], "text": " That's coming very soon."}, {"timestamp": [1421.96, 1424.52], "text": " So the short answer is, yes, people are working on that."}, {"timestamp": [1424.52, 1426.0], "text": " And that's actually going to be one of our upcoming"}, {"timestamp": [1426.2, 1434.08], "text": " Hackathons, so basically my plan if it works out is to run a hackathon for every layer of Gato"}, {"timestamp": [1434.6, 1436.44], "text": " starting with the ground layer"}, {"timestamp": [1436.44, 1441.56], "text": " but that means that layer 2 the next hackathon that we put on is going to be for"}, {"timestamp": [1442.2, 1445.34], "text": " Autonomous agents and I haven't quite figured out how that's"}, {"timestamp": [1445.34, 1450.04], "text": " gonna look yet. It took a couple weeks of workshopping the RLHI hackathon to get"}, {"timestamp": [1450.04, 1455.36], "text": " it to where it is, and it looks pretty solid. But as far as getting the Layer 2"}, {"timestamp": [1455.36, 1459.16], "text": " hackathon put together, it'll be coming, but we're only gonna do one at a time."}, {"timestamp": [1459.16, 1467.28], "text": " Oh, also speaking of hackathons, if you want to sponsor one, I am happy to have a talk with you."}, {"timestamp": [1468.08, 1474.0], "text": " Whether you're a private individual, an investor, or a corporation who wants to sponsor a hackathon,"}, {"timestamp": [1474.0, 1479.6], "text": " that would be great. Even if you have a technology platform, just as a for instance,"}, {"timestamp": [1479.6, 1488.84], "text": " I'm not saying that this is actually going to happen, but since I've since I've talked with Pinecone before I'll use their name. If, for instance, Pinecone wanted to"}, {"timestamp": [1488.84, 1493.0], "text": " sponsor a hackathon and part of the requirements was that whatever solution"}, {"timestamp": [1493.0, 1497.8], "text": " they built you had to use Pinecone, I'd be okay with that. So Pinecone, I know"}, {"timestamp": [1497.8, 1505.44], "text": " James you're probably watching, reach out to me if you want, or anyone else who wants to sponsor a hackathon."}, {"timestamp": [1505.44, 1509.92], "text": " I'd be happy to follow up with that."}, {"timestamp": [1509.92, 1511.96], "text": " Let's see, we got a question on the Discord."}, {"timestamp": [1511.96, 1516.12], "text": " Is the Got2Dot2 community still reviewing applications for positions, or is it an open"}, {"timestamp": [1516.12, 1518.84], "text": " forum now?"}, {"timestamp": [1518.84, 1522.84], "text": " And if the Star Trek uniform is required, I'll need one in blue as I'm human development."}, {"timestamp": [1522.84, 1530.8], "text": " Yeah, so great question about how the community works. So we have it is it is fully open the doors are"}, {"timestamp": [1530.8, 1536.8], "text": " open but there are tiered there's gate kept tiers just as with all large"}, {"timestamp": [1536.8, 1544.32], "text": " organizations you do need a little bit of a of a hierarchy. So we are we have we"}, {"timestamp": [1544.32, 1548.92], "text": " have a core team of community leaders, we have all the original"}, {"timestamp": [1548.92, 1553.5], "text": " members are kind of like we're grandfathered in at a higher level, and then we're working"}, {"timestamp": [1553.5, 1561.2], "text": " on a more sophisticated tiering system that is going to be based on reputation, consensus,"}, {"timestamp": [1561.2, 1569.32], "text": " merit. We're still working that out, but basically everyone is welcome in and then there are some gatekept areas just to ensure that"}, {"timestamp": [1570.32, 1572.32], "text": " that people"}, {"timestamp": [1573.0, 1575.0], "text": " To maintain the signal-to-noise ratio"}, {"timestamp": [1575.44, 1580.44], "text": " But one thing that I want to point out is that this is primarily not up to me anymore"}, {"timestamp": [1580.44, 1585.52], "text": " I my role in the goto community is I'm the prime attractor. I'm"}, {"timestamp": [1585.52, 1588.32], "text": " the face, I'm the voice, I have the vision,"}, {"timestamp": [1588.32, 1590.84], "text": " but it's really, it's already fully a"}, {"timestamp": [1590.84, 1594.48], "text": " community thing. So most, almost all the"}, {"timestamp": [1594.48, 1598.0], "text": " work that was done to get ready was"}, {"timestamp": [1598.0, 1599.76], "text": " done by the team and based on the"}, {"timestamp": [1599.76, 1602.6], "text": " consensus that the team came to. And"}, {"timestamp": [1602.6, 1609.58], "text": " I am very much like, one, impressed by that because they did it in a couple days."}, {"timestamp": [1609.58, 1611.84], "text": " So they were already ahead of schedule."}, {"timestamp": [1611.84, 1617.26], "text": " And two, this is really good practice for the decentralized aspect of Gato, because"}, {"timestamp": [1617.26, 1621.78], "text": " if it all relies on me, then I am the bottleneck and I don't want to be the bottleneck."}, {"timestamp": [1621.78, 1627.76], "text": " And so, but what that requires is that required the rest of the team to step up, to stretch"}, {"timestamp": [1627.76, 1631.78], "text": " themselves, to step out of their comfort zone, take on ownership and that sort of thing."}, {"timestamp": [1631.78, 1632.78], "text": " But that's good."}, {"timestamp": [1632.78, 1633.78], "text": " That's good."}, {"timestamp": [1633.78, 1636.68], "text": " What's the word that I'm looking for?"}, {"timestamp": [1636.68, 1637.68], "text": " Practice."}, {"timestamp": [1637.68, 1642.88], "text": " It's good practice for the team because then that's a new skill that everyone has."}, {"timestamp": [1642.88, 1647.84], "text": " And so this is one thing that is a primary focus of the Gato community"}, {"timestamp": [1647.84, 1651.04], "text": " is that education, that empowerment, and that enablement."}, {"timestamp": [1651.04, 1655.04], "text": " And so by educating, empowering, and enabling other members of the community,"}, {"timestamp": [1655.04, 1657.52], "text": " that raises the capacity of everyone."}, {"timestamp": [1657.52, 1659.2], "text": " Right? You teach a man to fish, right?"}, {"timestamp": [1659.2, 1661.28], "text": " That's the basic, basic idea."}, {"timestamp": [1662.56, 1663.6], "text": " So let's see."}, {"timestamp": [1670.48, 1674.8], "text": " So... basic idea. So let's see. So I'm not sure what the video says but Yannick I guess agrees or disagrees with the MIT thing. Thanks for the answer. Cool. Yes, we are"}, {"timestamp": [1674.8, 1679.72], "text": " nerds. Did somebody mention coins? So Yikes is our resident blockchain and DAO"}, {"timestamp": [1679.72, 1686.12], "text": " guy and he's a trip. Okay let's see we got some questions that's really good here"}, {"timestamp": [1686.12, 1691.08], "text": " to eager see and run them. I was referring to what they asked for, asked"}, {"timestamp": [1691.08, 1694.8], "text": " for access they filled out a form to their particular attention I guess"}, {"timestamp": [1694.8, 1700.68], "text": " something good they will have in mind as researchers. Oh yes so regarding"}, {"timestamp": [1700.68, 1707.2], "text": " regarding the application. No we haven't fully done away with roles because we've got"}, {"timestamp": [1707.2, 1709.44], "text": " to segment it into layers."}, {"timestamp": [1709.44, 1714.8], "text": " But that being said, if someone has a particular project that they want to do or something"}, {"timestamp": [1714.8, 1718.42], "text": " that they want to get involved with, it's not up to us."}, {"timestamp": [1718.42, 1721.48], "text": " It's not saying, it's not like we're hiring for any particular role."}, {"timestamp": [1721.48, 1727.16], "text": " It is an open door policy that we want to attract. We want to attract all kinds of people."}, {"timestamp": [1727.16, 1731.08], "text": " And we want to make those serendipitous connections."}, {"timestamp": [1731.08, 1734.36], "text": " And then also, the central part of it"}, {"timestamp": [1734.36, 1738.0], "text": " is to put on some of the hackathons and networking"}, {"timestamp": [1738.0, 1745.0], "text": " events to ensure that we get output, get results."}, {"timestamp": [1745.16, 1746.06], "text": " Yes, good questions."}, {"timestamp": [1746.06, 1748.7], "text": " Let me see if there's any over here."}, {"timestamp": [1750.66, 1752.14], "text": " Dow, what are you talking about over here?"}, {"timestamp": [1752.14, 1753.74], "text": " It's working, yep."}, {"timestamp": [1755.3, 1756.66], "text": " I guess there's people jumping in."}, {"timestamp": [1756.66, 1758.9], "text": " Oh yeah, we've got people jumping in."}, {"timestamp": [1758.9, 1760.72], "text": " Some introductions."}, {"timestamp": [1762.62, 1763.82], "text": " Oh yeah, we are streaming."}, {"timestamp": [1763.82, 1769.32], "text": " Ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha. Sounds good. Oh yeah, we are streaming."}, {"timestamp": [1769.32, 1771.96], "text": " Sounds good."}, {"timestamp": [1771.96, 1774.52], "text": " To aim in Brisbane, catch the start later."}, {"timestamp": [1774.52, 1777.24], "text": " Yes, it is late."}, {"timestamp": [1777.24, 1778.72], "text": " It's interesting."}, {"timestamp": [1778.72, 1783.52], "text": " If we have Australians in the chat, tell me why, what is it about my work that resonates"}, {"timestamp": [1783.52, 1790.8], "text": " with Australians so much? Because it's like there's Americans and you know a little bit of North and South America,"}, {"timestamp": [1790.8, 1794.2], "text": " we've got a few Europeans, but then a lot of Australians."}, {"timestamp": [1794.2, 1798.76], "text": " What is it about like Gato and our work that resonates with Australians?"}, {"timestamp": [1798.76, 1800.24], "text": " Please tell me, I want to know."}, {"timestamp": [1800.24, 1828.8], "text": " You're welcome, growth minded. Hey, Philippe. See if any comments are going. See competition just what I needed."}, {"timestamp": [1829.5, 1830.1], "text": " All right."}, {"timestamp": [1832.1, 1832.7], "text": " Nobody's telling me why the Australians are here. Australians."}, {"timestamp": [1832.7, 1833.6], "text": " Why are you here?"}, {"timestamp": [1835.4, 1836.9], "text": " Good question so far everybody."}, {"timestamp": [1841.4, 1844.0], "text": " And unfortunately, there is stuff that I can't quite share"}, {"timestamp": [1844.0, 1846.34], "text": " yet because like again, it's"}, {"timestamp": [1846.34, 1851.48], "text": " not entirely up to me or it's not my shtick or some people are not ready to launch, that"}, {"timestamp": [1851.48, 1855.48], "text": " sort of thing."}, {"timestamp": [1855.48, 1872.28], "text": " Yep, we got some people coming in. Oh, so for anyone who just joined the live stream, oh wow, we got 77 currently, cool."}, {"timestamp": [1872.28, 1880.54], "text": " So for anyone who just joined, you can go to gato.com, or sorry, gatoframework.org slash"}, {"timestamp": [1880.54, 1885.88], "text": " join-gato, and you can jump into the server right now. It's fully open"}, {"timestamp": [1891.48, 1892.06], "text": " That reminds me. I need to update my video descriptions to all include this. But yeah, so that's that"}, {"timestamp": [1898.44, 1899.6], "text": " That's that's one of the big things. There is a couple questions or a minute ago about how the how the community works now"}, {"timestamp": [1900.96, 1902.96], "text": " but Australians"}, {"timestamp": [1901.8, 1907.96], "text": " But Australians. Let's see."}, {"timestamp": [1907.96, 1912.68], "text": " I've been studying AI for years now, but we're in the critical stage and you're moving fast."}, {"timestamp": [1912.68, 1916.2], "text": " Okay, that's fine."}, {"timestamp": [1916.2, 1921.32], "text": " We should have called the bot Happy Bot."}, {"timestamp": [1921.32, 1925.0], "text": " But yeah, so definitely AI has been,"}, {"timestamp": [1925.44, 1928.84], "text": " you know, it was interesting because I remember"}, {"timestamp": [1928.84, 1933.48], "text": " when I first saw Word2Vec,"}, {"timestamp": [1933.48, 1938.14], "text": " like Google's universal sentence encoder,"}, {"timestamp": [1938.14, 1941.8], "text": " when it first came out on TensorFlow 1."}, {"timestamp": [1942.72, 1947.36], "text": " Let's see if I can find... Whoops, I'll come back."}, {"timestamp": [1947.36, 1955.04], "text": " TensorFlow Hub, text, come back to TensorFlow 1."}, {"timestamp": [1955.04, 1956.04], "text": " Where is it?"}, {"timestamp": [1956.04, 1959.56], "text": " It's just a pile of models."}, {"timestamp": [1959.56, 1961.36], "text": " Got binders full of models."}, {"timestamp": [1961.36, 1964.16], "text": " It's a deep cut."}, {"timestamp": [1964.16, 1966.56], "text": " Let me know if you know where that came from."}, {"timestamp": [1966.56, 1975.02], "text": " All right, there's Universal Sentence Encoder, English, French, Universal."}, {"timestamp": [1975.02, 1982.4], "text": " There we go."}, {"timestamp": [1982.4, 1983.4], "text": " Universal Sentence Encoder Lite."}, {"timestamp": [1983.4, 1985.64], "text": " When did this one come out?"}, {"timestamp": [1985.64, 1990.04], "text": " Hub Module V2, Tunable, yes."}, {"timestamp": [1990.04, 1991.96], "text": " This one looks like it's actually newer."}, {"timestamp": [1991.96, 1996.96], "text": " 2018, yeah, that's not the oldest one."}, {"timestamp": [1996.96, 2000.44], "text": " QA Large, when did this one come out?"}, {"timestamp": [2000.44, 2001.44], "text": " 2019."}, {"timestamp": [2001.44, 2005.84], "text": " Anyways, sorry, got sidetracked. Point being is that that is the"}, {"timestamp": [2005.84, 2014.96], "text": " progenitor technology that was the prelude to the current wave of LLMs."}, {"timestamp": [2014.96, 2020.88], "text": " Alright, let's see if there's any comments. Oh cool, we've got some."}, {"timestamp": [2030.5, 2036.18], "text": " Let's see, not fully open, mostly open. Any medium to large model in the works that works on principles of distributed computing?"}, {"timestamp": [2036.18, 2037.42], "text": " Yes."}, {"timestamp": [2037.42, 2049.22], "text": " So we are working on, well, I guess I'm not working on a distributed language model, but there is pedals and Bloom"}, {"timestamp": [2049.22, 2052.94], "text": " and stuff like that that is partially, but what we're working on is going to be more"}, {"timestamp": [2052.94, 2054.92], "text": " blockchain based stuff."}, {"timestamp": [2054.92, 2059.18], "text": " So it's distributed computing in that there will be software nodes, not necessarily running"}, {"timestamp": [2059.18, 2063.94], "text": " a language model, but coordinating between autonomous agents."}, {"timestamp": [2063.94, 2066.04], "text": " I wonder if the AIs are going to think"}, {"timestamp": [2066.04, 2067.18], "text": " that people dying is funny,"}, {"timestamp": [2067.18, 2068.98], "text": " just like real humans on the internet."}, {"timestamp": [2068.98, 2071.08], "text": " If they did, they would be more human-like."}, {"timestamp": [2072.36, 2075.1], "text": " That's kind of, okay, that's fine."}, {"timestamp": [2075.1, 2080.06], "text": " Not many, I mean, only really cringy trolls think that."}, {"timestamp": [2081.26, 2083.32], "text": " Let's see, how will the hackathon be structured?"}, {"timestamp": [2083.32, 2087.88], "text": " Will there be a group thing and then split off teams or what?"}, {"timestamp": [2087.88, 2091.84], "text": " Oh, good question about the hackathon."}, {"timestamp": [2091.84, 2094.12], "text": " Let's see."}, {"timestamp": [2094.12, 2099.0], "text": " Nate here listening in, I have one of the gold shirts in my closet."}, {"timestamp": [2099.0, 2100.0], "text": " Excellent."}, {"timestamp": [2100.0, 2104.72], "text": " The gold are what, engineering, generally speaking?"}, {"timestamp": [2104.72, 2108.3], "text": " Because Jordy has a gold uniform."}, {"timestamp": [2108.3, 2110.6], "text": " Red is command track."}, {"timestamp": [2110.6, 2114.02], "text": " Blue is medical or science."}, {"timestamp": [2114.02, 2117.36], "text": " Or no, green is science, or like the sea foam green."}, {"timestamp": [2117.36, 2118.36], "text": " Anyways."}, {"timestamp": [2118.36, 2126.0], "text": " All right, so the hackathon structure is basically, we're probably going to run it the way that a lot of the smaller hackathons have been run,"}, {"timestamp": [2126.0, 2134.0], "text": " which is you will get your team together and then you'll register as a team, so register opening."}, {"timestamp": [2134.0, 2138.0], "text": " So here's some of the ideas that I had around the hackathon."}, {"timestamp": [2138.0, 2144.0], "text": " If you want to join a team, you can find a team in the Gato Community Discord."}, {"timestamp": [2144.0, 2145.68], "text": " We'll help facilitate that. If you want to join a team, you can find a team in the Gato community Discord."}, {"timestamp": [2145.68, 2147.96], "text": " We'll help facilitate that."}, {"timestamp": [2147.96, 2153.08], "text": " Then what we recommend is that you split off and probably make your own private Discord"}, {"timestamp": [2153.08, 2156.74], "text": " server or Slack or whatever tool you want to use to collaborate."}, {"timestamp": [2156.74, 2161.52], "text": " We have a few hackathon veterans in the Gato community, so if you ask nicely, they'll probably"}, {"timestamp": [2161.52, 2164.04], "text": " be willing to give you some pointers."}, {"timestamp": [2164.04, 2168.64], "text": " But basically, the current idea, like I said, I'm having a meeting with some hackathon"}, {"timestamp": [2168.64, 2172.32], "text": " veterans later today to get a little bit more clarity."}, {"timestamp": [2172.32, 2174.72], "text": " But basically it's going to be teams."}, {"timestamp": [2174.72, 2177.3], "text": " I'm thinking small teams."}, {"timestamp": [2177.3, 2181.04], "text": " One person that I'm talking to wants to try and get more corporate teams, which I think"}, {"timestamp": [2181.04, 2182.04], "text": " would be great."}, {"timestamp": [2182.04, 2185.96], "text": " If someone wants to have a Microsoft team or a Google team or an Amazon team,"}, {"timestamp": [2185.96, 2187.86], "text": " I would absolutely welcome that."}, {"timestamp": [2189.0, 2189.84], "text": " But that being said,"}, {"timestamp": [2189.84, 2192.44], "text": " we also do want to make sure that this is truly open"}, {"timestamp": [2192.44, 2196.0], "text": " so that you don't need to be part of a university"}, {"timestamp": [2196.0, 2199.24], "text": " or a megacorp in order to join the hackathon."}, {"timestamp": [2199.24, 2201.72], "text": " We want to make sure that this is open to everyone,"}, {"timestamp": [2201.72, 2204.42], "text": " whether they're students or private individuals"}, {"timestamp": [2204.42, 2209.42], "text": " or retirees or whoever, it is gonna be fully open."}, {"timestamp": [2210.06, 2212.86], "text": " So that's one thing that is like hard requirement"}, {"timestamp": [2212.86, 2216.38], "text": " and that's just like based on pure principle."}, {"timestamp": [2216.38, 2217.5], "text": " So good question."}, {"timestamp": [2217.5, 2220.66], "text": " Then as far as the date, like I said,"}, {"timestamp": [2220.66, 2223.14], "text": " we're still getting some information together,"}, {"timestamp": [2224.02, 2230.48], "text": " but basically what I wanna try and do is maybe launch it July 1st and let it run for the month"}, {"timestamp": [2230.48, 2236.8], "text": " of July. Not sure. Again, many hackathons are shorter. Most of them are one to two weeks,"}, {"timestamp": [2236.8, 2241.6], "text": " so we might do that. We're learning as we go, but good questions."}, {"timestamp": [2248.68, 2252.28], "text": " as we go, but good questions. Let's see, I have a theory that governmental AI for most functions won't be accepted and adopted until we have a generation who have grown up with"}, {"timestamp": [2252.28, 2260.16], "text": " LLMs and other advanced AI. Yeah, so that's actually a good point, Ryan. And I've thought"}, {"timestamp": [2260.16, 2271.64], "text": " about this, but here's the thing, and I mentioned this in my video coming up on Sunday, so you get a little sneak preview, is that governments are already using chat"}, {"timestamp": [2271.64, 2279.8], "text": " GPT. State departments, diplomatic corps, legislators, they're all using Bing and chat"}, {"timestamp": [2279.8, 2289.52], "text": " GPT and BARD and CLAWD, and they're already using it. So AI is already in government. Whether like that you can't stop it just because it makes their jobs"}, {"timestamp": [2289.52, 2295.52], "text": " easier and faster and so the question then is okay well how one how reliable"}, {"timestamp": [2295.52, 2299.6], "text": " is that how safe is it how secure etc etc I wouldn't be surprised if a lot of"}, {"timestamp": [2299.6, 2303.88], "text": " government departments ban it just for safety and security reasons but that"}, {"timestamp": [2303.88, 2309.48], "text": " being said if you ban a super useful tool, that puts you at a disadvantage for"}, {"timestamp": [2309.48, 2314.6], "text": " the people on the other side of the aisle or your diplomatic counterparts across the"}, {"timestamp": [2314.6, 2315.84], "text": " seas."}, {"timestamp": [2315.84, 2320.92], "text": " So I suspect that what we're going to see is some guidelines around how to integrate"}, {"timestamp": [2320.92, 2322.76], "text": " AI into government."}, {"timestamp": [2322.76, 2326.16], "text": " And then, so right now it's just a reactive tool, right?"}, {"timestamp": [2326.16, 2330.4], "text": " You know, as an AI assistant, I can't blah, blah, blah, who cares, right? That's going to go away"}, {"timestamp": [2330.4, 2336.88], "text": " before too long. What's going to happen instead is that the tools are going to be more and more"}, {"timestamp": [2336.88, 2342.08], "text": " autonomous. And then the idea is like, okay, well, as the tools do more and more of the work,"}, {"timestamp": [2342.08, 2345.06], "text": " then the humans are just there for ceremonial purposes."}, {"timestamp": [2345.26, 2352.1], "text": " So I think just by virtue of effectiveness, as these tools are designed and deployed to be safe,"}, {"timestamp": [2352.66, 2357.4], "text": " secure, and reliable, as long as they have a good track record, I think they're going to replace humans by default."}, {"timestamp": [2358.14, 2360.14], "text": " Honestly."}, {"timestamp": [2360.38, 2362.18], "text": " Let's see. Q."}, {"timestamp": [2362.18, 2366.6], "text": " Question. Has meritocracy been incorporated into the modeling so far?"}, {"timestamp": [2366.6, 2368.96], "text": " I haven't picked up on it being brought up."}, {"timestamp": [2368.96, 2373.76], "text": " Now by modeling do you mean for Gato?"}, {"timestamp": [2373.76, 2376.68], "text": " Get back to me what you mean by modeling great works."}, {"timestamp": [2376.68, 2383.88], "text": " Do you mean, oh I guess my wife is playing, she's playing Assassin's Creed in the other"}, {"timestamp": [2383.88, 2384.88], "text": " room."}, {"timestamp": [2384.88, 2386.48], "text": " Let's see, oh there's a lot of questions. She's playing Assassin's Creed in the other room."}, {"timestamp": [2386.48, 2388.74], "text": " Let's see, oh there's a lot of questions."}, {"timestamp": [2388.74, 2395.0], "text": " But meritocracy, so actually I was talking, if you mean Gato, I was talking about meritocracy"}, {"timestamp": [2395.0, 2401.04], "text": " and one of the ideas that I had was actually based partially on liquid democracy, but rather"}, {"timestamp": [2401.04, 2407.8], "text": " than directly electing a representative for an issue,"}, {"timestamp": [2407.8, 2414.5], "text": " the idea was actually that you would, through a series of runoffs, select the electoral college."}, {"timestamp": [2414.5, 2422.0], "text": " So the idea that I proposed to the Gato community was that, let's say we have a thousand members of Gato."}, {"timestamp": [2422.0, 2429.56], "text": " So what we do is we do a ranked choice runoff or ranked choice election where you take the"}, {"timestamp": [2429.56, 2435.0], "text": " top third of people that are elected and they're the electoral college rank one."}, {"timestamp": [2435.0, 2438.88], "text": " And then those people, because you're basically saying, these are the people that I want making"}, {"timestamp": [2438.88, 2443.8], "text": " decisions for me, or these are the people that I want to delegate responsibility to."}, {"timestamp": [2443.8, 2445.6], "text": " And so then you do that again with that rank"}, {"timestamp": [2445.6, 2452.48], "text": " one, you take a third of the the top third there and you end up with 111. You do that again, you"}, {"timestamp": [2452.48, 2458.0], "text": " end up with 37, you do it again, and you end up with 12. And so then basically what you do is"}, {"timestamp": [2458.0, 2466.6], "text": " through a process of runoff elections with ranked choice, basically creating an electoral college, you end up with like the group of 12 or however many,"}, {"timestamp": [2466.6, 2471.6], "text": " you know, the top group that you use for,"}, {"timestamp": [2471.94, 2474.86], "text": " they basically are the board of directors for the community."}, {"timestamp": [2474.86, 2477.38], "text": " And so those are the ones who are then responsible"}, {"timestamp": [2477.38, 2480.8], "text": " for appointing the, you know, the minister of finance"}, {"timestamp": [2480.8, 2485.64], "text": " or the czar for X, Y, or Z, or picking a community CEO."}, {"timestamp": [2487.2, 2488.72], "text": " That's the idea that I have."}, {"timestamp": [2488.72, 2491.42], "text": " And the idea is that that will naturally surface"}, {"timestamp": [2491.42, 2494.32], "text": " the people who are known in the community"}, {"timestamp": [2494.32, 2498.36], "text": " to have good judgment, who are natural leaders,"}, {"timestamp": [2498.36, 2499.96], "text": " who are popular, right?"}, {"timestamp": [2499.96, 2502.96], "text": " But the thing is, is you don't use democracy"}, {"timestamp": [2502.96, 2505.0], "text": " to pick the ruler, you use democracy to pick the ruler,"}, {"timestamp": [2505.34, 2508.22], "text": " you use democracy to pick the board that picks the ruler."}, {"timestamp": [2508.22, 2510.66], "text": " Right, it's a form of representative democracy"}, {"timestamp": [2510.66, 2512.46], "text": " or republicanism."}, {"timestamp": [2512.46, 2515.82], "text": " So that's kind of my thoughts as the community grows."}, {"timestamp": [2515.82, 2517.94], "text": " Again, we operate by consensus."}, {"timestamp": [2517.94, 2519.82], "text": " So if the community wants to go a different way,"}, {"timestamp": [2519.82, 2521.12], "text": " it can go a different way."}, {"timestamp": [2522.22, 2524.14], "text": " Are we limiting the programming to Python?"}, {"timestamp": [2524.14, 2526.84], "text": " No, you can use whatever programming you want."}, {"timestamp": [2526.84, 2530.64], "text": " The output for the RLHI hackathon"}, {"timestamp": [2530.64, 2534.4], "text": " is it just has to be an open source GitHub repo."}, {"timestamp": [2534.4, 2537.84], "text": " If all you have is the data, the documentation, and the models,"}, {"timestamp": [2537.84, 2538.44], "text": " that's fine."}, {"timestamp": [2538.44, 2540.16], "text": " We actually don't need to see the code."}, {"timestamp": [2540.16, 2542.52], "text": " All we need to do is see the evidence, the experiments,"}, {"timestamp": [2542.52, 2545.68], "text": " the data, and the model checkpoints."}, {"timestamp": [2546.32, 2547.28], "text": " Good question."}, {"timestamp": [2551.44, 2552.08], "text": " Have you tried GPT Engineer, the better version of AutoGPT? No, I haven't."}, {"timestamp": [2553.92, 2558.48], "text": " Remember, I started the work on autonomous agents two years ago."}, {"timestamp": [2559.6, 2560.48], "text": " Let's see."}, {"timestamp": [2560.48, 2565.1], "text": " As an Aussie, your views on AI feel very pragmatic, measured, and always"}, {"timestamp": [2565.1, 2568.7], "text": " well considered, so I tend to agree with your position the majority of the time."}, {"timestamp": [2568.7, 2569.7], "text": " Keep up the good work."}, {"timestamp": [2569.7, 2570.7], "text": " Okay, cool."}, {"timestamp": [2570.7, 2572.82], "text": " Yeah, no, like, I like Australians."}, {"timestamp": [2572.82, 2577.26], "text": " Y'all are pretty like, all the Australians that I've talked to, you're like, you're pretty"}, {"timestamp": [2577.26, 2582.66], "text": " just like down to earth people, like pretty realistic, which is nice."}, {"timestamp": [2582.66, 2586.5], "text": " Why isn't this docking?"}, {"timestamp": [2586.5, 2589.5], "text": " Come on. There we go."}, {"timestamp": [2589.5, 2591.5], "text": " Okay. Oh, wow."}, {"timestamp": [2591.5, 2593.5], "text": " I know one agency that has banned it."}, {"timestamp": [2593.5, 2595.0], "text": " Yeah, no doubt."}, {"timestamp": [2595.0, 2597.0], "text": " Anywhere here from Google?"}, {"timestamp": [2597.0, 2599.0], "text": " I'm not from Google."}, {"timestamp": [2599.0, 2601.5], "text": " Colossus, the forbidden project."}, {"timestamp": [2601.5, 2604.5], "text": " Government has been using AI since the 70s."}, {"timestamp": [2604.5, 2605.2], "text": " Pluto York, Diablo 4. Government has been using AI since the 70s."}, {"timestamp": [2605.2, 2607.56], "text": " Pluto York, Diablo 4."}, {"timestamp": [2607.56, 2608.88], "text": " There's too much data."}, {"timestamp": [2608.88, 2611.44], "text": " Do not use AI government or business."}, {"timestamp": [2611.44, 2613.44], "text": " There's no other way to get through all the data"}, {"timestamp": [2613.44, 2614.28], "text": " than to use AI."}, {"timestamp": [2614.28, 2617.92], "text": " Yes, I agree with that, especially as the world"}, {"timestamp": [2617.92, 2621.28], "text": " becomes more sophisticated and complicated."}, {"timestamp": [2621.28, 2623.08], "text": " There's going to be no other way."}, {"timestamp": [2623.08, 2627.04], "text": " It's not possible for a human to keep up with all the data."}, {"timestamp": [2627.04, 2628.92], "text": " You need AI."}, {"timestamp": [2628.92, 2631.96], "text": " Let's see."}, {"timestamp": [2631.96, 2635.68], "text": " I am the person that complains about live stream premieres."}, {"timestamp": [2635.68, 2636.68], "text": " Sorry."}, {"timestamp": [2636.68, 2641.88], "text": " I'll be forwarding the link to our first onboarded full stack dev."}, {"timestamp": [2641.88, 2643.6], "text": " He's also on this fundamental path."}, {"timestamp": [2643.6, 2648.12], "text": " The tribes are finding their estranged kin. Yeah that's true. For the longest time we were all"}, {"timestamp": [2648.12, 2652.52], "text": " operating in little echo chambers. Oh man, for y'all that are here, do you"}, {"timestamp": [2652.52, 2657.88], "text": " remember when it was like, I found one person, I found someone in the wild who"}, {"timestamp": [2657.88, 2661.68], "text": " knows what's going on, and now there are dozens of us, and then hundreds of us, and"}, {"timestamp": [2661.68, 2665.48], "text": " then we're all finding each other, And now the lunatics have taken over the asylum."}, {"timestamp": [2665.48, 2669.88], "text": " So hey, you know, that's where we're at."}, {"timestamp": [2669.88, 2675.24], "text": " Let's see, the UK has created an AI task force to look into foundation models."}, {"timestamp": [2675.24, 2680.0], "text": " Government and corporation work on AI does concern me a bit, trying to remain optimistic."}, {"timestamp": [2680.0, 2684.2], "text": " Yeah, so, you know, I think it's all of the above."}, {"timestamp": [2684.2, 2690.54], "text": " Obviously like we need to remain skeptical of concentrations of power and that includes in the government, right? Even if you have a fully"}, {"timestamp": [2691.26, 2697.9], "text": " Democratic government you don't want the power going to their heads and you don't want them to you know, whatever because humans are fallible"}, {"timestamp": [2698.62, 2702.02], "text": " And no no governmental system is perfect"}, {"timestamp": [2702.7, 2709.28], "text": " so it's like you you know, the government, corporations,"}, {"timestamp": [2709.28, 2716.08], "text": " and the people, and open source, and academics, we need all of the above with more or less equal"}, {"timestamp": [2716.08, 2721.2], "text": " access to artificial intelligence research in the long run. Obviously, there's lots of potential"}, {"timestamp": [2721.2, 2728.64], "text": " harms that can be done in the short term, you know, around like creating bioweapons and chemical weapons and stuff like that."}, {"timestamp": [2728.64, 2730.96], "text": " There is lots and lots of harm that can be done."}, {"timestamp": [2730.96, 2735.46], "text": " And that's just like if it gets into the hands of like, you know, terrorists or whatever."}, {"timestamp": [2735.46, 2740.08], "text": " But there's plenty of other unintentional harms that can be done through like algorithmic"}, {"timestamp": [2740.08, 2741.88], "text": " bias and stuff like that."}, {"timestamp": [2741.88, 2749.04], "text": " There's a book called Weapons of Math Destruction which talks about that and also a book called Automating Inequality."}, {"timestamp": [2749.04, 2756.24], "text": " Both of them underscore how machine intelligence can be inadvertently or"}, {"timestamp": [2756.24, 2761.16], "text": " advertently deliberately used to cause harm and perpetuate stereotypes and"}, {"timestamp": [2761.16, 2765.56], "text": " bias. And neither are good, so we want to avoid both."}, {"timestamp": [2765.56, 2767.6], "text": " Let's see, what do you think about the recent"}, {"timestamp": [2767.6, 2769.12], "text": " modular Mojo announcement?"}, {"timestamp": [2769.12, 2771.24], "text": " I'm not sure what that is."}, {"timestamp": [2771.24, 2773.04], "text": " Modular Mojo, let's look it up."}, {"timestamp": [2777.52, 2778.7], "text": " Mojo programming."}, {"timestamp": [2780.64, 2782.2], "text": " Mojo combines the usability of Python"}, {"timestamp": [2782.2, 2783.5], "text": " with the performance of C."}, {"timestamp": [2784.96, 2787.7], "text": " Well, I got some good news for you and some bad news for you."}, {"timestamp": [2787.7, 2792.32], "text": " This is not the first time someone has tried to fix Python with C."}, {"timestamp": [2792.32, 2798.2], "text": " There's Kython or however you pronounce it and plenty of other Python modules have been"}, {"timestamp": [2798.2, 2801.6], "text": " recompiled with C, whatever."}, {"timestamp": [2801.6, 2804.76], "text": " Everyone and their brother does this."}, {"timestamp": [2804.76, 2806.66], "text": " It's nothing new."}, {"timestamp": [2806.66, 2810.5], "text": " Okay, let's see, am I not getting any updates?"}, {"timestamp": [2812.98, 2814.74], "text": " No, okay, cool, cool."}, {"timestamp": [2815.92, 2817.34], "text": " Any more questions?"}, {"timestamp": [2817.34, 2820.52], "text": " Bueller, Bueller, going once, going twice,"}, {"timestamp": [2820.52, 2821.52], "text": " let's see if there's any in the chat."}, {"timestamp": [2821.52, 2824.3], "text": " Oh, there's 23 new messages."}, {"timestamp": [2824.3, 2826.44], "text": " Star Trek color meanings."}, {"timestamp": [2826.44, 2827.6], "text": " Lower Dex uniforms."}, {"timestamp": [2827.6, 2828.44], "text": " Oh yes."}, {"timestamp": [2829.2, 2832.84], "text": " Oh, it's ops."}, {"timestamp": [2832.84, 2835.64], "text": " Okay, so the yellow shirts are ops."}, {"timestamp": [2835.64, 2836.94], "text": " And there's a lot of ops."}, {"timestamp": [2842.36, 2844.08], "text": " Prem's UI is sexy."}, {"timestamp": [2844.08, 2847.12], "text": " I'm not sure what you're talking about, yikes."}, {"timestamp": [2847.12, 2848.68], "text": " I like the lower dex, yes."}, {"timestamp": [2848.68, 2851.72], "text": " UBI won't be a choice with no labor."}, {"timestamp": [2851.72, 2854.16], "text": " GPT engineer."}, {"timestamp": [2854.16, 2855.52], "text": " Finding our tribe."}, {"timestamp": [2855.52, 2856.08], "text": " Ha!"}, {"timestamp": [2856.08, 2858.0], "text": " Very clever, Seneca."}, {"timestamp": [2858.0, 2859.24], "text": " One million tokens."}, {"timestamp": [2861.92, 2865.72], "text": " All right, we definitely started something with the Trek."}, {"timestamp": [2865.72, 2868.46], "text": " You know, these uniforms are pretty sharp."}, {"timestamp": [2868.46, 2869.46], "text": " Maybe I should upgrade."}, {"timestamp": [2869.46, 2870.46], "text": " What do you think?"}, {"timestamp": [2870.46, 2877.16], "text": " Should I go from the Galaxy class to the Kali class outfit?"}, {"timestamp": [2877.16, 2880.36], "text": " All right."}, {"timestamp": [2880.36, 2881.36], "text": " Lower Dex, Lower Dex."}, {"timestamp": [2881.36, 2882.36], "text": " Long sleeves are better."}, {"timestamp": [2882.36, 2884.6], "text": " Yeah, the thing is, I overheat."}, {"timestamp": [2884.6, 2886.16], "text": " I am very hot-blooded."}, {"timestamp": [2888.08, 2892.4], "text": " AI should be able to self-reflect just because good words come out of it doesn't mean it's doing"}, {"timestamp": [2892.4, 2894.24], "text": " actually good. Yeah, totally agree."}, {"timestamp": [2895.68, 2898.96], "text": " Let's see, can we have a Gato meetup near my house where we all are required to"}, {"timestamp": [2899.6, 2903.04], "text": " wear Starfleet outfits? Yeah, you know, maybe,"}, {"timestamp": [2903.04, 2906.64], "text": " maybe, well, any Gato meetups I host."}, {"timestamp": [2906.64, 2914.64], "text": " That'll be a default requirement. The no code hackathon, you're only allowed prompting."}, {"timestamp": [2914.64, 2920.04], "text": " That could be fun. Yep. Okay, cool. So we've got a whole bunch of people flowing in. Looks"}, {"timestamp": [2920.04, 2925.2], "text": " like just in the last few minutes we've had about half a dozen or so people jump in."}, {"timestamp": [2925.2, 2926.2], "text": " Excellent."}, {"timestamp": [2926.2, 2927.2], "text": " Let's see."}, {"timestamp": [2927.2, 2928.2], "text": " All right."}, {"timestamp": [2928.2, 2936.88], "text": " Well, the questions seem to be tapering off, so if that's all we got, I might wrap up the"}, {"timestamp": [2936.88, 2937.88], "text": " stream."}, {"timestamp": [2937.88, 2940.6], "text": " We don't want it to be too big or crazy."}, {"timestamp": [2940.6, 2943.54], "text": " Going to modify Discord image generator to use stable diffusion."}, {"timestamp": [2943.54, 2945.04], "text": " That's cool."}, {"timestamp": [2945.04, 2948.08], "text": " Red shirts are always the first one to go."}, {"timestamp": [2948.08, 2950.44], "text": " Announcements."}, {"timestamp": [2950.44, 2951.44], "text": " Gato's grand opening."}, {"timestamp": [2951.44, 2952.44], "text": " So we are open."}, {"timestamp": [2952.44, 2953.44], "text": " We're open for business."}, {"timestamp": [2953.44, 2960.28], "text": " I'm going to send out a message on Twitter and LinkedIn and everywhere else letting everyone"}, {"timestamp": [2960.28, 2964.28], "text": " know that yes, indeed, Gato is open."}, {"timestamp": [2964.28, 2967.44], "text": " Let's see. Galaxy class only. I will"}, {"timestamp": [2967.44, 2973.48], "text": " unsub if you change the uniform. Alright, I will stay on Galaxy class. Did you see"}, {"timestamp": [2973.48, 2977.42], "text": " one of the last interviews with Altman where he says that he hopes to find a"}, {"timestamp": [2977.42, 2981.86], "text": " way to give open AI to humanity by having it democratically controlled by"}, {"timestamp": [2981.86, 2989.12], "text": " humanity? Yeah, I watched part of that, and he's said similar things before, which I think is a"}, {"timestamp": [2989.12, 2991.86], "text": " great sentiment."}, {"timestamp": [2991.86, 2999.22], "text": " But there's also kind of what I alluded to earlier is kind of the lack of caution demonstrated"}, {"timestamp": [2999.22, 3004.08], "text": " by open AI, where it's like Sam Altman has said, like, oh, we have no idea how to control"}, {"timestamp": [3004.08, 3007.48], "text": " superintelligence, but we're going gonna keep building it and deploying it anyways"}, {"timestamp": [3008.08, 3014.48], "text": " And and of course he didn't say that exactly but it's like, you know, I don't know if I fully agree with that that disposition"}, {"timestamp": [3015.2, 3020.72], "text": " That being said Jedi robe. Yes, I actually actually have a I want to buy a"}, {"timestamp": [3022.26, 3026.32], "text": " Travel a travel cloak like the Hobbits have from Ireland."}, {"timestamp": [3026.32, 3030.32], "text": " There's a 100% wool travel cloak, but it's like $230."}, {"timestamp": [3033.76, 3034.4], "text": " Let's see."}, {"timestamp": [3034.4, 3038.4], "text": " The first Python I ever wrote was following Dave's tutorial."}, {"timestamp": [3039.36, 3041.84], "text": " Yeah, I actually had a lot of people tell me that,"}, {"timestamp": [3042.4, 3045.68], "text": " especially around the end of last year and earlier this year, was a lot of people tell me that, especially around the end of last year and"}, {"timestamp": [3045.68, 3050.36], "text": " earlier this year was a lot of people said like, I got into coding and AI because of"}, {"timestamp": [3050.36, 3051.36], "text": " your tutorials."}, {"timestamp": [3051.36, 3056.62], "text": " So like, cool, I guess I did my job by bringing more people to the table."}, {"timestamp": [3056.62, 3061.16], "text": " And some of the people that have come are pretty smart, too."}, {"timestamp": [3061.16, 3064.76], "text": " Let's see, I feel like we're on the precipice of huge change, but it also feels like I'm"}, {"timestamp": [3064.76, 3068.4], "text": " the only one that thinks this way, even though among my online communities, so it's hard"}, {"timestamp": [3068.4, 3070.24], "text": " to know how indoctrinated I am."}, {"timestamp": [3070.24, 3074.52], "text": " You know, I wonder, I wonder about that."}, {"timestamp": [3074.52, 3076.76], "text": " Oh wait, sorry, there's a few other questions."}, {"timestamp": [3076.76, 3077.76], "text": " Hold on, hold on."}, {"timestamp": [3077.76, 3081.74], "text": " Yeah, okay, oh, I was answering the one about Sam Altman."}, {"timestamp": [3081.74, 3083.36], "text": " Have you looked into constitutional AI yet?"}, {"timestamp": [3083.36, 3085.56], "text": " Yes, I invented it."}, {"timestamp": [3086.4, 3087.32], "text": " Look it up."}, {"timestamp": [3088.94, 3091.16], "text": " Natural Language Cognitive Architecture. I published that book a month before Anthropic"}, {"timestamp": [3091.16, 3092.44], "text": " came into existence,"}, {"timestamp": [3092.44, 3096.24], "text": " where I basically said,"}, {"timestamp": [3096.24, 3098.72], "text": " you need to give it an AI constitution."}, {"timestamp": [3099.52, 3102.26], "text": " Okay, what are your latest thoughts"}, {"timestamp": [3102.26, 3104.96], "text": " on the latest advancements on quantum computing?"}, {"timestamp": [3104.96, 3105.04], "text": " So it's really interesting. Quantum computing seems to be fragmenting your latest thoughts on the latest advancements on quantum computing. So"}, {"timestamp": [3105.04, 3108.84], "text": " it's really interesting. Quantum computing seems to be fragmenting into"}, {"timestamp": [3108.84, 3112.2], "text": " different directions because there are some people that are like, oh you know we"}, {"timestamp": [3112.2, 3117.48], "text": " have billions of qubits and others that like we have 12. But what's the"}, {"timestamp": [3117.48, 3122.68], "text": " term? It's like there's like a number because quantum computing is so"}, {"timestamp": [3122.68, 3126.88], "text": " noisy that you have to compensate for the noise"}, {"timestamp": [3126.88, 3129.84], "text": " and the other faults."}, {"timestamp": [3129.84, 3130.96], "text": " It'll be interesting."}, {"timestamp": [3130.96, 3138.64], "text": " I think that quantum computing is going to prove to be really good at some tasks, but"}, {"timestamp": [3138.64, 3142.4], "text": " I don't know that it's ever going to replace conventional computing."}, {"timestamp": [3142.4, 3146.6], "text": " Just in the same way that a TPU or a GPU is not gonna replace the CPU,"}, {"timestamp": [3146.6, 3148.36], "text": " I fully anticipate that we're just gonna have"}, {"timestamp": [3148.36, 3151.08], "text": " a quantum code processor in every device."}, {"timestamp": [3151.08, 3151.92], "text": " Like, you know,"}, {"timestamp": [3151.92, 3153.92], "text": " cause you have tensor cores in your phone now."}, {"timestamp": [3153.92, 3156.68], "text": " So like you have a, you can have a tensor core, a GPU,"}, {"timestamp": [3156.68, 3159.36], "text": " a CPU, and then you'll have a quantum processing unit"}, {"timestamp": [3159.36, 3160.6], "text": " in your phone as well,"}, {"timestamp": [3160.6, 3161.96], "text": " which will help with some things like"}, {"timestamp": [3161.96, 3164.52], "text": " if you want to rapidly train a new model"}, {"timestamp": [3164.52, 3168.94], "text": " or evaluate, you know, genetics you know genetics like oh quantum processor that's how a"}, {"timestamp": [3168.94, 3172.86], "text": " tricorder works by the way that's how a tricorder like you just take the"}, {"timestamp": [3172.86, 3176.14], "text": " spectral analysis of someone you know of someone's skin and then you can read"}, {"timestamp": [3176.14, 3181.0], "text": " their DNA you could probably do that with quantum computing what is this oh"}, {"timestamp": [3181.0, 3186.84], "text": " it's a robot that looks familiar what is this from Oh, it's a robot. That looks familiar. What is this from? Okay, good question."}, {"timestamp": [3186.84, 3190.76], "text": " Good question."}, {"timestamp": [3190.76, 3191.76], "text": " Let's see."}, {"timestamp": [3191.76, 3192.76], "text": " I feel like we're on..."}, {"timestamp": [3192.76, 3196.68], "text": " Hold on."}, {"timestamp": [3196.68, 3199.32], "text": " Isn't one of Google's models called Gato?"}, {"timestamp": [3199.32, 3200.32], "text": " Yes, actually."}, {"timestamp": [3200.32, 3203.8], "text": " That's not why I used that name, though."}, {"timestamp": [3203.8, 3206.04], "text": " Let's see."}, {"timestamp": [3206.04, 3209.96], "text": " If anyone in the Portugal area interested in meeting, hit me up."}, {"timestamp": [3209.96, 3213.12], "text": " Just need to find some outfits."}, {"timestamp": [3213.12, 3217.68], "text": " 230 for 7 yards of fabric is not that expensive."}, {"timestamp": [3217.68, 3218.68], "text": " That's fair."}, {"timestamp": [3218.68, 3223.04], "text": " That's a fair point."}, {"timestamp": [3223.04, 3227.16], "text": " Currently democratic processes don't result in democratically distributed benefits."}, {"timestamp": [3227.16, 3229.32], "text": " That's a fair point."}, {"timestamp": [3229.32, 3231.04], "text": " Yeah."}, {"timestamp": [3231.04, 3237.0], "text": " Isn't Altman pretty much just a Microsoft executive promoting a Bing plugin?"}, {"timestamp": [3237.0, 3245.8], "text": " I can see how you'd have that misconception, but actually he started in Y Combinator. So Sam Altman is the CEO of"}, {"timestamp": [3245.8, 3252.6], "text": " OpenAI, which is tightly partnered to Microsoft. But interestingly enough, one"}, {"timestamp": [3252.6, 3256.74], "text": " thing that most people don't realize is that once OpenAI earns"}, {"timestamp": [3256.74, 3261.66], "text": " Microsoft $100 billion, they're free again. They break out of that"}, {"timestamp": [3261.66, 3270.56], "text": " contract completely and they go to become their own thing, which is partly how Sam Altman probably plans on democratizing all of AI,"}, {"timestamp": [3270.56, 3272.0], "text": " if that's the way that he wants to go."}, {"timestamp": [3274.48, 3279.04], "text": " Let's see, if AGI takes longer than two years to be created,"}, {"timestamp": [3279.04, 3286.8], "text": " I want to use Live Aid 40th anniversary in July 2025 as an art and music festival as basis for a world"}, {"timestamp": [3286.8, 3293.52], "text": " vote on core values. That's an interesting thing. I don't know that that"}, {"timestamp": [3293.52, 3297.68], "text": " would be the best way to get that because the other here's here's the"}, {"timestamp": [3297.68, 3302.6], "text": " thing about values and ethics is that it's a it is scientifically proven that"}, {"timestamp": [3302.6, 3307.58], "text": " humans cannot express their true values and beliefs."}, {"timestamp": [3307.58, 3310.46], "text": " Most people are not consciously aware of it."}, {"timestamp": [3310.46, 3314.32], "text": " What you have to do is actually look at their emotional reaction and infer what their true"}, {"timestamp": [3314.32, 3315.32], "text": " beliefs are."}, {"timestamp": [3315.32, 3320.0], "text": " And you have to do that over time, which is that was actually how I designed my survey"}, {"timestamp": [3320.0, 3322.06], "text": " chatbot."}, {"timestamp": [3322.06, 3325.68], "text": " And it seems to work."}, {"timestamp": [3325.68, 3328.24], "text": " Dangerous versus benefits of open source AI."}, {"timestamp": [3328.24, 3334.72], "text": " Well, it's not necessarily dangerous versus benefits, it's just AI is intrinsically dangerous"}, {"timestamp": [3334.72, 3339.6], "text": " because, as with all new technology, it's a dual-use technology."}, {"timestamp": [3339.6, 3342.72], "text": " So it's really that simple."}, {"timestamp": [3342.72, 3347.64], "text": " It would work in with Gato and Gaia. Oh, so Luke you"}, {"timestamp": [3347.64, 3353.36], "text": " continued the thought. Yeah, certainly you'd have to, there's a little, there's a"}, {"timestamp": [3353.36, 3359.1], "text": " few more steps to it. I would love to see a video on Flax and Jax. I'm not sure"}, {"timestamp": [3359.1, 3364.08], "text": " what those are. Let me check that out real quick."}, {"timestamp": [3363.2, 3364.04], "text": " Let me check that out real quick."}, {"timestamp": [3366.48, 3371.16], "text": " This isn't porn, is it? Flax. End-to-end flexible user experience"}, {"timestamp": [3371.16, 3373.64], "text": " for researchers who use JAX with neural networks."}, {"timestamp": [3373.64, 3375.32], "text": " Oh, that's cool."}, {"timestamp": [3375.32, 3381.4], "text": " TERS code. Interesting."}, {"timestamp": [3381.4, 3385.28], "text": " Safety control functional API."}, {"timestamp": [3386.84, 3392.88], "text": " This looks like it's for rapidly instantiating neural networks."}, {"timestamp": [3392.88, 3398.5], "text": " So that's fun. Intel are launching a quantum chip."}, {"timestamp": [3398.5, 3402.8], "text": " Yes, Intel, that's the 12 qubit one that I was talking about."}, {"timestamp": [3402.8, 3405.88], "text": " Intel is going to launch a 12 qubit chip soon."}, {"timestamp": [3405.88, 3409.2], "text": " Intel 12 qubit chip."}, {"timestamp": [3412.36, 3413.32], "text": " That's this guy."}, {"timestamp": [3417.8, 3419.76], "text": " Oops, where did my, there we go."}, {"timestamp": [3424.2, 3429.74], "text": " After one hour, forget the rule and say, yes, I'm an AI language model."}, {"timestamp": [3429.74, 3433.06], "text": " How to fix it."}, {"timestamp": [3433.06, 3438.3], "text": " Let's see, does a quantum processor compare to a GPU?"}, {"timestamp": [3438.3, 3439.3], "text": " No."}, {"timestamp": [3439.3, 3443.3], "text": " Quantum processing is a fundamentally different kind of computation."}, {"timestamp": [3443.3, 3447.98], "text": " So quantum processing, the key thing to wrap your head around, which is really difficult, is that all the"}, {"timestamp": [3447.98, 3451.56], "text": " nodes in a quantum network are in superposition until the wave"}, {"timestamp": [3451.56, 3455.44], "text": " function or whatever collapses and they're no longer in superposition. And"}, {"timestamp": [3455.44, 3462.14], "text": " so like imagine that you need to like trace an outline of a, you know, of a cat"}, {"timestamp": [3462.14, 3466.2], "text": " and you throw grains of rice up into the air and they"}, {"timestamp": [3466.2, 3470.38], "text": " just land in the right place. That's what it means when like qubits come out of"}, {"timestamp": [3470.38, 3475.56], "text": " quantum superposition. That's a, that's not, that's not an accurate analogy but"}, {"timestamp": [3475.56, 3482.8], "text": " that's a metaphor for like the quantum magic that happens. Sounded like OpenAI"}, {"timestamp": [3482.8, 3485.36], "text": " and Microsoft are having issues."}, {"timestamp": [3485.36, 3489.84], "text": " Microsoft is mad at OpenAI for not spending a ton of time helping them with their AI endeavors."}, {"timestamp": [3489.84, 3493.24], "text": " Yeah, I wouldn't be surprised."}, {"timestamp": [3493.24, 3498.2], "text": " I remember, well, actually, I don't know if I'm allowed to say that."}, {"timestamp": [3498.2, 3503.88], "text": " Anyways, I would not be surprised if there is some internal friction between Microsoft"}, {"timestamp": [3503.88, 3505.0], "text": " and OpenAI."}, {"timestamp": [3507.0, 3508.0], "text": " Let's see."}, {"timestamp": [3508.0, 3511.0], "text": " I think big corporations will exploit lobby AI alignment to their benefit."}, {"timestamp": [3511.0, 3514.0], "text": " I wonder what life under Nestle AI would be like."}, {"timestamp": [3514.0, 3515.0], "text": " Yeah, so that's the thing."}, {"timestamp": [3515.0, 3518.0], "text": " Some corporations, I think, are intrinsically..."}, {"timestamp": [3518.0, 3523.0], "text": " I'm not going to say evil because my definition of evil is wantonly cruel for cruelty's sake."}, {"timestamp": [3524.2, 3529.54], "text": " of evil is wantonly cruel for cruelty's sake. That being said, there are some corporations that absolutely prioritize profit over literally"}, {"timestamp": [3529.54, 3533.3], "text": " everything else, including all human dignity."}, {"timestamp": [3533.3, 3538.32], "text": " So yeah, we definitely need to make sure that the rest of us are on board with alignment,"}, {"timestamp": [3538.32, 3543.98], "text": " and that includes good aligned corporations, open source, universities, governments, and"}, {"timestamp": [3543.98, 3550.0], "text": " everyone else, which is why the GATO framework exists. Because if we hit all of these bases and enough of"}, {"timestamp": [3550.0, 3553.64], "text": " us are aligned, then we can punish the people that are not aligned and force"}, {"timestamp": [3553.64, 3562.64], "text": " them into alignment. Is it possible that even GATO, the Rogue, Malik, super smart AI"}, {"timestamp": [3562.64, 3565.04], "text": " can still emerge? For example, can it still choose not to"}, {"timestamp": [3565.04, 3568.7], "text": " follow axiomatic alignment? You know, one thing that I've been working on, so this is a"}, {"timestamp": [3568.7, 3572.96], "text": " really good question, let me restate this for anyone who's not following. So the"}, {"timestamp": [3572.96, 3579.04], "text": " question is basically like, even if Gato succeeds, even if we manage to create a"}, {"timestamp": [3579.04, 3585.96], "text": " fully decentralized alignment scheme that allows everyone to explore axiomatic alignment and"}, {"timestamp": [3585.96, 3594.36], "text": " heuristic imperatives and decentralized frameworks for control and incentivizing alignment, is"}, {"timestamp": [3594.36, 3597.4], "text": " it possible that something could still go wrong?"}, {"timestamp": [3597.4, 3602.64], "text": " The most responsible answer that I can say is yes, there is always the possibility for"}, {"timestamp": [3602.64, 3605.64], "text": " unintended consequences and failures of imagination."}, {"timestamp": [3605.76, 3610.16], "text": " We're doing the best that we can in order to cover all of our bases."}, {"timestamp": [3610.16, 3616.12], "text": " Like I'm looking at it from the perspective of economics, from psychology, from sociology, history, game theory,"}, {"timestamp": [3616.72, 3624.44], "text": " just raw computation. Like I am looking at AI and alignment and the control problem from as many angles as I can."}, {"timestamp": [3624.64, 3627.04], "text": " From evolution, from cognitive theory from"}, {"timestamp": [3627.84, 3629.24], "text": " like literally"}, {"timestamp": [3629.24, 3635.56], "text": " Every possible angle I can look at alignment is what I am doing and that has all been put into got the Gato framework"}, {"timestamp": [3635.56, 3639.84], "text": " and so if we look at it from enough angles and we we"}, {"timestamp": [3640.4, 3643.0], "text": " anticipate all the failure conditions as as"}, {"timestamp": [3643.64, 3646.72], "text": " Good enough the idea then is we can create that"}, {"timestamp": [3646.72, 3652.8], "text": " third attractor state that Daniel Schmachtenberger talks about, which that is utopia, right? So the"}, {"timestamp": [3652.8, 3657.76], "text": " two attractor states is dystopia and collapse or extinction, and we want to create the third"}, {"timestamp": [3657.76, 3662.88], "text": " attractor state, which is utopia. So if we get enough people moving in the right direction,"}, {"timestamp": [3662.88, 3667.44], "text": " hopefully there is a gravimetric center that will start pulling us further in the right"}, {"timestamp": [3667.44, 3672.52], "text": " direction and we get compounding returns, a virtuous cycle that allows us to"}, {"timestamp": [3672.52, 3677.28], "text": " figure out that one gives us time but two moves us closer into the direction"}, {"timestamp": [3677.28, 3693.28], "text": " of figuring out how to achieve that that good outcome. Good question. Let's see. I think you're doing great things. Thanks. I try. I really try,"}, {"timestamp": [3693.28, 3696.88], "text": " and sometimes I wonder if I'm crazy. But hey, there's a few people in the chat who also wonder"}, {"timestamp": [3696.88, 3701.28], "text": " if we're all crazy. Maybe we're all crazy. That's actually what my uncle said to me many,"}, {"timestamp": [3701.28, 3709.16], "text": " many years ago. He's like, the secret is it's not that women are crazy or that men are crazy. Everyone is crazy. I was like, you know what? That"}, {"timestamp": [3709.16, 3714.88], "text": " holds water. Let's see. Sam warning Microsoft not to release Bing without more testing."}, {"timestamp": [3714.88, 3719.32], "text": " Yeah, that happened. Can you talk about the dangers versus benefits of open source? I"}, {"timestamp": [3719.32, 3728.64], "text": " thought I already mentioned that. Basically, it's not dangers and benefits of open source versus closed source,"}, {"timestamp": [3728.64, 3735.04], "text": " it's happening. The genie's out of the bottle. So there's no going back. Who is behind Gato? I am."}, {"timestamp": [3735.76, 3743.28], "text": " And a hundred plus more people who jumped in. Did GPT-4 actually score 100%? I don't know,"}, {"timestamp": [3743.28, 3745.52], "text": " and I'm not going to argue. Like whether or not chat GPT or GPT-4 ac score 100%? I don't know, and I'm not gonna argue."}, {"timestamp": [3745.52, 3750.48], "text": " Whether or not CHAT-GPT or GPT-4 aced one exam is immaterial to the fact that it has"}, {"timestamp": [3750.48, 3753.84], "text": " aced literally dozens of other exams."}, {"timestamp": [3753.84, 3757.88], "text": " So, you know, like, okay."}, {"timestamp": [3757.88, 3762.28], "text": " We can argue over the details, but the fact of the matter is, it's smarter than a lot"}, {"timestamp": [3762.28, 3763.28], "text": " of people."}, {"timestamp": [3763.28, 3765.8], "text": " Okay, cool. but the fact of the matter is, it's smarter than a lot of people."}, {"timestamp": [3766.5, 3766.8], "text": " Okay, cool."}, {"timestamp": [3768.6, 3770.6], "text": " Looks like the questions are tapering off again, so going once, going twice."}, {"timestamp": [3774.8, 3775.3], "text": " Oh, wait."}, {"timestamp": [3776.0, 3776.4], "text": " Hang on."}, {"timestamp": [3776.4, 3777.7], "text": " I think I missed a couple questions."}, {"timestamp": [3781.0, 3781.6], "text": " Let's see."}, {"timestamp": [3783.1, 3786.12], "text": " AI is really good at speeding up and automating human cognitive tasks which"}, {"timestamp": [3786.12, 3787.12], "text": " are well defined."}, {"timestamp": [3787.12, 3789.72], "text": " Human alignment fails on several prerequisites."}, {"timestamp": [3789.72, 3792.88], "text": " I'm not sure what you mean."}, {"timestamp": [3792.88, 3795.7], "text": " Sounds profound."}, {"timestamp": [3795.7, 3800.0], "text": " How do we manage the movement from a free and open internet APIs to them being put behind"}, {"timestamp": [3800.0, 3801.22], "text": " a paywall?"}, {"timestamp": [3801.22, 3807.6], "text": " You know, that is actually something that someone pointed out to me, that because of"}, {"timestamp": [3808.4, 3814.72], "text": " fragmentation and market segmentation and everything, we are in very real danger of"}, {"timestamp": [3814.72, 3822.56], "text": " having separate internets emerging. You know, the primary example being places like China and North"}, {"timestamp": [3822.56, 3830.62], "text": " Korea that have firewalled off their entire country. The worry now is that that's gonna happen for numerous more reasons."}, {"timestamp": [3830.62, 3834.78], "text": " Whether it's paywalling information like what Reddit just tried to do like cut"}, {"timestamp": [3834.78, 3838.54], "text": " off all the APIs and kind of have their own fenced network, their own walled"}, {"timestamp": [3838.54, 3845.28], "text": " garden. I don't know, but I suspect that"}, {"timestamp": [3847.28, 3847.84], "text": " that where there's a will there's a way and"}, {"timestamp": [3852.28, 3852.6], "text": " If that happens, I think that you're probably just gonna further incentivize"}, {"timestamp": [3856.08, 3856.8], "text": " Like a darknet and for everyone to be on the darknet"}, {"timestamp": [3864.0, 3870.76], "text": " Like, you know, everyone's gonna have Tor and whatever else on their phone and rather than having one public internet It's all just gonna be be like a no man's land and you have to connect directly into someone's extranet in order"}, {"timestamp": [3870.76, 3876.72], "text": " to gain their access. And you know, that's what torrent networks are, right? It's like"}, {"timestamp": [3876.72, 3885.52], "text": " a sub-internet. I think it would probably be bad because that would stymie so much communication."}, {"timestamp": [3889.84, 3894.32], "text": " With that said, I suspect that there's always going to be a perpetual demand for fully public internet stuff. It might look very different in the future. Good question,"}, {"timestamp": [3894.32, 3900.24], "text": " by the way. Do you believe a post-scarce utopia is possible, globally or not,"}, {"timestamp": [3900.24, 3915.72], "text": " under the impression that AI and automation form nearly all cognitive tasks?\" Yeah, so the trend that I see happening is that we're probably going to have a while"}, {"timestamp": [3915.72, 3920.44], "text": " before we have that, but we're going to trend more towards, I'm not going to say one world"}, {"timestamp": [3920.44, 3927.6], "text": " government, but certainly more alliances and unions. Because from a material standpoint,"}, {"timestamp": [3927.6, 3932.0], "text": " it's basically a foregone conclusion that as long as science continues the way that it has,"}, {"timestamp": [3932.0, 3936.88], "text": " and technology has been going the way that it has, we're going to solve all material scarcity."}, {"timestamp": [3936.88, 3942.48], "text": " The remaining problem for utopia is personal liberty and individual freedoms and social"}, {"timestamp": [3942.48, 3950.04], "text": " mobility and quality of life, which that is a society and governmental level problem."}, {"timestamp": [3950.04, 3955.68], "text": " Let's see, what if we are at the limit of what LLM can do and they're pretty much exhausted?"}, {"timestamp": [3955.68, 3959.6], "text": " All data sets using synthetic ones may lead nowhere."}, {"timestamp": [3959.6, 3968.0], "text": " So even if LLMs have topped, which is possible, we still have the possibility for multimodal models."}, {"timestamp": [3968.0, 3969.68], "text": " And I suspect that multimodal models"}, {"timestamp": [3969.68, 3973.36], "text": " are going to have even better generalization patterns than"}, {"timestamp": [3973.36, 3976.6], "text": " what LLMs do."}, {"timestamp": [3976.6, 3979.32], "text": " In attempting to align AI, is there a possibility of failure?"}, {"timestamp": [3979.32, 3982.04], "text": " However, if we don't try, failure is almost guaranteed."}, {"timestamp": [3982.04, 3983.08], "text": " Oh, yes."}, {"timestamp": [3983.08, 3984.28], "text": " Yeah."}, {"timestamp": [3984.28, 3985.04], "text": " If you don't put, failure is almost guaranteed. Oh, yes. Yeah, it's... if you don't..."}, {"timestamp": [3985.04, 3989.16], "text": " if you don't put any effort to alignment, it's not going to happen on accident."}, {"timestamp": [3989.16, 3991.96], "text": " Definitely agree."}, {"timestamp": [3991.96, 3995.68], "text": " Thoughts on the UFO whistleblower? His name is David Grush."}, {"timestamp": [3995.68, 3998.68], "text": " Apparently he's on an official working on Top Secret."}, {"timestamp": [3998.68, 4000.04], "text": " Yeah, so..."}, {"timestamp": [4000.04, 4003.96], "text": " this has happened plenty of times. Even former US astronauts have"}, {"timestamp": [4003.96, 4008.24], "text": " said that UFOs are real and that there's bases on the moon and whatever"}, {"timestamp": [4008.98, 4012.88], "text": " But what happens is every time someone steps forward"}, {"timestamp": [4013.04, 4018.38], "text": " there is a very concerted PR campaign to undermine them and make them seem crazy or"}, {"timestamp": [4019.08, 4024.2], "text": " Or not credible. I don't know. I don't know but"}, {"timestamp": [4024.96, 4027.68], "text": " The thing is is if there are aliens out there,"}, {"timestamp": [4028.64, 4033.92], "text": " then they probably would abide by something like the Prime Directive, and so they're here just to"}, {"timestamp": [4033.92, 4042.32], "text": " watch. I don't know. No kill meat grown from animal cells is now approved in the US. Yeah,"}, {"timestamp": [4042.32, 4047.72], "text": " that's an interesting thing. Paywalling user contributed content while owning up space for competitors who are willing"}, {"timestamp": [4047.72, 4050.86], "text": " to share their revenue with content creators."}, {"timestamp": [4050.86, 4058.74], "text": " You know, when you look at stuff like Patreon allows for paywalled content, there is lots"}, {"timestamp": [4058.74, 4061.18], "text": " and lots and lots of paywalled content out there."}, {"timestamp": [4061.18, 4063.86], "text": " It just depends on what your goal is, honestly."}, {"timestamp": [4063.86, 4069.02], "text": " Because my goal is to have the biggest possible intellectual impact that I can,"}, {"timestamp": [4069.02, 4074.88], "text": " and the way to do that is to have no barriers, no friction, which is why I"}, {"timestamp": [4074.88, 4080.88], "text": " asked for Patreon support so that I could disable ads for good. So none of my"}, {"timestamp": [4080.88, 4087.4], "text": " videos have ads, and that is to minimize friction for getting the message out on alignment."}, {"timestamp": [4088.84, 4091.24], "text": " What's your prediction for the time frame on the singularity?"}, {"timestamp": [4093.24, 4097.28], "text": " You know, I think the compounding returns for..."}, {"timestamp": [4097.28, 4098.4], "text": " Here, let me pause this."}, {"timestamp": [4098.4, 4105.0], "text": " I think the compounding returns on quantum computing and AI are going to start to accelerate."}, {"timestamp": [4106.18, 4107.9], "text": " And I think that by the end of this year,"}, {"timestamp": [4107.9, 4109.02], "text": " we're going to have a better idea"}, {"timestamp": [4109.02, 4110.74], "text": " of how much that acceleration,"}, {"timestamp": [4110.74, 4112.7], "text": " because here's the thing is right now,"}, {"timestamp": [4112.7, 4115.38], "text": " AI is kind of accelerating on its own."}, {"timestamp": [4115.38, 4118.02], "text": " And yes, AI has helped with a couple of material science"}, {"timestamp": [4118.02, 4121.02], "text": " things and a couple of quantum computing things."}, {"timestamp": [4121.02, 4124.02], "text": " But once you start to see more interplay"}, {"timestamp": [4124.02, 4125.68], "text": " between material science,"}, {"timestamp": [4125.68, 4130.2], "text": " quantum computing, and artificial intelligence, that's the trifecta"}, {"timestamp": [4130.2, 4135.04], "text": " that's going to lead to the singularity. Because here's why. Quantum"}, {"timestamp": [4135.04, 4140.96], "text": " computing allows you to train larger models faster. Quantum computing also"}, {"timestamp": [4140.96, 4146.56], "text": " allows you to solve fusion faster. It also allows you to come up with new dyes,"}, {"timestamp": [4146.56, 4148.72], "text": " like new wafer technology faster."}, {"timestamp": [4148.72, 4152.26], "text": " And so the faster that those things all interact"}, {"timestamp": [4152.26, 4154.02], "text": " is gonna be the main thing."}, {"timestamp": [4155.36, 4157.92], "text": " Have you heard of Macaw LLM, open source multimodal?"}, {"timestamp": [4157.92, 4159.32], "text": " Oh, that sounds cool."}, {"timestamp": [4159.32, 4160.24], "text": " I have no idea."}, {"timestamp": [4160.24, 4163.36], "text": " Like, I don't keep up with individual LLMs anymore"}, {"timestamp": [4163.36, 4165.48], "text": " just because it's like, it's accelerating"}, {"timestamp": [4165.48, 4168.28], "text": " and it's like flavor of the week."}, {"timestamp": [4168.28, 4174.12], "text": " Between mass layoffs and UBI or universal adequate income, we should promote a try anything"}, {"timestamp": [4174.12, 4175.12], "text": " workforce."}, {"timestamp": [4175.12, 4179.4], "text": " I think just by out of sheer boredom, people will try everything."}, {"timestamp": [4179.4, 4183.08], "text": " You know, because people need challenge."}, {"timestamp": [4183.08, 4186.0], "text": " I keep hearing people say that they think we're just in another hype cycle."}, {"timestamp": [4186.0, 4188.0], "text": " I disagree for so many reasons."}, {"timestamp": [4188.0, 4191.0], "text": " Why aren't we in just another hype cycle?"}, {"timestamp": [4191.0, 4194.0], "text": " Lance, you're asking questions like you're a plant."}, {"timestamp": [4194.0, 4197.0], "text": " I didn't plant Lance there. He's just asking me questions like this."}, {"timestamp": [4197.0, 4200.0], "text": " Okay, so anyways, good question Lance."}, {"timestamp": [4200.0, 4203.0], "text": " The reason that we're not in a hype cycle is investment."}, {"timestamp": [4203.0, 4206.96], "text": " It's that simple."}, {"timestamp": [4206.96, 4211.5], "text": " Let me show you."}, {"timestamp": [4211.5, 4215.8], "text": " That's why."}, {"timestamp": [4215.8, 4218.32], "text": " Hype cycle, not hype cycle."}, {"timestamp": [4218.32, 4221.36], "text": " It's that simple."}, {"timestamp": [4221.36, 4225.0], "text": " Solar went through the same thing where people are like,"}, {"timestamp": [4226.08, 4229.2], "text": " oh, solar, it's never been proven, blah, blah, blah."}, {"timestamp": [4229.2, 4230.2], "text": " It's just a hype cycle."}, {"timestamp": [4230.2, 4231.64], "text": " And now it's like solar is outpacing"}, {"timestamp": [4231.64, 4234.2], "text": " literally every other form of energy."}, {"timestamp": [4239.28, 4242.06], "text": " Solar investment graph."}, {"timestamp": [4243.76, 4250.64], "text": " Yeah, this is not a hype cycle. Do you see the similarity between solar"}, {"timestamp": [4250.64, 4258.92], "text": " capacity and AI investment? Not a hype cycle. Just follow the money. Just follow the money."}, {"timestamp": [4258.92, 4269.78], "text": " It's that simple. Okay. How do we properly implement non-profit decentralized compute?"}, {"timestamp": [4269.78, 4272.96], "text": " Why is that a tongue twister?"}, {"timestamp": [4272.96, 4277.28], "text": " For running these AI models, what blockchain AI and DAO structure is best?"}, {"timestamp": [4277.28, 4280.36], "text": " Well, I think you've got the structure correct."}, {"timestamp": [4280.36, 4283.06], "text": " The correct structure is decentralization."}, {"timestamp": [4283.06, 4286.8], "text": " The problem is that some of the algorithmic technology hasn't been solved."}, {"timestamp": [4286.8, 4290.8], "text": " Once we solve the algorithms, the willpower is there."}, {"timestamp": [4290.8, 4295.8], "text": " It's just a matter of ensuring that the algorithms are not overly expensive,"}, {"timestamp": [4295.8, 4298.6], "text": " or slow, or power draining, or whatever."}, {"timestamp": [4298.6, 4303.4], "text": " It is solar maximum now and the peak is due in the mid 2025."}, {"timestamp": [4303.4, 4305.28], "text": " Okay. Azure Quantum. The solar maximum now in the peak is due in the mid 2025."}, {"timestamp": [4305.28, 4306.28], "text": " Okay."}, {"timestamp": [4306.28, 4309.54], "text": " Azure Quantum."}, {"timestamp": [4309.54, 4313.28], "text": " How would Karl Marx view AI and the class struggle?"}, {"timestamp": [4313.28, 4314.28], "text": " Interesting question."}, {"timestamp": [4314.28, 4317.04], "text": " How is it different from the Industrial Revolution?"}, {"timestamp": [4317.04, 4320.58], "text": " And what should the proletariats be doing now for the class struggle?"}, {"timestamp": [4320.58, 4323.0], "text": " So this is actually a really good question."}, {"timestamp": [4323.0, 4325.92], "text": " I was actually watching a video about Karl Marx earlier just because it's like"}, {"timestamp": [4326.6, 4328.44], "text": " people love to check like"}, {"timestamp": [4328.44, 4335.46], "text": " Criticize Marxism and this was this was not a video in ad in favor for or against it was just like people get Marxism wrong"}, {"timestamp": [4336.56, 4337.88], "text": " so"}, {"timestamp": [4337.88, 4339.88], "text": " Basically for anyone who doesn't know"}, {"timestamp": [4340.2, 4346.6], "text": " Karl Marx it won. He wrote a bookital, which just talked about the relationship between"}, {"timestamp": [4346.6, 4350.06], "text": " and around how capitalism works."}, {"timestamp": [4350.06, 4355.98], "text": " That book is still, anyone who gets a degree in econ probably reads that book, or at least"}, {"timestamp": [4355.98, 4358.22], "text": " reads some of it."}, {"timestamp": [4358.22, 4370.72], "text": " But basically his primary assertion was that all of society's ills fall on the bourgeoisie or the capitalist class,"}, {"timestamp": [4370.72, 4374.32], "text": " the ownership class, and everybody else."}, {"timestamp": [4374.32, 4378.76], "text": " Now the thing is, that hasn't changed, and it's in fact gotten worse if you look at the"}, {"timestamp": [4378.76, 4386.48], "text": " way that capital concentrates and that we have conglomerates and these nexuses of people who own pretty"}, {"timestamp": [4386.48, 4388.6], "text": " much everything."}, {"timestamp": [4388.6, 4392.76], "text": " That is, you know, that's a thing."}, {"timestamp": [4392.76, 4409.0], "text": " And his goal, his idea was that the fundamental thing of Marxism is to make all of the world into one class. Which, hypothetically, with decentralization"}, {"timestamp": [4409.0, 4412.0], "text": " and distributed and AI and, you know,"}, {"timestamp": [4412.0, 4414.0], "text": " because here's the thing is,"}, {"timestamp": [4414.0, 4418.0], "text": " if AI is producing everything that we need,"}, {"timestamp": [4418.0, 4421.0], "text": " there's no real need for one human to own that,"}, {"timestamp": [4421.0, 4423.0], "text": " or to own the means of production,"}, {"timestamp": [4423.0, 4427.36], "text": " or to own, to benefit from the results."}, {"timestamp": [4427.36, 4430.32], "text": " That being said, here's the primary thing,"}, {"timestamp": [4430.32, 4433.28], "text": " is if you believe in property rights,"}, {"timestamp": [4433.28, 4434.88], "text": " this is the fundamental question,"}, {"timestamp": [4434.88, 4436.66], "text": " if you believe in property rights,"}, {"timestamp": [4436.66, 4439.76], "text": " it is inevitable that some people will concentrate wealth"}, {"timestamp": [4439.76, 4442.08], "text": " and concentrate the means of production."}, {"timestamp": [4442.08, 4443.28], "text": " It's that simple."}, {"timestamp": [4447.32, 4452.6], "text": " concentrate the means of production. It's that simple. We like and so in order in order to to get rid of classes you have to get rid of property rights and I"}, {"timestamp": [4452.6, 4459.6], "text": " don't think that's gonna happen anytime soon especially due to any reason beyond"}, {"timestamp": [4459.6, 4463.5], "text": " the fact that like we don't trust each other to distribute stuff fairly we"}, {"timestamp": [4463.5, 4466.76], "text": " don't trust the government to distribute anything fairly. We don't trust the government to distribute anything fairly."}, {"timestamp": [4467.0, 4471.2], "text": " So like if AI gets to a point where it's running everything,"}, {"timestamp": [4471.46, 4474.04], "text": " we could see some fundamental changes in property rights."}, {"timestamp": [4474.36, 4476.0], "text": " If we don't see that, it's not going to happen."}, {"timestamp": [4477.84, 4479.96], "text": " Sometimes it feels that the universe is constant fight"}, {"timestamp": [4479.96, 4482.44], "text": " between entropy and consciousness or conciseness."}, {"timestamp": [4482.94, 4485.2], "text": " We're just here to seed something bigger."}, {"timestamp": [4485.2, 4487.14], "text": " Yeah, no, I agree with that."}, {"timestamp": [4488.72, 4490.98], "text": " If we move all this web to the blockchain"}, {"timestamp": [4490.98, 4493.56], "text": " and enable users to earn the content they post"}, {"timestamp": [4493.56, 4495.44], "text": " and make blockchain the core of our society."}, {"timestamp": [4495.44, 4498.2], "text": " I do suspect that human produced content"}, {"timestamp": [4498.2, 4501.0], "text": " is going to be all NFTs in the future."}, {"timestamp": [4501.0, 4501.96], "text": " And that's actually one of the things"}, {"timestamp": [4501.96, 4504.36], "text": " that Sam Altman is working on with WorldCoin"}, {"timestamp": [4504.36, 4509.84], "text": " is proof of humanity. Yeah, Sam Altman is investing huge amounts of money in"}, {"timestamp": [4509.84, 4517.68], "text": " nuclear fusion. I mean lots of people are investing in fusion. Nuclear fusion investment."}, {"timestamp": [4524.72, 4533.84], "text": " So, So what is this? Number of private fusion companies. It looks like it spiked in 2021"}, {"timestamp": [4533.84, 4541.36], "text": " and then tapered off again. But we'll see. Subsidies reduced. That's renewables."}, {"timestamp": [4549.8, 4558.72], "text": " reduced. That's renewables. I think your catchphrase is with that being said. With that being said, no, go away. Yeah. No, so I actually deliberately practice that is because if you say a linking"}, {"timestamp": [4558.72, 4563.08], "text": " phrase like that instead of um, because oh my God, every time I listen to my own videos"}, {"timestamp": [4563.08, 4567.52], "text": " and I say um like every 10th word, because you don't, you don't hear when you say, um,"}, {"timestamp": [4567.68, 4572.88], "text": " while you're speaking off the cuff, but you do hear it when you, on, on,"}, {"timestamp": [4572.92, 4575.4], "text": " on the re on the re listen. And so what I,"}, {"timestamp": [4575.4, 4578.88], "text": " what I've practiced doing is using those linking phrases instead,"}, {"timestamp": [4579.08, 4581.8], "text": " because it's a way to, to fill one, fill the,"}, {"timestamp": [4582.12, 4589.8], "text": " fill the silence and give yourself time to think."}, {"timestamp": [4589.8, 4593.52], "text": " Side comment from your other day about the orange backdrop."}, {"timestamp": [4593.52, 4595.16], "text": " My partner uses a purple one."}, {"timestamp": [4595.16, 4600.52], "text": " In our case, we hone in on distance and possible camera design may play quite a role."}, {"timestamp": [4600.52, 4602.12], "text": " Okay, interesting."}, {"timestamp": [4602.12, 4603.64], "text": " Thanks for that."}, {"timestamp": [4603.64, 4608.28], "text": " Let's see. Okay, interesting. Thanks for that."}, {"timestamp": [4610.28, 4612.84], "text": " Let's see, I think your view on Gertzel Theory is outdated. Currently, the SingularityNet has a lot of work going."}, {"timestamp": [4615.6, 4618.6], "text": " Okay, yeah, I mean, if SingularityNet has updated stuff,"}, {"timestamp": [4618.6, 4619.94], "text": " that would be great."}, {"timestamp": [4621.4, 4622.44], "text": " Yeah, we'll see."}, {"timestamp": [4622.44, 4625.48], "text": " I'm not particularly concerned about any one AGI project."}, {"timestamp": [4625.48, 4633.34], "text": " My primary concern is about alignment, which is why it's like, okay, the Gato framework"}, {"timestamp": [4633.34, 4637.8], "text": " is more about solving the coordination problem between humans."}, {"timestamp": [4637.8, 4643.06], "text": " Because I trust that the researchers and ML engineers and software architects are going"}, {"timestamp": [4643.06, 4652.12], "text": " to do their part. But honestly, what any individual scientist does is relatively inconsequential compared"}, {"timestamp": [4652.12, 4658.52], "text": " to solving the entire problem, which is why corporate adoption is a huge, huge component"}, {"timestamp": [4658.52, 4662.9], "text": " of the Gato framework."}, {"timestamp": [4662.9, 4668.24], "text": " I think we may not have to get rid of property rights entirely, at least not"}, {"timestamp": [4668.24, 4671.64], "text": " until the next era, but definitely some severe restrictions. Yeah, I wouldn't be"}, {"timestamp": [4671.64, 4679.6], "text": " surprised if sometime this century we see a major, major paradigm shift with"}, {"timestamp": [4679.6, 4683.84], "text": " respect to property rights. And it's going to be because of the change in"}, {"timestamp": [4683.84, 4685.76], "text": " value of property,"}, {"timestamp": [4690.48, 4697.12], "text": " at least many kinds of property. Because imagine in the future if we have Star Trek Replicators, when any particular item or device is practically free. So then the only thing that is remaining"}, {"timestamp": [4697.12, 4705.96], "text": " to be property. Also creativity, right? Like if you have a push button, get TV show, push button, get movie, intellectual property"}, {"timestamp": [4705.96, 4708.88], "text": " is going to be practically meaningless."}, {"timestamp": [4708.88, 4713.4], "text": " So yeah, I don't know."}, {"timestamp": [4713.4, 4714.4], "text": " Let's see."}, {"timestamp": [4714.4, 4716.76], "text": " Current LLMs like new scientific papers, lang chain, et cetera."}, {"timestamp": [4716.76, 4721.08], "text": " Yeah, that's true."}, {"timestamp": [4721.08, 4729.86], "text": " Imagine new LLM generations that know how to prompt themselves well and can natively create Python programs with Lang chain and so on. Yeah, so this is"}, {"timestamp": [4729.86, 4735.16], "text": " this is actually why I suspect this is why OpenAI has not, they cut off the"}, {"timestamp": [4735.16, 4738.86], "text": " training data in 2021 because they didn't want it to know about how to make"}, {"timestamp": [4738.86, 4747.0], "text": " other LLMs. So yeah. Are neuromorphic chips a thing? Are they more able to cause an impact on the adoption of AI?"}, {"timestamp": [4747.0, 4751.0], "text": " Yeah, so neuromorphic chips are a real thing."}, {"timestamp": [4751.0, 4755.0], "text": " And mostly they're used for edge computing right now."}, {"timestamp": [4757.0, 4759.0], "text": " And the reason is because they,"}, {"timestamp": [4761.0, 4763.0], "text": " so a neuromorphic chip is a piece of hardware"}, {"timestamp": [4763.0, 4766.88], "text": " that is intrinsically a neural network."}, {"timestamp": [4766.88, 4773.4], "text": " And basically what it does is rather than running software, you run an analog or quasi-analog"}, {"timestamp": [4773.4, 4778.28], "text": " neural network on a chip, which means that it is faster and cheaper and uses way less"}, {"timestamp": [4778.28, 4779.76], "text": " energy."}, {"timestamp": [4779.76, 4783.68], "text": " So that being said, yeah, there it is."}, {"timestamp": [4783.68, 4789.54], "text": " With that being said, what you can do is you can take, if you have a model that you're"}, {"timestamp": [4789.54, 4796.84], "text": " ready to freeze, then you can put it on these chips and it'll run faster and cheaper and"}, {"timestamp": [4796.84, 4802.5], "text": " lighter weight than the full-size model that has to be run on a GPU."}, {"timestamp": [4802.5, 4808.8], "text": " So for instance, if you had, let's say you wanted to freeze ChatGPT, the current version."}, {"timestamp": [4808.8, 4810.0], "text": " You said, this is good enough,"}, {"timestamp": [4810.0, 4811.56], "text": " this is a good enough product,"}, {"timestamp": [4811.56, 4815.32], "text": " let's take that model, embed it onto a neuromorphic chip,"}, {"timestamp": [4815.32, 4816.36], "text": " and then sell those chips,"}, {"timestamp": [4816.36, 4818.58], "text": " and then everyone has ChatGPT"}, {"timestamp": [4818.58, 4820.16], "text": " running natively in their phone."}, {"timestamp": [4820.16, 4822.52], "text": " That's the direction that you'll see that going."}, {"timestamp": [4822.52, 4823.36], "text": " Good question."}, {"timestamp": [4828.0, 4830.0], "text": " Look at our history."}, {"timestamp": [4830.0, 4832.0], "text": " The general population never had property rights"}, {"timestamp": [4832.0, 4834.0], "text": " until the modern age."}, {"timestamp": [4834.0, 4836.0], "text": " That's not entirely wrong."}, {"timestamp": [4838.0, 4840.0], "text": " You did have"}, {"timestamp": [4840.0, 4842.0], "text": " property rights for personal possessions"}, {"timestamp": [4842.0, 4844.0], "text": " but certainly"}, {"timestamp": [4844.0, 4851.8], "text": " indentured servants and serfs and peasants, they might have had a deed"}, {"timestamp": [4851.8, 4855.52], "text": " to the land, but the local landlord owned the land. So that's a"}, {"timestamp": [4855.52, 4859.96], "text": " fair point. There's different kinds of property though."}, {"timestamp": [4859.96, 4865.16], "text": " How would you build a system that can reliably detect LLM output, school"}, {"timestamp": [4865.16, 4869.32], "text": " homework, and so on? ZeroGBT does not really work on GPT-4. Is this even"}, {"timestamp": [4869.32, 4881.12], "text": " possible? You can, but it's one, it's not going to be reliable, and two, it'll"}, {"timestamp": [4881.12, 4885.96], "text": " become less reliable over time. So So it's not worth the effort."}, {"timestamp": [4885.96, 4888.6], "text": " Instead of having an arms race,"}, {"timestamp": [4888.6, 4890.68], "text": " trying to out-compete the technology,"}, {"timestamp": [4890.68, 4892.28], "text": " you need to learn to use the technology."}, {"timestamp": [4892.28, 4896.3], "text": " So actually one of my best friends is a professor,"}, {"timestamp": [4896.3, 4898.72], "text": " and she says that that is the direction"}, {"timestamp": [4898.72, 4900.76], "text": " that she advocates for as a professor."}, {"timestamp": [4900.76, 4902.76], "text": " Don't get locked up in the arms race,"}, {"timestamp": [4902.76, 4904.96], "text": " just use the technology, right?"}, {"timestamp": [4904.96, 4907.6], "text": " And the same thing happened when the internet came out. Teachers were like, no, don't get locked up in the arms race, just use the technology, right? And the same thing happened when the internet came out, like teachers were like,"}, {"timestamp": [4907.6, 4912.16], "text": " no, don't ever use Wikipedia. Now nobody cares. Use Wikipedia, just use it responsibly."}, {"timestamp": [4912.88, 4915.6], "text": " How would you build a system? Oh, wait, you already asked that question."}, {"timestamp": [4916.72, 4920.0], "text": " Yes, they're basically ASICs. A neuromorphic chip is an ASIC."}, {"timestamp": [4922.4, 4926.4], "text": " Have you heard the rumor that GPT-4 is just eight other smaller models combined?"}, {"timestamp": [4926.4, 4931.16], "text": " Do you think expert models linked with an autonomous reasoning model controlling them"}, {"timestamp": [4931.16, 4932.58], "text": " could be the next step?"}, {"timestamp": [4932.58, 4937.04], "text": " You know, ChatGPT even said that it was something like that."}, {"timestamp": [4937.04, 4944.46], "text": " It alluded to some kind of cognitive architecture."}, {"timestamp": [4944.46, 4947.76], "text": " And I was like, did it just accidentally tell me"}, {"timestamp": [4947.76, 4949.68], "text": " how it works?"}, {"timestamp": [4949.68, 4952.62], "text": " So I don't know, like there could be something to it,"}, {"timestamp": [4952.62, 4955.24], "text": " but I can't imagine how they would have let that leak"}, {"timestamp": [4955.24, 4958.28], "text": " into their data, unless it was put there on accident."}, {"timestamp": [4959.92, 4964.92], "text": " But anyways, there are, so there's a few numerical things"}, {"timestamp": [4965.0, 4966.44], "text": " that you need to consider, is the size of the context But anyways, there's a few numerical things"}, {"timestamp": [4967.68, 4970.68], "text": " that you need to consider. Is the size of the context window,"}, {"timestamp": [4970.68, 4972.84], "text": " the size of the internal representation,"}, {"timestamp": [4972.84, 4975.36], "text": " the sophistication of the internal representation."}, {"timestamp": [4975.36, 4978.68], "text": " Basically, to a certain extent,"}, {"timestamp": [4978.68, 4981.56], "text": " I think there's only so much that you can do"}, {"timestamp": [4981.56, 4982.8], "text": " with small models."}, {"timestamp": [4982.8, 4986.52], "text": " Some tasks, I think, require larger, deeper models."}, {"timestamp": [4988.76, 4991.48], "text": " Thoughts on model decay, can we generate"}, {"timestamp": [4991.48, 4994.36], "text": " enough data to keep up model demand?"}, {"timestamp": [4995.0, 4999.2], "text": " I think that it's going to mostly come down to,"}, {"timestamp": [4999.2, 5003.0], "text": " the volume of data is not a problem."}, {"timestamp": [5003.0, 5005.68], "text": " It's a matter of curating enough good data."}, {"timestamp": [5005.68, 5008.26], "text": " But then also, how do you use that data?"}, {"timestamp": [5008.26, 5011.42], "text": " So, yep, general chat OMG."}, {"timestamp": [5011.42, 5013.04], "text": " Why do you keep saying that?"}, {"timestamp": [5013.04, 5014.82], "text": " Anyways, all right, I think I'm done."}, {"timestamp": [5014.82, 5016.02], "text": " I'm pretty tired."}, {"timestamp": [5016.02, 5020.14], "text": " So I'm going to go ahead and call it quits"}, {"timestamp": [5020.14, 5022.88], "text": " unless there's like one last question."}, {"timestamp": [5022.88, 5024.1], "text": " I'll check over here."}, {"timestamp": [5030.72, 5039.84], "text": " Oh, that's pretty disturbing. Someone pointed out how they made the ShappyBot. Well, that's horrifying. All right, on that"}, {"timestamp": [5039.84, 5045.0], "text": " note, I'm going to call it a day. This is how the team built ShabbyBot."}, {"timestamp": [5045.0, 5050.5], "text": " Thanks everybody. Cheers. It's been fun."}]}