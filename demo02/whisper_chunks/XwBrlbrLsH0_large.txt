{"text": " My name is Christopher Mar\u00edn and I'm a marketer with a background in technology. Please join me in an exploration of the world of generative AI, where technology and creativity collide to produce truly revolutionary results. From photorealistic images and music to complex code and language, these innovations are pushing the boundaries of what's possible and changing the way that we think about our craft. I've been experimenting with generative AI for a few years now. I was fortunate to be able to test out early versions of GPT for text generation. And on the imaging side, I got to play with tools like generative adversarial networks for style transfer and disco diffusion, wombo to play with tools like Generative Adversarial Networks for style transfer, and Disco Diffusion, Wombo Dream, and other tools. These early apps were rather primitive, and the output was not particularly useful for professional work, so it was easy to dismiss them as toys. Now though, we've gotten to the point where you simply can't ignore them. My goal is to give marketers a sense of where we are in this space, and where we appear to be headed. I'm going to touch on aspects of technology, law, history, and the day-to-day impact on our lives. This tech is going to have a tremendous impact on everything that we do in this field, and you ignore it at your peril. Future videos will go more in-depth on areas like image and text creation. When you think about what it is that we do in this profession every day, it covers a very broad spectrum of tasks. As creators, we build ads, we write copy, we do sponsorships and events and publicity and PR and strategy and social and so much more. We never have enough time or resources to get everything done. That's true in every shop out there to some degree or another. Where these new technologies come into play is that they can help automate a lot of this work. It won't do everything well. It is not yet to the point where it replaces us, but we all get an extra pair of virtual hands to help with the endless tasks on our plates. Think of it as getting an intern. This slice of the AI sector is exploding. Here you can see some of the generative AI landscapes put together by Sequoia, Base10, and Antler. The latter has a nice little database of companies in this area. They're tracking over 300 of them, and that is not a complete list. This space is exploding in terms of energy and hype and funding. If we narrow it down a bit to the things that are important to marketing, there's some really interesting tools out there that are useful in our day-to-day work. You can do things like point some of them to a web page or a blog post and ask them to build a video for you. You can also feed them a song and automatically generate new ones that are inspired by it. They can create presentations for you based off a single prompt or create your ad copy and images. It seems like every week something new comes out. And one of the reasons why people are giddy about generative AI is that the coherence and quality of the outputs keeps increasing. Here's an example. If you look at this set of images from Google, the state of the art in 2014 for image generation is fuzzy. It's black and white. You can tell it's a face, but it isn't great. It looks like a bad photocopy of a still from a grainy surveillance video. This is nowhere near where we are nowadays, where photorealistic outputs are achievable. In fact, there was an interesting study that was done recently on synthetic images versus photographs of actual humans. People seemed to prefer the computer-generated ones and thought they were more real than traditional photographs. That's astonishing. We've come a long way since the first mathematical model of a neural network called a perceptron, which was invented way back in 1943 by McCulloch and Pitts and finally implemented in hardware in 1957. This device was connected to a camera that produced a 400 pixel image. So what's driving all these recent improvements in quality? Some of it has to do with the amount and quality of data that is being fed into the models. GPT-3, for example, was supposedly trained on vast swaths of the web. And one useful measure of the power of these systems is something called the parameter count. In this chart, which was shared by a very talented AI researcher by the name of David Shapiro, we can see that state of the art in early 2018 was a model called ELMO that clocked in at 94 million parameters. Then later that year, we had BERT at 340 million parameters. So we see this count increase and also a fascination with Sesame Street characters. Fast forward to GPT-2 in early 2019, and we get 1.5 billion parameters. Then GPT-3, which is a base model for Chad GPT arrives two years later at 175 billion parameters. In 2021, we got Microsoft's Megatron Turing model at over half a trillion parameters. You can clearly see an almost linear increase over time in those parameter counts. So why does that matter? Well, it turns out that as parameter counts and the amount and quality of data increases, new capabilities emerge. Here you can see an example that Google shared with a party model, where at 750 million parameters, the system is able to generate an image of a kangaroo holding a sign. But the words are illegible. If you crank that up to 20 billion parameters, not only does the fidelity of the image increase, but the model learned how to spell. The researchers didn't teach it how to spell. The behavior spontaneously emerged. And this keeps happening with these technologies. Their own creators are continually astonished by these emergent capabilities. It can produce code, rap, do poetry, music, all sorts of things. Facebook had to shut down a project way back in 2017 where two chatbots started talking to each other as they invented their own language that humans couldn't understand. So what happens when we get to that trillion parameter count? The possibilities are astonishing to contemplate. That's especially true because AI researchers are learning to make these models even more efficient, with fewer parameters. You have a model like GPT-NeoX at only 20 billion parameters, which is a small fraction of the size of GPT-3, and it can produce very compelling and creative stories out of applications like novel AI. In that way, parameter count is similar to megahertz for processors or megapixels for cameras. The increases tell you something, but it isn't the full story. To give you a sense of how powerful these large language models have become, here you can see how chat2BT responds to some of the original Turing test questions. Alan Turing devised this test years ago to help us determine exactly when we got to a point where an artificial system was truly intelligent. We've made impressive progress. Now let's dive just a little bit into GPT because that's the one that we've all heard about now because of ChatGPT. I saw the other day that over 30% of American adults have tried out this technology and it's on track to be the app with the fastest adoption in history. GPT is a large language model, and here's what it stands for. Generative means it is capable of creating new things. Pre-trained means that out of the box it can do a host of different tasks. And this is different from classical machine learning models that were trained to do a single task, classify items, perform sentiment analysis, that sort of thing. GPT models can write sentences, they can write blog posts, or perform more traditional machine learning tasks like sentiment analysis. The T stands for transformers. This was a technology that was initially developed by Google. In 2017, they very kindly shared it with the world in a paper called, Attention is all you need. Transformers is a neural network architecture, and what it does is sequence to sequence predictions. A sequence would be something like 1, 2, 3. If I start with that, and then I ask you to predict what comes next, you would say 4, 5, 6. If instead I said 4, 6, 8, you would respond with 10, 12, 14. If I gave you to be or not, you would say to be. So this ability to take in a sequence of inputs and then predict the sequence of outputs is a foundational element of this model. And it turns out to be extremely powerful, because a sequence can be anything. For example, they can be sentences. And that makes sense, because the Google team was initially focused on translations, and their task was to determine how to go from one language to another, even when the word order doesn't always match. This technique can also be applied to code generation or even tasks like using DNA to predict protein sequences. Anything that has a pattern can be fed into these transformers. Now that you know what GPD stands for, let's look at how we use them. You start out with pre-trained models which are capable of doing a whole lot of things, but you need to be able to direct them to produce useful output. And the way you do that is through a process called prompt engineering. For example, you can ask the model to give you a headline that matches a particular set of conditions, like including certain words or using a particular tone. It turns out that prompt engineering is an art form that requires some level of skill, just like any other activity. One pattern that I've noticed among some folks when they're first introduced to this tech is that they'll use some quick and dirty perfunctory prompt. And when the output doesn't match the caliber of a highly trained professional, particularly one in their area of specialization, they scoff at the results and declare with confidence that it's only capable of mediocrity. Musicians will say that the output sounds like music, and highly accomplished writers or editors say that the text is bland and soulless. In fairness to the critics, these models are not yet to the point where they can produce works of the caliber of say, Vivaldi or Shakespeare. Even now, people can produce quality outputs that suffice for many marketing needs. It takes some training though. Imagine handing someone an instrument that they've never played and expecting them to dazzle you with a stunning rendition of your favorite song. It is true that the bar has been lowered tremendously by this technology. It democratizes access to creative outlets that were inaccessible to the majority of people. Folks that couldn't draw a stick figure are suddenly capable of producing works that win awards. It also opens creative outlets to disabled people that physically couldn't participate in some of these arts. However, some skill is still involved to get the highest quality outputs. The world is just getting started with prompt engineering. There is so much yet to learn and invent. Prompts can let you guide those pre-trained models towards useful results. Though they're filled with tons of general purpose knowledge, it's unlikely that they know anything about your particular campaign or all the latest details about the products or service that you work on. There are ways of imparting that knowledge into these systems using a technique called fine tuning. It is a bit of a dark art at the moment, but together with expert prompts, you can generate truly stunning works that align to your brand and objectives. And we're approaching what I like to think of as the anything-to-anything era. As a marketer, you already deal with all these modalities. You have text, images, audio, video, data, code, and 3D objects. The truly talented amongst us know how to assemble all the right elements into compelling experiences. What's fascinating about these new generative technologies is that they permit you to go from one to another. A canonical example would start out with text and transform that into an image. You can also do the reverse though and start out with an image that gets converted to text on the other end. You can go from text to song. Google just came out with a new music model. You can go from text to song. Google just came out with a new music model that lets you go from image to song. They showed an example of Van Gogh's Starry Night image getting converted into music. And we're getting to the point where pretty much any input can go to any output. Just imagine the power that gives you as a marketer. If the current pace of progress continues unabated, you'll soon be able to create anything you want, and then quickly and inexpensively orchestrate experiences across all these modalities. That's incredibly exciting. And this is possible because these models are composable. You can stack them on top of each other and rearrange inputs and outputs in all sorts of interesting ways. For example, one great way to level up your generative AI images is to use a GPT-based tool to embellish your initial prompt. Here you can see a working demo available to anyone via Hugging Phase, where the conversational capabilities of GPT and Whisper are paired with a mathematical rigger of WolframAlpha along with the realistic avatars from XHuman. These are all linked via the Lang Cheng project. It gives us a glimpse of the types of applications we will see in the future. An example where that approach would be useful on the marketing side would be through the enrichment of personas we create as the archetypes of the customers we serve. Imagine feeding a chatbot all of the information that you have on a particular persona and then asking it to react to certain scenarios or product enhancements. You could take this a step further and embody that persona in an interactive avatar. On the technology side, you have this notion of a full-stack developer. That's a person that knows how to do the front-end coding to build user interfaces, but can also tackle back-end applications and databases and whatever else you need to build a modern app. Generative AI can do something similar and empower a new set of full-stack marketers. These will be somewhat akin to movie directors, in that they will be able to quickly create artifacts across modalities and then bundle them in creative ways. Those that master these new technologies will be demonstrably more productive than those that don't take the time to learn them. In terms of job safety, it makes no sense to stick your head in the sand and hope that this AI stuff will simply go away. It's not gonna happen. The genie is out of the bottle. And when companies figure out how this accelerates productivity, there's no turning back. But of course, as with everything else, there's a downside to these advancements. We've all been seeing headlines in the news lately about these technologies taking away jobs, along with predictions like 90% of online content will be created by AI by 2025. There is a lot of fear in the system, and some of it is wholly justified. AI will take jobs, there's no question about it. Initially, the folks that are going to be the most at risk are beginners and those of meddling talent. There's a very real danger now that people that are just entering the workforce and those that don't have adjacent skills in business or tech will get supplanted by the machines. And that's why proponents of this field that are in the quest towards AGI or Artificial General Intelligence often tout the need to deploy something like universal basic income. The failure to provide a safety net if most jobs get automated would be catastrophic. It is useful though to step back a bit from all that hype, drama, and fear and realize that we've gone through similar disruptions many times in the past. For example, if we go way back a couple thousand years ago, we arrive at the dawn of the written word. That technology was introduced into an era of strong oral traditions. You had people that had mastered the art of verbal storytelling, and those orators were not in the least bit pleased with this newfangled writing technology. Here you can see a quote from Socrates, one of the wisest and most accomplished people in history, where he rails against writing as something that is going to destroy our memory and which will give people the appearance of wisdom versus true wisdom. If you make the language a bit less archaic, you could almost mistake this for a modern diatrab against chat GPT. I'm sure he would have also been less than thrilled about the memory loss implications of Google search. Now the funny thing is that the only reason that we know about him is because some of his disciples, like Plato, embraced that shiny new tech and included him as a character in their writings. Otherwise he could have easily been lost to posterity. Fast forward a couple millennia and you have the introduction of photography. At the time, portrait painters were up in arms with that new tech and there was vehement pushback in some quarters about photography not being a true art. Photographers were ridiculed by more traditional artists as little more than button pushers that had no true skills or creative vision. It wasn't until much later that the works of photographers such as Ansel Adams got grudging acceptance in those quarters. But now, of course, some photographers are up in arms because generative AI is poised to take a slice of their pie. This is not a wholly irrational fear, especially for areas like stock photography. We see then that there is a detectable pattern with these disruptions. What tends to happen is that the new technologies eventually coexist with the old ones, even if the latter are transformed to some degree. and the transition itself is painful for those involved. For example, the oral tradition is still alive and well in classrooms, as well as in theater, movies, and even video games. People will continue to paint because it's a pleasurable and fulfilling activity, in the same way that pianists didn't disappear with the introduction of that pianists didn't disappear with the introduction of the pianola or records or radio, which automated that task. The same thing will likely happen with photography. Human beings will always have a need to reminisce over artifacts to store memories of their lives. In some ways, that's how we know who we are, by looking back at where we came from. That doesn't mean that there won't be change, though, and some of it will be wrenching. Photography as a discipline is becoming more computational, and we're headed in directions that would have likely astonished pioneers like Daguerre or Eastman Kodak. I believe we're moving in the direction of a setup that will enable people to capture wide swaths of reality and then extract the bits and pieces that are useful at a later date. This is nicely captured in Insta360's slogan of, shoot first, frame later. We can already see glimpses of this future with existing products like 360 cameras, the LiDAR and depth map capabilities that already exist in many phones, neural radiance fields or NERF capabilities that players like Luma and NVIDIA are producing, and light field cameras and lenses like the K-Lens. At some point, a company is gonna combine a number of these innovations into a single device that captures high-fidelity 3D scenes with movement, out of which at a later time you can extract 2D stills for photos, 2D movement for videos, or full-blown 3D scenes for augmented reality or VR apps. These raw reality captures could of course be combined with synthetic objects using generative AI. We can already see very primitive versions of this with the AR apps from Ikea or Home Depot that let you visualize what a piece of furniture would look like in your living room via an iPhone. It's a very exciting time to be alive, but of course, with any disruptions of this magnitude, you're going to have victims and a predictable backlash. At this stage, the most vociferous opposition comes from the art community, some of whom are united under the banner of AI art is stealing. Some of the most extreme members of this group are even making death threats against AI creators. The charge of stealing should give everyone pause, because most of us don't want to partake in unethical activities, and we certainly don't want to put our employers at risk either. I think it's worth breaking down exactly what is meant by the word theft. If we're talking about jobs, then that is absolutely the truth. AI will take away jobs, just like every prior wave of automation before it. Before anyone gets too high on their horse though, on this particular matter, I would ask them to look down at their feet and check out what they're wearing. In all likelihood, it is not shoes handcrafted by a shoemaker. Most of our footwear is now mass produced in some type of factory. By and large, people don't tend to work as artists and shoemakers anymore. As a species, we always tend to make the choice of low cost and convenience, which is why most of us don't travel via buggy or horse as much as that choice hurt the carriage and saddle makers when that transition occurred. Some of you will say, well, that wasn't me, my grandparents or great-grandparents made that decision. Well, let's fast forward to something more recent and think about how many of us stopped frequenting Blockbuster Video or a similar chain when Netflix came out. Or who among us has not shopped at Amazon, much to the detriment of your local mom-and-pop shop. We are all complicit in this quest for automation and convenience, so to look askance when it more directly affects you is understandable, but a bit hypocritical. The second charge under the AI art is stealing banner is that the outputs are simply banal derivative works purloined off the hard labor of others. In other words, AI art lacks originality, which is only possible through the more traditional means where humans are in more direct control of the output. This harkens back to the myth of the lone genius that cooks up splendid works in complete isolation from others. This is utter nonsense, and some of our wisest and most accomplished people in history have rightfully acknowledged that fact. Here you can see how Isaac Newton talked about working on the shoulders of giants. Picasso and Lincoln and so many others have made similar statements. We're all riffing off each other and making use of that creative commons in our shared history. Nobody is wholly original, though of course some people make better incremental improvements than others and we rightfully celebrate their brilliance. What generative AI does is to help speed up that process of riffing and remixing the useful contributions from the past in novel and new directions. Now just think about what it is that we do in our day-to-day work as marketers. If you need to launch a campaign or a new product or website, standard practice is to check out what the best in class or your peers are up to. You take those ideas and innovations and movements in fashion and styles and then craft something that matches your particular needs and the moment. The bottom line is I believe this part of the AI artist stealing case is simply overblown and not based on facts. Next we get to the legal aspects of this saga, where the story gets murky and convoluted rather quickly. The truth of the matter is that nobody knows how this will play out in the legal systems across the globe. It will probably take years for legislators, regulators, and judges to sort through this tangled thicket. Despite this fact, we still need to make our own personal decisions about the ethics of using this technology and determine the appropriate level of risk that it presents to the companies we serve. With that in mind, let's touch on a couple of aspects of this as they relate to the AI artist stealing charge. First, if a close replica of a copyrighted work is used for commercial purposes, then it is clear that in most cases it will run afoul of copyright regimes. Generative AI isn't bringing anything new to the table here. This is true regardless of the means of duplication. It could be photocopied or done in Windows Explorer or Photoshop. You can't directly replicate the works or copyrighted characters of others for profit, without legal risk. When we get to the notion of style, though, the story is completely different. You cannot copyright a style, at least in the United States, and there's a very good reason for that. If styles could be copyrighted, then you'd have no artistic movements. Imagine a world where Pablo Picasso could have prevented anyone from doing Cubist paintings, or Isaac Asimov owning grand space operas. In that universe, there would be no Arthur C. Clarke sagas, or Star Trek, or Star Wars. So artists getting upset with others for copying their style doesn't appear to have a strong basis in law, and frankly doesn't reflect the fact that artists themselves likely learn by mimicking the masters. We all profit from the comments. Then we get to the notion of fair use and transformative use. These come into play when we think about the large volume of images that these models are trained on. Again, there is ample precedent for organizations being able to use available materials on the web and elsewhere to build commercial services. That's the business model that underlies Google Search, Kayak, Yelp, and so many other online providers. We all benefit from that ready access to those materials that they sort through and augment and make available at our fingertips. Specifically though, in terms of case law, you have examples like the lawsuit that Google won against the Authors Guild, which enabled them to keep scanning books. And if you look outside the US, you see that Germany, for example, has specifically enshrined the ability to use machine learning to scan through works for useful and transformative purposes. Now there's all sorts of nuances when it comes to an artist's body of work. The questions about enabling them to opt in or out of these models are worthy of deliberation. What's also worth examining is what exactly gets included in these datasets and if they contain equitable representations of the world in terms of minorities and gender and so on. And that goes hand in hand with the possible degradation of the quality of generative AI results if there aren't sufficient samples in each group. These controversies have been swirling post-launch with DALI 2 and Stable Diffusion and are tied to similar charges in some quarters that ChattGBT has been neutered in the quest to, quote, go woke. We'll likely be debating this for a long time. Lastly, one of the charges that was made in the lawsuit against Stability AI and others seemed to incorrectly characterize this technology as something that acted somewhat akin to a catalog. Specifically, the charge was that if you search for an image of a dog eating an ice cream cone, the system would essentially look through the database of available images and try to return one that matched that query. This would be similar to a search engine. This is a fundamental misunderstanding of the technology. It just doesn't work that way. What these models instead do is to learn the patterns that are present in images, very similar to the way you or I might look at a painting. We'll notice the use of a particular technique when it comes to brush strokes or texture or color or composition. And unless you have a photographic memory, you don't memorize each brush stroke or pixel. It is the same thing with these models. In fact, you can prove it's the case, because if you look at one of the stable diffusion models, you see that it's a little bit over four gigabytes. Most of us likely have more than four gigs of images on our personal phones, and that model was trained on the Lion 5B set. It is not possible with our current technologies to store anywhere near 5 billion high-fidelity images in such a small amount of space. The other charge you'll see is that these models can return output that is similar to their training set. There is a small amount of truth here, but only in a very narrow sense. If a pattern is over-represented in the training set, then you can get something that somewhat resembles it through a process called memorization. Think of famous paintings like Van Gogh's Starry Night, or the Mona Lisa, that appear in endless iterations online. There was a study that recently tried to quantify this problem, but the methodology was questionable. They looked for images that appeared often in the set, and then ran 175 million generation requests to try to recreate them. After all that, there was only an infinitesimal small chance that they get a very rough facsimile of the original image. Essentially, you have to go out of your way to encounter this problem. On the text generation side, there is a similar challenge, but again, it's highly dependent on the types of requests you're making. Nevertheless, it's probably best practice to run any text you produce through a plagiarism checker like the one found in Grammarly, especially if it is long-form copy. The bottom line, from my perspective, is if a company is producing assets that align with their brand standards and don't visibly infringe on the works of others, the risk seems minimal. After all, we've had Photoshop and other tools for decades that already easily permit works of others to be misused, and there is no movement to ban those tools. Now, let's bring this back to a more personal level and discuss coming to terms with this technology. This can be incredibly difficult, especially for creators. Many of us have passions that can be tied to our profession and in key ways help define who we are as human beings. The idea that a machine could quickly churn out what we do is scary and upsetting. In some ways we're dealing with a stages of grief type of scenario where each of us will need to go through denial, anger, acceptance, and so on. I'd like to share a bit of my journey in this regard, and as you can likely tell from my numerous references to photography, that has been a passion of mine for quite some time. I spent years taking classes and workshops. I invested thousands of hours of my life honing that craft and thousands of dollars buying gear. And I have to admit, when I first put in some prompts for landscape photos and stable diffusion, with entries like Patagonia sunset, F11, water reflections, and so on, I was blown away by the results, and more than a little taken aback and sad. I wondered, is this the end of photography? This outlet that has brought me so much joy? What role will it play in a world where you can conjure these captivating vistas with a few keystrokes? And then I thought about the images themselves and what they meant to me as a person that tries to convey the beauty of the world I encounter. After some time, I came to terms with the situation and decided there's still value in this craft to capture and share key memories of my life. Incidentally, I created all the images you see here in stable diffusion, except for the blue one on the right. That shot I took in Banff National Forest in Canada. I caught up at some ungodly hour, like 3 or 4 AM, to get there during the blue hour before sunrise. On that trip, I taught my daughters about photography. And this shot hangs in my home. In other words, it carries an emotional resonance that the AI ones don't possess, since I spent minimal energy on the latter. For me, the difference between these objects is similar to that of making a splendid meal from scratch versus ordering takeout. However, if I take off my personal hat and don the cap of a marketer, then I have to accept the fact that those factors really don't matter in a business context. If I need an image for my webpage or ad, I'm probably going to go to a stock image library and find something there that in all likelihood has been used countless times before by others. From that perspective, the AI image is superior in that it is more likely to be unique. I say that, of course, with trepidation as someone that has profited from the sale of stock imagery. The bottom line is that we will probably all have to take a page from Ken Jennings' book and come to terms with the fact that AI is here to stay. What's exciting about the generative AI space is that we're just getting started. This year we can expect better video and 3D output, and the competition between OpenAI, Google, AnthropicAI, and others will be fierce. It's an incredible time to be alive as creators, with access to superpowers that our predecessors could only dream of. Let's take stock of some of the learnings in this area. First, there's no silver bullet with any of these technologies. Use lots of different models and services and generations to find what you're looking for. All of the abilities you've honed as a marketer are still useful to convert these raw inputs into something that is production ready. At this stage, you still need an eye for design, good writing and editing skills, and a deep understanding of your business. Use AI as a muse, a collaborator, and an accelerator. Do not blindly trust the output of any of these models. Think of it as having an eager intern that lacks context and understanding of so much of what makes our world tick. The quality of these outputs keeps increasing. So even if you're unimpressed by what you see today, that will likely change in the future. I will now leave you with this quote from T.S. Eliot, which I think is very relevant to this new generative AI era. It goes back to the idea of riffing off others. He writes, The good poet welds his theft into a whole of feeling which is unique and utterly different from that which was torn. That's what we're doing here. It's building off the works of others into something else entirely that's new and useful. Bye!", "chunks": [{"timestamp": [0.0, 11.24], "text": " My name is Christopher Mar\u00edn and I'm a marketer with a background in technology."}, {"timestamp": [11.24, 17.04], "text": " Please join me in an exploration of the world of generative AI, where technology and creativity"}, {"timestamp": [17.04, 20.12], "text": " collide to produce truly revolutionary results."}, {"timestamp": [20.12, 26.68], "text": " From photorealistic images and music to complex code and language, these innovations are pushing the boundaries"}, {"timestamp": [26.68, 29.04], "text": " of what's possible and changing the way"}, {"timestamp": [29.04, 31.16], "text": " that we think about our craft."}, {"timestamp": [31.16, 32.92], "text": " I've been experimenting with generative AI"}, {"timestamp": [32.92, 34.48], "text": " for a few years now."}, {"timestamp": [34.48, 36.76], "text": " I was fortunate to be able to test out early versions"}, {"timestamp": [36.76, 39.4], "text": " of GPT for text generation."}, {"timestamp": [39.4, 40.96], "text": " And on the imaging side,"}, {"timestamp": [40.96, 43.72], "text": " I got to play with tools like generative adversarial networks"}, {"timestamp": [43.72, 45.44], "text": " for style transfer and disco diffusion, wombo to play with tools like Generative Adversarial Networks for style transfer, and"}, {"timestamp": [45.44, 50.8], "text": " Disco Diffusion, Wombo Dream, and other tools. These early apps were rather primitive, and"}, {"timestamp": [50.8, 55.7], "text": " the output was not particularly useful for professional work, so it was easy to dismiss"}, {"timestamp": [55.7, 61.12], "text": " them as toys. Now though, we've gotten to the point where you simply can't ignore"}, {"timestamp": [61.12, 65.6], "text": " them. My goal is to give marketers a sense of where we are in this space,"}, {"timestamp": [71.52, 76.72], "text": " and where we appear to be headed. I'm going to touch on aspects of technology, law, history, and the day-to-day impact on our lives. This tech is going to have a tremendous impact on"}, {"timestamp": [76.72, 82.0], "text": " everything that we do in this field, and you ignore it at your peril. Future videos will"}, {"timestamp": [82.0, 85.84], "text": " go more in-depth on areas like image and text creation."}, {"timestamp": [85.84, 90.36], "text": " When you think about what it is that we do in this profession every day, it covers a"}, {"timestamp": [90.36, 97.28], "text": " very broad spectrum of tasks. As creators, we build ads, we write copy, we do sponsorships"}, {"timestamp": [97.28, 102.96], "text": " and events and publicity and PR and strategy and social and so much more. We never have"}, {"timestamp": [102.96, 107.0], "text": " enough time or resources to get everything done."}, {"timestamp": [107.0, 112.0], "text": " That's true in every shop out there to some degree or another. Where these new technologies"}, {"timestamp": [112.0, 117.24], "text": " come into play is that they can help automate a lot of this work. It won't do everything"}, {"timestamp": [117.24, 123.0], "text": " well. It is not yet to the point where it replaces us, but we all get an extra pair"}, {"timestamp": [123.0, 125.8], "text": " of virtual hands to help with the endless"}, {"timestamp": [125.8, 129.7], "text": " tasks on our plates. Think of it as getting an intern."}, {"timestamp": [129.7, 134.96], "text": " This slice of the AI sector is exploding. Here you can see some of the generative AI"}, {"timestamp": [134.96, 141.2], "text": " landscapes put together by Sequoia, Base10, and Antler. The latter has a nice little database"}, {"timestamp": [141.2, 145.42], "text": " of companies in this area. They're tracking over 300 of them,"}, {"timestamp": [145.42, 147.88], "text": " and that is not a complete list."}, {"timestamp": [147.88, 150.54], "text": " This space is exploding in terms of energy"}, {"timestamp": [150.54, 152.88], "text": " and hype and funding."}, {"timestamp": [152.88, 154.68], "text": " If we narrow it down a bit to the things"}, {"timestamp": [154.68, 156.24], "text": " that are important to marketing,"}, {"timestamp": [156.24, 159.0], "text": " there's some really interesting tools out there"}, {"timestamp": [159.0, 161.36], "text": " that are useful in our day-to-day work."}, {"timestamp": [161.36, 163.04], "text": " You can do things like point some of them"}, {"timestamp": [163.04, 166.08], "text": " to a web page or a blog post and ask"}, {"timestamp": [166.08, 171.2], "text": " them to build a video for you. You can also feed them a song and automatically generate"}, {"timestamp": [171.2, 175.88], "text": " new ones that are inspired by it. They can create presentations for you based off a single"}, {"timestamp": [175.88, 182.8], "text": " prompt or create your ad copy and images. It seems like every week something new comes"}, {"timestamp": [182.8, 185.36], "text": " out. And one of the reasons why people are giddy"}, {"timestamp": [185.36, 188.84], "text": " about generative AI is that the coherence"}, {"timestamp": [188.84, 191.56], "text": " and quality of the outputs keeps increasing."}, {"timestamp": [191.56, 192.76], "text": " Here's an example."}, {"timestamp": [192.76, 195.52], "text": " If you look at this set of images from Google,"}, {"timestamp": [195.52, 199.48], "text": " the state of the art in 2014 for image generation is fuzzy."}, {"timestamp": [199.48, 200.84], "text": " It's black and white."}, {"timestamp": [200.84, 203.56], "text": " You can tell it's a face, but it isn't great."}, {"timestamp": [203.56, 210.72], "text": " It looks like a bad photocopy of a still from a grainy surveillance video. This is nowhere near where we are nowadays,"}, {"timestamp": [210.72, 215.24], "text": " where photorealistic outputs are achievable. In fact, there was an interesting study that"}, {"timestamp": [215.24, 220.78], "text": " was done recently on synthetic images versus photographs of actual humans. People seemed"}, {"timestamp": [220.78, 227.52], "text": " to prefer the computer-generated ones and thought they were more real than traditional photographs. That's astonishing."}, {"timestamp": [227.8, 233.32], "text": " We've come a long way since the first mathematical model of a neural network called a perceptron,"}, {"timestamp": [233.68, 240.6], "text": " which was invented way back in 1943 by McCulloch and Pitts and finally implemented in hardware in"}, {"timestamp": [241.36, 247.84], "text": " 1957. This device was connected to a camera that produced a 400 pixel image."}, {"timestamp": [247.84, 252.68], "text": " So what's driving all these recent improvements in quality? Some of it has to do with the"}, {"timestamp": [252.68, 258.88], "text": " amount and quality of data that is being fed into the models. GPT-3, for example, was supposedly"}, {"timestamp": [258.88, 264.68], "text": " trained on vast swaths of the web. And one useful measure of the power of these systems"}, {"timestamp": [264.68, 266.8], "text": " is something called the parameter count."}, {"timestamp": [266.8, 269.88], "text": " In this chart, which was shared by a very talented AI"}, {"timestamp": [269.88, 272.56], "text": " researcher by the name of David Shapiro,"}, {"timestamp": [272.56, 276.04], "text": " we can see that state of the art in early 2018"}, {"timestamp": [276.04, 278.64], "text": " was a model called ELMO that clocked in"}, {"timestamp": [278.64, 281.32], "text": " at 94 million parameters."}, {"timestamp": [281.32, 285.2], "text": " Then later that year, we had BERT at 340 million parameters."}, {"timestamp": [285.32, 289.4], "text": " So we see this count increase and also a fascination with Sesame Street"}, {"timestamp": [289.4, 293.52], "text": " characters. Fast forward to GPT-2 in early 2019,"}, {"timestamp": [293.52, 298.0], "text": " and we get 1.5 billion parameters. Then GPT-3,"}, {"timestamp": [298.12, 302.32], "text": " which is a base model for Chad GPT arrives two years later at"}, {"timestamp": [302.32, 305.0], "text": " 175 billion parameters."}, {"timestamp": [305.24, 308.7], "text": " In 2021, we got Microsoft's Megatron Turing model"}, {"timestamp": [308.7, 311.56], "text": " at over half a trillion parameters."}, {"timestamp": [311.56, 315.72], "text": " You can clearly see an almost linear increase over time"}, {"timestamp": [315.72, 317.36], "text": " in those parameter counts."}, {"timestamp": [317.36, 318.72], "text": " So why does that matter?"}, {"timestamp": [318.72, 321.12], "text": " Well, it turns out that as parameter counts"}, {"timestamp": [321.12, 324.48], "text": " and the amount and quality of data increases,"}, {"timestamp": [324.48, 326.0], "text": " new capabilities emerge."}, {"timestamp": [326.0, 330.0], "text": " Here you can see an example that Google shared with a party model,"}, {"timestamp": [330.0, 336.0], "text": " where at 750 million parameters, the system is able to generate an image of a kangaroo holding a sign."}, {"timestamp": [336.0, 338.0], "text": " But the words are illegible."}, {"timestamp": [338.0, 341.0], "text": " If you crank that up to 20 billion parameters,"}, {"timestamp": [341.0, 346.86], "text": " not only does the fidelity of the image increase, but the model learned how to spell."}, {"timestamp": [346.86, 349.28], "text": " The researchers didn't teach it how to spell."}, {"timestamp": [349.28, 352.14], "text": " The behavior spontaneously emerged."}, {"timestamp": [352.14, 355.22], "text": " And this keeps happening with these technologies."}, {"timestamp": [355.22, 360.0], "text": " Their own creators are continually astonished by these emergent capabilities."}, {"timestamp": [360.0, 366.72], "text": " It can produce code, rap, do poetry, music, all sorts of things."}, {"timestamp": [366.72, 371.94], "text": " Facebook had to shut down a project way back in 2017 where two chatbots started talking"}, {"timestamp": [371.94, 376.78], "text": " to each other as they invented their own language that humans couldn't understand."}, {"timestamp": [376.78, 380.86], "text": " So what happens when we get to that trillion parameter count?"}, {"timestamp": [380.86, 384.22], "text": " The possibilities are astonishing to contemplate."}, {"timestamp": [384.22, 390.0], "text": " That's especially true because AI researchers are learning to make these models even more efficient, with fewer parameters."}, {"timestamp": [390.0, 397.0], "text": " You have a model like GPT-NeoX at only 20 billion parameters, which is a small fraction of the size of GPT-3,"}, {"timestamp": [397.0, 402.0], "text": " and it can produce very compelling and creative stories out of applications like novel AI."}, {"timestamp": [402.0, 409.6], "text": " In that way, parameter count is similar to megahertz for processors or megapixels for cameras. The increases"}, {"timestamp": [409.6, 413.56], "text": " tell you something, but it isn't the full story. To give you a sense of how"}, {"timestamp": [413.56, 417.88], "text": " powerful these large language models have become, here you can see how chat2BT"}, {"timestamp": [417.88, 422.92], "text": " responds to some of the original Turing test questions. Alan Turing devised this"}, {"timestamp": [422.92, 430.28], "text": " test years ago to help us determine exactly when we got to a point where an artificial system was truly intelligent."}, {"timestamp": [430.28, 435.16], "text": " We've made impressive progress. Now let's dive just a little bit into GPT because"}, {"timestamp": [435.16, 439.44], "text": " that's the one that we've all heard about now because of ChatGPT. I saw the"}, {"timestamp": [439.44, 443.52], "text": " other day that over 30% of American adults have tried out this technology"}, {"timestamp": [443.52, 445.34], "text": " and it's on track to be"}, {"timestamp": [445.34, 449.22], "text": " the app with the fastest adoption in history."}, {"timestamp": [449.22, 453.8], "text": " GPT is a large language model, and here's what it stands for."}, {"timestamp": [453.8, 457.14], "text": " Generative means it is capable of creating new things."}, {"timestamp": [457.14, 461.2], "text": " Pre-trained means that out of the box it can do a host of different tasks."}, {"timestamp": [461.2, 468.24], "text": " And this is different from classical machine learning models that were trained to do a single task, classify items, perform sentiment"}, {"timestamp": [468.24, 472.92], "text": " analysis, that sort of thing. GPT models can write sentences, they can write blog"}, {"timestamp": [472.92, 476.64], "text": " posts, or perform more traditional machine learning tasks like sentiment"}, {"timestamp": [476.64, 481.84], "text": " analysis. The T stands for transformers. This was a technology that was initially"}, {"timestamp": [481.84, 488.5], "text": " developed by Google. In 2017, they very kindly shared it with the world in a paper called,"}, {"timestamp": [488.5, 490.5], "text": " Attention is all you need."}, {"timestamp": [490.5, 493.5], "text": " Transformers is a neural network architecture,"}, {"timestamp": [493.5, 497.0], "text": " and what it does is sequence to sequence predictions."}, {"timestamp": [497.0, 500.5], "text": " A sequence would be something like 1, 2, 3."}, {"timestamp": [500.5, 503.5], "text": " If I start with that, and then I ask you to predict what comes next,"}, {"timestamp": [503.5, 505.64], "text": " you would say 4, 5, 6."}, {"timestamp": [505.64, 512.44], "text": " If instead I said 4, 6, 8, you would respond with 10, 12, 14."}, {"timestamp": [512.44, 516.26], "text": " If I gave you to be or not, you would say to be."}, {"timestamp": [516.26, 521.6], "text": " So this ability to take in a sequence of inputs and then predict the sequence of outputs is"}, {"timestamp": [521.6, 524.28], "text": " a foundational element of this model."}, {"timestamp": [524.28, 529.08], "text": " And it turns out to be extremely powerful, because a sequence can be anything."}, {"timestamp": [529.08, 530.72], "text": " For example, they can be sentences."}, {"timestamp": [530.72, 535.32], "text": " And that makes sense, because the Google team was initially focused on translations, and"}, {"timestamp": [535.32, 540.36], "text": " their task was to determine how to go from one language to another, even when the word"}, {"timestamp": [540.36, 542.84], "text": " order doesn't always match."}, {"timestamp": [542.84, 545.32], "text": " This technique can also be applied to code generation"}, {"timestamp": [545.32, 552.84], "text": " or even tasks like using DNA to predict protein sequences. Anything that has a pattern can"}, {"timestamp": [552.84, 555.36], "text": " be fed into these transformers."}, {"timestamp": [555.36, 559.96], "text": " Now that you know what GPD stands for, let's look at how we use them. You start out with"}, {"timestamp": [559.96, 564.72], "text": " pre-trained models which are capable of doing a whole lot of things, but you need to be"}, {"timestamp": [564.72, 570.08], "text": " able to direct them to produce useful output. And the way you do that is through a process called prompt"}, {"timestamp": [570.08, 575.92], "text": " engineering. For example, you can ask the model to give you a headline that matches a particular set"}, {"timestamp": [575.92, 581.36], "text": " of conditions, like including certain words or using a particular tone. It turns out that prompt"}, {"timestamp": [581.36, 585.12], "text": " engineering is an art form that requires some level of skill,"}, {"timestamp": [589.6, 594.88], "text": " just like any other activity. One pattern that I've noticed among some folks when they're first introduced to this tech is that they'll use some quick and dirty perfunctory prompt. And when the"}, {"timestamp": [594.88, 599.44], "text": " output doesn't match the caliber of a highly trained professional, particularly one in their"}, {"timestamp": [599.44, 607.2], "text": " area of specialization, they scoff at the results and declare with confidence that it's only capable of mediocrity."}, {"timestamp": [607.2, 611.26], "text": " Musicians will say that the output sounds like music, and highly accomplished writers"}, {"timestamp": [611.26, 615.88], "text": " or editors say that the text is bland and soulless."}, {"timestamp": [615.88, 620.38], "text": " In fairness to the critics, these models are not yet to the point where they can produce"}, {"timestamp": [620.38, 625.84], "text": " works of the caliber of say, Vivaldi or Shakespeare. Even now, people can produce"}, {"timestamp": [625.84, 632.16], "text": " quality outputs that suffice for many marketing needs. It takes some training though. Imagine"}, {"timestamp": [632.16, 636.74], "text": " handing someone an instrument that they've never played and expecting them to dazzle"}, {"timestamp": [636.74, 641.44], "text": " you with a stunning rendition of your favorite song. It is true that the bar has been lowered"}, {"timestamp": [641.44, 648.08], "text": " tremendously by this technology. It democratizes access to creative outlets that were inaccessible to the majority of"}, {"timestamp": [648.08, 649.08], "text": " people."}, {"timestamp": [649.08, 653.84], "text": " Folks that couldn't draw a stick figure are suddenly capable of producing works that win"}, {"timestamp": [653.84, 655.16], "text": " awards."}, {"timestamp": [655.16, 660.4], "text": " It also opens creative outlets to disabled people that physically couldn't participate"}, {"timestamp": [660.4, 661.88], "text": " in some of these arts."}, {"timestamp": [661.88, 665.22], "text": " However, some skill is still involved to get the highest"}, {"timestamp": [665.22, 670.28], "text": " quality outputs. The world is just getting started with prompt engineering. There is"}, {"timestamp": [670.28, 673.54], "text": " so much yet to learn and invent."}, {"timestamp": [673.54, 677.44], "text": " Prompts can let you guide those pre-trained models towards useful results. Though they're"}, {"timestamp": [677.44, 682.6], "text": " filled with tons of general purpose knowledge, it's unlikely that they know anything about"}, {"timestamp": [682.6, 685.48], "text": " your particular campaign or all the latest"}, {"timestamp": [685.48, 688.54], "text": " details about the products or service that you work on."}, {"timestamp": [688.54, 692.76], "text": " There are ways of imparting that knowledge into these systems using a technique called"}, {"timestamp": [692.76, 693.76], "text": " fine tuning."}, {"timestamp": [693.76, 699.04], "text": " It is a bit of a dark art at the moment, but together with expert prompts, you can generate"}, {"timestamp": [699.04, 704.6], "text": " truly stunning works that align to your brand and objectives."}, {"timestamp": [704.6, 708.92], "text": " And we're approaching what I like to think of as the anything-to-anything era."}, {"timestamp": [708.92, 711.84], "text": " As a marketer, you already deal with all these modalities."}, {"timestamp": [711.84, 717.8], "text": " You have text, images, audio, video, data, code, and 3D objects."}, {"timestamp": [717.8, 723.48], "text": " The truly talented amongst us know how to assemble all the right elements into compelling"}, {"timestamp": [723.48, 724.48], "text": " experiences."}, {"timestamp": [724.48, 727.88], "text": " What's fascinating about these new generative technologies"}, {"timestamp": [727.88, 731.64], "text": " is that they permit you to go from one to another."}, {"timestamp": [731.64, 734.52], "text": " A canonical example would start out with text"}, {"timestamp": [734.52, 736.52], "text": " and transform that into an image."}, {"timestamp": [736.52, 739.86], "text": " You can also do the reverse though and start out with an image"}, {"timestamp": [739.86, 742.2], "text": " that gets converted to text on the other end."}, {"timestamp": [742.2, 744.2], "text": " You can go from text to song."}, {"timestamp": [744.2, 746.8], "text": " Google just came out with a new music model. You can go from text to song. Google just came out with a new music model"}, {"timestamp": [746.8, 749.54], "text": " that lets you go from image to song."}, {"timestamp": [749.54, 752.72], "text": " They showed an example of Van Gogh's Starry Night image"}, {"timestamp": [752.72, 755.34], "text": " getting converted into music."}, {"timestamp": [755.34, 757.38], "text": " And we're getting to the point where pretty much"}, {"timestamp": [757.38, 760.18], "text": " any input can go to any output."}, {"timestamp": [760.18, 762.84], "text": " Just imagine the power that gives you as a marketer."}, {"timestamp": [762.84, 766.2], "text": " If the current pace of progress continues unabated,"}, {"timestamp": [766.2, 769.3], "text": " you'll soon be able to create anything you want,"}, {"timestamp": [769.3, 772.1], "text": " and then quickly and inexpensively"}, {"timestamp": [772.1, 775.6], "text": " orchestrate experiences across all these modalities."}, {"timestamp": [775.6, 777.2], "text": " That's incredibly exciting."}, {"timestamp": [777.2, 780.6], "text": " And this is possible because these models are composable."}, {"timestamp": [780.6, 782.5], "text": " You can stack them on top of each other"}, {"timestamp": [782.5, 785.24], "text": " and rearrange inputs and outputs in all sorts"}, {"timestamp": [785.24, 786.68], "text": " of interesting ways."}, {"timestamp": [786.68, 792.08], "text": " For example, one great way to level up your generative AI images is to use a GPT-based"}, {"timestamp": [792.08, 795.16], "text": " tool to embellish your initial prompt."}, {"timestamp": [795.16, 800.92], "text": " Here you can see a working demo available to anyone via Hugging Phase, where the conversational"}, {"timestamp": [800.92, 807.12], "text": " capabilities of GPT and Whisper are paired with a mathematical rigger of WolframAlpha"}, {"timestamp": [807.12, 812.88], "text": " along with the realistic avatars from XHuman. These are all linked via the Lang Cheng project."}, {"timestamp": [813.44, 817.52], "text": " It gives us a glimpse of the types of applications we will see in the future."}, {"timestamp": [817.52, 821.92], "text": " An example where that approach would be useful on the marketing side would be through the"}, {"timestamp": [821.92, 825.96], "text": " enrichment of personas we create as the archetypes of"}, {"timestamp": [825.96, 827.96], "text": " the customers we serve."}, {"timestamp": [827.96, 834.0], "text": " Imagine feeding a chatbot all of the information that you have on a particular persona and"}, {"timestamp": [834.0, 838.28], "text": " then asking it to react to certain scenarios or product enhancements."}, {"timestamp": [838.28, 843.9], "text": " You could take this a step further and embody that persona in an interactive avatar."}, {"timestamp": [843.9, 845.44], "text": " On the technology side,"}, {"timestamp": [845.44, 848.32], "text": " you have this notion of a full-stack developer."}, {"timestamp": [848.32, 849.76], "text": " That's a person that knows how to do"}, {"timestamp": [849.76, 852.36], "text": " the front-end coding to build user interfaces,"}, {"timestamp": [852.36, 854.72], "text": " but can also tackle back-end applications and"}, {"timestamp": [854.72, 857.96], "text": " databases and whatever else you need to build a modern app."}, {"timestamp": [857.96, 860.64], "text": " Generative AI can do something similar"}, {"timestamp": [860.64, 864.22], "text": " and empower a new set of full-stack marketers."}, {"timestamp": [864.22, 869.0], "text": " These will be somewhat akin to movie directors, in that they will be able to quickly create"}, {"timestamp": [869.0, 874.68], "text": " artifacts across modalities and then bundle them in creative ways."}, {"timestamp": [874.68, 879.78], "text": " Those that master these new technologies will be demonstrably more productive than those"}, {"timestamp": [879.78, 882.0], "text": " that don't take the time to learn them."}, {"timestamp": [882.0, 886.92], "text": " In terms of job safety, it makes no sense to stick your head in the sand"}, {"timestamp": [886.92, 889.6], "text": " and hope that this AI stuff will simply go away."}, {"timestamp": [889.6, 891.24], "text": " It's not gonna happen."}, {"timestamp": [891.24, 893.16], "text": " The genie is out of the bottle."}, {"timestamp": [893.16, 894.44], "text": " And when companies figure out"}, {"timestamp": [894.44, 896.66], "text": " how this accelerates productivity,"}, {"timestamp": [896.66, 898.36], "text": " there's no turning back."}, {"timestamp": [898.36, 900.8], "text": " But of course, as with everything else,"}, {"timestamp": [900.8, 903.32], "text": " there's a downside to these advancements."}, {"timestamp": [903.32, 905.12], "text": " We've all been seeing headlines in the news"}, {"timestamp": [905.12, 911.18], "text": " lately about these technologies taking away jobs, along with predictions like 90% of online"}, {"timestamp": [911.18, 917.92], "text": " content will be created by AI by 2025. There is a lot of fear in the system, and some of"}, {"timestamp": [917.92, 924.1], "text": " it is wholly justified. AI will take jobs, there's no question about it. Initially, the"}, {"timestamp": [924.1, 927.76], "text": " folks that are going to be the most at risk are beginners and those of"}, {"timestamp": [927.76, 929.36], "text": " meddling talent."}, {"timestamp": [929.36, 934.24], "text": " There's a very real danger now that people that are just entering the workforce and those"}, {"timestamp": [934.24, 939.68], "text": " that don't have adjacent skills in business or tech will get supplanted by the machines."}, {"timestamp": [939.68, 945.2], "text": " And that's why proponents of this field that are in the quest towards AGI or Artificial General Intelligence"}, {"timestamp": [946.08, 951.2], "text": " often tout the need to deploy something like universal basic income. The failure to provide"}, {"timestamp": [951.2, 957.68], "text": " a safety net if most jobs get automated would be catastrophic. It is useful though to step back a"}, {"timestamp": [957.68, 965.7], "text": " bit from all that hype, drama, and fear and realize that we've gone through similar disruptions many times in the past."}, {"timestamp": [965.7, 971.02], "text": " For example, if we go way back a couple thousand years ago, we arrive at the dawn of the written"}, {"timestamp": [971.02, 972.7], "text": " word."}, {"timestamp": [972.7, 977.44], "text": " That technology was introduced into an era of strong oral traditions."}, {"timestamp": [977.44, 981.74], "text": " You had people that had mastered the art of verbal storytelling, and those orators were"}, {"timestamp": [981.74, 985.6], "text": " not in the least bit pleased with this newfangled writing"}, {"timestamp": [985.6, 986.6], "text": " technology."}, {"timestamp": [986.6, 991.4], "text": " Here you can see a quote from Socrates, one of the wisest and most accomplished people"}, {"timestamp": [991.4, 996.04], "text": " in history, where he rails against writing as something that is going to destroy our"}, {"timestamp": [996.04, 1001.52], "text": " memory and which will give people the appearance of wisdom versus true wisdom."}, {"timestamp": [1001.52, 1005.38], "text": " If you make the language a bit less archaic, you could almost mistake"}, {"timestamp": [1005.38, 1010.32], "text": " this for a modern diatrab against chat GPT. I'm sure he would have also been less than"}, {"timestamp": [1010.32, 1015.8], "text": " thrilled about the memory loss implications of Google search. Now the funny thing is that"}, {"timestamp": [1015.8, 1021.28], "text": " the only reason that we know about him is because some of his disciples, like Plato,"}, {"timestamp": [1021.28, 1026.76], "text": " embraced that shiny new tech and included him as a character in their writings. Otherwise"}, {"timestamp": [1026.76, 1030.44], "text": " he could have easily been lost to posterity."}, {"timestamp": [1030.44, 1035.64], "text": " Fast forward a couple millennia and you have the introduction of photography. At the time,"}, {"timestamp": [1035.64, 1040.36], "text": " portrait painters were up in arms with that new tech and there was vehement pushback in"}, {"timestamp": [1040.36, 1045.64], "text": " some quarters about photography not being a true art. Photographers were ridiculed"}, {"timestamp": [1045.64, 1050.94], "text": " by more traditional artists as little more than button pushers that had no true skills"}, {"timestamp": [1050.94, 1055.54], "text": " or creative vision. It wasn't until much later that the works of photographers such"}, {"timestamp": [1055.54, 1062.06], "text": " as Ansel Adams got grudging acceptance in those quarters. But now, of course, some photographers"}, {"timestamp": [1062.06, 1065.04], "text": " are up in arms because generative AI is poised"}, {"timestamp": [1065.04, 1067.32], "text": " to take a slice of their pie."}, {"timestamp": [1067.32, 1072.72], "text": " This is not a wholly irrational fear, especially for areas like stock photography."}, {"timestamp": [1072.72, 1076.88], "text": " We see then that there is a detectable pattern with these disruptions."}, {"timestamp": [1076.88, 1082.32], "text": " What tends to happen is that the new technologies eventually coexist with the old ones, even"}, {"timestamp": [1082.32, 1090.24], "text": " if the latter are transformed to some degree. and the transition itself is painful for those involved. For example, the oral"}, {"timestamp": [1090.24, 1095.72], "text": " tradition is still alive and well in classrooms, as well as in theater, movies,"}, {"timestamp": [1095.72, 1099.92], "text": " and even video games. People will continue to paint because it's a"}, {"timestamp": [1099.92, 1104.2], "text": " pleasurable and fulfilling activity, in the same way that pianists didn't"}, {"timestamp": [1104.2, 1105.24], "text": " disappear with the introduction of that pianists didn't disappear"}, {"timestamp": [1105.24, 1111.32], "text": " with the introduction of the pianola or records or radio, which automated that task."}, {"timestamp": [1111.32, 1114.84], "text": " The same thing will likely happen with photography."}, {"timestamp": [1114.84, 1119.08], "text": " Human beings will always have a need to reminisce over artifacts to store memories of their"}, {"timestamp": [1119.08, 1120.08], "text": " lives."}, {"timestamp": [1120.08, 1125.3], "text": " In some ways, that's how we know who we are, by looking back at where we came from."}, {"timestamp": [1125.3, 1128.24], "text": " That doesn't mean that there won't be change, though,"}, {"timestamp": [1128.24, 1130.12], "text": " and some of it will be wrenching."}, {"timestamp": [1130.12, 1134.0], "text": " Photography as a discipline is becoming more computational,"}, {"timestamp": [1134.0, 1135.52], "text": " and we're headed in directions"}, {"timestamp": [1135.52, 1137.64], "text": " that would have likely astonished pioneers"}, {"timestamp": [1137.64, 1140.6], "text": " like Daguerre or Eastman Kodak."}, {"timestamp": [1140.6, 1143.26], "text": " I believe we're moving in the direction of a setup"}, {"timestamp": [1143.26, 1150.56], "text": " that will enable people to capture wide swaths of reality and then extract the bits and pieces that are useful at a later"}, {"timestamp": [1150.56, 1151.62], "text": " date."}, {"timestamp": [1151.62, 1158.12], "text": " This is nicely captured in Insta360's slogan of, shoot first, frame later."}, {"timestamp": [1158.12, 1163.76], "text": " We can already see glimpses of this future with existing products like 360 cameras, the"}, {"timestamp": [1163.76, 1165.72], "text": " LiDAR and depth map capabilities"}, {"timestamp": [1165.72, 1167.74], "text": " that already exist in many phones,"}, {"timestamp": [1167.74, 1170.3], "text": " neural radiance fields or NERF capabilities"}, {"timestamp": [1170.3, 1173.32], "text": " that players like Luma and NVIDIA are producing,"}, {"timestamp": [1173.32, 1176.46], "text": " and light field cameras and lenses like the K-Lens."}, {"timestamp": [1176.46, 1178.84], "text": " At some point, a company is gonna combine"}, {"timestamp": [1178.84, 1181.72], "text": " a number of these innovations into a single device"}, {"timestamp": [1181.72, 1186.3], "text": " that captures high-fidelity 3D scenes with movement, out of which at a"}, {"timestamp": [1186.3, 1194.28], "text": " later time you can extract 2D stills for photos, 2D movement for videos, or full-blown 3D scenes"}, {"timestamp": [1194.28, 1198.02], "text": " for augmented reality or VR apps."}, {"timestamp": [1198.02, 1203.9], "text": " These raw reality captures could of course be combined with synthetic objects using generative"}, {"timestamp": [1203.9, 1206.12], "text": " AI. We can already see very"}, {"timestamp": [1206.12, 1212.34], "text": " primitive versions of this with the AR apps from Ikea or Home Depot that let you visualize"}, {"timestamp": [1212.34, 1216.44], "text": " what a piece of furniture would look like in your living room via an iPhone. It's a"}, {"timestamp": [1216.44, 1222.48], "text": " very exciting time to be alive, but of course, with any disruptions of this magnitude, you're"}, {"timestamp": [1222.48, 1225.84], "text": " going to have victims and a predictable backlash."}, {"timestamp": [1225.84, 1229.06], "text": " At this stage, the most vociferous opposition"}, {"timestamp": [1229.06, 1231.14], "text": " comes from the art community,"}, {"timestamp": [1231.14, 1233.6], "text": " some of whom are united under the banner of"}, {"timestamp": [1233.6, 1235.96], "text": " AI art is stealing."}, {"timestamp": [1235.96, 1238.32], "text": " Some of the most extreme members of this group"}, {"timestamp": [1238.32, 1242.28], "text": " are even making death threats against AI creators."}, {"timestamp": [1242.28, 1246.72], "text": " The charge of stealing should give everyone pause, because most of us don't want"}, {"timestamp": [1246.72, 1252.4], "text": " to partake in unethical activities, and we certainly don't want to put our employers at risk"}, {"timestamp": [1252.4, 1258.72], "text": " either. I think it's worth breaking down exactly what is meant by the word theft. If we're talking"}, {"timestamp": [1258.72, 1266.48], "text": " about jobs, then that is absolutely the truth. AI will take away jobs, just like every prior wave of"}, {"timestamp": [1266.48, 1272.48], "text": " automation before it. Before anyone gets too high on their horse though, on this particular matter,"}, {"timestamp": [1272.48, 1276.72], "text": " I would ask them to look down at their feet and check out what they're wearing."}, {"timestamp": [1276.72, 1283.6], "text": " In all likelihood, it is not shoes handcrafted by a shoemaker. Most of our footwear is now mass"}, {"timestamp": [1283.6, 1285.28], "text": " produced in some type of factory."}, {"timestamp": [1285.28, 1289.84], "text": " By and large, people don't tend to work as artists and shoemakers anymore. As a"}, {"timestamp": [1289.84, 1295.72], "text": " species, we always tend to make the choice of low cost and convenience, which"}, {"timestamp": [1295.72, 1301.42], "text": " is why most of us don't travel via buggy or horse as much as that choice hurt the"}, {"timestamp": [1301.42, 1309.28], "text": " carriage and saddle makers when that transition occurred. Some of you will say, well, that wasn't me, my grandparents or great-grandparents made"}, {"timestamp": [1309.28, 1310.28], "text": " that decision."}, {"timestamp": [1310.28, 1314.8], "text": " Well, let's fast forward to something more recent and think about how many of us stopped"}, {"timestamp": [1314.8, 1320.4], "text": " frequenting Blockbuster Video or a similar chain when Netflix came out."}, {"timestamp": [1320.4, 1326.72], "text": " Or who among us has not shopped at Amazon, much to the detriment of your local mom-and-pop shop."}, {"timestamp": [1326.72, 1331.2], "text": " We are all complicit in this quest for automation and convenience,"}, {"timestamp": [1331.2, 1336.96], "text": " so to look askance when it more directly affects you is understandable, but a bit hypocritical."}, {"timestamp": [1336.96, 1343.2], "text": " The second charge under the AI art is stealing banner is that the outputs are simply banal"}, {"timestamp": [1343.2, 1346.38], "text": " derivative works purloined off the hard labor"}, {"timestamp": [1346.38, 1353.64], "text": " of others. In other words, AI art lacks originality, which is only possible through the more traditional"}, {"timestamp": [1353.64, 1359.44], "text": " means where humans are in more direct control of the output. This harkens back to the myth"}, {"timestamp": [1359.44, 1366.1], "text": " of the lone genius that cooks up splendid works in complete isolation from others."}, {"timestamp": [1366.1, 1371.76], "text": " This is utter nonsense, and some of our wisest and most accomplished people in history have"}, {"timestamp": [1371.76, 1374.58], "text": " rightfully acknowledged that fact."}, {"timestamp": [1374.58, 1379.12], "text": " Here you can see how Isaac Newton talked about working on the shoulders of giants."}, {"timestamp": [1379.12, 1383.0], "text": " Picasso and Lincoln and so many others have made similar statements."}, {"timestamp": [1383.0, 1385.28], "text": " We're all riffing off each other"}, {"timestamp": [1385.28, 1390.72], "text": " and making use of that creative commons in our shared history. Nobody is wholly original,"}, {"timestamp": [1390.72, 1394.16], "text": " though of course some people make better incremental improvements than others"}, {"timestamp": [1394.8, 1401.52], "text": " and we rightfully celebrate their brilliance. What generative AI does is to help speed up that"}, {"timestamp": [1401.52, 1405.92], "text": " process of riffing and remixing the useful contributions from the past"}, {"timestamp": [1406.48, 1412.08], "text": " in novel and new directions. Now just think about what it is that we do in our day-to-day work as"}, {"timestamp": [1412.08, 1419.36], "text": " marketers. If you need to launch a campaign or a new product or website, standard practice is to"}, {"timestamp": [1419.36, 1426.16], "text": " check out what the best in class or your peers are up to. You take those ideas and innovations and movements"}, {"timestamp": [1426.16, 1432.8], "text": " in fashion and styles and then craft something that matches your particular needs and the moment."}, {"timestamp": [1432.8, 1439.28], "text": " The bottom line is I believe this part of the AI artist stealing case is simply overblown and not"}, {"timestamp": [1439.28, 1446.14], "text": " based on facts. Next we get to the legal aspects of this saga, where the story gets murky and convoluted"}, {"timestamp": [1446.14, 1447.68], "text": " rather quickly."}, {"timestamp": [1447.68, 1451.64], "text": " The truth of the matter is that nobody knows how this will play out in the legal systems"}, {"timestamp": [1451.64, 1452.8], "text": " across the globe."}, {"timestamp": [1452.8, 1459.26], "text": " It will probably take years for legislators, regulators, and judges to sort through this"}, {"timestamp": [1459.26, 1461.28], "text": " tangled thicket."}, {"timestamp": [1461.28, 1467.16], "text": " Despite this fact, we still need to make our own personal decisions about the ethics"}, {"timestamp": [1467.16, 1471.72], "text": " of using this technology and determine the appropriate level of risk that it presents"}, {"timestamp": [1471.72, 1477.62], "text": " to the companies we serve. With that in mind, let's touch on a couple of aspects of this"}, {"timestamp": [1477.62, 1480.76], "text": " as they relate to the AI artist stealing charge."}, {"timestamp": [1480.76, 1486.64], "text": " First, if a close replica of a copyrighted work is used for commercial purposes, then"}, {"timestamp": [1486.64, 1492.94], "text": " it is clear that in most cases it will run afoul of copyright regimes."}, {"timestamp": [1492.94, 1497.4], "text": " Generative AI isn't bringing anything new to the table here. This is true regardless"}, {"timestamp": [1497.4, 1502.94], "text": " of the means of duplication. It could be photocopied or done in Windows Explorer or Photoshop."}, {"timestamp": [1502.94, 1505.18], "text": " You can't directly replicate the works or"}, {"timestamp": [1505.18, 1509.98], "text": " copyrighted characters of others for profit, without legal risk."}, {"timestamp": [1509.98, 1514.14], "text": " When we get to the notion of style, though, the story is completely different."}, {"timestamp": [1514.14, 1519.14], "text": " You cannot copyright a style, at least in the United States, and there's a very good"}, {"timestamp": [1519.14, 1520.46], "text": " reason for that."}, {"timestamp": [1520.46, 1525.52], "text": " If styles could be copyrighted, then you'd have no artistic movements."}, {"timestamp": [1525.52, 1530.4], "text": " Imagine a world where Pablo Picasso could have prevented anyone from doing Cubist paintings,"}, {"timestamp": [1530.4, 1534.36], "text": " or Isaac Asimov owning grand space operas."}, {"timestamp": [1534.36, 1539.72], "text": " In that universe, there would be no Arthur C. Clarke sagas, or Star Trek, or Star Wars."}, {"timestamp": [1539.72, 1544.48], "text": " So artists getting upset with others for copying their style doesn't appear to have a strong"}, {"timestamp": [1544.48, 1549.5], "text": " basis in law, and frankly doesn't reflect the fact that artists themselves likely learn"}, {"timestamp": [1549.5, 1554.54], "text": " by mimicking the masters. We all profit from the comments."}, {"timestamp": [1554.54, 1559.54], "text": " Then we get to the notion of fair use and transformative use. These come into play when"}, {"timestamp": [1559.54, 1566.8], "text": " we think about the large volume of images that these models are trained on. Again, there is ample precedent for"}, {"timestamp": [1566.8, 1572.8], "text": " organizations being able to use available materials on the web and elsewhere to build commercial"}, {"timestamp": [1572.8, 1579.52], "text": " services. That's the business model that underlies Google Search, Kayak, Yelp, and so many other"}, {"timestamp": [1579.52, 1586.12], "text": " online providers. We all benefit from that ready access to those materials that they sort through"}, {"timestamp": [1586.12, 1591.82], "text": " and augment and make available at our fingertips. Specifically though, in terms of case law,"}, {"timestamp": [1591.82, 1597.0], "text": " you have examples like the lawsuit that Google won against the Authors Guild, which enabled"}, {"timestamp": [1597.0, 1601.92], "text": " them to keep scanning books. And if you look outside the US, you see that Germany, for"}, {"timestamp": [1601.92, 1606.46], "text": " example, has specifically enshrined the ability to use machine learning"}, {"timestamp": [1606.46, 1610.7], "text": " to scan through works for useful and transformative purposes."}, {"timestamp": [1610.7, 1615.94], "text": " Now there's all sorts of nuances when it comes to an artist's body of work."}, {"timestamp": [1615.94, 1622.18], "text": " The questions about enabling them to opt in or out of these models are worthy of deliberation."}, {"timestamp": [1622.18, 1626.5], "text": " What's also worth examining is what exactly gets included in these datasets"}, {"timestamp": [1626.5, 1632.0], "text": " and if they contain equitable representations of the world in terms of minorities and gender and so on."}, {"timestamp": [1632.0, 1637.5], "text": " And that goes hand in hand with the possible degradation of the quality of generative AI results"}, {"timestamp": [1637.5, 1641.0], "text": " if there aren't sufficient samples in each group."}, {"timestamp": [1641.0, 1645.62], "text": " These controversies have been swirling post-launch with DALI 2 and Stable"}, {"timestamp": [1645.62, 1651.8], "text": " Diffusion and are tied to similar charges in some quarters that ChattGBT has been neutered"}, {"timestamp": [1651.8, 1657.88], "text": " in the quest to, quote, go woke. We'll likely be debating this for a long time."}, {"timestamp": [1657.88, 1662.96], "text": " Lastly, one of the charges that was made in the lawsuit against Stability AI and others"}, {"timestamp": [1662.96, 1666.12], "text": " seemed to incorrectly characterize this technology"}, {"timestamp": [1666.12, 1670.76], "text": " as something that acted somewhat akin to a catalog. Specifically, the charge was that"}, {"timestamp": [1670.76, 1675.28], "text": " if you search for an image of a dog eating an ice cream cone, the system would essentially"}, {"timestamp": [1675.28, 1681.4], "text": " look through the database of available images and try to return one that matched that query."}, {"timestamp": [1681.4, 1685.74], "text": " This would be similar to a search engine. This is a fundamental misunderstanding"}, {"timestamp": [1685.74, 1691.32], "text": " of the technology. It just doesn't work that way. What these models instead do is"}, {"timestamp": [1691.32, 1696.42], "text": " to learn the patterns that are present in images, very similar to the way you or I might"}, {"timestamp": [1696.42, 1700.26], "text": " look at a painting. We'll notice the use of a particular technique when it comes to"}, {"timestamp": [1700.26, 1706.48], "text": " brush strokes or texture or color or composition. And unless you have a photographic memory,"}, {"timestamp": [1706.48, 1710.36], "text": " you don't memorize each brush stroke or pixel."}, {"timestamp": [1710.36, 1712.88], "text": " It is the same thing with these models."}, {"timestamp": [1712.88, 1715.1], "text": " In fact, you can prove it's the case,"}, {"timestamp": [1715.1, 1718.0], "text": " because if you look at one of the stable diffusion models,"}, {"timestamp": [1718.0, 1721.16], "text": " you see that it's a little bit over four gigabytes."}, {"timestamp": [1721.16, 1723.8], "text": " Most of us likely have more than four gigs of images"}, {"timestamp": [1723.8, 1726.52], "text": " on our personal phones, and that model was"}, {"timestamp": [1726.52, 1729.08], "text": " trained on the Lion 5B set."}, {"timestamp": [1729.08, 1736.38], "text": " It is not possible with our current technologies to store anywhere near 5 billion high-fidelity"}, {"timestamp": [1736.38, 1739.18], "text": " images in such a small amount of space."}, {"timestamp": [1739.18, 1742.64], "text": " The other charge you'll see is that these models can return output that is similar to"}, {"timestamp": [1742.64, 1744.32], "text": " their training set."}, {"timestamp": [1744.32, 1749.84], "text": " There is a small amount of truth here, but only in a very narrow sense. If a pattern is"}, {"timestamp": [1749.84, 1754.88], "text": " over-represented in the training set, then you can get something that somewhat resembles it"}, {"timestamp": [1754.88, 1760.32], "text": " through a process called memorization. Think of famous paintings like Van Gogh's Starry Night,"}, {"timestamp": [1760.32, 1764.4], "text": " or the Mona Lisa, that appear in endless iterations online."}, {"timestamp": [1764.4, 1770.62], "text": " There was a study that recently tried to quantify this problem, but the methodology was questionable."}, {"timestamp": [1770.62, 1777.06], "text": " They looked for images that appeared often in the set, and then ran 175 million generation"}, {"timestamp": [1777.06, 1780.62], "text": " requests to try to recreate them."}, {"timestamp": [1780.62, 1788.0], "text": " After all that, there was only an infinitesimal small chance that they get a very rough facsimile of the original image."}, {"timestamp": [1788.0, 1792.0], "text": " Essentially, you have to go out of your way to encounter this problem."}, {"timestamp": [1792.0, 1799.0], "text": " On the text generation side, there is a similar challenge, but again, it's highly dependent on the types of requests you're making."}, {"timestamp": [1799.0, 1805.28], "text": " Nevertheless, it's probably best practice to run any text you produce through a plagiarism"}, {"timestamp": [1805.28, 1810.0], "text": " checker like the one found in Grammarly, especially if it is long-form copy."}, {"timestamp": [1810.72, 1816.32], "text": " The bottom line, from my perspective, is if a company is producing assets that align with"}, {"timestamp": [1816.32, 1821.84], "text": " their brand standards and don't visibly infringe on the works of others, the risk seems minimal."}, {"timestamp": [1822.4, 1825.84], "text": " After all, we've had Photoshop and other tools for decades"}, {"timestamp": [1825.84, 1830.78], "text": " that already easily permit works of others to be misused, and there is no movement to"}, {"timestamp": [1830.78, 1831.78], "text": " ban those tools."}, {"timestamp": [1831.78, 1836.32], "text": " Now, let's bring this back to a more personal level and discuss coming to terms with this"}, {"timestamp": [1836.32, 1847.76], "text": " technology. This can be incredibly difficult, especially for creators. Many of us have passions that can be tied to our profession and in key ways help define"}, {"timestamp": [1847.76, 1850.54], "text": " who we are as human beings."}, {"timestamp": [1850.54, 1856.28], "text": " The idea that a machine could quickly churn out what we do is scary and upsetting."}, {"timestamp": [1856.28, 1860.82], "text": " In some ways we're dealing with a stages of grief type of scenario where each of us"}, {"timestamp": [1860.82, 1865.28], "text": " will need to go through denial, anger, acceptance, and so on."}, {"timestamp": [1866.16, 1870.56], "text": " I'd like to share a bit of my journey in this regard, and as you can likely tell from my"}, {"timestamp": [1870.56, 1875.84], "text": " numerous references to photography, that has been a passion of mine for quite some time."}, {"timestamp": [1875.84, 1882.16], "text": " I spent years taking classes and workshops. I invested thousands of hours of my life honing"}, {"timestamp": [1882.16, 1885.36], "text": " that craft and thousands of dollars buying gear."}, {"timestamp": [1885.36, 1889.76], "text": " And I have to admit, when I first put in some prompts for landscape photos"}, {"timestamp": [1890.32, 1897.68], "text": " and stable diffusion, with entries like Patagonia sunset, F11, water reflections, and so on,"}, {"timestamp": [1897.68, 1903.92], "text": " I was blown away by the results, and more than a little taken aback and sad. I wondered,"}, {"timestamp": [1903.92, 1905.72], "text": " is this the end of photography?"}, {"timestamp": [1905.72, 1908.68], "text": " This outlet that has brought me so much joy?"}, {"timestamp": [1908.68, 1911.0], "text": " What role will it play in a world"}, {"timestamp": [1911.0, 1913.64], "text": " where you can conjure these captivating vistas"}, {"timestamp": [1913.64, 1915.44], "text": " with a few keystrokes?"}, {"timestamp": [1915.44, 1917.6], "text": " And then I thought about the images themselves"}, {"timestamp": [1917.6, 1919.04], "text": " and what they meant to me as a person"}, {"timestamp": [1919.04, 1922.88], "text": " that tries to convey the beauty of the world I encounter."}, {"timestamp": [1922.88, 1925.36], "text": " After some time, I came to terms with the situation"}, {"timestamp": [1925.92, 1932.96], "text": " and decided there's still value in this craft to capture and share key memories of my life."}, {"timestamp": [1932.96, 1936.56], "text": " Incidentally, I created all the images you see here in stable diffusion,"}, {"timestamp": [1937.2, 1942.48], "text": " except for the blue one on the right. That shot I took in Banff National Forest in Canada. I"}, {"timestamp": [1942.48, 1948.52], "text": " caught up at some ungodly hour, like 3 or 4 AM, to get there during the blue hour before"}, {"timestamp": [1948.52, 1949.52], "text": " sunrise."}, {"timestamp": [1949.52, 1952.76], "text": " On that trip, I taught my daughters about photography."}, {"timestamp": [1952.76, 1955.04], "text": " And this shot hangs in my home."}, {"timestamp": [1955.04, 1960.96], "text": " In other words, it carries an emotional resonance that the AI ones don't possess, since I spent"}, {"timestamp": [1960.96, 1963.04], "text": " minimal energy on the latter."}, {"timestamp": [1963.04, 1968.64], "text": " For me, the difference between these objects is similar to that of making a splendid meal"}, {"timestamp": [1968.64, 1971.32], "text": " from scratch versus ordering takeout."}, {"timestamp": [1971.32, 1976.8], "text": " However, if I take off my personal hat and don the cap of a marketer, then I have to"}, {"timestamp": [1976.8, 1981.16], "text": " accept the fact that those factors really don't matter in a business context."}, {"timestamp": [1981.16, 1989.2], "text": " If I need an image for my webpage or ad, I'm probably going to go to a stock image library and find something there that in all likelihood has been used countless"}, {"timestamp": [1989.2, 1995.68], "text": " times before by others. From that perspective, the AI image is superior in that it is more"}, {"timestamp": [1995.68, 2000.46], "text": " likely to be unique. I say that, of course, with trepidation as someone that has profited"}, {"timestamp": [2000.46, 2008.44], "text": " from the sale of stock imagery. The bottom line is that we will probably all have to take a page from Ken Jennings' book"}, {"timestamp": [2008.44, 2012.68], "text": " and come to terms with the fact that AI is here to stay."}, {"timestamp": [2012.68, 2016.88], "text": " What's exciting about the generative AI space is that we're just getting started."}, {"timestamp": [2016.88, 2022.52], "text": " This year we can expect better video and 3D output, and the competition between OpenAI,"}, {"timestamp": [2022.52, 2025.56], "text": " Google, AnthropicAI, and others will be fierce."}, {"timestamp": [2025.56, 2032.0], "text": " It's an incredible time to be alive as creators, with access to superpowers that our predecessors"}, {"timestamp": [2032.0, 2033.16], "text": " could only dream of."}, {"timestamp": [2033.16, 2035.96], "text": " Let's take stock of some of the learnings in this area."}, {"timestamp": [2035.96, 2040.24], "text": " First, there's no silver bullet with any of these technologies."}, {"timestamp": [2040.24, 2044.88], "text": " Use lots of different models and services and generations to find what you're looking"}, {"timestamp": [2044.88, 2045.84], "text": " for."}, {"timestamp": [2052.48, 2058.24], "text": " All of the abilities you've honed as a marketer are still useful to convert these raw inputs into something that is production ready. At this stage, you still need an eye for design,"}, {"timestamp": [2058.24, 2069.0], "text": " good writing and editing skills, and a deep understanding of your business. Use AI as a muse, a collaborator, and an accelerator."}, {"timestamp": [2069.0, 2072.2], "text": " Do not blindly trust the output of any of these models."}, {"timestamp": [2072.2, 2077.92], "text": " Think of it as having an eager intern that lacks context and understanding of so much"}, {"timestamp": [2077.92, 2079.98], "text": " of what makes our world tick."}, {"timestamp": [2079.98, 2083.08], "text": " The quality of these outputs keeps increasing."}, {"timestamp": [2083.08, 2087.68], "text": " So even if you're unimpressed by what you see today, that will likely change in the"}, {"timestamp": [2087.68, 2088.68], "text": " future."}, {"timestamp": [2088.68, 2091.08], "text": " I will now leave you with this quote from T.S."}, {"timestamp": [2091.08, 2095.62], "text": " Eliot, which I think is very relevant to this new generative AI era."}, {"timestamp": [2095.62, 2098.8], "text": " It goes back to the idea of riffing off others."}, {"timestamp": [2098.8, 2099.8], "text": " He writes,"}, {"timestamp": [2099.8, 2105.42], "text": " The good poet welds his theft into a whole of feeling which is unique and utterly different"}, {"timestamp": [2105.42, 2106.82], "text": " from that which was torn."}, {"timestamp": [2106.82, 2108.5], "text": " That's what we're doing here."}, {"timestamp": [2108.5, 2130.12], "text": " It's building off the works of others into something else entirely that's new and useful. Bye!"}]}