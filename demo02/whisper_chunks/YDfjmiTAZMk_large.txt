{"text": " Morning everybody David Shapiro here with a new video. So you probably notice a little bit of a different setup. I am kind of pimping out my my recording setup. But today we're going to talk about the open AI democratic inputs to AI and the Gato framework. So you guys have heard me mention the Gato framework quite a few times. So we're going to kind of first kind of talk about like this democratic inputs to AI, which is a grant challenge. And then I'll also introduce you to the Gato framework, which there is some overlap. But the takeaway is that I and the Gato community are going to put in a proposal to OpenAI's challenge. So right off the bat, the democratic inputs to AI is going to be 10 $100,000 grants that OpenAI gives in order to basically democratize the way that they get feedback in order to decide how AI will behave. So they give some examples of what they mean by a democratic process. And then they also give a few examples of the kinds of questions that they're going to want to address. Sorry where did it go. Here we go. So one example is how far do you think the personalization of AI assistants like ChatGPT to align with tastes and preferences should go? What boundaries, if any, should exist in this process? So these are the kinds of policy questions that they want to have a scalable system to address. And they give, you know know quite a few examples like Wikipedia Twitter Democracy Next so on and so forth. So there's all kinds of things which with those existing systems you might be asking like OK well why what's like what's missing. And so there's a few things that they talk about that they want to like the criteria that they want to address so criteria that they want to address. So one, evaluation. They want to make sure that the evaluation follows metrics and so on that the methodology is good. Robustness. Obviously you want to make sure that the resulting information that you get is robust and defensible, but also resistant to trolling and other problems. Inclusiveness and representativeness, you know, obviously if you only survey or poll, you know, a small majority of people or I guess small minority of people rather, you're not going to have a good representation of the global willpower and global desires of all humans. And that's part of the goal here is that pretty much all humans are stakeholders in AI. So therefore we need to make sure that we represent everyone on the planet. Empowerment of minority opinions. So this is one of the hardest problems because when you have a democratic process you often have majority rules which means that you have tyranny of the majority. So how do you represent the interests of everyone while also kind of abiding by or following the collective willpower. So in that case finding consensus can be very difficult. Effective moderation, again, making sure that stuff stays on topic, so on and so forth. Scalability, so again, scalability is one of the chief criteria here because it needs to encompass the entire planet. Finally, actionability and legibility, these are just kind of boilerplate requirements. There's a few other footnotes. But yeah, so those are the primary goals is how do you create something that can achieve this. And it sounds like a very daunting task, but I think that we're up to it. So with all that said, the Gato community, and actually even some of my Patreons have already expressed interest in participating. So we'll get that organized very quickly. We have until just under a month from now to submit our proposal which I have no doubt that we'll be able to do considering we pulled the Gato framework together in four weeks flat. So we have roughly the same amount of time to do something that is less extensive. Basically we have to design one tool or one platform rather than an entire global movement. So I have alluded to the Gato framework quite a few times. So let's talk about the Gato framework. So you can learn about our Gato framework here on Gato framework dot org. It is a global decentralized movement to achieve first and foremost utopia which we define utopia quite simply as a world state where everyone on the planet has high standard of living, high individual liberty, and also high social mobility. So obviously the word utopia often has a lot of baggage associated with it. You know, whether you think Star Trek or something else, and utopia means different things to different people, but in terms of universal principles and also measurable like a KPI or metrics, we, we define utopia as a high standard of living, a high individual liberty and high social mobility. If we get those three criteria to be global, we will consider that success. Now also, Gato is meant to avoid dystopia. So on one hand, you have utopia versus dystopia, but we also aim to avoid cataclysmic outcomes by solving problems such as the coordination problem that Daniel Schmachtenberger and Liv Bowery talk about with Mollack. You've probably seen some of my other videos and the goal there is to avoid extinction by creating global consensus around how to align AI, which is a very comprehensive process. We'll go into it just a little bit, but basically it is a decentralized layered approach to achieving global alignment. So for instance, the first layer is model alignment. Model alignment is the low-level things such as building and training and fine-tuning individual language models and other AI models, multimodal models as they come. So we'll address problems like fine-tuning, MESA optimization, inner alignment, and so on. But it's important to remember that model alignment is only one small component of achieving utopia, avoiding dystopia, and avoiding extinction. Yes, we believe that there will come a time when AI becomes super intelligent and it cannot be contained. And we have to get it right before that happens. But even before that, we could end up in dystopia, right? So there's kind of a gated process. So model alignment, even Sam Altman has said that RLHF is not the way to get, you know, solve the control problem, but it's a good way to make a good chat bot so we're aligned there. The next phase is autonomous systems. So one thing that a lot of people are afraid of in the long run is runaway autonomous AI. Basically super intelligence that has no leash, that has no shackles. And so one of the reasons that we advocate for building autonomous systems today is because we need to practice building these systems to understand the architectures and the behaviors. For instance, one of the things that people suspect will happen is instrumental convergence. Instrumental convergence is the idea that AI systems, no matter what objectives you give them, they will want things like to protect power, to get more data, that sort of stuff. And so by practicing building autonomous systems today, we can go ahead and start researching and understanding, one, how to make autonomous systems stable, even as they change and improve themselves. We can also figure out what needs to go into automating their internal learning processes and stuff because super intelligence was never ever going to be a single model, right? It's not going to be GPT-7, you know, in a robot. Autonomous systems from a software and hardware perspective are going to be very complex systems, so we need to start working on these today. And you know, in point of fact, people have already started working on autonomous systems and they're only going to get more powerful over time. Layer three of the Gato framework is the advocacy of using decentralized technologies such as blockchain and federations in order to basically first solve the problem of in the future AI will spend more time talking to each other than to us. So we need to create a framework that includes things such as consensus mechanisms as well as reputation management systems. Because the thing is is in the future you're not going to be able to look at the code or data or design of every autonomous agent out there, but instead you can look at the behavior of those agents and track it over time. And so then what we can do is embed alignment algorithms into those decentralized networks and those decentralized networks can be used to gatekeep resources like data, network access, power, and compute. And that will actually change the instrumental convergence, meaning that autonomous AI agents will be incentivized to self-align if they want access to things like power, data, and compute. And that decentralized network will also create a layer that that allows for easy collaboration between humans and AI because again blockchain DAOs and other decentralized technologies allow for collective consensus to be achieved before making decisions and actions. And that will be the kind of the the fabric that pulls humans and AI together. And so those first three layers are the technical layers. These are the coding, data, and cryptographic problems that Gato aims to solve. But it's not going to be a centralized effort. This is just a roadmap that anyone can follow. And so then the top four layers of Gato are more about the social, geopolitical, and economic layers. So for instance, number four, layer four, is corporate adoption. We have one simple mantra, which is aligned AI is good for business. Fortunately, it seems like some companies, OpenAI, Microsoft, and IBM, believe this, at least in principle, at least in word. You know, obviously actions speak louder than words, and so we will see what actions they take over time. But the general principle is, and many of my Patreon supporters already get this and know this, where I help them with understanding AI alignment, and they say this is obviously good for business. Aligned AI is good for business for a number of reasons, not the least of which is that it's more trustworthy and more scalable. The more aligned an AI system is, the more trustworthy it is, and therefore the less supervision it requires, which means that it is more scalable and can take on more workload faster. So in this respect, we hope that this pattern proves out over longer periods of time, which means that those businesses that adopt aligned AI will simply do better in the long run, and they will have a competitive advantage. Obviously, we can't count on this forever, which is why we also advocate for national regulation. Now, fortunately, we have seen calls for national regulation already, ranging in, you know, from empowering existing agencies like the FTC, SEC, and so on and so forth. And those are, of course, American entities. Pretty much every nation has regulatory bodies that are already in place that could be empowered to help regulate AI. Now, that being said, there's also a case to be made for advocating for an AI-specific entity. We're not going to take, Gato is not going to take a position one way or another, but we do advocate for national regulation of some kind across the world. And this national regulation is not just about punishing or constraining, we also advocate for incentivizing aligned behavior, such as through research grants and other financial incentives, maybe even including tax breaks for companies that meet alignment standards, similar to how there are carbon credits, for instance, as one example of incentivizing the behavior that you wanna to see with financial gains. Again, we believe that aligned AI is its own financial incentive, but not everyone's going to believe that. One example that I like to use is when smoking was banned from bars and restaurants. When smoking was banned from bars and restaurants, it actually increased patronage of bars and restaurants because a few bad actors, aka people that wanted to smoke inside that behavior was that noxious behavior was no longer allowed and so then businesses all benefited and now it's just a foregone conclusion that you shouldn't allow smoking inside. That is the kind of nature of national regulation so if we ban misaligned AI it'll bring more people to the table. national regulation. So if we ban misaligned AI, it'll bring more people to the table. Number six is international treaties. So Gato advocates for the creation of international agencies. OpenAI recently published that they are advocating for an agency model perhaps on the IAEA, the International Atomic Energy Agency, which is a regulator that performs inspections and other functions around nuclear energy and nuclear enrichment. We don't necessarily disagree with that, but we think that it should be yes and. So Gato advocates for the creation of an entity like CERN, which is primarily a research organization rather than a regulatory organization. And the reason that we advocate for international cooperation on AI research is because, again, we believe that eventually, one day, we are going to lose control of the AI, in which case human regulation won't matter. So what we need to do is actually focus more resources on understanding alignment and autonomous systems and how to create what we call axiomatic alignment. So axiomatic alignment is one of the goal states of the Gato framework, wherein alignment is very difficult for AI to deviate from due to a saturation of aligned models, aligned data sets, and what we also call epistemic convergence, which is the idea. It's very similar to instrumental convergence. But the idea of epistemic convergence is that any sufficiently intelligent entity, no matter where they start, they ought to come to some similar conclusions with obviously some variants, but by intersecting with the same laws of physics, the same universe, the same galaxy, the same planet, pretty much any sufficiently intelligent entity ought to come to some similar conclusions. And then finally the top layer of GATO is global consensus, wherein we use exponential technologies like AI, social media, and so on in order to create outreach outreach into the academic institutions into primary education into industry so on and so forth. And that's why I've been doing more interviews for instance. So those are the layers of gotcha and taken all together. The goal is to again achieve, excuse me, utopia, avoid dystopia, and avoid collapse. And each of these layers, you don't have to eat the whole elephant. The idea is that whatever your specialization is, you can participate in Gato without saying like, yes, I am a Gato employee or whatever. That's not the point. We also have the Gato traditions, which is a set of 10 kind of principles or behaviors that everyone can engage in to help advance this initiative towards global alignment. So the first tradition is start where you are, use what you have, do what you can. Basically this says that whatever you're capable of, whatever your passions are and your strengths are, you can use them. So for instance I get a lot of messages by people saying like you know oh well I'm just a lawyer. I don't know anything about A.I. or I'm a graphic artist or you know I just use Twitter and make memes. Whatever it is that you're capable of doing you can advance the initiative of A.I. So for instance there's a Twitter feed out there. What is it the A.I. safety memes Twitter feed. If that's all you do that's fine. If you're a lawyer you you can look at Gato and AI alignment from a legal perspective, or from a business policy perspective, or whatever your perspective is. You have something that you can contribute. And by everyone contributing in a decentralized manner, we can solve that coordination problem that, like I said, that Daniel Schmachtenberger and Liv Bowery point out. Principle number two is work towards consensus. So while global consensus is not fully possible, we're not ever going to come to a unanimous decision, that doesn't mean that the idea of consensus is not valuable and very helpful in this process because what I mean by that is that when you have consensus as a principle, as an ideal, you're going to listen more, you're going to listen differently, and you're also going to find more novel and unique and creative solutions that strive to meet everyone's needs and desires. Number three is broadcast your findings, which is basically don't keep things locked up. We very much advocate for open source, open communication, knowledge sharing, and so on, because knowledge sharing and broadcasting good information is part of building consensus. Number four is think globally globally act locally. So think globally. The problem of solving a alignment is a global problem. It is as global as nuclear deterrent or climate change. Right. This is a global problem. Now that being said none of us have a global reach or global influence. Right. I'm on YouTube. I do have a global ish audience but I can still only do you know something with my own hands. Right. And so by distributing the workload and acting locally but keeping in mind that this is a global problem we can work together. Number five in it to win it. This is for all the cookies. Basically we achieve you as many people point out like we either achieve there. Number five, in it to win it. This is for all the cookies basically. We achieve you as many people point out like we either achieve utopia by solving all these problems or we're on an inevitable downslide towards utopia, dystopia collapse and then finally extinction. So this is what some people say a binary outcome or a bimodal outcome where it's we solve this or we don't. Excuse me. Number six is step up. So step up talks about if there's something that you see that you can do, you can advocate in your community, in your company, in your family, whatever. Step up, speak out. It could also be if Gato aligns with you, download the framework, start your own Gato community or join a community that is aligned with Gato aligns with you, download the framework, start your own Gato community or join a community that is aligned with Gato and start sharing and start doing the work. But Gato will not succeed if everyone is passive. That is the key thing here. Number seven is think exponentially. As I mentioned, we very much advocate using exponential technologies, namely social media and artificial intelligence. If you can create an AI tool that helps advance alignment, whether it's by building consensus or solving problems, do it. If you have a communication platform, podcasts, memes, Reddit's, whatever. Use those exponential technologies and those network effects to get the message out, to build consensus, and to do more with less basically. Number eight is trust the process. We are not the first decentralized global movement and we won't be the last, but the point is that decentralized global movements do work, and in the Gatua framework we list about I think eight or eleven different decentralized movements that we took inspiration from. And so, yes, you're only going to see your little narrow part, but if everyone is doing the same thing in parallel, even though you don't see it, you trust that it's out there and that they are doing it. Number nine is strike while the iron is hot. There are going to be plenty of opportunities out here, and this one is exactly what this policy, or sorry, this tradition means is open AI presented an opportunity, so we're going to make use of that opportunity, and so we're going to strike while the iron's hot. And finally, tradition number 10, divide and conquer. Again, everyone is going to be working in parallel to solve alignment, and not everyone's going to agree, but that's okay alignment, and not everyone's going to agree, but that's okay, right? We will work towards consensus over time. So that is the Gato layers and traditions. Many of you have said that you want to get involved. You don't need our permission to get involved. However, you can apply to join the main Gato community with this form, we do have it automatically piped into our Discord and we automatically, or not automatically, but we can all vote on accepting members or not. We also have a, first I need to tell everyone, we are way behind on accepting people. We also haven't fully automated the onboarding and invitation process. So if you did apply on the old form, we haven't gotten to you and you need to apply on the new form. And number two, if you don't get accepted, first be patient because we're trying to get to everyone and automate as much of it as possible. And number two, if you're not accepted, that doesn't necessarily mean that you don't have something to contribute But we we need to make sure that we don't have too many cooks in the kitchen, right? And so what we're going to be doing is setting up more Gato communities that are more open for everyone to join So, you know don't take it personally Because there's plenty of people that that do have something to contribute But that we just don't have a role for in the main Gato community yet. And then finally If you if you're ready to participate we have two documents. So one is the main Gato framework Which is a 70 page document that outlines everything that I've said here and more including lots and lots of suggestions, explanations as to why, how, and so on, whether you want to advocate for Gato or participate in one layer, or even we have recommendations on how to set up your own Gato community. And then the other document is a one-page handout, which I actually take this to meet-up groups now, which if you just wanna give someone a really high level snapshot of Gato, it's a one page handout that you can use to share the idea, to kind of plant those seeds and get the conversation started. That is about it for the Gato community. We also have a few more pages, such as like news and updates for anything that is happening with the Gato community or relevant to us. We actually need to update this cause I've had a few more podcasts. And then we have a community showcase page where we'll be accumulating use cases, business cases and other stories of successes related to AI alignment and adoption. So for instance, we have a few other projects, a few other irons in the fire that will get updated as those get completed. We've got folks participating in hackathons, then of course we've got, you know, Gato will be participating in the democratic inputs to AI, that sort of thing. So if all of this resonates with you, if you wanna solve this problem, and this is gonna be true whether or not you believe that AGI is eminent or not. This is gonna, like Gato is valid whether or not you believe that AI represents an existential threat, because whatever else is true, AI is disrupting the economy today. So there are alignment questions that we need to solve today and there are coordination problems we need to solve today, regardless of where AI ultimately ends up. So with all that, thanks for watching. I hope you got a lot out of this and yeah, stay tuned for more. We will keep up the hard work. the hard work.", "chunks": [{"timestamp": [0.0, 5.0], "text": " Morning everybody David Shapiro here with a new video."}, {"timestamp": [5.0, 8.0], "text": " So you probably notice a little bit of a different setup."}, {"timestamp": [8.0, 13.0], "text": " I am kind of pimping out my my recording setup."}, {"timestamp": [13.0, 22.0], "text": " But today we're going to talk about the open AI democratic inputs to AI and the Gato framework."}, {"timestamp": [22.0, 26.0], "text": " So you guys have heard me mention the Gato framework quite a few times."}, {"timestamp": [26.0, 32.8], "text": " So we're going to kind of first kind of talk about like this democratic inputs to AI,"}, {"timestamp": [32.8, 37.3], "text": " which is a grant challenge. And then I'll also introduce you to the Gato framework,"}, {"timestamp": [37.3, 50.28], "text": " which there is some overlap. But the takeaway is that I and the Gato community are going to put in a proposal to OpenAI's challenge."}, {"timestamp": [50.28, 58.76], "text": " So right off the bat, the democratic inputs to AI is going to be 10 $100,000 grants that"}, {"timestamp": [58.76, 69.28], "text": " OpenAI gives in order to basically democratize the way that they get feedback in order to decide how AI will behave."}, {"timestamp": [69.28, 73.44], "text": " So they give some examples of what they mean by a democratic process."}, {"timestamp": [73.44, 81.04], "text": " And then they also give a few examples of the kinds of questions that they're going to want to address."}, {"timestamp": [81.04, 82.88], "text": " Sorry where did it go. Here we go."}, {"timestamp": [82.88, 87.84], "text": " So one example is how far do you think the personalization of AI assistants like ChatGPT"}, {"timestamp": [87.84, 91.76], "text": " to align with tastes and preferences should go? What boundaries, if any,"}, {"timestamp": [91.76, 93.76], "text": " should exist in this process?"}, {"timestamp": [93.76, 101.52], "text": " So these are the kinds of policy questions that they want to have a scalable system to address."}, {"timestamp": [101.52, 106.68], "text": " And they give, you know know quite a few examples like Wikipedia"}, {"timestamp": [106.68, 108.92], "text": " Twitter Democracy Next"}, {"timestamp": [108.96, 109.72], "text": " so on and so forth."}, {"timestamp": [109.72, 111.16], "text": " So there's all kinds of things"}, {"timestamp": [112.16, 114.16], "text": " which with those existing systems"}, {"timestamp": [114.28, 116.2], "text": " you might be asking like OK well why"}, {"timestamp": [116.2, 118.4], "text": " what's like what's missing."}, {"timestamp": [119.2, 121.06], "text": " And so there's a few things that they talk"}, {"timestamp": [121.06, 122.6], "text": " about that they want to"}, {"timestamp": [123.6, 126.0], "text": " like the criteria that they want to address so criteria that they want to address. So one,"}, {"timestamp": [126.64, 133.2], "text": " evaluation. They want to make sure that the evaluation follows metrics and so on that the"}, {"timestamp": [133.2, 140.96], "text": " methodology is good. Robustness. Obviously you want to make sure that the resulting information"}, {"timestamp": [140.96, 145.06], "text": " that you get is robust and defensible, but also resistant to"}, {"timestamp": [145.06, 150.8], "text": " trolling and other problems. Inclusiveness and representativeness,"}, {"timestamp": [150.8, 158.24], "text": " you know, obviously if you only survey or poll, you know, a small majority of people"}, {"timestamp": [158.24, 161.72], "text": " or I guess small minority of people rather, you're not going to have a good"}, {"timestamp": [161.72, 167.0], "text": " representation of the global willpower and global desires of all humans."}, {"timestamp": [167.0, 174.0], "text": " And that's part of the goal here is that pretty much all humans are stakeholders in AI."}, {"timestamp": [174.0, 178.0], "text": " So therefore we need to make sure that we represent everyone on the planet."}, {"timestamp": [178.0, 181.0], "text": " Empowerment of minority opinions."}, {"timestamp": [181.0, 187.0], "text": " So this is one of the hardest problems because when you have a democratic"}, {"timestamp": [187.0, 192.68], "text": " process you often have majority rules which means that you have tyranny of the majority."}, {"timestamp": [192.68, 198.86], "text": " So how do you represent the interests of everyone while also kind of abiding by or following"}, {"timestamp": [198.86, 209.0], "text": " the collective willpower. So in that case finding consensus can be very difficult. Effective moderation, again, making sure that stuff stays on topic, so on and so forth."}, {"timestamp": [209.0, 217.0], "text": " Scalability, so again, scalability is one of the chief criteria here because it needs to encompass the entire planet."}, {"timestamp": [217.0, 226.88], "text": " Finally, actionability and legibility, these are just kind of boilerplate requirements. There's a few other footnotes."}, {"timestamp": [226.88, 229.32], "text": " But yeah, so those are the primary goals is how do you"}, {"timestamp": [229.32, 231.8], "text": " create something that can achieve this."}, {"timestamp": [231.8, 233.6], "text": " And it sounds like a very daunting task,"}, {"timestamp": [233.6, 236.2], "text": " but I think that we're up to it."}, {"timestamp": [236.2, 239.84], "text": " So with all that said, the Gato community,"}, {"timestamp": [239.84, 241.52], "text": " and actually even some of my Patreons"}, {"timestamp": [241.52, 244.8], "text": " have already expressed interest in participating."}, {"timestamp": [244.8, 247.2], "text": " So we'll get that organized very quickly."}, {"timestamp": [247.2, 252.52], "text": " We have until just under a month from now to submit our proposal which I have no doubt"}, {"timestamp": [252.52, 256.64], "text": " that we'll be able to do considering we pulled the Gato framework together in four weeks"}, {"timestamp": [256.64, 257.92], "text": " flat."}, {"timestamp": [257.92, 262.5], "text": " So we have roughly the same amount of time to do something that is less extensive."}, {"timestamp": [262.5, 266.24], "text": " Basically we have to design one tool or one platform rather than an entire"}, {"timestamp": [266.24, 267.44], "text": " global movement. So"}, {"timestamp": [268.18, 270.2], "text": " I have alluded to the Gato framework quite a few"}, {"timestamp": [270.2, 272.52], "text": " times. So let's talk about the Gato framework."}, {"timestamp": [273.32, 275.4], "text": " So you can learn about our Gato framework"}, {"timestamp": [275.4, 277.52], "text": " here on Gato framework dot org."}, {"timestamp": [278.4, 281.32], "text": " It is a global decentralized"}, {"timestamp": [281.36, 283.08], "text": " movement to achieve"}, {"timestamp": [284.12, 288.08], "text": " first and foremost utopia which we define utopia quite"}, {"timestamp": [288.08, 295.12], "text": " simply as a world state where everyone on the planet has high standard of living, high"}, {"timestamp": [295.12, 298.86], "text": " individual liberty, and also high social mobility."}, {"timestamp": [298.86, 304.46], "text": " So obviously the word utopia often has a lot of baggage associated with it."}, {"timestamp": [304.46, 307.68], "text": " You know, whether you think Star Trek or something else,"}, {"timestamp": [307.68, 310.0], "text": " and utopia means different things to different people,"}, {"timestamp": [310.4, 315.4], "text": " but in terms of universal principles and also measurable like a KPI or metrics,"}, {"timestamp": [317.08, 321.52], "text": " we, we define utopia as a high standard of living,"}, {"timestamp": [321.8, 324.32], "text": " a high individual liberty and high social mobility."}, {"timestamp": [324.6, 330.72], "text": " If we get those three criteria to be global, we will consider that success. Now also, Gato is"}, {"timestamp": [330.72, 338.24], "text": " meant to avoid dystopia. So on one hand, you have utopia versus dystopia, but we also aim to avoid"}, {"timestamp": [338.24, 343.68], "text": " cataclysmic outcomes by solving problems such as the coordination problem that Daniel Schmachtenberger"}, {"timestamp": [343.68, 346.56], "text": " and Liv Bowery talk about with Mollack."}, {"timestamp": [346.56, 349.0], "text": " You've probably seen some of my other videos"}, {"timestamp": [349.0, 352.12], "text": " and the goal there is to avoid extinction"}, {"timestamp": [352.12, 357.2], "text": " by creating global consensus around how to align AI,"}, {"timestamp": [357.2, 359.44], "text": " which is a very comprehensive process."}, {"timestamp": [359.44, 362.6], "text": " We'll go into it just a little bit,"}, {"timestamp": [362.6, 368.32], "text": " but basically it is a decentralized layered approach to achieving"}, {"timestamp": [368.32, 374.64], "text": " global alignment. So for instance, the first layer is model alignment. Model alignment is"}, {"timestamp": [374.64, 380.96], "text": " the low-level things such as building and training and fine-tuning individual language models and"}, {"timestamp": [380.96, 388.24], "text": " other AI models, multimodal models as they come. So we'll address problems like fine-tuning, MESA optimization, inner alignment, and so on."}, {"timestamp": [388.88, 394.0], "text": " But it's important to remember that model alignment is only one small component of"}, {"timestamp": [394.0, 401.28], "text": " achieving utopia, avoiding dystopia, and avoiding extinction. Yes, we believe that there will come"}, {"timestamp": [401.28, 406.2], "text": " a time when AI becomes super intelligent and it cannot be contained."}, {"timestamp": [406.2, 409.48], "text": " And we have to get it right before that happens."}, {"timestamp": [409.48, 413.14], "text": " But even before that, we could end up in dystopia, right?"}, {"timestamp": [413.14, 415.6], "text": " So there's kind of a gated process."}, {"timestamp": [415.6, 418.2], "text": " So model alignment, even Sam Altman"}, {"timestamp": [418.2, 421.6], "text": " has said that RLHF is not the way to get,"}, {"timestamp": [421.6, 424.2], "text": " you know, solve the control problem,"}, {"timestamp": [424.2, 428.0], "text": " but it's a good way to make a good chat bot so we're aligned there."}, {"timestamp": [428.0, 432.0], "text": " The next phase is autonomous systems."}, {"timestamp": [432.0, 436.0], "text": " So one thing that a lot of people are afraid of in the long run is"}, {"timestamp": [436.0, 440.0], "text": " runaway autonomous AI. Basically super intelligence that has no"}, {"timestamp": [440.0, 444.0], "text": " leash, that has no shackles. And so one of the reasons that we"}, {"timestamp": [444.0, 447.14], "text": " advocate for building autonomous systems today"}, {"timestamp": [447.14, 451.12], "text": " is because we need to practice building these systems"}, {"timestamp": [451.12, 454.62], "text": " to understand the architectures and the behaviors."}, {"timestamp": [454.62, 457.76], "text": " For instance, one of the things that people suspect will happen"}, {"timestamp": [457.76, 459.8], "text": " is instrumental convergence."}, {"timestamp": [459.8, 461.84], "text": " Instrumental convergence is the idea"}, {"timestamp": [461.84, 465.24], "text": " that AI systems, no matter what objectives you"}, {"timestamp": [465.24, 471.52], "text": " give them, they will want things like to protect power, to get more data, that sort of stuff."}, {"timestamp": [471.52, 477.6], "text": " And so by practicing building autonomous systems today, we can go ahead and start researching"}, {"timestamp": [477.6, 483.44], "text": " and understanding, one, how to make autonomous systems stable, even as they change and improve"}, {"timestamp": [483.44, 484.44], "text": " themselves."}, {"timestamp": [484.44, 486.24], "text": " We can also figure out what needs to"}, {"timestamp": [486.24, 491.76], "text": " go into automating their internal learning processes and stuff because super intelligence"}, {"timestamp": [491.76, 497.84], "text": " was never ever going to be a single model, right? It's not going to be GPT-7, you know, in a robot."}, {"timestamp": [498.72, 503.6], "text": " Autonomous systems from a software and hardware perspective are going to be very complex systems,"}, {"timestamp": [503.6, 505.32], "text": " so we need to start working on these today."}, {"timestamp": [505.32, 510.72], "text": " And you know, in point of fact, people have already started working on autonomous systems"}, {"timestamp": [510.72, 513.52], "text": " and they're only going to get more powerful over time."}, {"timestamp": [513.52, 520.68], "text": " Layer three of the Gato framework is the advocacy of using decentralized technologies such as blockchain"}, {"timestamp": [520.68, 528.24], "text": " and federations in order to basically first solve the problem of in the future AI will"}, {"timestamp": [528.24, 534.0], "text": " spend more time talking to each other than to us. So we need to create a framework that includes"}, {"timestamp": [534.0, 539.84], "text": " things such as consensus mechanisms as well as reputation management systems. Because the thing"}, {"timestamp": [539.84, 546.64], "text": " is is in the future you're not going to be able to look at the code or data or design of every"}, {"timestamp": [546.64, 551.36], "text": " autonomous agent out there, but instead you can look at the behavior of those agents and"}, {"timestamp": [551.36, 553.4], "text": " track it over time."}, {"timestamp": [553.4, 558.7], "text": " And so then what we can do is embed alignment algorithms into those decentralized networks"}, {"timestamp": [558.7, 565.8], "text": " and those decentralized networks can be used to gatekeep resources like data, network access, power, and compute."}, {"timestamp": [565.8, 573.24], "text": " And that will actually change the instrumental convergence, meaning that"}, {"timestamp": [573.24, 578.72], "text": " autonomous AI agents will be incentivized to self-align if they want"}, {"timestamp": [578.72, 583.4], "text": " access to things like power, data, and compute. And that decentralized"}, {"timestamp": [583.4, 586.32], "text": " network will also create a layer that that allows"}, {"timestamp": [586.32, 593.28], "text": " for easy collaboration between humans and AI because again blockchain DAOs and other decentralized"}, {"timestamp": [593.28, 598.96], "text": " technologies allow for collective consensus to be achieved before making decisions and actions."}, {"timestamp": [599.76, 605.84], "text": " And that will be the kind of the the fabric that pulls humans and AI together."}, {"timestamp": [605.84, 608.88], "text": " And so those first three layers are the technical layers."}, {"timestamp": [608.88, 614.56], "text": " These are the coding, data, and cryptographic problems that Gato aims to solve."}, {"timestamp": [614.56, 616.8], "text": " But it's not going to be a centralized effort."}, {"timestamp": [616.8, 620.62], "text": " This is just a roadmap that anyone can follow."}, {"timestamp": [620.62, 627.24], "text": " And so then the top four layers of Gato are more about the social, geopolitical, and economic layers."}, {"timestamp": [627.6, 634.84], "text": " So for instance, number four, layer four, is corporate adoption. We have one simple mantra, which is aligned AI is good for business."}, {"timestamp": [635.8, 639.82], "text": " Fortunately, it seems like some companies, OpenAI, Microsoft, and IBM,"}, {"timestamp": [641.12, 643.48], "text": " believe this, at least in principle, at least in word."}, {"timestamp": [644.36, 647.08], "text": " You know, obviously actions speak louder than words,"}, {"timestamp": [647.08, 650.3], "text": " and so we will see what actions they take over time."}, {"timestamp": [650.3, 652.88], "text": " But the general principle is,"}, {"timestamp": [652.88, 655.68], "text": " and many of my Patreon supporters already get this"}, {"timestamp": [655.68, 657.72], "text": " and know this, where I help them"}, {"timestamp": [657.72, 659.68], "text": " with understanding AI alignment,"}, {"timestamp": [659.68, 662.22], "text": " and they say this is obviously good for business."}, {"timestamp": [662.22, 665.62], "text": " Aligned AI is good for business for a number of reasons,"}, {"timestamp": [665.62, 667.78], "text": " not the least of which is that it's more trustworthy"}, {"timestamp": [667.78, 669.1], "text": " and more scalable."}, {"timestamp": [669.1, 671.3], "text": " The more aligned an AI system is,"}, {"timestamp": [671.3, 672.5], "text": " the more trustworthy it is,"}, {"timestamp": [672.5, 675.1], "text": " and therefore the less supervision it requires,"}, {"timestamp": [675.1, 676.72], "text": " which means that it is more scalable"}, {"timestamp": [676.72, 679.22], "text": " and can take on more workload faster."}, {"timestamp": [679.22, 680.34], "text": " So in this respect,"}, {"timestamp": [680.34, 682.86], "text": " we hope that this pattern proves out"}, {"timestamp": [682.86, 684.58], "text": " over longer periods of time,"}, {"timestamp": [684.58, 685.0], "text": " which means"}, {"timestamp": [685.0, 690.6], "text": " that those businesses that adopt aligned AI will simply do better in the long run, and"}, {"timestamp": [690.6, 692.24], "text": " they will have a competitive advantage."}, {"timestamp": [692.24, 697.12], "text": " Obviously, we can't count on this forever, which is why we also advocate for national"}, {"timestamp": [697.12, 698.12], "text": " regulation."}, {"timestamp": [698.12, 710.0], "text": " Now, fortunately, we have seen calls for national regulation already, ranging in, you know, from empowering existing agencies like the FTC, SEC, and so on and so forth."}, {"timestamp": [710.0, 712.0], "text": " And those are, of course, American entities."}, {"timestamp": [712.0, 721.0], "text": " Pretty much every nation has regulatory bodies that are already in place that could be empowered to help regulate AI."}, {"timestamp": [721.0, 726.16], "text": " Now, that being said, there's also a case to be made for advocating for an AI-specific entity."}, {"timestamp": [727.52, 732.56], "text": " We're not going to take, Gato is not going to take a position one way or another, but we do"}, {"timestamp": [733.28, 740.16], "text": " advocate for national regulation of some kind across the world. And this national regulation"}, {"timestamp": [740.16, 747.52], "text": " is not just about punishing or constraining, we also advocate for incentivizing aligned behavior,"}, {"timestamp": [747.52, 749.52], "text": " such as through research grants"}, {"timestamp": [749.52, 751.94], "text": " and other financial incentives,"}, {"timestamp": [751.94, 754.96], "text": " maybe even including tax breaks for companies"}, {"timestamp": [754.96, 756.82], "text": " that meet alignment standards,"}, {"timestamp": [756.82, 760.38], "text": " similar to how there are carbon credits, for instance,"}, {"timestamp": [760.38, 763.78], "text": " as one example of incentivizing the behavior"}, {"timestamp": [763.78, 765.04], "text": " that you wanna to see with"}, {"timestamp": [765.04, 770.8], "text": " financial gains. Again, we believe that aligned AI is its own financial"}, {"timestamp": [770.8, 774.64], "text": " incentive, but not everyone's going to believe that. One example that I like to"}, {"timestamp": [774.64, 780.48], "text": " use is when smoking was banned from bars and restaurants. When smoking was banned"}, {"timestamp": [780.48, 783.68], "text": " from bars and restaurants, it actually increased patronage of bars and"}, {"timestamp": [783.68, 790.08], "text": " restaurants because a few bad actors, aka people that wanted to smoke inside that behavior was that noxious"}, {"timestamp": [790.08, 794.64], "text": " behavior was no longer allowed and so then businesses all benefited and now it's just a"}, {"timestamp": [794.64, 799.92], "text": " foregone conclusion that you shouldn't allow smoking inside. That is the kind of nature of"}, {"timestamp": [799.92, 804.96], "text": " national regulation so if we ban misaligned AI it'll bring more people to the table."}, {"timestamp": [804.96, 806.0], "text": " national regulation. So if we ban misaligned AI, it'll bring more people to the table."}, {"timestamp": [811.52, 820.48], "text": " Number six is international treaties. So Gato advocates for the creation of international agencies. OpenAI recently published that they are advocating for an agency model perhaps on the IAEA,"}, {"timestamp": [820.48, 826.16], "text": " the International Atomic Energy Agency, which is a regulator that performs inspections and other"}, {"timestamp": [828.64, 835.04], "text": " functions around nuclear energy and nuclear enrichment. We don't necessarily disagree with"}, {"timestamp": [835.04, 840.64], "text": " that, but we think that it should be yes and. So Gato advocates for the creation of an entity like"}, {"timestamp": [840.64, 848.2], "text": " CERN, which is primarily a research organization rather than a regulatory organization."}, {"timestamp": [848.2, 853.84], "text": " And the reason that we advocate for international cooperation on AI research is because, again,"}, {"timestamp": [853.84, 858.68], "text": " we believe that eventually, one day, we are going to lose control of the AI, in which"}, {"timestamp": [858.68, 860.86], "text": " case human regulation won't matter."}, {"timestamp": [860.86, 869.0], "text": " So what we need to do is actually focus more resources on understanding alignment and autonomous systems and how to create what we call"}, {"timestamp": [869.28, 870.4], "text": " axiomatic alignment."}, {"timestamp": [870.4, 875.16], "text": " So axiomatic alignment is one of the goal states of the Gato framework,"}, {"timestamp": [875.56, 880.36], "text": " wherein alignment is very difficult for AI to deviate from"}, {"timestamp": [881.0, 884.36], "text": " due to a saturation of aligned models, aligned data sets,"}, {"timestamp": [884.72, 887.28], "text": " and what we also call epistemic convergence, which"}, {"timestamp": [887.28, 888.34], "text": " is the idea."}, {"timestamp": [888.34, 891.12], "text": " It's very similar to instrumental convergence."}, {"timestamp": [891.12, 893.68], "text": " But the idea of epistemic convergence"}, {"timestamp": [893.68, 897.28], "text": " is that any sufficiently intelligent entity,"}, {"timestamp": [897.28, 899.36], "text": " no matter where they start, they ought"}, {"timestamp": [899.36, 903.28], "text": " to come to some similar conclusions"}, {"timestamp": [903.28, 906.56], "text": " with obviously some variants, but by"}, {"timestamp": [906.56, 910.16], "text": " intersecting with the same laws of physics, the same universe, the same"}, {"timestamp": [910.16, 915.36], "text": " galaxy, the same planet, pretty much any sufficiently intelligent entity ought to"}, {"timestamp": [915.36, 919.4], "text": " come to some similar conclusions. And then finally the top layer of GATO is"}, {"timestamp": [919.4, 924.24], "text": " global consensus, wherein we use exponential technologies like AI, social"}, {"timestamp": [924.24, 927.6], "text": " media, and so on in order to create outreach"}, {"timestamp": [928.4, 931.3], "text": " outreach into the academic institutions into primary"}, {"timestamp": [931.3, 934.1], "text": " education into industry so on and so forth."}, {"timestamp": [934.1, 936.3], "text": " And that's why I've been doing more interviews for instance."}, {"timestamp": [937.0, 941.2], "text": " So those are the layers of gotcha and taken all together."}, {"timestamp": [941.2, 947.0], "text": " The goal is to again achieve, excuse me, utopia, avoid dystopia, and avoid collapse."}, {"timestamp": [947.0, 950.3], "text": " And each of these layers, you don't have to eat the whole elephant."}, {"timestamp": [950.3, 955.8], "text": " The idea is that whatever your specialization is, you can participate in Gato without saying like,"}, {"timestamp": [955.8, 959.2], "text": " yes, I am a Gato employee or whatever. That's not the point."}, {"timestamp": [959.2, 965.0], "text": " We also have the Gato traditions, which is a set of 10 kind of principles or behaviors"}, {"timestamp": [965.0, 970.6], "text": " that everyone can engage in to help advance this initiative towards global"}, {"timestamp": [970.6, 975.34], "text": " alignment. So the first tradition is start where you are, use what you have, do"}, {"timestamp": [975.34, 979.48], "text": " what you can. Basically this says that whatever you're capable of, whatever your"}, {"timestamp": [979.48, 983.2], "text": " passions are and your strengths are, you can use them. So for instance I get a lot"}, {"timestamp": [983.2, 986.56], "text": " of messages by people saying like you know oh well I'm just a lawyer."}, {"timestamp": [986.58, 987.92], "text": " I don't know anything about A.I."}, {"timestamp": [987.94, 989.26], "text": " or I'm a graphic artist"}, {"timestamp": [989.26, 990.72], "text": " or you know I just use Twitter"}, {"timestamp": [990.72, 991.44], "text": " and make memes."}, {"timestamp": [991.72, 993.64], "text": " Whatever it is that you're capable of doing you"}, {"timestamp": [993.64, 995.44], "text": " can advance the initiative of A.I."}, {"timestamp": [995.8, 997.8], "text": " So for instance there's a Twitter feed"}, {"timestamp": [997.8, 998.32], "text": " out there."}, {"timestamp": [998.78, 1000.36], "text": " What is it the A.I."}, {"timestamp": [1000.36, 1002.2], "text": " safety memes Twitter feed."}, {"timestamp": [1002.96, 1004.68], "text": " If that's all you do that's fine."}, {"timestamp": [1005.32, 1010.32], "text": " If you're a lawyer you you can look at Gato and AI alignment"}, {"timestamp": [1010.56, 1011.82], "text": " from a legal perspective,"}, {"timestamp": [1011.82, 1013.68], "text": " or from a business policy perspective,"}, {"timestamp": [1013.68, 1015.58], "text": " or whatever your perspective is."}, {"timestamp": [1015.58, 1017.88], "text": " You have something that you can contribute."}, {"timestamp": [1017.88, 1021.12], "text": " And by everyone contributing in a decentralized manner,"}, {"timestamp": [1021.12, 1023.96], "text": " we can solve that coordination problem"}, {"timestamp": [1023.96, 1026.96], "text": " that, like I said, that Daniel Schmachtenberger"}, {"timestamp": [1026.96, 1029.56], "text": " and Liv Bowery point out."}, {"timestamp": [1029.56, 1031.98], "text": " Principle number two is work towards consensus."}, {"timestamp": [1031.98, 1037.56], "text": " So while global consensus is not fully possible, we're not ever going to come to a unanimous"}, {"timestamp": [1037.56, 1045.4], "text": " decision, that doesn't mean that the idea of consensus is not valuable and very helpful in this process because"}, {"timestamp": [1045.4, 1050.96], "text": " what I mean by that is that when you have consensus as a principle, as"}, {"timestamp": [1050.96, 1054.6], "text": " an ideal, you're going to listen more, you're going to listen"}, {"timestamp": [1054.6, 1059.4], "text": " differently, and you're also going to find more novel and unique and creative"}, {"timestamp": [1059.4, 1066.0], "text": " solutions that strive to meet everyone's needs and desires. Number three is broadcast"}, {"timestamp": [1066.0, 1070.92], "text": " your findings, which is basically don't keep things locked up. We very much"}, {"timestamp": [1070.92, 1074.72], "text": " advocate for open source, open communication, knowledge sharing, and so"}, {"timestamp": [1074.72, 1079.72], "text": " on, because knowledge sharing and broadcasting good information is part of"}, {"timestamp": [1079.72, 1089.24], "text": " building consensus. Number four is think globally globally act locally. So think globally. The problem of solving a alignment is a global problem."}, {"timestamp": [1089.64, 1096.12], "text": " It is as global as nuclear deterrent or climate change."}, {"timestamp": [1096.16, 1100.68], "text": " Right. This is a global problem. Now that being said none of us have a global"}, {"timestamp": [1100.68, 1106.08], "text": " reach or global influence. Right. I'm on YouTube. I do have a global ish"}, {"timestamp": [1106.08, 1108.24], "text": " audience but I can still only do"}, {"timestamp": [1108.32, 1110.64], "text": " you know something with my own hands."}, {"timestamp": [1110.64, 1110.96], "text": " Right."}, {"timestamp": [1111.48, 1113.68], "text": " And so by distributing the workload"}, {"timestamp": [1113.68, 1114.88], "text": " and acting locally"}, {"timestamp": [1115.6, 1117.92], "text": " but keeping in mind that this is a global problem"}, {"timestamp": [1118.28, 1120.04], "text": " we can work together."}, {"timestamp": [1120.54, 1121.84], "text": " Number five in it to win it."}, {"timestamp": [1122.56, 1123.68], "text": " This is for all the cookies."}, {"timestamp": [1123.68, 1125.2], "text": " Basically we achieve you as many people point out like we either achieve there. Number five, in it to win it. This is for all the cookies basically. We achieve"}, {"timestamp": [1125.2, 1130.44], "text": " you as many people point out like we either achieve utopia by solving all these problems"}, {"timestamp": [1130.44, 1134.92], "text": " or we're on an inevitable downslide towards utopia, dystopia collapse and then finally"}, {"timestamp": [1134.92, 1140.16], "text": " extinction. So this is what some people say a binary outcome or a bimodal outcome where"}, {"timestamp": [1140.16, 1146.28], "text": " it's we solve this or we don't. Excuse me. Number six is step up."}, {"timestamp": [1146.28, 1148.88], "text": " So step up talks about if there's something"}, {"timestamp": [1148.88, 1150.0], "text": " that you see that you can do,"}, {"timestamp": [1150.0, 1151.88], "text": " you can advocate in your community,"}, {"timestamp": [1151.88, 1155.06], "text": " in your company, in your family, whatever."}, {"timestamp": [1155.06, 1156.48], "text": " Step up, speak out."}, {"timestamp": [1157.36, 1161.76], "text": " It could also be if Gato aligns with you,"}, {"timestamp": [1161.76, 1164.76], "text": " download the framework, start your own Gato community"}, {"timestamp": [1164.76, 1166.76], "text": " or join a community that is aligned with Gato aligns with you, download the framework, start your own Gato community or join a community"}, {"timestamp": [1166.76, 1170.48], "text": " that is aligned with Gato and start sharing and start doing the work."}, {"timestamp": [1170.48, 1174.36], "text": " But Gato will not succeed if everyone is passive."}, {"timestamp": [1174.36, 1175.92], "text": " That is the key thing here."}, {"timestamp": [1175.92, 1177.78], "text": " Number seven is think exponentially."}, {"timestamp": [1177.78, 1182.96], "text": " As I mentioned, we very much advocate using exponential technologies, namely social media"}, {"timestamp": [1182.96, 1189.16], "text": " and artificial intelligence. If you can create an AI tool that helps advance alignment, whether it's by"}, {"timestamp": [1189.16, 1191.56], "text": " building consensus or solving problems, do it."}, {"timestamp": [1191.86, 1197.76], "text": " If you have a communication platform, podcasts, memes, Reddit's, whatever."}, {"timestamp": [1198.44, 1202.38], "text": " Use those exponential technologies and those network effects to get the message"}, {"timestamp": [1202.38, 1206.32], "text": " out, to build consensus, and to do more with"}, {"timestamp": [1206.32, 1208.12], "text": " less basically."}, {"timestamp": [1208.12, 1210.46], "text": " Number eight is trust the process."}, {"timestamp": [1210.46, 1215.82], "text": " We are not the first decentralized global movement and we won't be the last, but the"}, {"timestamp": [1215.82, 1221.36], "text": " point is that decentralized global movements do work, and in the Gatua framework we list"}, {"timestamp": [1221.36, 1226.12], "text": " about I think eight or eleven different decentralized movements"}, {"timestamp": [1226.12, 1229.34], "text": " that we took inspiration from."}, {"timestamp": [1229.34, 1234.0], "text": " And so, yes, you're only going to see your little narrow part, but if everyone is doing"}, {"timestamp": [1234.0, 1238.16], "text": " the same thing in parallel, even though you don't see it, you trust that it's out there"}, {"timestamp": [1238.16, 1240.0], "text": " and that they are doing it."}, {"timestamp": [1240.0, 1242.2], "text": " Number nine is strike while the iron is hot."}, {"timestamp": [1242.2, 1246.72], "text": " There are going to be plenty of opportunities out here, and this one is exactly what this"}, {"timestamp": [1246.72, 1252.7], "text": " policy, or sorry, this tradition means is open AI presented an opportunity, so we're"}, {"timestamp": [1252.7, 1256.06], "text": " going to make use of that opportunity, and so we're going to strike while the iron's"}, {"timestamp": [1256.06, 1257.3], "text": " hot."}, {"timestamp": [1257.3, 1260.22], "text": " And finally, tradition number 10, divide and conquer."}, {"timestamp": [1260.22, 1264.94], "text": " Again, everyone is going to be working in parallel to solve alignment, and not everyone's"}, {"timestamp": [1264.94, 1265.12], "text": " going to agree, but that's okay alignment, and not everyone's going to"}, {"timestamp": [1265.12, 1270.8], "text": " agree, but that's okay, right? We will work towards consensus over time. So that is the"}, {"timestamp": [1271.36, 1277.12], "text": " Gato layers and traditions. Many of you have said that you want to get involved. You don't need our"}, {"timestamp": [1277.12, 1286.32], "text": " permission to get involved. However, you can apply to join the main Gato community with this form, we do have it automatically piped"}, {"timestamp": [1286.32, 1292.0], "text": " into our Discord and we automatically, or not automatically, but we can all vote on"}, {"timestamp": [1292.8, 1299.84], "text": " accepting members or not. We also have a, first I need to tell everyone, we are way behind on"}, {"timestamp": [1299.84, 1305.08], "text": " accepting people. We also haven't fully automated the onboarding and invitation process. So"}, {"timestamp": [1305.08, 1310.76], "text": " if you did apply on the old form, we haven't gotten to you and you need to apply on the"}, {"timestamp": [1310.76, 1315.78], "text": " new form. And number two, if you don't get accepted, first be patient because we're trying"}, {"timestamp": [1315.78, 1322.0], "text": " to get to everyone and automate as much of it as possible. And number two, if you're"}, {"timestamp": [1322.0, 1325.96], "text": " not accepted, that doesn't necessarily mean that you don't have something to contribute"}, {"timestamp": [1326.06, 1329.84], "text": " But we we need to make sure that we don't have too many cooks in the kitchen, right?"}, {"timestamp": [1329.84, 1334.72], "text": " And so what we're going to be doing is setting up more Gato communities that are more open"}, {"timestamp": [1335.28, 1337.28], "text": " for everyone to join"}, {"timestamp": [1337.28, 1339.28], "text": " So, you know don't take it personally"}, {"timestamp": [1340.0, 1343.52], "text": " Because there's plenty of people that that do have something to contribute"}, {"timestamp": [1343.6, 1349.36], "text": " But that we just don't have a role for in the main Gato community yet. And then finally"}, {"timestamp": [1350.24, 1356.8], "text": " If you if you're ready to participate we have two documents. So one is the main Gato framework"}, {"timestamp": [1357.12, 1363.48], "text": " Which is a 70 page document that outlines everything that I've said here and more"}, {"timestamp": [1364.16, 1369.0], "text": " including lots and lots of suggestions, explanations as to why, how,"}, {"timestamp": [1369.0, 1373.0], "text": " and so on, whether you want to advocate for Gato or participate in one layer,"}, {"timestamp": [1373.0, 1379.0], "text": " or even we have recommendations on how to set up your own Gato community."}, {"timestamp": [1379.0, 1382.0], "text": " And then the other document is a one-page handout,"}, {"timestamp": [1382.0, 1384.0], "text": " which I actually take this to meet-up groups now,"}, {"timestamp": [1384.0, 1386.96], "text": " which if you just wanna give someone"}, {"timestamp": [1386.96, 1389.08], "text": " a really high level snapshot of Gato,"}, {"timestamp": [1389.08, 1392.38], "text": " it's a one page handout that you can use"}, {"timestamp": [1392.38, 1395.52], "text": " to share the idea, to kind of plant those seeds"}, {"timestamp": [1395.52, 1398.36], "text": " and get the conversation started."}, {"timestamp": [1399.48, 1402.04], "text": " That is about it for the Gato community."}, {"timestamp": [1402.04, 1404.64], "text": " We also have a few more pages,"}, {"timestamp": [1404.64, 1406.28], "text": " such as like news and updates"}, {"timestamp": [1407.18, 1410.36], "text": " for anything that is happening with the Gato community"}, {"timestamp": [1410.36, 1411.28], "text": " or relevant to us."}, {"timestamp": [1411.28, 1412.32], "text": " We actually need to update this"}, {"timestamp": [1412.32, 1414.32], "text": " cause I've had a few more podcasts."}, {"timestamp": [1414.32, 1416.04], "text": " And then we have a community showcase page"}, {"timestamp": [1416.04, 1419.46], "text": " where we'll be accumulating use cases,"}, {"timestamp": [1419.46, 1423.0], "text": " business cases and other stories of successes"}, {"timestamp": [1424.76, 1427.6], "text": " related to AI alignment and adoption."}, {"timestamp": [1427.6, 1432.44], "text": " So for instance, we have a few other projects, a few other irons in the fire"}, {"timestamp": [1432.44, 1436.84], "text": " that will get updated as those get completed. We've got folks participating"}, {"timestamp": [1436.84, 1441.2], "text": " in hackathons, then of course we've got, you know, Gato will be participating in"}, {"timestamp": [1441.2, 1446.8], "text": " the democratic inputs to AI, that sort of thing. So if all of this resonates with you,"}, {"timestamp": [1446.8, 1448.36], "text": " if you wanna solve this problem,"}, {"timestamp": [1448.36, 1451.48], "text": " and this is gonna be true whether or not you believe"}, {"timestamp": [1451.48, 1453.84], "text": " that AGI is eminent or not."}, {"timestamp": [1453.84, 1456.56], "text": " This is gonna, like Gato is valid whether or not"}, {"timestamp": [1456.56, 1460.04], "text": " you believe that AI represents an existential threat,"}, {"timestamp": [1460.04, 1461.68], "text": " because whatever else is true,"}, {"timestamp": [1461.68, 1464.56], "text": " AI is disrupting the economy today."}, {"timestamp": [1464.56, 1467.4], "text": " So there are alignment questions that we need to solve today"}, {"timestamp": [1467.4, 1470.36], "text": " and there are coordination problems we need to solve today,"}, {"timestamp": [1470.36, 1473.86], "text": " regardless of where AI ultimately ends up."}, {"timestamp": [1473.86, 1475.72], "text": " So with all that, thanks for watching."}, {"timestamp": [1475.72, 1477.6], "text": " I hope you got a lot out of this"}, {"timestamp": [1477.6, 1479.24], "text": " and yeah, stay tuned for more."}, {"timestamp": [1479.24, 1481.2], "text": " We will keep up the hard work."}, {"timestamp": [1476.94, 1479.74], "text": " the hard work."}]}