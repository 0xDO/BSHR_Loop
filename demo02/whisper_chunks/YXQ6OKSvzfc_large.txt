{"text": " Hey everyone, David Shapiro here with an update. Sorry it's been a while. I am doing much better, thank you for asking and thanks for all the kind words. Yeah, so a couple days ago I posted a video where I said like we're going to have AGI within 18 months and that caused a stir in some corners of the internet. But I wanted to share like why believe that, because maybe not everyone has seen the same information that I have. So first, Morgan Stanley research on NVIDIA. This was really big on Reddit. And basically, why we are writing this. We have seen several reports that in our view incorrectly characterize the direct opportunity for NVIDIA, in particular the revenue from chat GPT inference. We think that GPT-5 is currently being trained on 25,000 GPUs or $225 million or so of NVIDIA hardware, and the inference costs are likely much lower than some of the numbers we have seen. Further reducing inference costs will be critical in resolving the cost of search debate from Cloud Titans.\" So basically, if chat GPT becomes much, much cheaper, then it's actually going to be cheaper than search, is kind of how I'm interpreting that. Now, this paper goes on to say that the industry is pivoting, so rather than seeing this as a trendy new fad or a shiny new toy, they're saying, no, this actually has serious business implications, which people like I have been saying for years, but the industry is catching up, especially when you see how much revenue Google lost just with the introduction of ChatGPT. I like this, and we're not trying to be curmudgeons on the opportunity. So anyways, Morgan Stanley, NVIDIA, and I've been in NVIDIA's corner for a while saying that like I think they're the underdog, they're the unsung hero here. So anyways, you look at the investment and so this reminds me of the ramp up for solar. So 10 to 15 years ago, all the debates were like, oh solar is not efficient, solar isn't helpful, it's too expensive, blah blah blah. And then once you see the business investment going up, that's when you know you're at the inflection point. So AI is no longer just a bunch of us you know writing papers and tinkering. When you see the millions, and in this case, a quarter of a billion dollars being invested, that's when you know that things are changing. And so this reminds me of like the 2013 to 2015 range, maybe actually even like 2017 range for solar, where it's like, actually, no, it makes financial sense. But of course, everything with AI is exponentially faster. So NVIDIA is participating, they've got the hardware, they're building out the big computers, so on and so forth. The investment is there, so the improvement is coming, the exponential ramp up is coming. Now, that's great. One tool, let's take a quick break. And when I talked about N8n, Nathan or Nathan, I'm not sure how people pronounce it, as well as LangChain, people were quick to point out LangFlow, which is a graphical interface for LangChain. So this fills in a really big gap for LangChain, which is, okay, how do you see it? How are things cross-linked? So I wanted to share this tool. It's github.com slash logspace-ai slash langflow. So you can just look up langflow and you'll find it. So this is a good chaining tool, a nice graphical interface. This is exactly the direction that things are going. Great, okay, so we've got the business investment. We've got people creating open source libraries. It's going, it's advancing. So I wanted to share this paper with you. MMReact for, what was it? Multimodal reasoning and action. So this basically makes use of the latest GPT where you've got vision and chat and it's like it's kind of it's exactly what you what you kind of expect but this page does a good job of giving you a bunch of different examples and there are I think they're pre-recorded is it playing it looks okay there it goes so you can check out this paper the full paper is here and there's a live demo up on Hugging Face. So you can try different stuff and then talk about it, which is great. The fact that they're able to share this for free just as a demonstration is just a hint as to what's coming. Because imagine when this is commoditized, you can do it on your phone, right? Your phone's hardware will be powerful enough to run some of these models within a few years. Certainly if it's offloaded to the cloud, it's powerful enough to do it now. When you stitch together the rapidly decreasing cost of inference, these things are basically going to be free to use pretty soon. When you look at the fact that an open source framework like Langflow and so on can allow pretty much anyone to create cognitive workflows and all these things, it's like, okay, yeah, we're going to have really powerful machines soon. And so someone asked for clarification when I said, okay, well, what do you mean when you say AGI within 18 months? Because nobody can agree on the definition. And if you watched the Sam Altman, Lex Friedman interview, he refers, Sam Altman refers to AGI several times, but the definition seems to change. Because early in the interview, he talks about like, oh, you know, you put someone in front of GPT-4 or chat GPT-4 and what's the first thing that they do when, and these are his words, when they interact with an AGI is they try and break it or tease it or whatever. And then later he says, oh, well, GPT-5, that's not even gonna be AGI. So he keeps like equivocating and bouncing back and forth. I think that part of what's going on here is there's no good definition. And because later in the conversation, they were talking about things that a chat model can't do. It's not autonomous, right? But, I'm glad you asked, reflection came out. An autonomous agent with dynamic memory and self-reflection. So between cognitive workflows and autonomy and the investment coming up into these models, we are far closer to fully autonomous agents than I think many people recognize. So the reflection stuff, I'm not going to do a full video on reflection, there's other ones out there, but basically this outperforms humans in a few tasks, and it forms a very, very basic kind of cognitive architecture loop. So query, action, environment, reward, reflect, and then repeat. So you just continuously iterate on something in a loop, and there you go. And also, for people who keep asking me what I think about, what's his name, Ben Goertzel. I'm not sure if I'm saying his name right, but I read his seminal paper a couple years ago on general theory, on general intelligence, and he never mentioned iteration or loops, at least not to the degree that you need to when you're talking about actual intelligence. So I personally don't think that he's done anything particularly relevant today. I'm not going to comment on his older work because obviously he's made anything particularly relevant today. I'm not gonna comment on his older work because obviously he's made a name for himself, so on and so forth. But I don't think that Ben has done anything really pertinent to cognitive architecture, which is the direction that things are going. But yeah, so when MIT is doing research on cognitive architecture and autonomous designs, when Morgan Stanley and NVIDIA doing research on cognitive architecture and autonomous designs. When Morgan Stanley and NVIDIA are working on investing literally hundreds of millions of dollars to drive down inference cost, and when open source libraries are creating the rudiments of cognitive architectures, we are ramping up fast. And so someone asked what I meant, again, kind of getting back to that. What did I mean by AGI within 18 months? I said in 18 months, any possible definition of AGI that you have will be satisfied. Um, so it's like, I don't care what your definition of AGI is, unless like, there's still some people out there that like you asked them and it's like, Oh, well, once AGI hits, like the skies will darken and Nuclear weapons will rain down and I'm like that's not AGI. That's Ultron That's different. That's that's a fantasy That's probably not going to happen. It could if Skynet's going to happen it will happen within 18 months But I don't think it's gonna happen Okay, so that's section one of the video talking about the news and everything out there So now let me pivot and talk about the work that I've been doing. So I've been making extensive use of ChatGPT4 to accelerate my own research. I've been working on a few things. Many of you are going to be familiar with my work on the heuristic imperatives, which is how do you create a fully autonomous machine that is safe and stable, ideally for all of eternity. So this is probably one of my most important pieces of work and I've put it into all of my books and a lot of other stuff. The TLDR of heuristic imperatives is it's like, it's similar to Asimov's three laws of robotics, but it is much, much more broadly generalized, and it is also not androcentric or anthropocentric. And so basically, the three rules, that if you embed them into your autonomous AI systems, reduce suffering in the universe, increase prosperity in the universe, and increase understanding in the universe, this creates a very thoughtful machine and it serves as a really good reinforcement learning mechanism, self-evaluation mechanism that results in a very thoughtful machine. So that information is all available out here under on my github, Dave Schapp slash here is to comparatives. I've got it published as a Word doc and a PDF. So I started adopting a more scientific approach because well, there's a reason that the scientific paper format works. So if you wanna come out here and read it, it's out there, it's totally free, of course. Oh, actually that reminds me, I need to put away to cite my work because you can cite GitHub repos. But basically, this provides quite a bit. And one thing to point out is that this paper was almost written entirely word for word by chat-gpt4, meaning that all of the reasoning that it does was performed by chat-gpt4, and at the very end, I actually had it reflect on its own performance. It looks like it's not gonna load that much. More pages, oh, there we go. Examples. So anyways, when you read this and you keep in mind that the nuance of it, whoops, that the nuance of this was within the capacity of CHAT-GPT-4, you will see that these models are already capable of very, very nuanced, empathetic, and moral reasoning. And this is one thing that a lot of people complain about. They're like, oh well it doesn't truly understand anything. I always say that humans don't truly understand anything, so that's a frivolous argument. But that leads to another area of research which I'll get into in a minute. But basically, keep in mind how nuanced this paper is and keep in mind that ChatGPT wrote pretty much the entire thing and I've also got the transcript of the conversation at the end. So if you want to read the whole transcript, please feel free to read the whole transcript and you can see where we worked through the whole paper. Yeah, so that's it. So on the topic of does the machine truly understand anything, that resulted in this transcript, which I have yet to format this into a full scientific paper, but basically the the TLDR here is that I call it the epistemic pragmatic orthogonality, which is that the epistemic truth of whether or not a machine truly understands anything is orthogonal or uncorrelated with how useful it is or objectively correct it is. Right, so if you look, basically it doesn't matter if the machine truly understands anything because again that's not really germane to its function as a machine and so this is it's a fancy term but it basically says okay and there's there was actually a great Reddit post where it's like, can we stop arguing over whether or not it's sentient or conscious or understands anything? That doesn't matter. What matters is its physical, objective, measurable impact and whether it is objectively or measurably correct or useful. So I call that the epistemic pragmatic orthogonality principle of artificial intelligence. I've got it summarized here so you can just read this is the executive summary that I actually use chat GPT to write. So again a lot of the work that I'm doing is anchored by chat GPT and the fact that chat GPT was able to have a very nuanced conversation about its own understanding kind of tells you how smart these machines are. Yep, so that is that paper. Now moving on back to some of the cognitive architecture stuff, one thing that I'm working on is called REMO, so the Rolling Episodic Memory Organizer for Autonomous AI Systems. I initially called this HMCS, which is hierarchical memory consolidation system, but that's a mouthful and it doesn't abide by the current trend where you use an acronym that's easy to say, right? So REMO, rolling episodic memory organizer, much easier to say, much easier to remember. Basically what this does is, it's also not done. So I need to add a caveat there. I'm working through it here with chat GPT-4, where we're working on defining the problem, writing the code, so on and so forth. But basically, what this does is rather than just using semantic search, because a lot of folks have realized that yes, semantic search is really great because it allows you to search based on semantic similarity rather than just keywords. Super powerful, super fast, using stuff like Pinecone, still not good enough because it is not organized in the same way that a human memory is. So, the entire point of Remo is to do two things. The two primary goals is to maintain salience and coherence. So, salient memories means that what you're looking at is actually germane, actually relevant to the conversation that you're having, which can be more difficult if you just use semantic search. The other thing is coherence, which is keeping the context of those memories basically in a coherent narrative. So if rather than just focusing on semantic search, the two terms that I'm introducing are salience and coherence, and of course this is rooted in temporal binding. So human memories are temporal and associative. So, those four concepts, salience and coherence, are achieved with temporal and associative or semantic consolidation. And so, what I mean by temporal consolidation is you take clusters of memories that are temporally bounded or temporally nearby and you summarize those. So that gives you temporal consolidation, which allows you to take, you can compress memories, AI memories, on a factor of five to one, 10 to one, 20 to one, depending on how concisely you summarize them. So that gives you a lot of consolidation. Then you use semantic modeling to create a semantic web or a cluster from the semantic embeddings of those summaries. So it's a layered process. Actually, here, I think I can just show you here. Wait, no, I've got the paper here. Let me show you the Remo paper. So this is a work in progress. It'll be published soon. But let me show you the diagrams because this will just make it make much more sense. Oh, and chat GPT can make diagrams too. You just ask it to output a mermaid diagram definition and it'll do it. So here's the TLDR, the very simple version of the Remo framework. It's got three layers. So here's the TLDR, the very simple version of the Remo framework. It's got three layers. So there's the raw logs layer, which is just the chat logs back and forth, the temporal consolidation layer, which as I just mentioned, allows you to compress memories based on temporal grouping. And then finally, the semantic consolidation layer, which allows you to create and extract topics based on semantic similarity. So by having these two layers that have different kinds of consolidation, you end up with what I call temporally invariant recall. So the topics that we extract are going to include all the time from beginning to end that is relevant while also having benefited from temporal consolidation. I'm going to come up with some better diagrams to demonstrate this, but basically it's like... Actually I can't think of a good way to describe it. But anyway, so this paper is coming and I'm actively experimenting with this on a newer version of Raven that uses a lot more implied cognition. So I talked about implied cognition in a previous episode, but basically implied cognition is when I, in using ChatGPT4, I realized that it is able to think through stuff without you having to design a more sophisticated cognitive architecture. So the cognitive architecture with GPT-4 as the cognitive engine actually becomes much simpler and you only have to focus, I don't wanna say only, but the focus shifts then to memory because once you have the correct memories, the model becomes much more intelligent. So that's up here under Remo framework. I'm working on a conversation with Raven to demonstrate this and that's that, the paper will be coming too. So this is one big important piece of work. The other most important piece of work that I'm working on is the Atom framework, which this paper is already done, but Atom framework, here, let me just load it here. There we go. So, Autonomous Task Orchestration Manager. So this is another kind of long-term memory for autonomous AI systems. That's basically like the TLDR is, it's like JIRA or Trello, but for machines with an API. It's like Jira or Trello, but for machines with an API. And so in this case, it's inspired by a lot of things. One, Agile, two, OnTask by David Bader, Neuroscience for Dummies, Jira, Trello, a whole bunch of other stuff. But basically we talk about cognitive control. So I'm introducing a lot of neuroscience terms to the AI community. So cognitive control has to do with task selection, task switching, task decomposition, goal tracking, goal states, those sorts of things. And then we talk about, you know, some of the inspiration, Agile, JIRA, Trello. And then, so it's like, okay, so what are the things that we need to talk or that we need to include in order for an AI system to be fully autonomous and track tasks over time? So you need tools and tool definitions, you need resource management, and you need an agent model. All these are described later on or in greater depth. Then actually in my conversation with ChatGPT, one of the things that it said is like, okay, well, how do you prioritize stuff? And I was like, I'm glad you asked. And so I shared my work with the heuristic imperatives and ChatGPT agreed like, oh yeah, this is a really great framework for prioritizing tasks and measuring success. Okay, great, let's use that. I think, let's see, is the transcript posted? I don't know if I posted the transcript, I didn't. I'll post the full transcript of making the Atom framework in the repo. So then we get into like, okay, so now that you have all the background, what do we talk about? So it's all about tasks and the data that goes into the task. So first you need to figure out how to represent a task. So there's basic stuff like task ID, description, type, goal state, priority, dependencies, resource, time estimates, task status, assigned agents, progress. And then the one that is new is task impetus. So this is something that you might not think of if you think about your JIRA board or your Kanban board or your Trello board is the why. So the why is implicit in our tasks. Why am I trying to do this? But when we added this, chatGPT got really excited and it's like, oh yeah, it's actually really important to record why any autonomous entity is doing a task for a number of reasons. One, to track priorities, or the impetus might be superseded later on, any number of things, but also you need to justify the use of those resources in that time. So this all goes into the representation of a task, which you can do in JSON, YAML, flat files, vector databases, whatever, I don't care. Like, you can figure out how you want to represent it. I'm probably just going to do these in text files, vector databases, whatever, I don't care. Like, you can figure out how you want to represent it. I'm probably just going to do these in text files, honestly, because that's the easiest thing for an LLM to read. And then, so talking about the task representation, then we move on to the task lifecycle. Task creation, decomposition, prioritization, execution, monitoring and updating, and then finally completing the task. And then you archive it and you save it for later so that you can refer back to it. Again, this is still primarily a long-term memory system for autonomous AI systems. Some of the folks that I work with on Discord, and by work with I mean just like I'm in the AI communities with them, they all think that the Atom framework is pretty cool. So then we talk about task corpus management, which is like, okay, looking at an individual task is fine, but how do you look at your entire body of tasks? Because in autonomous AI, it might have five tasks, it might have 5,000 tasks, and then you need some processes to like, okay, if we're going through these tasks, how do we manage a huge volume of tasks? And so some ideas about how to do that are here. And then finally, one of the last sections is some implementation guidelines, which is just, okay, this is probably some things that you wanna think about when you deploy your implementation of the Atom framework. Yeah, so I think that's about it. Obviously, I'm always working on a few different things, but the Atom framework and the Remo framework are the two biggest things that I'm working on in terms of autonomous AI. And so yeah, all this stuff is coming fast. I think that's about it. So thanks for watching. Like and subscribe and support me on Patreon if you'd like. For anyone who does jump in on Patreon, I'm happy to answer some questions for you, even jump on video calls if you jump in at the high enough tier. I help all kinds of people. I do have a few NDAs that I have to honor, but those are pretty narrow and some of them are also expiring. So I've had people ask you know for help just with writing prompts for chat GPT. I've had people ask simple things like how did you learn what you learned, all kinds of stuff. But yeah so that's that. Thanks for watching and cheers everybody. MBC \ub274\uc2a4 \uae40\uc7ac\uacbd\uc785\ub2c8\ub2e4.", "chunks": [{"timestamp": [0.0, 3.16], "text": " Hey everyone, David Shapiro here with an update."}, {"timestamp": [3.16, 4.96], "text": " Sorry it's been a while."}, {"timestamp": [4.96, 9.4], "text": " I am doing much better, thank you for asking and thanks for all the kind words."}, {"timestamp": [9.4, 16.2], "text": " Yeah, so a couple days ago I posted a video where I said like we're going to have AGI"}, {"timestamp": [16.2, 22.32], "text": " within 18 months and that caused a stir in some corners of the internet."}, {"timestamp": [22.32, 26.16], "text": " But I wanted to share like why believe that, because maybe not everyone"}, {"timestamp": [26.16, 32.4], "text": " has seen the same information that I have. So first, Morgan Stanley research on NVIDIA."}, {"timestamp": [33.52, 39.04], "text": " This was really big on Reddit. And basically, why we are writing this. We have seen several"}, {"timestamp": [39.04, 45.2], "text": " reports that in our view incorrectly characterize the direct opportunity for NVIDIA, in particular the revenue from"}, {"timestamp": [45.2, 54.08], "text": " chat GPT inference. We think that GPT-5 is currently being trained on 25,000 GPUs or $225"}, {"timestamp": [54.08, 59.68], "text": " million or so of NVIDIA hardware, and the inference costs are likely much lower than some of the"}, {"timestamp": [59.68, 71.92], "text": " numbers we have seen. Further reducing inference costs will be critical in resolving the cost of search debate from Cloud Titans.\" So basically, if chat GPT becomes much, much cheaper, then it's actually"}, {"timestamp": [71.92, 78.24], "text": " going to be cheaper than search, is kind of how I'm interpreting that. Now, this paper goes on to"}, {"timestamp": [78.24, 85.84], "text": " say that the industry is pivoting, so rather than seeing this as a trendy new fad or a shiny new toy,"}, {"timestamp": [85.84, 87.48], "text": " they're saying, no, this actually has serious"}, {"timestamp": [87.48, 90.52], "text": " business implications, which people like I have been saying"}, {"timestamp": [90.52, 93.6], "text": " for years, but the industry is catching up,"}, {"timestamp": [93.6, 97.0], "text": " especially when you see how much revenue Google lost"}, {"timestamp": [97.0, 99.44], "text": " just with the introduction of ChatGPT."}, {"timestamp": [101.52, 104.0], "text": " I like this, and we're not trying to be curmudgeons"}, {"timestamp": [104.0, 104.96], "text": " on the opportunity."}, {"timestamp": [106.36, 113.14], "text": " So anyways, Morgan Stanley, NVIDIA, and I've been in NVIDIA's corner for a while saying"}, {"timestamp": [113.14, 116.9], "text": " that like I think they're the underdog, they're the unsung hero here."}, {"timestamp": [116.9, 122.12], "text": " So anyways, you look at the investment and so this reminds me of the ramp up for solar."}, {"timestamp": [122.12, 126.16], "text": " So 10 to 15 years ago, all the debates were like, oh solar is not"}, {"timestamp": [126.16, 132.64], "text": " efficient, solar isn't helpful, it's too expensive, blah blah blah. And then once you see the business"}, {"timestamp": [132.64, 137.92], "text": " investment going up, that's when you know you're at the inflection point. So AI is no longer just"}, {"timestamp": [137.92, 147.04], "text": " a bunch of us you know writing papers and tinkering. When you see the millions, and in this case, a quarter of a billion dollars"}, {"timestamp": [147.04, 150.64], "text": " being invested, that's when you know that things are changing."}, {"timestamp": [150.64, 157.04], "text": " And so this reminds me of like the 2013 to 2015 range, maybe actually even like 2017"}, {"timestamp": [157.04, 160.72], "text": " range for solar, where it's like, actually, no, it makes financial sense."}, {"timestamp": [160.72, 171.06], "text": " But of course, everything with AI is exponentially faster. So NVIDIA is participating, they've got the hardware, they're building out the big computers,"}, {"timestamp": [171.06, 172.6], "text": " so on and so forth."}, {"timestamp": [172.6, 176.84], "text": " The investment is there, so the improvement is coming, the exponential ramp up is coming."}, {"timestamp": [176.84, 179.12], "text": " Now, that's great."}, {"timestamp": [179.12, 181.36], "text": " One tool, let's take a quick break."}, {"timestamp": [181.36, 186.08], "text": " And when I talked about N8n, Nathan or Nathan,"}, {"timestamp": [186.28, 188.24], "text": " I'm not sure how people pronounce it,"}, {"timestamp": [188.24, 189.68], "text": " as well as LangChain,"}, {"timestamp": [189.68, 191.96], "text": " people were quick to point out LangFlow,"}, {"timestamp": [191.96, 195.64], "text": " which is a graphical interface for LangChain."}, {"timestamp": [195.64, 199.68], "text": " So this fills in a really big gap for LangChain,"}, {"timestamp": [199.68, 201.84], "text": " which is, okay, how do you see it?"}, {"timestamp": [201.84, 203.32], "text": " How are things cross-linked?"}, {"timestamp": [203.32, 205.04], "text": " So I wanted to share this tool."}, {"timestamp": [205.04, 210.04], "text": " It's github.com slash logspace-ai slash langflow."}, {"timestamp": [211.24, 213.28], "text": " So you can just look up langflow and you'll find it."}, {"timestamp": [213.28, 218.0], "text": " So this is a good chaining tool, a nice graphical interface."}, {"timestamp": [218.0, 220.56], "text": " This is exactly the direction that things are going."}, {"timestamp": [221.88, 224.6], "text": " Great, okay, so we've got the business investment."}, {"timestamp": [224.6, 227.4], "text": " We've got people creating open source libraries."}, {"timestamp": [227.4, 229.16], "text": " It's going, it's advancing."}, {"timestamp": [229.16, 231.64], "text": " So I wanted to share this paper with you."}, {"timestamp": [231.64, 234.48], "text": " MMReact for, what was it?"}, {"timestamp": [234.48, 236.72], "text": " Multimodal reasoning and action."}, {"timestamp": [236.72, 246.98], "text": " So this basically makes use of the latest GPT where you've got vision and chat and it's like it's kind of it's exactly what"}, {"timestamp": [246.98, 250.72], "text": " you what you kind of expect but this page does a good job of giving you a"}, {"timestamp": [250.72, 255.54], "text": " bunch of different examples and there are I think they're pre-recorded is it"}, {"timestamp": [255.54, 261.84], "text": " playing it looks okay there it goes so you can check out this paper the full"}, {"timestamp": [261.84, 270.96], "text": " paper is here and there's a live demo up on Hugging Face. So you can try different stuff and then talk about it, which is great."}, {"timestamp": [270.96, 275.36], "text": " The fact that they're able to share this for free just as a demonstration is"}, {"timestamp": [275.36, 281.88], "text": " just a hint as to what's coming. Because imagine when this is commoditized, you"}, {"timestamp": [281.88, 288.22], "text": " can do it on your phone, right? Your phone's hardware will be powerful enough to run some of these models within a few years."}, {"timestamp": [288.22, 297.0], "text": " Certainly if it's offloaded to the cloud, it's powerful enough to do it now."}, {"timestamp": [297.0, 302.22], "text": " When you stitch together the rapidly decreasing cost of inference, these things are basically"}, {"timestamp": [302.22, 312.48], "text": " going to be free to use pretty soon. When you look at the fact that an open source framework like Langflow and so on can allow pretty much anyone to create"}, {"timestamp": [312.48, 319.12], "text": " cognitive workflows and all these things, it's like, okay, yeah, we're going to have really"}, {"timestamp": [319.12, 326.08], "text": " powerful machines soon. And so someone asked for clarification when I said, okay, well, what do you mean when you say"}, {"timestamp": [326.08, 332.0], "text": " AGI within 18 months? Because nobody can agree on the definition. And if you watched the Sam Altman,"}, {"timestamp": [332.0, 337.52], "text": " Lex Friedman interview, he refers, Sam Altman refers to AGI several times, but the definition"}, {"timestamp": [337.52, 341.84], "text": " seems to change. Because early in the interview, he talks about like, oh, you know, you put someone"}, {"timestamp": [341.84, 346.56], "text": " in front of GPT-4 or chat GPT-4 and what's the first thing that they do when,"}, {"timestamp": [346.56, 350.04], "text": " and these are his words, when they interact with an AGI"}, {"timestamp": [350.04, 352.04], "text": " is they try and break it or tease it or whatever."}, {"timestamp": [352.04, 354.8], "text": " And then later he says, oh, well, GPT-5,"}, {"timestamp": [354.8, 356.32], "text": " that's not even gonna be AGI."}, {"timestamp": [356.32, 359.22], "text": " So he keeps like equivocating and bouncing back and forth."}, {"timestamp": [360.56, 363.16], "text": " I think that part of what's going on here"}, {"timestamp": [363.16, 365.12], "text": " is there's no good definition."}, {"timestamp": [365.12, 367.04], "text": " And because later in the conversation,"}, {"timestamp": [367.04, 369.64], "text": " they were talking about things that a chat model can't do."}, {"timestamp": [369.64, 372.0], "text": " It's not autonomous, right?"}, {"timestamp": [372.0, 377.0], "text": " But, I'm glad you asked, reflection came out."}, {"timestamp": [377.0, 381.32], "text": " An autonomous agent with dynamic memory and self-reflection."}, {"timestamp": [381.32, 390.32], "text": " So between cognitive workflows and autonomy and the investment coming up into these models,"}, {"timestamp": [390.32, 397.1], "text": " we are far closer to fully autonomous agents than I think many people recognize."}, {"timestamp": [397.1, 400.42], "text": " So the reflection stuff, I'm not going to do a full video on reflection, there's other"}, {"timestamp": [400.42, 405.68], "text": " ones out there, but basically this outperforms humans in a few tasks,"}, {"timestamp": [405.68, 408.0], "text": " and it forms a very, very basic"}, {"timestamp": [408.0, 410.48], "text": " kind of cognitive architecture loop."}, {"timestamp": [410.48, 412.82], "text": " So query, action, environment, reward,"}, {"timestamp": [412.82, 414.64], "text": " reflect, and then repeat."}, {"timestamp": [414.64, 417.72], "text": " So you just continuously iterate on something in a loop,"}, {"timestamp": [417.72, 419.12], "text": " and there you go."}, {"timestamp": [419.12, 421.52], "text": " And also, for people who keep asking me"}, {"timestamp": [421.52, 424.64], "text": " what I think about, what's his name, Ben Goertzel."}, {"timestamp": [424.64, 428.74], "text": " I'm not sure if I'm saying his name right, but I read his seminal paper a couple years"}, {"timestamp": [428.74, 434.28], "text": " ago on general theory, on general intelligence, and he never mentioned iteration or loops,"}, {"timestamp": [434.28, 438.22], "text": " at least not to the degree that you need to when you're talking about actual intelligence."}, {"timestamp": [438.22, 444.28], "text": " So I personally don't think that he's done anything particularly relevant today."}, {"timestamp": [444.28, 445.96], "text": " I'm not going to comment on his older work because obviously he's made anything particularly relevant today. I'm not gonna comment on his older work"}, {"timestamp": [445.96, 447.96], "text": " because obviously he's made a name for himself,"}, {"timestamp": [447.96, 449.14], "text": " so on and so forth."}, {"timestamp": [449.14, 451.94], "text": " But I don't think that Ben has done anything"}, {"timestamp": [451.94, 454.3], "text": " really pertinent to cognitive architecture,"}, {"timestamp": [454.3, 456.5], "text": " which is the direction that things are going."}, {"timestamp": [457.42, 460.78], "text": " But yeah, so when MIT is doing research"}, {"timestamp": [460.78, 464.58], "text": " on cognitive architecture and autonomous designs,"}, {"timestamp": [464.58, 465.0], "text": " when Morgan Stanley and NVIDIA doing research on cognitive architecture and autonomous designs."}, {"timestamp": [465.0, 471.24], "text": " When Morgan Stanley and NVIDIA are working on investing literally hundreds of millions"}, {"timestamp": [471.24, 478.52], "text": " of dollars to drive down inference cost, and when open source libraries are creating the"}, {"timestamp": [478.52, 482.48], "text": " rudiments of cognitive architectures, we are ramping up fast."}, {"timestamp": [482.48, 485.88], "text": " And so someone asked what I meant, again, kind of getting back to that."}, {"timestamp": [485.88, 488.56], "text": " What did I mean by AGI within 18 months?"}, {"timestamp": [488.76, 494.64], "text": " I said in 18 months, any possible definition of AGI that you have will be"}, {"timestamp": [494.64, 495.36], "text": " satisfied."}, {"timestamp": [495.92, 500.22], "text": " Um, so it's like, I don't care what your definition of AGI is, unless like, there's"}, {"timestamp": [500.22, 503.36], "text": " still some people out there that like you asked them and it's like, Oh, well, once"}, {"timestamp": [503.36, 505.46], "text": " AGI hits, like the skies will darken and"}, {"timestamp": [505.46, 508.92], "text": " Nuclear weapons will rain down and I'm like that's not AGI. That's Ultron"}, {"timestamp": [509.52, 511.96], "text": " That's different. That's that's a fantasy"}, {"timestamp": [512.6, 517.04], "text": " That's probably not going to happen. It could if Skynet's going to happen it will happen within 18 months"}, {"timestamp": [518.6, 520.04], "text": " But I don't think it's gonna happen"}, {"timestamp": [520.04, 524.96], "text": " Okay, so that's section one of the video talking about the news and everything out there"}, {"timestamp": [525.76, 530.0], "text": " So now let me pivot and talk about the work that I've been doing."}, {"timestamp": [530.0, 536.0], "text": " So I've been making extensive use of ChatGPT4 to accelerate my own research."}, {"timestamp": [536.0, 538.66], "text": " I've been working on a few things."}, {"timestamp": [538.66, 542.04], "text": " Many of you are going to be familiar with my work on the heuristic imperatives, which"}, {"timestamp": [542.04, 545.28], "text": " is how do you create a fully autonomous machine"}, {"timestamp": [545.28, 548.62], "text": " that is safe and stable, ideally for all of eternity."}, {"timestamp": [549.96, 554.52], "text": " So this is probably one of my most important pieces of work"}, {"timestamp": [554.52, 556.28], "text": " and I've put it into all of my books"}, {"timestamp": [556.28, 557.68], "text": " and a lot of other stuff."}, {"timestamp": [557.68, 561.52], "text": " The TLDR of heuristic imperatives is it's like,"}, {"timestamp": [561.52, 565.5], "text": " it's similar to Asimov's three laws of robotics,"}, {"timestamp": [565.5, 568.5], "text": " but it is much, much more broadly generalized,"}, {"timestamp": [568.5, 572.7], "text": " and it is also not androcentric or anthropocentric."}, {"timestamp": [572.7, 574.7], "text": " And so basically, the three rules,"}, {"timestamp": [574.7, 579.1], "text": " that if you embed them into your autonomous AI systems,"}, {"timestamp": [579.1, 580.5], "text": " reduce suffering in the universe,"}, {"timestamp": [580.5, 581.9], "text": " increase prosperity in the universe,"}, {"timestamp": [581.9, 583.8], "text": " and increase understanding in the universe,"}, {"timestamp": [583.8, 586.96], "text": " this creates a very thoughtful machine and it serves as a"}, {"timestamp": [586.96, 593.16], "text": " really good reinforcement learning mechanism, self-evaluation mechanism that"}, {"timestamp": [593.16, 598.76], "text": " results in a very thoughtful machine. So that information is all available out"}, {"timestamp": [598.76, 604.84], "text": " here under on my github, Dave Schapp slash here is to comparatives. I've got it"}, {"timestamp": [604.84, 608.04], "text": " published as a Word doc and a PDF."}, {"timestamp": [608.04, 611.36], "text": " So I started adopting a more scientific approach"}, {"timestamp": [611.36, 612.84], "text": " because well, there's a reason"}, {"timestamp": [612.84, 615.52], "text": " that the scientific paper format works."}, {"timestamp": [615.52, 617.96], "text": " So if you wanna come out here and read it,"}, {"timestamp": [617.96, 620.88], "text": " it's out there, it's totally free, of course."}, {"timestamp": [620.88, 621.92], "text": " Oh, actually that reminds me,"}, {"timestamp": [621.92, 624.28], "text": " I need to put away to cite my work"}, {"timestamp": [624.28, 625.88], "text": " because you can cite GitHub repos."}, {"timestamp": [625.88, 630.08], "text": " But basically, this provides quite a bit."}, {"timestamp": [630.08, 636.6], "text": " And one thing to point out is that this paper was almost written entirely word for word by chat-gpt4,"}, {"timestamp": [636.6, 642.88], "text": " meaning that all of the reasoning that it does was performed by chat-gpt4,"}, {"timestamp": [642.88, 645.0], "text": " and at the very end,"}, {"timestamp": [646.6, 649.66], "text": " I actually had it reflect on its own performance."}, {"timestamp": [651.64, 653.72], "text": " It looks like it's not gonna load that much."}, {"timestamp": [653.72, 655.0], "text": " More pages, oh, there we go."}, {"timestamp": [655.0, 656.2], "text": " Examples."}, {"timestamp": [656.2, 659.88], "text": " So anyways, when you read this and you keep in mind"}, {"timestamp": [659.88, 662.3], "text": " that the nuance of it, whoops,"}, {"timestamp": [662.3, 670.56], "text": " that the nuance of this was within the capacity of CHAT-GPT-4, you will see that these models are"}, {"timestamp": [670.56, 676.24], "text": " already capable of very, very nuanced, empathetic, and moral reasoning. And this"}, {"timestamp": [676.24, 678.76], "text": " is one thing that a lot of people complain about. They're like, oh well it"}, {"timestamp": [678.76, 682.36], "text": " doesn't truly understand anything. I always say that humans don't truly"}, {"timestamp": [682.36, 685.6], "text": " understand anything, so that's a frivolous argument."}, {"timestamp": [685.6, 692.32], "text": " But that leads to another area of research which I'll get into in a minute. But basically, keep in"}, {"timestamp": [692.32, 698.56], "text": " mind how nuanced this paper is and keep in mind that ChatGPT wrote pretty much the entire thing"}, {"timestamp": [698.56, 703.2], "text": " and I've also got the transcript of the conversation at the end. So if you want to read the whole"}, {"timestamp": [703.2, 706.0], "text": " transcript, please feel free to read the whole transcript"}, {"timestamp": [706.0, 710.76], "text": " and you can see where we worked through the whole paper."}, {"timestamp": [710.76, 712.6], "text": " Yeah, so that's it."}, {"timestamp": [712.6, 720.96], "text": " So on the topic of does the machine truly understand anything, that resulted in this"}, {"timestamp": [720.96, 727.8], "text": " transcript, which I have yet to format this into a full scientific paper,"}, {"timestamp": [727.8, 733.76], "text": " but basically the the TLDR here is that I call it the epistemic pragmatic"}, {"timestamp": [733.76, 738.3], "text": " orthogonality, which is that the epistemic truth of whether or not a"}, {"timestamp": [738.3, 747.5], "text": " machine truly understands anything is orthogonal or uncorrelated with how useful it is or objectively correct it is."}, {"timestamp": [747.5, 753.12], "text": " Right, so if you look, basically it doesn't matter if the machine truly"}, {"timestamp": [753.12, 757.28], "text": " understands anything because again that's not really germane to its"}, {"timestamp": [757.28, 763.18], "text": " function as a machine and so this is it's a fancy term but it basically says"}, {"timestamp": [763.18, 765.92], "text": " okay and there's there was actually a great Reddit"}, {"timestamp": [765.92, 769.78], "text": " post where it's like, can we stop arguing over whether or not it's sentient or conscious"}, {"timestamp": [769.78, 771.44], "text": " or understands anything?"}, {"timestamp": [771.44, 773.54], "text": " That doesn't matter."}, {"timestamp": [773.54, 781.2], "text": " What matters is its physical, objective, measurable impact and whether it is objectively or measurably"}, {"timestamp": [781.2, 783.4], "text": " correct or useful."}, {"timestamp": [783.4, 789.72], "text": " So I call that the epistemic pragmatic orthogonality principle of artificial intelligence. I've got it summarized here"}, {"timestamp": [789.72, 794.34], "text": " so you can just read this is the executive summary that I actually use"}, {"timestamp": [794.34, 799.42], "text": " chat GPT to write. So again a lot of the work that I'm doing is anchored by chat"}, {"timestamp": [799.42, 807.0], "text": " GPT and the fact that chat GPT was able to have a very nuanced conversation about its own understanding"}, {"timestamp": [807.0, 810.0], "text": " kind of tells you how smart these machines are."}, {"timestamp": [810.0, 813.0], "text": " Yep, so that is that paper."}, {"timestamp": [813.0, 817.0], "text": " Now moving on back to some of the cognitive architecture stuff,"}, {"timestamp": [817.0, 820.0], "text": " one thing that I'm working on is called REMO,"}, {"timestamp": [820.0, 824.0], "text": " so the Rolling Episodic Memory Organizer for Autonomous AI Systems."}, {"timestamp": [824.0, 826.36], "text": " I initially called this HMCS,"}, {"timestamp": [826.36, 829.3], "text": " which is hierarchical memory consolidation system,"}, {"timestamp": [829.3, 832.0], "text": " but that's a mouthful and it doesn't abide"}, {"timestamp": [832.0, 835.88], "text": " by the current trend where you use an acronym"}, {"timestamp": [835.88, 837.4], "text": " that's easy to say, right?"}, {"timestamp": [837.4, 839.68], "text": " So REMO, rolling episodic memory organizer,"}, {"timestamp": [839.68, 842.28], "text": " much easier to say, much easier to remember."}, {"timestamp": [842.28, 848.08], "text": " Basically what this does is, it's also not done. So I need to add"}, {"timestamp": [848.08, 853.2], "text": " a caveat there. I'm working through it here with chat GPT-4, where we're working on defining the"}, {"timestamp": [853.2, 858.8], "text": " problem, writing the code, so on and so forth. But basically, what this does is rather than just"}, {"timestamp": [858.8, 866.4], "text": " using semantic search, because a lot of folks have realized that yes, semantic search is really great because it allows"}, {"timestamp": [866.4, 872.24], "text": " you to search based on semantic similarity rather than just keywords. Super powerful, super fast,"}, {"timestamp": [873.04, 879.2], "text": " using stuff like Pinecone, still not good enough because it is not organized in the same way that"}, {"timestamp": [879.2, 889.12], "text": " a human memory is. So, the entire point of Remo is to do two things. The two primary goals is"}, {"timestamp": [889.12, 895.88], "text": " to maintain salience and coherence. So, salient memories means that what you're looking at"}, {"timestamp": [895.88, 900.12], "text": " is actually germane, actually relevant to the conversation that you're having, which"}, {"timestamp": [900.12, 908.6], "text": " can be more difficult if you just use semantic search. The other thing is coherence, which is keeping the context of those memories"}, {"timestamp": [909.88, 911.72], "text": " basically in a coherent narrative."}, {"timestamp": [911.72, 915.2], "text": " So if rather than just focusing on semantic search,"}, {"timestamp": [915.2, 917.8], "text": " the two terms that I'm introducing"}, {"timestamp": [917.8, 919.52], "text": " are salience and coherence,"}, {"timestamp": [919.52, 923.38], "text": " and of course this is rooted in temporal binding."}, {"timestamp": [923.38, 926.6], "text": " So human memories are temporal and associative."}, {"timestamp": [926.6, 929.44], "text": " So, those four concepts, salience and coherence,"}, {"timestamp": [929.44, 932.74], "text": " are achieved with temporal and associative"}, {"timestamp": [932.74, 935.44], "text": " or semantic consolidation."}, {"timestamp": [935.44, 938.54], "text": " And so, what I mean by temporal consolidation"}, {"timestamp": [938.54, 941.28], "text": " is you take clusters of memories"}, {"timestamp": [941.28, 944.62], "text": " that are temporally bounded or temporally nearby"}, {"timestamp": [944.62, 946.56], "text": " and you summarize those."}, {"timestamp": [946.56, 949.56], "text": " So that gives you temporal consolidation,"}, {"timestamp": [949.56, 952.74], "text": " which allows you to take, you can compress memories,"}, {"timestamp": [952.74, 956.48], "text": " AI memories, on a factor of five to one,"}, {"timestamp": [956.48, 957.72], "text": " 10 to one, 20 to one,"}, {"timestamp": [957.72, 961.04], "text": " depending on how concisely you summarize them."}, {"timestamp": [961.04, 963.56], "text": " So that gives you a lot of consolidation."}, {"timestamp": [963.56, 967.52], "text": " Then you use semantic modeling to create a"}, {"timestamp": [967.52, 974.4], "text": " semantic web or a cluster from the semantic embeddings of those summaries. So it's a layered"}, {"timestamp": [974.4, 984.52], "text": " process. Actually, here, I think I can just show you here. Wait, no, I've got the paper"}, {"timestamp": [984.52, 988.08], "text": " here. Let me show you the Remo paper. So this is"}, {"timestamp": [988.08, 992.0], "text": " a work in progress. It'll be published soon. But let me show you the diagrams because this"}, {"timestamp": [992.0, 996.52], "text": " will just make it make much more sense. Oh, and chat GPT can make diagrams too. You just"}, {"timestamp": [996.52, 1004.04], "text": " ask it to output a mermaid diagram definition and it'll do it. So here's the TLDR, the very"}, {"timestamp": [1004.04, 1006.5], "text": " simple version of the Remo framework. It's got three layers. So here's the TLDR, the very simple version of the Remo framework."}, {"timestamp": [1006.5, 1008.24], "text": " It's got three layers."}, {"timestamp": [1008.24, 1009.56], "text": " So there's the raw logs layer,"}, {"timestamp": [1009.56, 1012.52], "text": " which is just the chat logs back and forth,"}, {"timestamp": [1012.52, 1014.16], "text": " the temporal consolidation layer,"}, {"timestamp": [1014.16, 1016.48], "text": " which as I just mentioned,"}, {"timestamp": [1016.48, 1021.48], "text": " allows you to compress memories based on temporal grouping."}, {"timestamp": [1022.08, 1024.72], "text": " And then finally, the semantic consolidation layer,"}, {"timestamp": [1024.72, 1031.16], "text": " which allows you to create and extract topics based on semantic similarity. So by"}, {"timestamp": [1031.16, 1035.64], "text": " having these two layers that have different kinds of consolidation,"}, {"timestamp": [1035.64, 1041.78], "text": " you end up with what I call temporally invariant recall. So the topics that we"}, {"timestamp": [1041.78, 1049.4], "text": " extract are going to include all the time from beginning to end"}, {"timestamp": [1049.4, 1055.28], "text": " that is relevant while also having benefited from temporal consolidation."}, {"timestamp": [1055.28, 1061.78], "text": " I'm going to come up with some better diagrams to demonstrate this, but basically it's like..."}, {"timestamp": [1061.78, 1065.0], "text": " Actually I can't think of a good way to describe it."}, {"timestamp": [1065.46, 1067.42], "text": " But anyway, so this paper is coming"}, {"timestamp": [1067.42, 1070.1], "text": " and I'm actively experimenting with this"}, {"timestamp": [1070.1, 1071.98], "text": " on a newer version of Raven"}, {"timestamp": [1071.98, 1074.3], "text": " that uses a lot more implied cognition."}, {"timestamp": [1074.3, 1077.4], "text": " So I talked about implied cognition in a previous episode,"}, {"timestamp": [1077.4, 1080.86], "text": " but basically implied cognition is when I,"}, {"timestamp": [1080.86, 1082.7], "text": " in using ChatGPT4,"}, {"timestamp": [1082.7, 1085.42], "text": " I realized that it is able to think through stuff"}, {"timestamp": [1085.42, 1086.84], "text": " without you having to design"}, {"timestamp": [1086.84, 1089.26], "text": " a more sophisticated cognitive architecture."}, {"timestamp": [1089.26, 1091.98], "text": " So the cognitive architecture with GPT-4"}, {"timestamp": [1091.98, 1095.1], "text": " as the cognitive engine actually becomes much simpler"}, {"timestamp": [1095.1, 1097.78], "text": " and you only have to focus, I don't wanna say only,"}, {"timestamp": [1097.78, 1100.0], "text": " but the focus shifts then to memory"}, {"timestamp": [1100.0, 1101.94], "text": " because once you have the correct memories,"}, {"timestamp": [1101.94, 1104.52], "text": " the model becomes much more intelligent."}, {"timestamp": [1104.52, 1106.64], "text": " So that's up here under Remo framework."}, {"timestamp": [1106.64, 1111.64], "text": " I'm working on a conversation with Raven to demonstrate this"}, {"timestamp": [1111.64, 1114.8], "text": " and that's that, the paper will be coming too."}, {"timestamp": [1114.8, 1117.16], "text": " So this is one big important piece of work."}, {"timestamp": [1117.16, 1119.84], "text": " The other most important piece of work that I'm working on"}, {"timestamp": [1119.84, 1123.16], "text": " is the Atom framework, which this paper is already done,"}, {"timestamp": [1124.04, 1128.52], "text": " but Atom framework, here, let me just load it here."}, {"timestamp": [1128.52, 1129.36], "text": " There we go."}, {"timestamp": [1129.36, 1132.16], "text": " So, Autonomous Task Orchestration Manager."}, {"timestamp": [1132.16, 1134.56], "text": " So this is another kind of long-term memory"}, {"timestamp": [1134.56, 1136.56], "text": " for autonomous AI systems."}, {"timestamp": [1136.56, 1140.04], "text": " That's basically like the TLDR is,"}, {"timestamp": [1140.04, 1144.42], "text": " it's like JIRA or Trello, but for machines with an API."}, {"timestamp": [1144.4, 1145.92], "text": " It's like Jira or Trello, but for machines with an API."}, {"timestamp": [1150.92, 1151.04], "text": " And so in this case, it's inspired by a lot of things."}, {"timestamp": [1155.32, 1158.24], "text": " One, Agile, two, OnTask by David Bader, Neuroscience for Dummies, Jira, Trello,"}, {"timestamp": [1158.24, 1160.3], "text": " a whole bunch of other stuff."}, {"timestamp": [1160.3, 1163.68], "text": " But basically we talk about cognitive control."}, {"timestamp": [1163.68, 1165.92], "text": " So I'm introducing a lot of neuroscience terms"}, {"timestamp": [1165.92, 1167.24], "text": " to the AI community."}, {"timestamp": [1167.24, 1169.72], "text": " So cognitive control has to do with task selection,"}, {"timestamp": [1169.72, 1171.96], "text": " task switching, task decomposition,"}, {"timestamp": [1171.96, 1175.36], "text": " goal tracking, goal states, those sorts of things."}, {"timestamp": [1175.36, 1178.12], "text": " And then we talk about, you know,"}, {"timestamp": [1178.12, 1180.68], "text": " some of the inspiration, Agile, JIRA, Trello."}, {"timestamp": [1181.64, 1183.24], "text": " And then, so it's like, okay,"}, {"timestamp": [1183.24, 1186.8], "text": " so what are the things that we need to talk or that we need to include"}, {"timestamp": [1186.8, 1189.94], "text": " in order for an AI system to be fully autonomous"}, {"timestamp": [1189.94, 1193.14], "text": " and track tasks over time?"}, {"timestamp": [1193.14, 1194.9], "text": " So you need tools and tool definitions,"}, {"timestamp": [1194.9, 1197.54], "text": " you need resource management, and you need an agent model."}, {"timestamp": [1197.54, 1201.5], "text": " All these are described later on or in greater depth."}, {"timestamp": [1202.62, 1207.5], "text": " Then actually in my conversation with ChatGPT,"}, {"timestamp": [1207.5, 1209.12], "text": " one of the things that it said is like,"}, {"timestamp": [1209.12, 1210.42], "text": " okay, well, how do you prioritize stuff?"}, {"timestamp": [1210.42, 1211.88], "text": " And I was like, I'm glad you asked."}, {"timestamp": [1211.88, 1214.24], "text": " And so I shared my work with the heuristic imperatives"}, {"timestamp": [1214.24, 1216.12], "text": " and ChatGPT agreed like, oh yeah,"}, {"timestamp": [1216.12, 1219.36], "text": " this is a really great framework for prioritizing tasks"}, {"timestamp": [1219.36, 1221.04], "text": " and measuring success."}, {"timestamp": [1221.04, 1222.44], "text": " Okay, great, let's use that."}, {"timestamp": [1224.24, 1227.02], "text": " I think, let's see, is the transcript posted?"}, {"timestamp": [1227.02, 1228.98], "text": " I don't know if I posted the transcript, I didn't."}, {"timestamp": [1228.98, 1230.68], "text": " I'll post the full transcript"}, {"timestamp": [1230.68, 1234.5], "text": " of making the Atom framework in the repo."}, {"timestamp": [1235.62, 1237.6], "text": " So then we get into like, okay,"}, {"timestamp": [1237.6, 1239.56], "text": " so now that you have all the background,"}, {"timestamp": [1239.56, 1240.8], "text": " what do we talk about?"}, {"timestamp": [1240.8, 1242.2], "text": " So it's all about tasks"}, {"timestamp": [1242.2, 1243.72], "text": " and the data that goes into the task."}, {"timestamp": [1243.72, 1249.6], "text": " So first you need to figure out how to represent a task. So there's basic stuff like task ID, description, type, goal state,"}, {"timestamp": [1249.6, 1255.68], "text": " priority, dependencies, resource, time estimates, task status, assigned agents, progress. And then"}, {"timestamp": [1255.68, 1269.0], "text": " the one that is new is task impetus. So this is something that you might not think of if you think about your JIRA board or your Kanban board or your Trello board is the why."}, {"timestamp": [1269.0, 1274.0], "text": " So the why is implicit in our tasks. Why am I trying to do this?"}, {"timestamp": [1274.0, 1285.24], "text": " But when we added this, chatGPT got really excited and it's like, oh yeah, it's actually really important to record why any autonomous entity is doing a task for a number of reasons."}, {"timestamp": [1285.24, 1287.2], "text": " One, to track priorities,"}, {"timestamp": [1287.2, 1291.56], "text": " or the impetus might be superseded later on,"}, {"timestamp": [1291.56, 1292.4], "text": " any number of things,"}, {"timestamp": [1292.4, 1293.96], "text": " but also you need to justify the use"}, {"timestamp": [1293.96, 1295.96], "text": " of those resources in that time."}, {"timestamp": [1295.96, 1298.52], "text": " So this all goes into the representation of a task,"}, {"timestamp": [1298.52, 1300.48], "text": " which you can do in JSON, YAML,"}, {"timestamp": [1300.48, 1303.2], "text": " flat files, vector databases, whatever, I don't care."}, {"timestamp": [1303.2, 1305.42], "text": " Like, you can figure out how you want to represent it. I'm probably just going to do these in text files, vector databases, whatever, I don't care. Like, you can figure out how you want to represent it."}, {"timestamp": [1305.42, 1307.54], "text": " I'm probably just going to do these in text files,"}, {"timestamp": [1307.54, 1308.9], "text": " honestly, because that's the easiest thing"}, {"timestamp": [1308.9, 1310.58], "text": " for an LLM to read."}, {"timestamp": [1311.9, 1314.7], "text": " And then, so talking about the task representation,"}, {"timestamp": [1314.7, 1316.98], "text": " then we move on to the task lifecycle."}, {"timestamp": [1316.98, 1320.62], "text": " Task creation, decomposition, prioritization, execution,"}, {"timestamp": [1320.62, 1321.7], "text": " monitoring and updating,"}, {"timestamp": [1321.7, 1323.86], "text": " and then finally completing the task."}, {"timestamp": [1323.86, 1328.0], "text": " And then you archive it and you save it for later so that you can refer back to it."}, {"timestamp": [1328.0, 1333.0], "text": " Again, this is still primarily a long-term memory system for autonomous AI systems."}, {"timestamp": [1333.0, 1337.0], "text": " Some of the folks that I work with on Discord,"}, {"timestamp": [1337.0, 1342.0], "text": " and by work with I mean just like I'm in the AI communities with them,"}, {"timestamp": [1342.0, 1345.64], "text": " they all think that the Atom framework is pretty cool."}, {"timestamp": [1347.74, 1350.88], "text": " So then we talk about task corpus management, which is like, okay, looking at an individual task is fine,"}, {"timestamp": [1350.88, 1353.28], "text": " but how do you look at your entire body of tasks?"}, {"timestamp": [1353.28, 1355.98], "text": " Because in autonomous AI, it might have five tasks,"}, {"timestamp": [1355.98, 1358.04], "text": " it might have 5,000 tasks,"}, {"timestamp": [1358.04, 1361.44], "text": " and then you need some processes to like,"}, {"timestamp": [1361.44, 1363.28], "text": " okay, if we're going through these tasks,"}, {"timestamp": [1363.28, 1365.64], "text": " how do we manage a huge volume of tasks?"}, {"timestamp": [1365.64, 1368.16], "text": " And so some ideas about how to do that are here."}, {"timestamp": [1368.16, 1370.94], "text": " And then finally, one of the last sections"}, {"timestamp": [1370.94, 1373.48], "text": " is some implementation guidelines, which is just,"}, {"timestamp": [1373.48, 1375.82], "text": " okay, this is probably some things"}, {"timestamp": [1375.82, 1378.52], "text": " that you wanna think about when you deploy"}, {"timestamp": [1378.52, 1380.82], "text": " your implementation of the Atom framework."}, {"timestamp": [1381.78, 1384.08], "text": " Yeah, so I think that's about it."}, {"timestamp": [1384.08, 1385.68], "text": " Obviously, I'm always working on a few different"}, {"timestamp": [1385.68, 1391.16], "text": " things, but the Atom framework and the Remo framework are the two biggest things that"}, {"timestamp": [1391.16, 1397.8], "text": " I'm working on in terms of autonomous AI. And so yeah, all this stuff is coming fast."}, {"timestamp": [1397.8, 1403.64], "text": " I think that's about it. So thanks for watching. Like and subscribe and support me on Patreon"}, {"timestamp": [1403.64, 1405.32], "text": " if you'd like."}, {"timestamp": [1405.32, 1410.36], "text": " For anyone who does jump in on Patreon, I'm happy to answer some questions for you, even"}, {"timestamp": [1410.36, 1414.0], "text": " jump on video calls if you jump in at the high enough tier."}, {"timestamp": [1414.0, 1415.56], "text": " I help all kinds of people."}, {"timestamp": [1415.56, 1421.08], "text": " I do have a few NDAs that I have to honor, but those are pretty narrow and some of them"}, {"timestamp": [1421.08, 1423.44], "text": " are also expiring."}, {"timestamp": [1423.44, 1425.64], "text": " So I've had people ask you know"}, {"timestamp": [1425.64, 1431.88], "text": " for help just with writing prompts for chat GPT. I've had people ask simple"}, {"timestamp": [1431.88, 1437.44], "text": " things like how did you learn what you learned, all kinds of stuff. But yeah so"}, {"timestamp": [1437.44, 1441.72], "text": " that's that. Thanks for watching and cheers everybody."}, {"timestamp": [1435.78, 1439.78], "text": " MBC \ub274\uc2a4 \uae40\uc7ac\uacbd\uc785\ub2c8\ub2e4."}]}