{"text": " Welcome to the Invincible Innovation Show, the podcast for changemakers. Hey, everyone, I'm so happy to see you with me. Welcome, ladies and gentlemen. We have an extraordinary episode in Invincible Innovation today. I'm your host, Adima Zolrior, product design and AI expert. And in this episode, I have the pleasure of speaking with an AI researcher who will share his insight on the role of AI and the workforce, its positive and negative implication and the impact on humanity. Join us as we delve into the fascinating world of AI and uncover how it is shaping the future of work. So, hi David. Hello, thanks for having me. Good to be here. So happy that you're here. David is the AI thought leader and researcher and gonna have a really fascinating talk. We're live on LinkedIn, YouTube, and Facebook and you're so invited to join the discussion and ask questions. So let's start. So how do you think really AI will really change the nature of work? Yeah, I mean, you know, that's a great place to start. So one thing that I kind of have this mantra that I use to kind of tell people what I expect is going to happen, and that is that, tell people what I expect is going to happen. And that is that, you know, AI is, it has the potential to be better, faster, and cheaper than human labor in a lot of ways. So better, faster, cheaper. Like that's, I mean, that's why we implement technology anyways, right? That's why we have printers instead of typewriters. That's why we have databases instead of, you know, filing cabinets. But with the, the primary difference with AI is that it has the ability to think. So Satya Nadella, the CEO of Microsoft, during the Microsoft Inspire keynote speech said that, one way to think about generative AI is that it's a reasoning engine, and it's only going to get better from here. So it's really going to drastically change our relationship to work, who does work, what kind of work, and that sort of thing. So the rule of thumb that I have arrived at to kind of figure out like, okay, well, what are humans going to do? What are you and I going to do? And what I came to, what I realized is that you have to look at the demand side rather than the supply side or the capacity side. And so if machines are capable of doing thought labor and physical labor better, faster and cheaper than humans, then you have to look at what are other humans willing to pay for, for another person to do. And so then that's why I think that you see the rise of streamers and YouTube content creators. And I think that we're also going to see demand for human labor in anything that's kind of intrinsically emotional or social, as kind of the way that we're going to change our relationship to work. Of course, there's a lot more to unpack there, but that's kind of the high-level overview. Yeah, but what comes to me when I think about the change in the workforce is the fact that most people thought about like, yeah, we're going to have like cars driving without drivers and maybe in the supermarkets we would not have anyone doing the cashing and everything. But right now I think that most people understand that even very sophisticated jobs like lawyers and copywriters and things that, and doctors of course, that demand so much of us could be done by a machine, which is a very sophisticated machine. Yes. Yeah, you know, so there's still a scarcity mentality around some of those professions, right? This is the reason that doctors and lawyers are so expensive. They're highly educated professionals, you know, that requires a lot of school and a lot of experience. And it will be a while before machines are even capable of displacing those jobs. But one thing that I was on another podcast, and I was brainstorming ideas, just kind of as we were talking through, and I realized that 20 years from now, we might not have hospitals anymore. Because the combination of AI and telemedicine and and You know rejuvenation therapies might mean that even just the need for hospitals goes away So the the potential for change the way that we get the need that our needs met whether it's food or medical care or whatever a lot of these technologies have the possibility of really driving down the costs of Some of the basic services and goods that we need. So yeah, absolutely. Again, this is speculation. We don't know how it's going to play out or when, but it is hypothetically possible. Yeah. I think that if we're taking doctors, for example, it makes sense that we have a definition which is like, first is analyzing your problem, what is like, what is going on with you, and then treating you. And sometimes treatment defines, it needs something else than just understanding. It needs, of course, the capabilities to work with a human and to do certain procedures. And it's a bit different than just defining what needs to be done. And I think that maybe doctors would have different level of interacting with AI, but if we were thinking about advisor like legal advisor, lawyers, or consultants, or financial consultants and so forth, the majority of the work is just understanding and analyzing the data, right? Yeah, so one of my clients is, I actually have several clients that are physicians or former clients that are physicians or in the medical field. And one of the things that one of them said is that he wonders, and this is not necessarily a prediction, but he just wonders if the current school, like medical school of doctors, are gonna be like the last classically trained doctors. Because as AI becomes more powerful and it becomes part of the diagnostic tool, it becomes part of the treatment plan, it becomes part of the patient management platforms, then what doctors need to learn in the future might be very different. And we're already seeing this with medical imaging because obviously we have the ability to feed images into AI today, and you can generate images, you can analyze them. And in many cases, it's not universal, but we're getting pretty close pretty quickly. In many cases, machines are better at reading medical images than humans. So if that's the case, it would actually be unethical to use humans to do that job because they have worse outcomes. Now, if that happens for other professions, lawyers, doctors, drivers, whatever, if the machines become better than humans, then we would actually have an ethical obligation, arguably an ethical obligation, to move to machines to do these things. So that's another kind of way to look at it is, okay, if it provides better outcomes, what is our moral duty there? Yeah, and one of my recent guests was, we talked about AI in the military, which is kind of obvious that you could use a machine or a robot to do risky tasks instead of using a human being, which is something that we should consider, I guess. Oh yeah. Yeah, you know, de-risking things is another example of using AI, but of course, if you use AI too soon or use it wrong, you can actually increase risks. And so there's lots of talks on both sides of that, right? Is AI gonna kill everyone? Is it gonna save everyone? And of course it depends. It depends on how you use it, just like any technology, right, like whether it's nuclear technology or synthetic biology, all of these technologies have the capacity for doing a lot of good and a lot of harm. So I always remind people they are, like this is a dual use technology. Like, you know, you don't give a really sharp knife to a toddler. Likewise, you have to make sure that the safety and the training wheels are on for now with AI. So we talked about the changing workforce and we have a question from one of our viewers in LinkedIn. So what core competencies will be in need? So what do you think is really needed? Thank you. Yeah, that's a great question. Yeah, yeah, that's a great question. So, you know, if you listen to Harvard Business Review or any of the like kind of modern business theory, emotional intelligence and communication skills are all the rage, whether it's all the soft skills are increasingly important in the business world. And that's been a trend for at least the last decade or two. The recognition of emotional intelligence being critical, but also communication. The ability to express yourself is critical. And this is not just in the business world. One thing that I realized is that every lesson that I learned about interpersonal communication and emotional intelligence for like, you know, working on my marriage also directly applied to work. And every lesson that I learned about communication at work also directly apply applied to my personal life. And so these are just universal skills that all humans can benefit from. And it does take time and practice, right, you know, like, And it does take time and practice, right? You know, like I've had guests on other podcasts that weren't as well spoken or weren't as confident in their speaking Or or maybe not as self-aware or whatever and this is not not a criticism of anyone It's just an observation that there are differences in ability And and filling in those gaps as best you can Will really be a big difference for a lot of people moving forward. Because if you can express your fears, or your needs, or your strengths, or whatever it is, if you can connect with other humans better, that will serve you in every aspect of life, work or otherwise. Yeah, but when I think about what you're saying, we already know that there are like these chats that you could have with an entity, which is an AI, like in Replica, for example, and you could really communicate with these machines, which are like, you see an avatar, you could choose how he or she would look like, and people are really getting attached to these entities, actually, right? So maybe what we think about communication and about connection is gonna change, too. Yeah, no, that's an interesting point. And certainly, it kind of breaks both ways, because there are people that find the idea of having a relationship with a robot or a chatbot to be really unsettling or really cringey. And there are people that are really like into it. And you know, I've made a few videos on my YouTube channel about this kind of exploring both sides. Like what are the unmet needs that these chatbots and robots are fulfilling, whether it's, you know, romantic needs or emotional needs, or, you know, in some cases, sexual needs, uh, you know, but there's also opportunity here. And so I'm, I'm always very optimistic. And so one thing that I see is an opportunity to use these as teaching tools. And so there's actually plenty of stories about this of like people that had a relationship with a chatbot and they learned to communicate better because these machines, you have to be very explicit about what you want and need and feel and whatever. And even if you don't use stuff like if you don't use, you know, stuff like chat GPT or whatever for romantic purposes, just learning to express yourself very clearly and explicitly via these chat bots, that has helped my communication a lot. Some people notice that I tend to write like chat GPT writes now, just because I discovered like, this is a very clear, succinct way of communicating, you know, but on the other side, there is also a tremendous opportunity for education, whether it's on the human level or learning new skills or anything like that. Some of my clients, I've helped clients with all kinds of challenges. One was working on a program to help recently released inmates re-acclimate to society. And so by having a chatbot that is able to say that had the mission, I helped him program the mission of the chatbot was to reduce recidivism. So whatever else the chatbot was doing, it was there to help, you know, these former inmates re-engage with their life. And it had that mission of, let's keep you from going back. What do you need in order to not go back? And I was really proud of that project. So there's a lot of opportunity here. Yeah, it's like a friend that could be 24 seven there for you and it could help. I talked with someone who has a robot for mental health and it could be your guide and help you like in CBT and meditation, mindfulness, so forth. Usually we could get help more than we can do. who has a robot for mental health, and it could be your guide and help you in like in CBT and meditation, mindfulness, so forth. Usually we could get help. Most people would not really think about getting therapy or help, but it's cheap, it's available, it's 24 to seven, it's always there for you. And it's not saying that you don't need a therapist in that case, you could get further information between the meetings and the therapist could get like a summary of what has happened during the time that she was or he was not there. Right. Yeah. You know, I've even made some of my own chatbots to help like talk through emotional things or like unpack, you know, something that happened. And because I already know a lot about the mind and mental health and psychology and emotions, I know how to use this tool. And right now, what I will say is that there is still the lack of human intuition. Sometimes, in many cases, these chatbots, if you use them correctly or they're programmed correctly, they can be pretty insightful, but there's also really, really big gaps in their ability to intuit what's going on or to connect the dots. So certainly, and maybe that will always be true. Maybe there's just something fundamental about humans and human communication that some therapists will just always be better for chatbots. But at the same time, there's a lot of people who are not comfortable with therapists or can't afford therapists, and as you mentioned, the accessibility and low cost really greatly offsets that. There was a study some years ago that looked at the difference between, this is for therapy, the difference between professional, like licensed therapist help versus self-directed therapy, and while self-directed therapy. And while self-directed therapy was not quite as effective, the fact that it was cheaper and accessible meant that it had an outsized impact on the aggregate wellbeing of society. And I think that AI has the ability to turn that up so that it's much closer to close that gap. And of course, like, you know, I think everyone deserves to have a mental health. It's a difficult topic. Yeah, and someone, it doesn't have to call it a therapist, it could just be a friend that listens and are with you through the downs and upsides of life. So you don't have to call it a therapist. And many people would not like to be a friend of a therapist or to have a therapist. So what are the potential benefits of AI in the workforce and how can they be maximized? Yeah, so as I mentioned earlier, AI has the potential to be better, faster, cheaper, just like any technology, right? You know, you drive a car because it is better, faster, and cheaper than walking. Right, you can get to the next city in 30 minutes instead of tomorrow. And so likewise, AI has the ability to accelerate a lot of things for us, whether it's brainstorming, drafting things. And it can draft all kinds of things, whether it's technical documentation, works of fiction, emails. There's all kinds of ways that you can use it. It can also read a tremendous amount, especially as the chatbots get bigger. So Claude, for instance, is one of the competitors to chat GPT, and it has 100,000 token window. So 100,000 tokens is roughly 80,000 words that it can read in about 30 seconds. So that's basically an entire book, an entire nonfiction book that you can plug in and ask questions about and learn about without having to read it yourself. So that can literally save you many, many, many hours worth of reading in order to say, OK, I need this piece of information. Go get it. Let's go. And so that kind of acceleration is really what I recommend my clients look for, is don't look for something that's going to shave off 5-10 percent. Look for something that's going to triple your speed. Look for something that's going to quadruple your speed in order for specific tasks. Maybe not the entire project, but for certain tasks, you can certainly go 10 times faster or 100 times faster. That's really where you're going to get a good ROI implementing generative AI today. 10 times faster or 100 times faster. And that's really where you're gonna get a good ROI implementing generative AI today. Yeah, it reminds me of the strike in LA of the writers. And just think about it, instead of working half a year on a script, they could do it like in a month or a few days, I don't know exactly. But for sure, the fun part of being creative, of developing a character, of adding these like small glitches for a character is still theirs. It's, I guess the chat GPT could not, or similar to would not do that. Yeah. Yeah, you know, I use a variety of AI tools to help me with brainstorming in my fiction, whether it's, you know, kind of, you know, brainstorming in my fiction, whether it's kind of brainstorming characters or plots. And these chatbots, they understand story structure and principles of writing. But you're absolutely right. The thing about being a writer or any kind of creative type is I have a personal mission. There is something that I am trying to say or achieve with my works of fiction that the machine is just never going to have. That's just not part of how it's built. It is there to generate text, but I have an emotional mission that I am trying to tell a story for, or an experience that I'm trying to relate, a very specific experience. And so rather than look at these tools as replacing that, they're there to help and accelerate that and facilitate it. And you know, there's a lot of conversation. Obviously, there's lawsuits about this kind of thing. There's people defending it. So it's very polarizing on both sides. And you know, it's similar to arguments in the past, right? When the printing press was invented, some people thought that it was going to be the destruction because people were no longer writing longhand as much. And then, you know, typewriters, internet, photography cameras replaced a lot of painting. And so technology always, it almost seems like technology disrupts arts first. So maybe in hindsight, we shouldn't be surprised that, you know, writers and creative types were the first ones to get disrupted. Just spitballing, I don't know if that's sensible. Okay, we have a question related to the fact that you mentioned you're a chatbot. So how Daniel, I know Daniel is really cute. Which framers and models do you typically use to build a chatbot? Yeah, so right now the easiest way to build a chatbot? Yeah, so right now, the easiest way to build a chatbot is the chat GPT API. And so the chat GPT API gives you a few knobs and levers that make it pretty easy to build a chatbot, namely the system window. So if you're not familiar with this, the system window is a set of instructions that you can give the chatbot, where you can give it rules of how to engage with the user, or you can give it some background information. And I've made a lot of use of the system window to give it either specific missions, roles. You can give it formats. So if you need it to write code and use only this language, use this particular format, it can write code. You can tell it what not to do. You can use negative particular format, it can write code, you can tell it what not to do, you can use negative prompting, which is something that's really common in the image generation area. And so there's a lot of cross-pollination that can happen, but that's the primary thing. And honestly, I have found that the right system window can get some really good behavior out of these chatbots. One area of my research is more sophisticated cognitive architectures, which is to basically create autonomous agents. So you might've heard of like agent GPT or baby AGI or meta GPT. There's all kinds of ones out there. So I'm actually participating in a research project to publish a much more sophisticated framework that people can adopt. That paper should come out in October, I think. So stay tuned. Yeah. So Daniel just followed David, and he has a very successful YouTube channel, and you can see it on LinkedIn and so forth. So we talked about what could be a very good outcome from these AIs. So let's talk about potential risks and challenges associated with AI workforce. Yeah, so obviously, so there's a few ways to look at it. You can look at it from the perspective of a CEO, right? There's a few memes out there circulating on LinkedIn. And so like the chief security officer looks at AI as like a threat, you know, it's more hacking and spear phishing and that sort of thing. The CEO, however, is gonna look at it more as a combination of business opportunity and business threat. And so what I mean by that is that, you know, generative AI is happening, whether you like it or not. And if you ignore it, you're going to get left behind. So that's the biggest threat to any company. And some companies, especially brick and mortar ones, they can afford to ignore it and kind of be slow adopters. But any company in the service space, I think, probably needs to be paying attention. So that's kind of one of the big things to pay attention to. And as I mentioned earlier, it's not gonna necessarily fundamentally transform your business, but what it will do is it'll give you a competitive advantage because it'll allow you to accelerate some of those business processes that you need. And it can also allow you to greatly reduce the cost of some of those business processes. Some of my friends are lawyers, and we were talking about law as an intersection with generative AI, and different types of lawyers have different incentives. And so what I mean by that is that a private law firm, they bill hourly. So they're like, well, we're not going to use AI because we're going to take 100 hours of research and it's going to be 20 minutes. We can't bill for that. But on the other hand, corporate lawyers who are, you know, in-house counsel, they just need to get the job done and serve the company. So they're all about generative AI tools. And so we're seeing this really interesting market fragmentation. So those are some examples of opportunities and threats to do in the case of AI. Yeah. And we have a question related to that. Data security is a major issue to apply externally inside companies and we know that I think Samsung and maybe Apple denied access to their employees. Any advice on how to overcome this issue? Yeah, so if I understand the question, it has to do with data governance, which is, okay, so if you're sending private, whether personally private information or corporate confidential information to a vendor, how do they handle that? How do you control that? And so one thing that I noticed earlier on, because this was a big concern, I don't know if it was ever true explicitly, but certainly people believed it was true, that when you used various generative AI APIs, like OpenAI's endpoints, and again, I don't wanna, I'm not slandering them, I know that it's not true anymore, they have updated their policy, but it might have been true, where any data that you sent them, they might use it for training, and so that is still a very big fear. And whether or not it was open AI or any other companies, data is the new oil. And I'm surprised at the number of people who haven't heard this. Data is the new oil. So data is super valuable. And so a lot of companies want your data to train on. But one thing that I have advised some clients of is pay attention to the more mature vendors. And so what I mean by that is Microsoft has been serving companies and schools and governments for a long time. So Microsoft, for instance, really understands the value of respecting the data, integrity and privacy of their customers. Smaller companies may or may not. I've also worked with Nvidia and Nvidia. They're like we kind of like I've also worked with Nvidia, and Nvidia, they're like, we kind of like, I'm not quoting them exactly, but kind of the sentiment that they gave me was, we don't really care about your data, we're a hardware vendor, right? And so as long as you're using our models or our hardware, we don't care what you put on it. So that's one thing to just pay attention to is, yes, you might be sending new kinds of data, but cloud data is not a new thing. Just make sure that when you talk to your vendors, that they understand that data is data, corporate data is corporate data. They're just giving you a new set of tools to interact with this stuff. One of the things that Satya Nadella talked about at the Microsoft Inspire keynote was that they're actually air gapping your data. Like if you send stuff to Bing Enterprise, it's air gapped from the rest of Bing, from the rest of their AI framework. And that air gapping is what you really need to pay attention to, to ensure that your data has integrity. There's also GDPR from the European Union. Any company that is GDPR compliant is almost certainly going to be more cognizant of data ownership and data governance. So those are kind of my two main points. Yeah, I think that one of the things that comes to my mind is when you build something based on your data, using their engine, you're taking actually all your data from your company about your clients, about what you know about them, data that was gathered maybe through years of working with very important topics for your company. And then you're saying, OK, I'm sharing. As if I'm sharing this data, the engine gets smarter, and my competitors could use my data in order to compete with me, right? And what you're saying, it's not so it's, it doesn't work this way. Not directly. However, to that point, one thing that a lot of people are coming to realize is that there's a lot of latent capabilities and a lot of latent content already baked into large language models and generative AI models. And so what I mean by that is that they are trained on all the data from on the internet, right, basically the entire internet today, which means that they have a lot of knowledge that could be secret knowledge or that you might think is yours. But because it has read, you know, thousands and thousands of, you know, millions of pages, billions of pages worth of text. It has these emergent capabilities to connect dots and solve problems that you feel might be super proprietary. And you can test these because sometimes it's like, okay, do you know how to do this? And the, and the, you know, chat GPT will either do it really well or just fail spectacularly. So there are some capabilities that are in there that that might feel proprietary or might feel like trade secrets. I had one client who was working on a particular kind of SEO. It was based on guidelines from his country. And so I they're like, how do we get it to do this? I'm like, just ask it. It's already it's already read all the SEO guidelines. And they're like, oh, well, that completely destroys our business model, because now they were no longer the gatekeepers of this special knowledge. But that allowed them to just, rather than focus on that problem, focus on more engaging, harder problems. Yeah, and I think that this is a very good use case that usually people think about what could be done with it, and then only the hard work is done through what is already known to Chachapiti or similar. And only the more creative, fun, innovative part needs to be added upon what is already there. Yep. Yeah. Like I said, sometimes it comes back to mission. Sometimes it comes back to special knowledge or special goals that you have. but the AI is just, right now, it's just a tool that's there to help you. They will be more autonomous soon. That's what I'm working on. But yeah, for now it's there. It's just a tool to help you go faster. Yeah. So if you're saying it's gonna change so many roles or professions, what do you think people would really do? Would they have new roles, new professions that we don't know of, or they will work less, they will have more free time? What do you think will be like five years from now? Yeah, so there's a little bit of a myth in that technology always creates more jobs, and that's an oversimplification. So if you look in the past, yes, technology has created more jobs, but not directly. What technology does is that it lowers the cost of goods and services, which allows you to spend money elsewhere, which then creates new jobs. And so, as I mentioned, we should expect new technologies, powerful new technologies, again, to lower costs. That's why we use them. And so then if those costs of our basic goods and services goes down, then the cost of food, housing, healthcare, law, whatever you need, hopefully will be going down, which means that you need to work less to get your needs met. But at the same time, if the demand for human labor goes down, then there's this offset, right? Because if you don't have a job, if you don't have money, you can't pay for anything anyways. And so what I call this, I call it post-labor economics, where whether or not all human jobs go away, we should expect that some, many, or maybe even most human jobs go away. And so what we're gonna have to do is we're gonna have to renegotiate the social contract. And so the social contract right now is you work for money, you get money, and then the money that you have gives you the ability to demand goods and services, and that's how the world goes around. But if you don't have a job, that entire social contract breaks down. So we're going to need a new one. And I don't know how it's going to look, but I'm just starting the conversation of we're going to need to be thinking long and hard about how this relationship between people, businesses, and governments change in the coming five to ten years and longer. Yeah. But do you really believe that the government will take care of us and give us a general income for anyone? And do we really want to trust them to give us what to eat? Yeah, you know, the fears of central management are pretty well founded, because throughout the 20th century, various countries around the world tried central management models, and sometimes it resulted in mass famine, sometimes it lowered the access of goods and services, and while some countries have single payer systems for health care that can, that can sometimes result in longer wait times and lower quality of care. So what I hope is that the, the cost of some of our basic needs will be so low that it won't really matter. And so what I mean by that is you don't pay for air, right? Air is so abundant that it's free. What I'm hoping is that other goods and services like internet and water and food and housing and healthcare becomes so cheap that it doesn't really need to be managed. Because right now in America, I think healthcare takes up like a third of our entire GDP, which is insane. It should not be that expensive. And so of course, when you have something that is that expensive, that is that scarce, you have to very carefully manage it. But what I'm hoping is that through implementing artificial intelligence and automation, we can lower the cost of all of those things until they don't need to be quite, so that they're not as contentious to manage, basically. And so then then if that's the case, then it's basically the government will probably just subsidize businesses. So rather than the government giving you money directly, that's one possibility, it'll probably happen or at least experiments will happen. What I also expect is that businesses that have their margins thin too much, they'll probably be subsidized by the government because we still need those services. And so then I suspect we'll see this hybrid model of neoliberalism where it's like, okay, let the business seek efficiency, but also then subsidize it so that it can stay afloat. That's kind of what I anticipate right now. But when I think about it, the money goes to the private sector, to companies like Microsoft, OpenAI, Google, so forth. So they would need to have some kind of taxation on the AI in order to get these revenues, right? Yeah, yeah. So whether there's, it's entirely possible that you don't need any special taxation. You just need to raise the marginal tax rate, particularly on tech companies. And then in order to offset the deflationary force from people losing jobs, you would probably then just have a redistributive policy, basically just taking money from one place and giving it to another in order to keep the economy churning. That's probably the simplest way and we already have models for this. For instance, we have subsidies. We know how those work. We know how negative tax incomes work. We know how unemployment insurance works. So basically, I think that what we're gonna see is an incremental development of these existing systems to accommodate the changing economic landscape. But I think we have the fundamental tools that we need to adapt the economy to a post-labor economic system. As we said, you're very optimistic. You mentioned that before. Yes. Okay, so how will AI impact the skills and education required for jobs in the future and the implication that it has on the workers and the employers? You know, the prevailing wisdom right now is that AI is not going to replace you, the person using AI is going to replace you. And so the number one thing is, in terms of school, education requirements and training, is learning to replace you. And so the number one thing is in terms of school education requirements and training is learning to use AI tools. That's the number one thing right now. Now some of the other projects that I've participated in or consulted on have to do with using AI to revolutionize education. And so one of the things that I'm really hopeful for is, so there's this problem, it's called Bloom's Two Sigma Problem. And most people haven't heard of this, but you know what it is. And everyone colloquially knows what this problem is. And that is that if you have private tutoring, you score way higher in your grades. Even if you're an average student, the value of having one-on-one mentoring and tutoring really takes you to the next level. And so one of the things that I hope to see is that AI is going to close that gap of Bloom's two sigma problem. So the idea is that if you have high-end tutoring, you score two standard deviations above what you otherwise would have, which is incredible. And so if we can use AI to close the gap, to really ratchet up the value of education that everyone gets, whether it's primary education or continuing education or grad school or whatever, I already use AI extensively. Anything new that I need to learn, I get on Perplexity and I search for the best articles and then I plug it all into chat GPT and Clawed and make sure that I understand these new topics. And I think that once everyone is doing that and once these tools are deployed widespread, people are going to be able to engage with learning in a different way. Now, you know, obviously that can help with your career, but it also just helps in life in general. The more access to information that you have, the better off you are, generally speaking. Yeah. I think that what you're saying is that it could close the gaps within society right now. Only the wealthy people are, they could use private tutors and teachers. And the people who don't have will have kids that will not have this benefit. And if everybody could get that, the the kids who are talented and wise, and they don't have the money, would still be able to get into the good schools and to get a good education and to get better jobs afterwards. Yeah. And it's not necessarily just jobs. Here's an example of, so I'm from the American South and we have rednecks here. There's rednecks all over the world. They're called different things. But part of redneck culture is that you have to be very self-reliant. And part of being self-reliant means you gotta know what you're doing. You gotta be able to fix your own house, fix your own car. You gotta be able to take care of whatever issues. And so this is why I mentioned that like AI can help with all aspects of life. We mentioned earlier about relationships, right? So just changing your orientation to learning rather than thinking of just school, getting comfortable with upskilling yourself for whatever you need. You know, younger generations are pretty comfortable with this. It's weird, they actually do most of their learning on TikTok today. So kids these days, they come up with the craziest ideas. Yeah, but what you're saying gets me to think about another thing. We're saying as if the educational system is as is and you get a better way to do the education system. But actually all the system would change in a way that will not be these are the subjects you need to know, these are the tests you need to go through, these are like the SATs and so forth in order to get what you need. I guess that all the system would be redefined in a sense because there is no real meaning in order to just rethink and memorize information, I guess. Yeah. Yeah. So one way that you can think about education or learning is there's kind of three pillars. There's competencies, there's skills and knowledge. So competency is like, are you competent at learning, at education, at educating yourself? Do you, are you competent, you know, with particular domains? And then skills are like communication skills, studying skills, project management skills. And then skills are like communication skills, studying skills, project management skills. And then knowledge is just the content. What are the facts and figures that you have memorized? And so if you think of education as those three pillars, one, that's a very simple model, but it's also easy to see how AI can help with each of those, right? If I'm learning something, sometimes I'll tell like the chatbot, like, all right, quiz me on this thing, test how much I know, right? So you're testing for knowledge and then you can also test for skills. Like, did I figure this thing out right? Am I competent on this subject? And so that can really, really like just completely revolutionize our approach to education across the board. Yeah. Yeah. So we have a question from Yasha. Hi, Yasha. When will it be the norm that employers hire staff that studied AI as a prerequisite educational component? I think that we're starting to see it. If you go out on the job boards, you'll see we're just starting to see a surge in prompt engineers. And some prompt engineering jobs pay $300,000 a year. So I could be doing that job because I led the charge on this. But what they have said is they're like, one job description, I think it was at Claude, actually. They said, we understand that this is an entirely new discipline, so you're not going to be able to have more than two years of experience because this job did not exist two years ago. With that being said, as we, we, we traverse the, the bell curve of adoption, we're right now just approaching the, the, the leading edge, the innovators. We're not quite at the early majority of adoption. But within the next maybe 5 years, we should see the early majority. And so you're gonna see this huge demand. So story time at the beginning, sorry, at the beginning of my IT career, we were at the adoption curve of like Windows servers and VMware virtualization and then cloud. And so the demand for those skills went up so fast that it was just like, if you've got the baseline, then it's like promotion, just left and right. Like I changed job every 18 months and doubled my salary in two or three years. And I think we're gonna see the same trend with any AI skills. If you're already up to speed on prompt engineering and cognitive architectures and chat bots and whatever else, then you're gonna see a huge demand for those job skills or AI product, right? Just knowing how to implement and deploy AI into services. So yeah, I don't know if that directly answered your question, but that's kind of where I see things going. Yeah. Yeah. Thanks for everyone who's asking questions, and I'll show you too. So we're starting to think about the future of the automation of AI. And I want to ask you, what are the potential implications of artificial general intelligence on the future? So first, describe what the meaning of that, and then what would be the implications? Yeah, so well, first, we have to say that definitions of AGI, or artificial general intelligence, vary widely. Some people assume that it means that one machine is smarter than all humans combined forever. Some people say that it's just as smart as one person, and many definitions are somewhere in between. But basically, AGI is somewhere as intelligent as people, and then higher. One thing that I think would probably surprise people is that on a personal level, I don't think AGI is gonna change that much for individuals, at least not at first. And the reason is because the collective rest of humanity is smarter than you. So we're already used to living in a world where there's a lot more intelligence than ourselves. And so with that in mind, what AGI is gonna change in the long run is alleviating that scarcity of intellectual labor. So as we mentioned before, there's a shortage of doctors, lawyers, scientists, engineers. And so, you know, one of the biggest things that companies worry about and nations worry about is brain drain. If the experts leave, then you have to replace them with really expensive labor. But if everyone can have an in-house expert, then there's gonna be like zero shortage of expert knowledge and capacity. And that's really going to accelerate the global GDP, global economy, like we've never seen before. And I know that's hyperbole, but like, you know, GDP over the last century went up by a thousand fold. We're going to see GDP go up by a million fold in the next century, just because of alleviating those, the scarcity, the bottlenecks of human labor. So how that's going to play out, like I said, I think the biggest thing that you're going to feel as an individual is that the cost of necessary goods and services is going to go down a lot. That's what it looks like and feels like to you on an individual level when AGI happens and the cost, basically the price has collapsed of a lot of things. I hope that's what happens. So what is the big difference between what we have right now and this future capability? What is lacking for us in order to get there? There's a few things. One is autonomy. So again, one of the research, one of the topics that I research is how do you build machines that are fully autonomous and trustworthy? And so right now they're waiting for humans, right? If you have, if you hypothetically had chat GPT solving problems all day long without any human guidance, it could go way faster. But right now it's constrained by our speed, which we're very slow. It's also constrained by our creativity. We don't even know the right questions to ask. So part of creating autonomous machines is getting them to ask themselves the right questions and getting them to set the correct objectives for themselves so that they can do the research and do the work without any human intervention and so that they can do it safely and reliably. That is probably one of the primary things because right now already tools like ChatGPT and Claude already know more than you or I do on an individual basis. But getting that information out and then kind of setting it loose, right? Taking the leash off the dog so that, you know, but you don't want to do that if the dog is not well-trained, right? So that's where we're at right now is how do you train these digital animals so that they don't attack your neighbor or run away or whatever? So, but once that happens, you know, it's all bets are off, basically. But don't you think that that we need to involve some kind of common sense, morality, what we think about values in life in order to decide what is the direction? I guess that this is something that we're supposed to have as humans, I guess. Yeah, you know, and that's a great question. And that's actually been a primary area of my own learning and research over the last almost four years now, is learning how do humans develop morality? How do we develop values and ethics? Where does it come from? Why does it even happen in the first place? And so one of the things that that kind of a pattern that emerged is that there's a few main things that morality and ethics and values evolve around, or emerge from. One is social cohesion, right? That's why we have crime and law. It's basically, in the old times, human tribes, we had two basic impulses to when someone transgressed against the tribe. And that was you punish them to get them to stop whatever bad behavior it was, or you eject them. You send them out of the tribe, you banish them for good. And we have systemized that with prisons today because the idea of prisons is you're too dangerous for society, but we can't send you to Australia. Australia is a nation now, right? That's what the did, is they just banished people they didn't like to Australia. With Siberia, if you were. Right, right. Australia, Siberia, or wherever. You can't banish people anymore. The entire world is spoken for. So now we have prisons, and prisons is the modern equivalent of exiling someone or banishing them from the tribe, or punishing them for behavior you don't like. But looking at the first principles, why does this happen as an animal, as a species, is one area of research. Another is hygiene, actually. Hygiene and resource allocation are another big set of pillars that morality and ethics evolve around. Whether it's like sexual hygiene or scarce resources, like around food, for instance, or water. Anytime resources are scarce, that's where you see a lot of legislation and morality and ethics evolving around. And so those are just some examples. But honestly, one of the simplest things is appealing to universal frameworks. So after World War II, one of the things that we did was we came together, and we created what's called the Universal Declaration of Human Rights, the UDHR. And it is a list of 30 principles. It's not a constitution, it's just a list of 30 principles that all nations should aspire to uphold and reinforce. And this UDHR is all the language models already know it, you can go on a chat, GPT, or Claude, or, you know, whatever, all of them right now and ask them, what is UDHR? And how would you implement it? And this is a really powerful framework that can that can, it doesn't necessarily steer autonomy, but it creates really good boundaries of what to do and what not to do. So yeah, this is an active area of research. And all the experiments that I've done, like I said, there's papers coming out that I'm participating in. And I think that we're going to really demonstrate that there's really powerful sociological, philosophical, moral, and ethical frameworks that already exist, that all we need to do is just implement them systematically into these AI systems. And at least they'll understand what we need. Whether or not the AI machines decide to abide by them in the long run, that's another problem. But I'm not too worried about that one either. Yeah. It reminds me of the rules from Asimov book that you give for robots. I guess that it is fires from there. So we have another question from Daniel. David, during your previous discussion on AGI and your YouTube channel, you projected an 18 month timeframe. Are we still within that estimation? So first tell us what is the estimation and then you tell us if we're within that. Yeah, yeah. So for context, it was March or April of this year, I made a video on my YouTube channel and I said, AGI within 18 months, here's a bunch of projects and papers to back up that claim. Excuse me. And it was one of my most popular videos of all time. And since then, we've had basically on a daily basis, there are at least 50 new AI papers that come out literally every day of the week. On top of that, there's a lot more business investment, there's a lot more competitors, Microsoft OpenAI, Clawed, Google DeepMind, there's conversations on the national level and international level about AI research, the US Congress, EU, UN, literally everyone is paying attention to AI. And so we're at this really powerful inflection point where people are aware of what's happening, they're investing in it, so follow the money, right? If the, where the money goes, results follow. And the business incentive to do it is there. And all of the conversations that to do it is there. And all of the conversations that I've had with business leaders, there is a lot of interest in literally every sector of the economy to make AI happen and to and to take it to whatever degree it can. And that's actually part of my mission is to help businesses understand how to implement AI safely and productively. And so just because of the economic incentive to get to AGI, yes, it will happen by the end of 2024. Arguably, you could say that it's happening right now. It's just how smart is it and how fast is it and how cheap is it? So it'll get smarter, faster and cheaper over the next 12 to 16 months. Yeah, I see. We're going back to the fact that you're very pro AI and you're very optimistic and you think the risks are not as huge as people might think. So how would you explain all the people are saying that we need to be aware and to get all the regulations and it could destroy us. It's like the atomic bomb, so forth. How do you relate to these claims? Well, so I'm glad you used the race car analogy because race cars have two pedals. They have gas and they also have brakes. You can't win the race without brakes. If all you have is gas, you go into the wall. And so regulations and research and checks and licensing and all that other kind of fun stuff, those are all part of the wall. And so regulations and research and checks and licensing and all that other kind of fun stuff, those are all part of the process. You need gas and you need brakes. And so in this case, the analogy of gas is you accelerate, you deploy AI, you research AI. But at the same time, you have brakes that kind of slow things down to make sure that you have control, because that's why you have braking systems in cars, in race make sure that you have control. Because that's why you have braking systems in cars, in race cars, is to maintain control. Because if you have too much inertia, too much momentum carrying you in one direction, you lose control. And so if you need to change direction, you need to slow down, and then you change direction. That's literally driving. If you're going too fast around a curve, you drive off the road. So what you do is you slow down to make sure that you can maintain control and change direction as needed. On the other side, there's people that are worried about slowing down too much, because obviously, the slower you're going, the safer you are. This is a principle that I abide by, which is I prefer to keep my body at low kinetic energy, because high kinetic energy, like skiing, is how you get hurt, or motorcycles or whatever. And so, yeah, so lower energy is always safer. So the idea is balancing safety versus getting there, right? Because we don't want it to take 10,000 years to get there. We want to get there as soon as possible, but we also want to get there as safely as possible. So that's kind of the dichotomy. And while I am optimistic and I am for acceleration, I am also very much in favor of control, safety, stability, and steering correctly. It's all about steering. So steering equals regulation? How do you see the steering? They're slowing down. That's a good question. So steering, it's what are you steering towards, right? Because whenever you get in a car, you're trying to get somewhere. And so knowing where you're going is what you're steering towards. And you have to go around obstacles. You have to make sure that you don't drive in the ditch. And if, you know, if there's a detour, you'd go around the detour. And so one of the conversations that we're having, and when I say we, I mean like all of us on YouTube and the researchers and stuff, the conversation that we're having is and when I say we, I mean like, all of us on YouTube and the researchers and stuff. The conversation that we're having is, what are we steering towards? What is the outcome that we're looking for? And there's not really any consensus yet, but the message that I have is that, is that my mission is that we're steering towards what I call utopia. And so utopia is a very loaded term, but I define utopia as high standard of living for everyone, high social mobility for everyone, and high individual liberty for everyone. And so if we get to a point, if we agree that that is the direction that everyone wants to go, then once everyone agrees that's the destination, we can chart a course and we can steer towards that. And it's not just AI, it's economics, it's all technology, it's government, literally everything orbits around what is the destination, what is the mission we're trying to achieve, and that's how you steer towards it. But right now, there's not really any agreement on where we're going, and that's part of the reason that politics is so nasty right now. That's part of the reason that there's wars and stuff, because humans, by and large, can't agree on which direction to go or how to get there. Yeah, and what do you think about the meeting between Biden and all of the head of AI that they've done? Do you think that they would agree with that kind? I'm not sure if this is the direction that they're considering. What do you think? Well, I don't always agree with what some of the tech leaders say or do, but sometimes I do. And Sam Altman has talked a lot about how he believes that technology is the primary thing that increases quality of life for people. And I tend to agree with that because 200 years ago, before modern medicine, I would have been dead like five times over by now. I would not be alive as 37 years old in 200 years ago. And so, as 37 years old in 200 years ago. And so I also wouldn't have a lot of the cool games and toys and experiences because also I wouldn't have been able to travel to France and Canada and everywhere else that I've been because jet airliners didn't exist 200 years ago, unless I was really wealthy, but even then it would have taken three months to travel. So technology does, I think there is general consensus that technology improves the quality of life for people, or it can, again, it's dual use. At the same time, technology can increase prosperity, which is what businesses want. Another aspect, and this is the government's interest, is that, you know, because governments are trying to optimize for a few things. They want to increase their GDP. They also want to increase their geopolitical power, their ability to project power, and their military power. AI can help with all of those. And so, there's a lot of alignment of incentives between us individuals, businesses, and governments. And so, I see those as kind of the three pillars of society. And if we can align all of our interests together, say, yes, we all want to be safer. we all want to have more technology that can help our way of life, we all want to have more economic productivity, if we can agree on all those things, then yes, we can move in the right direction. Now, the wrench in the gears might be that some people want to stack the deck in their favor, And that's one thing that people are worried about right now. And so one of the ways that that could happen is called regulatory capture, where basically businesses try and get an enforced monopoly by manipulating government policy. So that's one of the biggest things we need to worry about. And this is true for all new technologies. It's not just AI. Regulatory capture, they did that for a while with radio frequencies, actually, where nobody was allowed to, unless you paid the government a lot of money, you'd get your radio station shut down. Now over, of course, radio stations have been around for decades, more than a hundred years now. Now we understand how to make sure that it's done fairly. Some of the meetings that business leaders have had with Congress, US Congress, have talked about how to do that correctly and fairly, and they pointed to the failures that we had around the internet, namely around social media and other harms that have been done. And so this is why politicians today are paying a little bit more attention to this new technology, because the idea, the prevailing idea in the 90s and early 2000s was government non-interference, particularly in America. Europe is usually a little bit more progressive, but it was like, let the private industry figure it out for itself, but that didn't go well. So now we're gonna see a little bit more. You're right, now we're gonna see a little bit more government oversight, but we gotta make sure that all the right voices are at the table, not just the tech leaders. We need to make sure that the voices of academics and you and me and that private citizens, that our interests are represented at the highest levels as well. Good question. Yeah. I don't know if that could be done. I feel that powerful men get more powerful through private sector or politics or whatever. And I feel that what you're describing is the other way around, meaning the power would go down and be equal, more equal and more available and accessible for people. And for me, when I think about the fearful side, I think about these huge enterprises getting much, much bigger and having more and more control over our lives. Yeah. Maybe you're right. Well, so you're right, though, because power begets more power, right? The more money you have, the more influence you have, the more you can consolidate it. We've seen this many times through history. This actually, the first, one of the first times this really happened in a big way that caused the collapse of society or contributed to the collapse of society was in ancient Rome. So in ancient Rome, wealthy landowners used the wealth of their land to buy more land. And guess what? The more land they had, the more wealth they had, which means that they could strong arm and get more land. And so eventually, in ancient Rome, most of the valuable land was owned by a very few number of people, which completely made the Roman economy lopsided. Now that didn't single-handedly cause the collapse of Rome, but it certainly contributed because then society was less and less fair. And so this goes back to, okay, well what is fair? And so there's this policy that I'm working on and brainstorming, I call it the Fair Deal. It's inspired by the New Deal from FDR in America in the past and the Square Deal by Teddy Roosevelt in the past. So the fair deal is about, let's have a not just a national conversation, but a global conversation about fairness. What is fair to businesses? What is fair to governments? But most importantly, what's fair to us? And that goes back to renegotiating that social contract that I mentioned, which is, what is the relationship and responsibilities of government, business, and voters or citizens? And so renegotiating that is one of the most important conversations. And like I said, I don't think it needs to be just a national conversation. I think it needs to be a global conversation of all citizens, of all nations, and between all nations around the world. Because AI is going to really, really disrupt the status quo. It's going to upset the apple cart. And so we have an opportunity to move society to be more fair. But of course, we have to decide, OK, what does fair mean? What does that look like? And that is an opportunity that we could miss. And so, you know, as optimistic as I am, I see a lot of potential for it to go well. It could also go poorly if we fail to step up and say, you know, we're going to participate in making sure that this is more fair moving forward. So stay tuned. I'll have more information about the fair deal idea coming in the future. In your YouTube channel? Yes, correct. Okay. So we're almost done with time. It's been fascinating. I hope we will have another discussion, David. It's been very, very interesting for me and for the viewers. So let's finish with the last question that I have. What is your number one tip for entrepreneurs today? Oh, boy. If you're just getting started on an AI startup, double down on the experience and expertise you already have. And the reason that I say that is because generative AI has given a lot of people the ability to pick low-hanging fruit outside of their areas of expertise. people the ability to pick low hanging fruit outside of their areas of expertise, all the low hanging fruit is gone. So I can't remember her name right now. The former CEO of Yahoo, she said that... Myers? Yeah, yeah, yeah, yeah. She said that we're going to have a whole crop of failed startups. It's going to burn through the startup area like a wildfire, but what's left is going to be the startups that were stronger. And one thing that I've noticed about all of my clients, the ones that are doing the best, is that they are bringing pre-existing experience and expertise to the table, and they're just adding generative AI to their toolbox. So what I caution people against doing right now is don't get into another domain that you have no business in, because you you have come to the false belief that just because it's easy to do on chat GPT, you can build a company around it. So really focus on the like, if you've got 20 years of experience in something, use that I have, there's a friend of mine, he lives just up the road. His background is in gaming and VR. And he tried to do all kinds and something, use that. There's a friend of mine, he lives just up the road. His background is in gaming and VR, and he tried to do all kinds of other stuff with AI. I'm like, no, focus on gaming and VR, because you already have a decade of experience with this. This will just turn it up faster. So that's the primary tip that I give to pretty much anyone, clients or otherwise, for entrepreneurs today with generative AI. Yeah, I totally agree with what you're saying. You know, I'm creating a course on creating AI products and I always like try to focus on that's the technology, but the idea and the value that you bring is much more important than technologies. This is just a tool to deliver what you want to deliver in the services or products that you really need to build. So- Exactly, yep. 100% agree. Okay, so first I want to thank you for your time. It's been very insightful, interesting talk for me and for the viewers. So thank you, David, for your time. You're welcome. And last thing, where could people hear more about your YouTube channel and contact you? Yeah, so my primary platform is obviously YouTube. Just search for David Shapiro AI, I come right up. I'm also on Patreon if people want one-on-one conversations or consultations, just sign up on my Patreon. And then also LinkedIn. Primarily what I'm looking for on LinkedIn is policy and research connections. So if you're in the university system or the government system, and you wanna collaborate on either cognitive architectures or the fair deal, that kind of stuff, reach out to me on LinkedIn. But otherwise YouTube and Patreon are the primary ways for most people to connect. So I really encourage people to do all of that. So thank you, David, again for your time. And I'm sure we're going to have another discussion if you'll be willing to do so. Yeah, hit me up whenever. Looking forward to it. Sure. Thanks. And to all you changemakers out there, thank you for joining us. See you another week. Bye-bye. See you another week. Bye-bye.", "chunks": [{"timestamp": [0.0, 8.0], "text": " Welcome to the Invincible Innovation Show, the podcast for changemakers."}, {"timestamp": [8.0, 15.0], "text": " Hey, everyone, I'm so happy to see you with me."}, {"timestamp": [15.0, 17.68], "text": " Welcome, ladies and gentlemen."}, {"timestamp": [17.68, 21.52], "text": " We have an extraordinary episode in Invincible Innovation today."}, {"timestamp": [21.52, 25.56], "text": " I'm your host, Adima Zolrior, product design and AI expert."}, {"timestamp": [25.56, 28.7], "text": " And in this episode, I have the pleasure of speaking"}, {"timestamp": [28.7, 31.76], "text": " with an AI researcher who will share his insight"}, {"timestamp": [31.76, 35.02], "text": " on the role of AI and the workforce,"}, {"timestamp": [35.02, 37.48], "text": " its positive and negative implication"}, {"timestamp": [37.48, 39.32], "text": " and the impact on humanity."}, {"timestamp": [39.32, 42.8], "text": " Join us as we delve into the fascinating world of AI"}, {"timestamp": [42.8, 46.48], "text": " and uncover how it is shaping the future of work."}, {"timestamp": [46.48, 48.32], "text": " So, hi David."}, {"timestamp": [49.16, 50.76], "text": " Hello, thanks for having me."}, {"timestamp": [50.76, 51.96], "text": " Good to be here."}, {"timestamp": [51.96, 53.28], "text": " So happy that you're here."}, {"timestamp": [53.28, 56.36], "text": " David is the AI thought leader and researcher"}, {"timestamp": [56.36, 58.92], "text": " and gonna have a really fascinating talk."}, {"timestamp": [58.92, 60.92], "text": " We're live on LinkedIn, YouTube, and Facebook"}, {"timestamp": [60.92, 63.0], "text": " and you're so invited to join the discussion"}, {"timestamp": [63.0, 64.66], "text": " and ask questions."}, {"timestamp": [64.66, 65.36], "text": " So let's start."}, {"timestamp": [66.0, 70.16], "text": " So how do you think really AI will really change the nature of work?"}, {"timestamp": [72.32, 78.24], "text": " Yeah, I mean, you know, that's a great place to start. So one thing that I kind of have this"}, {"timestamp": [78.24, 83.36], "text": " mantra that I use to kind of tell people what I expect is going to happen, and that is that,"}, {"timestamp": [82.76, 85.92], "text": " tell people what I expect is going to happen. And that is that, you know, AI is,"}, {"timestamp": [85.92, 88.92], "text": " it has the potential to be better, faster, and cheaper"}, {"timestamp": [88.92, 90.8], "text": " than human labor in a lot of ways."}, {"timestamp": [90.8, 92.04], "text": " So better, faster, cheaper."}, {"timestamp": [92.04, 92.88], "text": " Like that's, I mean,"}, {"timestamp": [92.88, 94.6], "text": " that's why we implement technology anyways, right?"}, {"timestamp": [94.6, 96.88], "text": " That's why we have printers instead of typewriters."}, {"timestamp": [96.88, 98.9], "text": " That's why we have databases instead of, you know,"}, {"timestamp": [98.9, 100.8], "text": " filing cabinets."}, {"timestamp": [100.8, 103.64], "text": " But with the, the primary difference with AI"}, {"timestamp": [103.64, 105.68], "text": " is that it has the ability to think."}, {"timestamp": [105.68, 109.04], "text": " So Satya Nadella, the CEO of Microsoft,"}, {"timestamp": [109.04, 112.06], "text": " during the Microsoft Inspire keynote speech said that,"}, {"timestamp": [112.06, 115.18], "text": " one way to think about generative AI is that it's a reasoning engine,"}, {"timestamp": [115.18, 117.36], "text": " and it's only going to get better from here."}, {"timestamp": [117.36, 121.6], "text": " So it's really going to drastically change our relationship to work,"}, {"timestamp": [121.6, 124.72], "text": " who does work, what kind of work, and that sort of thing."}, {"timestamp": [124.72, 130.26], "text": " So the rule of thumb that I have arrived at to kind of figure out like, okay, well,"}, {"timestamp": [130.26, 131.56], "text": " what are humans going to do?"}, {"timestamp": [131.56, 133.48], "text": " What are you and I going to do?"}, {"timestamp": [133.48, 137.22], "text": " And what I came to, what I realized is that you have to look at the demand side rather"}, {"timestamp": [137.22, 140.36], "text": " than the supply side or the capacity side."}, {"timestamp": [140.36, 146.24], "text": " And so if machines are capable of doing thought labor and physical labor better, faster and cheaper than humans,"}, {"timestamp": [146.24, 151.44], "text": " then you have to look at what are other humans willing to pay for, for another person to do."}, {"timestamp": [151.44, 156.96], "text": " And so then that's why I think that you see the rise of streamers and YouTube content creators."}, {"timestamp": [156.96, 163.56], "text": " And I think that we're also going to see demand for human labor in anything that's kind of intrinsically emotional or social,"}, {"timestamp": [163.56, 167.8], "text": " as kind of the way that we're going to change our relationship to work."}, {"timestamp": [167.8, 169.6], "text": " Of course, there's a lot more to unpack there,"}, {"timestamp": [169.6, 171.8], "text": " but that's kind of the high-level overview."}, {"timestamp": [171.8, 176.7], "text": " Yeah, but what comes to me when I think about the change in the workforce"}, {"timestamp": [176.7, 179.2], "text": " is the fact that most people thought about like,"}, {"timestamp": [179.2, 182.9], "text": " yeah, we're going to have like cars driving without drivers"}, {"timestamp": [182.9, 187.52], "text": " and maybe in the supermarkets we would not have anyone doing the"}, {"timestamp": [188.32, 193.84], "text": " cashing and everything. But right now I think that most people understand that even very"}, {"timestamp": [193.84, 202.72], "text": " sophisticated jobs like lawyers and copywriters and things that, and doctors of course, that"}, {"timestamp": [202.72, 207.04], "text": " demand so much of us could be done by a machine,"}, {"timestamp": [207.04, 209.92], "text": " which is a very sophisticated machine."}, {"timestamp": [209.92, 210.88], "text": " Yes."}, {"timestamp": [210.88, 214.24], "text": " Yeah, you know, so there's still a scarcity mentality"}, {"timestamp": [214.24, 216.5], "text": " around some of those professions, right?"}, {"timestamp": [216.5, 219.06], "text": " This is the reason that doctors and lawyers are so expensive."}, {"timestamp": [219.06, 222.04], "text": " They're highly educated professionals, you know,"}, {"timestamp": [222.04, 225.64], "text": " that requires a lot of school and a lot of experience."}, {"timestamp": [225.64, 231.1], "text": " And it will be a while before machines are even capable of displacing those jobs."}, {"timestamp": [231.1, 236.24], "text": " But one thing that I was on another podcast, and I was brainstorming ideas, just kind of"}, {"timestamp": [236.24, 241.04], "text": " as we were talking through, and I realized that 20 years from now, we might not have"}, {"timestamp": [241.04, 243.08], "text": " hospitals anymore."}, {"timestamp": [243.08, 246.56], "text": " Because the combination of AI and telemedicine and and"}, {"timestamp": [247.08, 252.5], "text": " You know rejuvenation therapies might mean that even just the need for hospitals goes away"}, {"timestamp": [252.5, 258.76], "text": " So the the potential for change the way that we get the need that our needs met whether it's food or medical care or whatever"}, {"timestamp": [258.76, 259.36], "text": " a"}, {"timestamp": [259.36, 263.8], "text": " lot of these technologies have the possibility of really driving down the costs of"}, {"timestamp": [263.94, 270.64], "text": " Some of the basic services and goods that we need. So yeah, absolutely. Again, this is speculation."}, {"timestamp": [270.64, 274.56], "text": " We don't know how it's going to play out or when, but it is hypothetically possible."}, {"timestamp": [274.56, 281.2], "text": " Yeah. I think that if we're taking doctors, for example, it makes sense that we have a"}, {"timestamp": [281.2, 288.66], "text": " definition which is like, first is analyzing your problem, what is like,"}, {"timestamp": [288.66, 293.9], "text": " what is going on with you, and then treating you. And sometimes treatment defines, it needs"}, {"timestamp": [293.9, 299.28], "text": " something else than just understanding. It needs, of course, the capabilities to work"}, {"timestamp": [299.28, 307.22], "text": " with a human and to do certain procedures. And it's a bit different than just defining what needs to be done."}, {"timestamp": [307.22, 313.04], "text": " And I think that maybe doctors would have different level of interacting with AI, but"}, {"timestamp": [313.04, 318.74], "text": " if we were thinking about advisor like legal advisor, lawyers, or consultants, or financial"}, {"timestamp": [318.74, 323.84], "text": " consultants and so forth, the majority of the work is just understanding and analyzing"}, {"timestamp": [323.84, 326.24], "text": " the data, right?"}, {"timestamp": [328.36, 330.96], "text": " Yeah, so one of my clients is, I actually have several clients that are physicians"}, {"timestamp": [330.96, 333.0], "text": " or former clients that are physicians"}, {"timestamp": [333.0, 334.96], "text": " or in the medical field."}, {"timestamp": [334.96, 336.88], "text": " And one of the things that one of them said"}, {"timestamp": [336.88, 338.2], "text": " is that he wonders,"}, {"timestamp": [338.2, 340.42], "text": " and this is not necessarily a prediction,"}, {"timestamp": [340.42, 343.64], "text": " but he just wonders if the current school,"}, {"timestamp": [343.64, 345.52], "text": " like medical school of doctors,"}, {"timestamp": [345.52, 348.88], "text": " are gonna be like the last classically trained doctors."}, {"timestamp": [348.88, 351.68], "text": " Because as AI becomes more powerful"}, {"timestamp": [351.68, 354.16], "text": " and it becomes part of the diagnostic tool,"}, {"timestamp": [354.16, 356.28], "text": " it becomes part of the treatment plan,"}, {"timestamp": [356.28, 359.56], "text": " it becomes part of the patient management platforms,"}, {"timestamp": [359.56, 362.88], "text": " then what doctors need to learn in the future"}, {"timestamp": [362.88, 364.36], "text": " might be very different."}, {"timestamp": [364.36, 367.0], "text": " And we're already seeing this with medical imaging"}, {"timestamp": [367.0, 369.1], "text": " because obviously we have the ability"}, {"timestamp": [369.1, 371.28], "text": " to feed images into AI today,"}, {"timestamp": [371.28, 374.0], "text": " and you can generate images, you can analyze them."}, {"timestamp": [374.0, 376.04], "text": " And in many cases, it's not universal,"}, {"timestamp": [376.04, 378.56], "text": " but we're getting pretty close pretty quickly."}, {"timestamp": [378.56, 380.96], "text": " In many cases, machines are better"}, {"timestamp": [380.96, 383.2], "text": " at reading medical images than humans."}, {"timestamp": [383.2, 386.12], "text": " So if that's the case, it would actually be unethical"}, {"timestamp": [386.12, 387.56], "text": " to use humans to do that job"}, {"timestamp": [387.56, 389.56], "text": " because they have worse outcomes."}, {"timestamp": [389.56, 392.32], "text": " Now, if that happens for other professions,"}, {"timestamp": [392.32, 394.24], "text": " lawyers, doctors, drivers, whatever,"}, {"timestamp": [394.24, 396.88], "text": " if the machines become better than humans,"}, {"timestamp": [396.88, 399.96], "text": " then we would actually have an ethical obligation,"}, {"timestamp": [399.96, 401.72], "text": " arguably an ethical obligation,"}, {"timestamp": [401.72, 404.0], "text": " to move to machines to do these things."}, {"timestamp": [404.0, 406.48], "text": " So that's another kind of way to look at it is,"}, {"timestamp": [406.48, 408.96], "text": " okay, if it provides better outcomes,"}, {"timestamp": [408.96, 411.64], "text": " what is our moral duty there?"}, {"timestamp": [411.64, 415.32], "text": " Yeah, and one of my recent guests was,"}, {"timestamp": [415.32, 417.88], "text": " we talked about AI in the military,"}, {"timestamp": [417.88, 420.92], "text": " which is kind of obvious that you could use a machine"}, {"timestamp": [420.92, 426.08], "text": " or a robot to do risky tasks instead of using a human being,"}, {"timestamp": [426.08, 429.92], "text": " which is something that we should consider, I guess."}, {"timestamp": [429.92, 430.84], "text": " Oh yeah."}, {"timestamp": [430.84, 434.52], "text": " Yeah, you know, de-risking things is another example"}, {"timestamp": [434.52, 438.42], "text": " of using AI, but of course, if you use AI too soon"}, {"timestamp": [438.42, 441.7], "text": " or use it wrong, you can actually increase risks."}, {"timestamp": [441.7, 444.76], "text": " And so there's lots of talks on both sides of that, right?"}, {"timestamp": [444.76, 446.04], "text": " Is AI gonna kill everyone?"}, {"timestamp": [446.04, 447.58], "text": " Is it gonna save everyone?"}, {"timestamp": [447.58, 448.78], "text": " And of course it depends."}, {"timestamp": [448.78, 451.42], "text": " It depends on how you use it, just like any technology,"}, {"timestamp": [451.42, 453.2], "text": " right, like whether it's nuclear technology"}, {"timestamp": [453.2, 455.98], "text": " or synthetic biology, all of these technologies"}, {"timestamp": [455.98, 458.02], "text": " have the capacity for doing a lot of good"}, {"timestamp": [458.02, 459.26], "text": " and a lot of harm."}, {"timestamp": [459.26, 460.96], "text": " So I always remind people they are,"}, {"timestamp": [460.96, 463.34], "text": " like this is a dual use technology."}, {"timestamp": [463.34, 465.84], "text": " Like, you know, you don't give a really sharp knife"}, {"timestamp": [465.84, 466.84], "text": " to a toddler."}, {"timestamp": [466.84, 468.88], "text": " Likewise, you have to make sure that the safety"}, {"timestamp": [468.88, 472.48], "text": " and the training wheels are on for now with AI."}, {"timestamp": [472.48, 475.4], "text": " So we talked about the changing workforce"}, {"timestamp": [475.4, 478.44], "text": " and we have a question from one of our viewers in LinkedIn."}, {"timestamp": [478.44, 482.88], "text": " So what core competencies will be in need?"}, {"timestamp": [482.88, 485.28], "text": " So what do you think is really needed? Thank you."}, {"timestamp": [485.28, 489.76], "text": " Yeah, that's a great question. Yeah, yeah, that's a great question. So, you know,"}, {"timestamp": [490.64, 495.28], "text": " if you listen to Harvard Business Review or any of the like kind of modern business theory,"}, {"timestamp": [496.24, 502.56], "text": " emotional intelligence and communication skills are all the rage, whether it's all the soft skills"}, {"timestamp": [503.28, 505.4], "text": " are increasingly important in the business world."}, {"timestamp": [505.4, 508.2], "text": " And that's been a trend for at least the last decade or two."}, {"timestamp": [508.2, 512.5], "text": " The recognition of emotional intelligence being critical, but also communication."}, {"timestamp": [512.5, 516.3], "text": " The ability to express yourself is critical."}, {"timestamp": [516.3, 518.0], "text": " And this is not just in the business world."}, {"timestamp": [518.0, 524.0], "text": " One thing that I realized is that every lesson that I learned about interpersonal communication"}, {"timestamp": [524.0, 529.2], "text": " and emotional intelligence for like, you know, working on my marriage also directly applied to work."}, {"timestamp": [529.84, 535.72], "text": " And every lesson that I learned about communication at work also directly apply applied to my personal life."}, {"timestamp": [536.12, 539.88], "text": " And so these are just universal skills that all humans can benefit from."}, {"timestamp": [540.2, 543.12], "text": " And it does take time and practice, right, you know, like,"}, {"timestamp": [542.56, 549.88], "text": " And it does take time and practice, right? You know, like I've had guests on other podcasts that weren't as well spoken or weren't as confident in their speaking"}, {"timestamp": [550.32, 555.28], "text": " Or or maybe not as self-aware or whatever and this is not not a criticism of anyone"}, {"timestamp": [555.28, 559.12], "text": " It's just an observation that there are differences in ability"}, {"timestamp": [559.56, 562.32], "text": " And and filling in those gaps as best you can"}, {"timestamp": [562.56, 565.06], "text": " Will really be a big difference"}, {"timestamp": [565.06, 566.32], "text": " for a lot of people moving forward."}, {"timestamp": [566.32, 568.24], "text": " Because if you can express your fears,"}, {"timestamp": [568.24, 571.64], "text": " or your needs, or your strengths, or whatever it is,"}, {"timestamp": [571.64, 574.84], "text": " if you can connect with other humans better,"}, {"timestamp": [574.84, 577.36], "text": " that will serve you in every aspect of life,"}, {"timestamp": [577.36, 579.06], "text": " work or otherwise."}, {"timestamp": [579.06, 582.04], "text": " Yeah, but when I think about what you're saying,"}, {"timestamp": [582.04, 584.36], "text": " we already know that there are like these"}, {"timestamp": [585.6, 591.12], "text": " chats that you could have with an entity, which is an AI, like in Replica, for example,"}, {"timestamp": [591.12, 597.52], "text": " and you could really communicate with these machines, which are like, you see an avatar,"}, {"timestamp": [597.52, 606.28], "text": " you could choose how he or she would look like, and people are really getting attached to these entities, actually, right?"}, {"timestamp": [606.28, 608.84], "text": " So maybe what we think about communication"}, {"timestamp": [608.84, 611.24], "text": " and about connection is gonna change, too."}, {"timestamp": [612.24, 614.16], "text": " Yeah, no, that's an interesting point."}, {"timestamp": [614.16, 616.56], "text": " And certainly, it kind of breaks both ways,"}, {"timestamp": [616.56, 618.78], "text": " because there are people that find the idea"}, {"timestamp": [618.78, 621.04], "text": " of having a relationship with a robot or a chatbot"}, {"timestamp": [621.04, 623.56], "text": " to be really unsettling or really cringey."}, {"timestamp": [623.56, 626.48], "text": " And there are people that are really like into it. And you know,"}, {"timestamp": [626.48, 629.44], "text": " I've made a few videos on my YouTube channel about this kind of exploring both"}, {"timestamp": [629.44, 629.8], "text": " sides."}, {"timestamp": [629.8, 634.04], "text": " Like what are the unmet needs that these chatbots and robots are fulfilling,"}, {"timestamp": [634.04, 637.2], "text": " whether it's, you know, romantic needs or emotional needs, or, you know,"}, {"timestamp": [637.2, 641.66], "text": " in some cases, sexual needs, uh, you know, but there's also opportunity here."}, {"timestamp": [641.68, 644.16], "text": " And so I'm, I'm always very optimistic."}, {"timestamp": [644.6, 646.88], "text": " And so one thing that I see is an opportunity"}, {"timestamp": [646.88, 649.2], "text": " to use these as teaching tools."}, {"timestamp": [649.2, 651.24], "text": " And so there's actually plenty of stories about this"}, {"timestamp": [651.24, 653.76], "text": " of like people that had a relationship with a chatbot"}, {"timestamp": [653.76, 655.84], "text": " and they learned to communicate better"}, {"timestamp": [655.84, 658.68], "text": " because these machines, you have to be very explicit"}, {"timestamp": [658.68, 661.22], "text": " about what you want and need and feel and whatever."}, {"timestamp": [661.22, 667.48], "text": " And even if you don't use stuff like if you don't use, you know, stuff like chat GPT or whatever for romantic purposes,"}, {"timestamp": [667.48, 670.08], "text": " just learning to express yourself very clearly"}, {"timestamp": [670.08, 673.52], "text": " and explicitly via these chat bots,"}, {"timestamp": [673.52, 675.92], "text": " that has helped my communication a lot."}, {"timestamp": [675.92, 677.62], "text": " Some people notice that I tend to write"}, {"timestamp": [677.62, 679.16], "text": " like chat GPT writes now,"}, {"timestamp": [679.16, 680.64], "text": " just because I discovered like,"}, {"timestamp": [680.64, 683.96], "text": " this is a very clear, succinct way of communicating,"}, {"timestamp": [683.96, 688.0], "text": " you know, but on the other side, there is also a tremendous opportunity"}, {"timestamp": [688.0, 691.4], "text": " for education, whether it's on the human level"}, {"timestamp": [691.4, 693.68], "text": " or learning new skills or anything like that."}, {"timestamp": [693.68, 695.52], "text": " Some of my clients, I've helped clients"}, {"timestamp": [695.52, 697.8], "text": " with all kinds of challenges."}, {"timestamp": [697.8, 704.0], "text": " One was working on a program to help recently released inmates"}, {"timestamp": [704.0, 705.9], "text": " re-acclimate to society."}, {"timestamp": [705.9, 708.98], "text": " And so by having a chatbot that is able to say"}, {"timestamp": [708.98, 711.26], "text": " that had the mission, I helped him program the mission"}, {"timestamp": [711.26, 714.5], "text": " of the chatbot was to reduce recidivism."}, {"timestamp": [714.5, 716.66], "text": " So whatever else the chatbot was doing,"}, {"timestamp": [716.66, 718.3], "text": " it was there to help, you know,"}, {"timestamp": [718.3, 722.76], "text": " these former inmates re-engage with their life."}, {"timestamp": [722.76, 725.2], "text": " And it had that mission of, let's keep you from going back. What do you need in order to not go back?"}, {"timestamp": [725.2, 727.92], "text": " And I was really proud of that project."}, {"timestamp": [727.92, 730.08], "text": " So there's a lot of opportunity here."}, {"timestamp": [730.08, 734.36], "text": " Yeah, it's like a friend that could be 24 seven there"}, {"timestamp": [734.36, 735.88], "text": " for you and it could help."}, {"timestamp": [735.88, 739.48], "text": " I talked with someone who has a robot for mental health"}, {"timestamp": [739.48, 742.2], "text": " and it could be your guide and help you like in CBT"}, {"timestamp": [742.2, 744.72], "text": " and meditation, mindfulness, so forth."}, {"timestamp": [744.72, 748.0], "text": " Usually we could get help more than we can do. who has a robot for mental health, and it could be your guide and help you in like in CBT and meditation, mindfulness, so forth."}, {"timestamp": [748.0, 749.96], "text": " Usually we could get help."}, {"timestamp": [749.96, 751.76], "text": " Most people would not really think"}, {"timestamp": [751.76, 753.8], "text": " about getting therapy or help,"}, {"timestamp": [753.8, 758.36], "text": " but it's cheap, it's available, it's 24 to seven,"}, {"timestamp": [758.36, 759.86], "text": " it's always there for you."}, {"timestamp": [759.86, 762.6], "text": " And it's not saying that you don't need a therapist"}, {"timestamp": [762.6, 768.54], "text": " in that case, you could get further information between the meetings and the therapist could get like"}, {"timestamp": [768.54, 774.58], "text": " a summary of what has happened during the time that she was or he was not there."}, {"timestamp": [774.58, 775.58], "text": " Right."}, {"timestamp": [775.58, 776.58], "text": " Yeah."}, {"timestamp": [776.58, 780.92], "text": " You know, I've even made some of my own chatbots to help like talk through emotional things"}, {"timestamp": [780.92, 784.34], "text": " or like unpack, you know, something that happened."}, {"timestamp": [784.34, 787.26], "text": " And because I already know a lot about the mind"}, {"timestamp": [787.26, 789.2], "text": " and mental health and psychology and emotions,"}, {"timestamp": [789.2, 791.24], "text": " I know how to use this tool."}, {"timestamp": [791.24, 793.76], "text": " And right now, what I will say is that there is still"}, {"timestamp": [793.76, 796.04], "text": " the lack of human intuition."}, {"timestamp": [796.04, 798.8], "text": " Sometimes, in many cases, these chatbots,"}, {"timestamp": [798.8, 801.66], "text": " if you use them correctly or they're programmed correctly,"}, {"timestamp": [801.66, 803.32], "text": " they can be pretty insightful,"}, {"timestamp": [803.32, 805.48], "text": " but there's also really, really big gaps"}, {"timestamp": [805.48, 808.78], "text": " in their ability to intuit what's going on"}, {"timestamp": [808.78, 809.96], "text": " or to connect the dots."}, {"timestamp": [809.96, 812.64], "text": " So certainly, and maybe that will always be true."}, {"timestamp": [812.64, 815.4], "text": " Maybe there's just something fundamental about humans"}, {"timestamp": [815.4, 818.74], "text": " and human communication that some therapists"}, {"timestamp": [818.74, 820.86], "text": " will just always be better for chatbots."}, {"timestamp": [820.86, 823.28], "text": " But at the same time, there's a lot of people"}, {"timestamp": [823.28, 825.12], "text": " who are not comfortable with"}, {"timestamp": [825.12, 830.3], "text": " therapists or can't afford therapists, and as you mentioned, the accessibility and low"}, {"timestamp": [830.3, 833.42], "text": " cost really greatly offsets that."}, {"timestamp": [833.42, 839.64], "text": " There was a study some years ago that looked at the difference between, this is for therapy,"}, {"timestamp": [839.64, 844.7], "text": " the difference between professional, like licensed therapist help versus self-directed"}, {"timestamp": [844.7, 845.64], "text": " therapy, and while self-directed therapy."}, {"timestamp": [845.64, 848.88], "text": " And while self-directed therapy was not quite as effective,"}, {"timestamp": [848.88, 851.6], "text": " the fact that it was cheaper and accessible"}, {"timestamp": [851.6, 853.84], "text": " meant that it had an outsized impact"}, {"timestamp": [853.84, 856.48], "text": " on the aggregate wellbeing of society."}, {"timestamp": [856.48, 858.84], "text": " And I think that AI has the ability to turn that up"}, {"timestamp": [858.84, 861.28], "text": " so that it's much closer to close that gap."}, {"timestamp": [861.28, 862.52], "text": " And of course, like, you know,"}, {"timestamp": [862.52, 864.64], "text": " I think everyone deserves to have a mental health."}, {"timestamp": [864.64, 866.64], "text": " It's a difficult topic."}, {"timestamp": [866.64, 870.36], "text": " Yeah, and someone, it doesn't have to call it a therapist,"}, {"timestamp": [870.36, 872.28], "text": " it could just be a friend that listens"}, {"timestamp": [872.28, 875.8], "text": " and are with you through the downs and upsides of life."}, {"timestamp": [875.8, 878.76], "text": " So you don't have to call it a therapist."}, {"timestamp": [878.76, 881.34], "text": " And many people would not like to be a friend"}, {"timestamp": [881.34, 883.78], "text": " of a therapist or to have a therapist."}, {"timestamp": [883.78, 888.82], "text": " So what are the potential benefits of AI in the workforce"}, {"timestamp": [889.48, 891.56], "text": " and how can they be maximized?"}, {"timestamp": [892.74, 894.86], "text": " Yeah, so as I mentioned earlier,"}, {"timestamp": [894.86, 898.02], "text": " AI has the potential to be better, faster, cheaper,"}, {"timestamp": [898.02, 899.38], "text": " just like any technology, right?"}, {"timestamp": [899.38, 900.94], "text": " You know, you drive a car"}, {"timestamp": [900.94, 903.5], "text": " because it is better, faster, and cheaper than walking."}, {"timestamp": [903.5, 908.34], "text": " Right, you can get to the next city in 30 minutes instead of tomorrow."}, {"timestamp": [908.34, 911.0], "text": " And so likewise, AI has the ability"}, {"timestamp": [911.0, 913.64], "text": " to accelerate a lot of things for us,"}, {"timestamp": [913.64, 916.92], "text": " whether it's brainstorming, drafting things."}, {"timestamp": [916.92, 918.6], "text": " And it can draft all kinds of things,"}, {"timestamp": [918.6, 921.14], "text": " whether it's technical documentation, works"}, {"timestamp": [921.14, 923.44], "text": " of fiction, emails."}, {"timestamp": [923.44, 925.28], "text": " There's all kinds of ways that you can use it."}, {"timestamp": [925.28, 929.28], "text": " It can also read a tremendous amount, especially as the chatbots get bigger."}, {"timestamp": [929.28, 936.48], "text": " So Claude, for instance, is one of the competitors to chat GPT, and it has 100,000 token window."}, {"timestamp": [936.48, 942.08], "text": " So 100,000 tokens is roughly 80,000 words that it can read in about 30 seconds."}, {"timestamp": [942.08, 946.58], "text": " So that's basically an entire book, an entire nonfiction book"}, {"timestamp": [946.58, 949.64], "text": " that you can plug in and ask questions about and learn about"}, {"timestamp": [949.64, 951.48], "text": " without having to read it yourself."}, {"timestamp": [951.48, 955.72], "text": " So that can literally save you many, many, many hours worth of reading"}, {"timestamp": [955.72, 958.22], "text": " in order to say, OK, I need this piece of information."}, {"timestamp": [958.52, 960.58], "text": " Go get it. Let's go."}, {"timestamp": [960.58, 964.36], "text": " And so that kind of acceleration is really what I recommend"}, {"timestamp": [964.36, 965.74], "text": " my clients look for,"}, {"timestamp": [965.74, 968.94], "text": " is don't look for something that's going to shave off 5-10 percent."}, {"timestamp": [968.94, 970.68], "text": " Look for something that's going to triple your speed."}, {"timestamp": [970.68, 972.7], "text": " Look for something that's going to quadruple"}, {"timestamp": [972.7, 975.72], "text": " your speed in order for specific tasks."}, {"timestamp": [975.72, 977.32], "text": " Maybe not the entire project,"}, {"timestamp": [977.32, 978.72], "text": " but for certain tasks,"}, {"timestamp": [978.72, 982.36], "text": " you can certainly go 10 times faster or 100 times faster."}, {"timestamp": [982.36, 984.9], "text": " That's really where you're going to get a good ROI"}, {"timestamp": [984.9, 985.2], "text": " implementing generative AI today. 10 times faster or 100 times faster. And that's really where you're gonna get a good ROI"}, {"timestamp": [985.2, 987.6], "text": " implementing generative AI today."}, {"timestamp": [987.6, 992.2], "text": " Yeah, it reminds me of the strike in LA of the writers."}, {"timestamp": [992.2, 994.0], "text": " And just think about it,"}, {"timestamp": [994.0, 996.16], "text": " instead of working half a year on a script,"}, {"timestamp": [996.16, 998.76], "text": " they could do it like in a month or a few days,"}, {"timestamp": [998.76, 999.76], "text": " I don't know exactly."}, {"timestamp": [999.76, 1003.84], "text": " But for sure, the fun part of being creative,"}, {"timestamp": [1003.84, 1005.62], "text": " of developing a character,"}, {"timestamp": [1005.62, 1009.26], "text": " of adding these like small glitches for a character"}, {"timestamp": [1009.26, 1010.9], "text": " is still theirs."}, {"timestamp": [1010.9, 1013.34], "text": " It's, I guess the chat GPT could not,"}, {"timestamp": [1013.34, 1015.82], "text": " or similar to would not do that."}, {"timestamp": [1015.82, 1016.66], "text": " Yeah."}, {"timestamp": [1016.66, 1019.54], "text": " Yeah, you know, I use a variety of AI tools"}, {"timestamp": [1019.54, 1022.58], "text": " to help me with brainstorming in my fiction,"}, {"timestamp": [1022.58, 1026.6], "text": " whether it's, you know, kind of, you know, brainstorming in my fiction, whether it's kind of brainstorming characters"}, {"timestamp": [1026.6, 1027.2], "text": " or plots."}, {"timestamp": [1027.2, 1030.36], "text": " And these chatbots, they understand story structure"}, {"timestamp": [1030.36, 1032.32], "text": " and principles of writing."}, {"timestamp": [1032.32, 1033.56], "text": " But you're absolutely right."}, {"timestamp": [1033.56, 1037.76], "text": " The thing about being a writer or any kind of creative type"}, {"timestamp": [1037.76, 1039.48], "text": " is I have a personal mission."}, {"timestamp": [1039.48, 1041.0], "text": " There is something that I am trying"}, {"timestamp": [1041.0, 1044.48], "text": " to say or achieve with my works of fiction"}, {"timestamp": [1044.48, 1045.6], "text": " that the machine is just never going"}, {"timestamp": [1045.6, 1050.88], "text": " to have. That's just not part of how it's built. It is there to generate text, but I have an"}, {"timestamp": [1050.88, 1057.04], "text": " emotional mission that I am trying to tell a story for, or an experience that I'm trying to relate,"}, {"timestamp": [1057.04, 1063.44], "text": " a very specific experience. And so rather than look at these tools as replacing that, they're"}, {"timestamp": [1063.44, 1065.34], "text": " there to help and accelerate that"}, {"timestamp": [1065.34, 1067.08], "text": " and facilitate it."}, {"timestamp": [1067.08, 1068.96], "text": " And you know, there's a lot of conversation."}, {"timestamp": [1068.96, 1072.1], "text": " Obviously, there's lawsuits about this kind of thing."}, {"timestamp": [1072.1, 1073.28], "text": " There's people defending it."}, {"timestamp": [1073.28, 1076.24], "text": " So it's very polarizing on both sides."}, {"timestamp": [1076.24, 1080.26], "text": " And you know, it's similar to arguments in the past, right?"}, {"timestamp": [1080.26, 1083.72], "text": " When the printing press was invented, some people thought that it was going to be the"}, {"timestamp": [1083.72, 1090.72], "text": " destruction because people were no longer writing longhand as much. And then, you know, typewriters, internet,"}, {"timestamp": [1091.76, 1097.68], "text": " photography cameras replaced a lot of painting. And so technology always, it almost seems like"}, {"timestamp": [1097.68, 1102.88], "text": " technology disrupts arts first. So maybe in hindsight, we shouldn't be surprised that,"}, {"timestamp": [1102.88, 1107.28], "text": " you know, writers and creative types were the first ones to get disrupted."}, {"timestamp": [1107.28, 1110.16], "text": " Just spitballing, I don't know if that's sensible."}, {"timestamp": [1111.56, 1113.66], "text": " Okay, we have a question related to the fact"}, {"timestamp": [1113.66, 1115.0], "text": " that you mentioned you're a chatbot."}, {"timestamp": [1115.0, 1117.9], "text": " So how Daniel, I know Daniel is really cute."}, {"timestamp": [1117.9, 1120.2], "text": " Which framers and models do you typically use"}, {"timestamp": [1120.2, 1121.64], "text": " to build a chatbot?"}, {"timestamp": [1123.64, 1126.64], "text": " Yeah, so right now the easiest way to build a chatbot? Yeah, so right now, the easiest way to build a chatbot"}, {"timestamp": [1126.64, 1129.24], "text": " is the chat GPT API."}, {"timestamp": [1129.24, 1131.72], "text": " And so the chat GPT API gives you"}, {"timestamp": [1131.72, 1134.96], "text": " a few knobs and levers that make it pretty easy"}, {"timestamp": [1134.96, 1138.12], "text": " to build a chatbot, namely the system window."}, {"timestamp": [1138.12, 1140.12], "text": " So if you're not familiar with this,"}, {"timestamp": [1140.12, 1142.18], "text": " the system window is a set of instructions"}, {"timestamp": [1142.18, 1143.88], "text": " that you can give the chatbot, where"}, {"timestamp": [1143.88, 1146.5], "text": " you can give it rules of how to engage with the user,"}, {"timestamp": [1146.5, 1148.76], "text": " or you can give it some background information."}, {"timestamp": [1148.76, 1151.32], "text": " And I've made a lot of use of the system window"}, {"timestamp": [1151.32, 1153.76], "text": " to give it either specific missions, roles."}, {"timestamp": [1153.76, 1155.88], "text": " You can give it formats."}, {"timestamp": [1155.88, 1160.72], "text": " So if you need it to write code and use only this language,"}, {"timestamp": [1160.72, 1164.08], "text": " use this particular format, it can write code."}, {"timestamp": [1164.08, 1165.96], "text": " You can tell it what not to do. You can use negative particular format, it can write code, you can tell it what not to do, you"}, {"timestamp": [1165.96, 1167.36], "text": " can use negative prompting, which"}, {"timestamp": [1167.36, 1171.96], "text": " is something that's really common in the image generation"}, {"timestamp": [1171.96, 1172.96], "text": " area."}, {"timestamp": [1172.96, 1174.84], "text": " And so there's a lot of cross-pollination"}, {"timestamp": [1174.84, 1177.08], "text": " that can happen, but that's the primary thing."}, {"timestamp": [1177.08, 1180.76], "text": " And honestly, I have found that the right system window"}, {"timestamp": [1180.76, 1184.56], "text": " can get some really good behavior out of these chatbots."}, {"timestamp": [1184.56, 1189.12], "text": " One area of my research is more sophisticated cognitive architectures,"}, {"timestamp": [1189.12, 1193.16], "text": " which is to basically create autonomous agents."}, {"timestamp": [1193.4, 1197.12], "text": " So you might've heard of like agent GPT or baby AGI or meta GPT."}, {"timestamp": [1197.12, 1198.36], "text": " There's all kinds of ones out there."}, {"timestamp": [1198.7, 1202.4], "text": " So I'm actually participating in a research project to publish a much more"}, {"timestamp": [1202.4, 1204.8], "text": " sophisticated framework that people can adopt."}, {"timestamp": [1205.12, 1208.06], "text": " That paper should come out in October, I think."}, {"timestamp": [1208.06, 1209.14], "text": " So stay tuned."}, {"timestamp": [1209.14, 1210.48], "text": " Yeah."}, {"timestamp": [1210.48, 1213.66], "text": " So Daniel just followed David, and he"}, {"timestamp": [1213.66, 1216.66], "text": " has a very successful YouTube channel,"}, {"timestamp": [1216.66, 1219.74], "text": " and you can see it on LinkedIn and so forth."}, {"timestamp": [1219.74, 1224.22], "text": " So we talked about what could be a very good outcome"}, {"timestamp": [1224.22, 1225.24], "text": " from these AIs."}, {"timestamp": [1225.24, 1228.12], "text": " So let's talk about potential risks and challenges"}, {"timestamp": [1228.12, 1231.42], "text": " associated with AI workforce."}, {"timestamp": [1233.38, 1237.54], "text": " Yeah, so obviously, so there's a few ways to look at it."}, {"timestamp": [1237.54, 1240.7], "text": " You can look at it from the perspective of a CEO, right?"}, {"timestamp": [1240.7, 1243.72], "text": " There's a few memes out there circulating on LinkedIn."}, {"timestamp": [1243.72, 1246.26], "text": " And so like the chief security officer"}, {"timestamp": [1246.26, 1248.1], "text": " looks at AI as like a threat, you know,"}, {"timestamp": [1248.1, 1250.2], "text": " it's more hacking and spear phishing"}, {"timestamp": [1250.2, 1251.8], "text": " and that sort of thing."}, {"timestamp": [1251.8, 1254.3], "text": " The CEO, however, is gonna look at it"}, {"timestamp": [1254.3, 1257.38], "text": " more as a combination of business opportunity"}, {"timestamp": [1257.38, 1258.6], "text": " and business threat."}, {"timestamp": [1258.6, 1261.72], "text": " And so what I mean by that is that, you know,"}, {"timestamp": [1261.72, 1263.92], "text": " generative AI is happening, whether you like it or not."}, {"timestamp": [1263.92, 1265.96], "text": " And if you ignore it, you're going to get left behind."}, {"timestamp": [1265.96, 1269.12], "text": " So that's the biggest threat to any company."}, {"timestamp": [1269.12, 1271.62], "text": " And some companies, especially brick and mortar ones,"}, {"timestamp": [1271.62, 1274.44], "text": " they can afford to ignore it and kind of be slow adopters."}, {"timestamp": [1274.44, 1277.96], "text": " But any company in the service space, I think,"}, {"timestamp": [1277.96, 1279.64], "text": " probably needs to be paying attention."}, {"timestamp": [1279.64, 1283.88], "text": " So that's kind of one of the big things to pay attention to."}, {"timestamp": [1283.88, 1285.24], "text": " And as I mentioned earlier,"}, {"timestamp": [1285.24, 1286.92], "text": " it's not gonna necessarily fundamentally"}, {"timestamp": [1286.92, 1288.48], "text": " transform your business,"}, {"timestamp": [1288.48, 1290.0], "text": " but what it will do is it'll give you"}, {"timestamp": [1290.0, 1291.94], "text": " a competitive advantage because it'll allow you"}, {"timestamp": [1291.94, 1295.84], "text": " to accelerate some of those business processes that you need."}, {"timestamp": [1295.84, 1298.56], "text": " And it can also allow you to greatly reduce the cost"}, {"timestamp": [1298.56, 1300.94], "text": " of some of those business processes."}, {"timestamp": [1300.94, 1302.14], "text": " Some of my friends are lawyers,"}, {"timestamp": [1302.14, 1304.68], "text": " and we were talking about law"}, {"timestamp": [1304.68, 1305.52], "text": " as an intersection with"}, {"timestamp": [1305.52, 1310.26], "text": " generative AI, and different types of lawyers have different incentives."}, {"timestamp": [1310.26, 1314.22], "text": " And so what I mean by that is that a private law firm, they bill hourly."}, {"timestamp": [1314.22, 1318.12], "text": " So they're like, well, we're not going to use AI because we're going to take 100 hours"}, {"timestamp": [1318.12, 1320.18], "text": " of research and it's going to be 20 minutes."}, {"timestamp": [1320.18, 1322.34], "text": " We can't bill for that."}, {"timestamp": [1322.34, 1325.2], "text": " But on the other hand, corporate lawyers who are, you know, in-house"}, {"timestamp": [1325.2, 1329.52], "text": " counsel, they just need to get the job done and serve the company. So they're all about generative"}, {"timestamp": [1329.52, 1333.92], "text": " AI tools. And so we're seeing this really interesting market fragmentation. So those"}, {"timestamp": [1333.92, 1340.8], "text": " are some examples of opportunities and threats to do in the case of AI. Yeah. And we have a question"}, {"timestamp": [1340.8, 1345.92], "text": " related to that. Data security is a major issue to apply externally inside companies"}, {"timestamp": [1345.92, 1353.12], "text": " and we know that I think Samsung and maybe Apple denied access to their employees. Any advice on"}, {"timestamp": [1353.12, 1360.0], "text": " how to overcome this issue? Yeah, so if I understand the question, it has to do with data governance,"}, {"timestamp": [1360.88, 1365.0], "text": " which is, okay, so if you're sending private,"}, {"timestamp": [1365.08, 1366.8], "text": " whether personally private information"}, {"timestamp": [1366.8, 1371.8], "text": " or corporate confidential information to a vendor,"}, {"timestamp": [1371.88, 1373.42], "text": " how do they handle that?"}, {"timestamp": [1373.42, 1374.68], "text": " How do you control that?"}, {"timestamp": [1374.68, 1377.7], "text": " And so one thing that I noticed earlier on,"}, {"timestamp": [1377.7, 1379.36], "text": " because this was a big concern,"}, {"timestamp": [1379.36, 1382.6], "text": " I don't know if it was ever true explicitly,"}, {"timestamp": [1382.6, 1384.84], "text": " but certainly people believed it was true,"}, {"timestamp": [1384.84, 1389.08], "text": " that when you used various generative AI APIs,"}, {"timestamp": [1389.08, 1392.96], "text": " like OpenAI's endpoints, and again, I don't wanna,"}, {"timestamp": [1392.96, 1396.12], "text": " I'm not slandering them, I know that it's not true anymore,"}, {"timestamp": [1396.12, 1398.8], "text": " they have updated their policy, but it might have been true,"}, {"timestamp": [1398.8, 1400.16], "text": " where any data that you sent them,"}, {"timestamp": [1400.16, 1401.72], "text": " they might use it for training,"}, {"timestamp": [1401.72, 1404.36], "text": " and so that is still a very big fear."}, {"timestamp": [1404.36, 1405.36], "text": " And whether or not it was"}, {"timestamp": [1405.36, 1410.24], "text": " open AI or any other companies, data is the new oil. And I'm surprised at the number of people"}, {"timestamp": [1410.24, 1415.76], "text": " who haven't heard this. Data is the new oil. So data is super valuable. And so a lot of companies"}, {"timestamp": [1415.76, 1421.52], "text": " want your data to train on. But one thing that I have advised some clients of is pay attention to"}, {"timestamp": [1421.52, 1427.72], "text": " the more mature vendors. And so what I mean by that is Microsoft has been serving companies"}, {"timestamp": [1427.72, 1429.82], "text": " and schools and governments for a long time."}, {"timestamp": [1430.12, 1435.0], "text": " So Microsoft, for instance, really understands the value of respecting"}, {"timestamp": [1435.0, 1438.22], "text": " the data, integrity and privacy of their customers."}, {"timestamp": [1438.66, 1441.0], "text": " Smaller companies may or may not."}, {"timestamp": [1441.72, 1444.26], "text": " I've also worked with Nvidia and Nvidia."}, {"timestamp": [1444.26, 1446.12], "text": " They're like we kind of like I've also worked with Nvidia, and Nvidia, they're like, we kind of like,"}, {"timestamp": [1446.12, 1447.26], "text": " I'm not quoting them exactly,"}, {"timestamp": [1447.26, 1449.28], "text": " but kind of the sentiment that they gave me was,"}, {"timestamp": [1449.28, 1450.5], "text": " we don't really care about your data,"}, {"timestamp": [1450.5, 1452.66], "text": " we're a hardware vendor, right?"}, {"timestamp": [1452.66, 1454.98], "text": " And so as long as you're using our models or our hardware,"}, {"timestamp": [1454.98, 1457.28], "text": " we don't care what you put on it."}, {"timestamp": [1457.28, 1460.78], "text": " So that's one thing to just pay attention to is,"}, {"timestamp": [1460.78, 1462.98], "text": " yes, you might be sending new kinds of data,"}, {"timestamp": [1462.98, 1466.86], "text": " but cloud data is not a new thing."}, {"timestamp": [1466.86, 1469.72], "text": " Just make sure that when you talk to your vendors,"}, {"timestamp": [1469.72, 1472.28], "text": " that they understand that data is data,"}, {"timestamp": [1472.28, 1473.96], "text": " corporate data is corporate data."}, {"timestamp": [1473.96, 1475.4], "text": " They're just giving you a new set of"}, {"timestamp": [1475.4, 1477.84], "text": " tools to interact with this stuff."}, {"timestamp": [1477.84, 1480.32], "text": " One of the things that Satya Nadella talked"}, {"timestamp": [1480.32, 1483.08], "text": " about at the Microsoft Inspire keynote"}, {"timestamp": [1483.08, 1485.64], "text": " was that they're actually air gapping your data."}, {"timestamp": [1485.64, 1488.0], "text": " Like if you send stuff to Bing Enterprise,"}, {"timestamp": [1488.0, 1490.2], "text": " it's air gapped from the rest of Bing,"}, {"timestamp": [1490.2, 1492.28], "text": " from the rest of their AI framework."}, {"timestamp": [1492.28, 1494.56], "text": " And that air gapping is what you really need"}, {"timestamp": [1494.56, 1495.76], "text": " to pay attention to,"}, {"timestamp": [1495.76, 1498.6], "text": " to ensure that your data has integrity."}, {"timestamp": [1498.6, 1501.72], "text": " There's also GDPR from the European Union."}, {"timestamp": [1501.72, 1503.64], "text": " Any company that is GDPR compliant"}, {"timestamp": [1503.64, 1506.64], "text": " is almost certainly going to be more cognizant"}, {"timestamp": [1506.64, 1508.92], "text": " of data ownership and data governance."}, {"timestamp": [1508.92, 1511.7], "text": " So those are kind of my two main points."}, {"timestamp": [1511.7, 1516.28], "text": " Yeah, I think that one of the things that comes to my mind"}, {"timestamp": [1516.28, 1519.52], "text": " is when you build something based on your data,"}, {"timestamp": [1519.52, 1523.04], "text": " using their engine, you're taking actually all your data"}, {"timestamp": [1523.04, 1525.8], "text": " from your company about your clients,"}, {"timestamp": [1525.8, 1529.18], "text": " about what you know about them, data that was gathered maybe"}, {"timestamp": [1529.18, 1534.66], "text": " through years of working with very important topics"}, {"timestamp": [1534.66, 1535.8], "text": " for your company."}, {"timestamp": [1535.8, 1537.56], "text": " And then you're saying, OK, I'm sharing."}, {"timestamp": [1537.56, 1540.94], "text": " As if I'm sharing this data, the engine gets smarter,"}, {"timestamp": [1540.94, 1543.52], "text": " and my competitors could use my data"}, {"timestamp": [1543.52, 1545.92], "text": " in order to compete with me, right? And what"}, {"timestamp": [1545.92, 1549.64], "text": " you're saying, it's not so it's, it doesn't work this way."}, {"timestamp": [1549.64, 1554.78], "text": " Not directly. However, to that point, one thing that a lot of people are coming to realize"}, {"timestamp": [1554.78, 1559.76], "text": " is that there's a lot of latent capabilities and a lot of latent content already baked"}, {"timestamp": [1559.76, 1568.0], "text": " into large language models and generative AI models. And so what I mean by that is that they are trained on all the data from on the internet,"}, {"timestamp": [1568.0, 1572.8], "text": " right, basically the entire internet today, which means that they have a lot of knowledge"}, {"timestamp": [1572.8, 1577.28], "text": " that could be secret knowledge or that you might think is yours."}, {"timestamp": [1578.0, 1583.52], "text": " But because it has read, you know, thousands and thousands of, you know, millions of pages,"}, {"timestamp": [1583.52, 1585.68], "text": " billions of pages worth of text."}, {"timestamp": [1585.68, 1591.16], "text": " It has these emergent capabilities to connect dots and solve problems that you feel might"}, {"timestamp": [1591.16, 1592.92], "text": " be super proprietary."}, {"timestamp": [1592.92, 1596.48], "text": " And you can test these because sometimes it's like, okay, do you know how to do this?"}, {"timestamp": [1596.48, 1601.28], "text": " And the, and the, you know, chat GPT will either do it really well or just fail spectacularly."}, {"timestamp": [1601.28, 1605.76], "text": " So there are some capabilities that are in there that that might feel proprietary"}, {"timestamp": [1605.76, 1610.66], "text": " or might feel like trade secrets. I had one client who was working on a particular kind"}, {"timestamp": [1610.66, 1616.5], "text": " of SEO. It was based on guidelines from his country. And so I they're like, how do we"}, {"timestamp": [1616.5, 1620.9], "text": " get it to do this? I'm like, just ask it. It's already it's already read all the SEO"}, {"timestamp": [1620.9, 1624.18], "text": " guidelines. And they're like, oh, well, that completely destroys our business model, because"}, {"timestamp": [1624.18, 1629.68], "text": " now they were no longer the gatekeepers of this special knowledge. But that allowed them"}, {"timestamp": [1629.68, 1634.16], "text": " to just, rather than focus on that problem, focus on more engaging, harder problems."}, {"timestamp": [1635.04, 1639.44], "text": " Yeah, and I think that this is a very good use case that usually people think about"}, {"timestamp": [1639.44, 1647.44], "text": " what could be done with it, and then only the hard work is done through what is already known to Chachapiti"}, {"timestamp": [1647.44, 1654.66], "text": " or similar. And only the more creative, fun, innovative part needs to be added upon what"}, {"timestamp": [1654.66, 1656.16], "text": " is already there."}, {"timestamp": [1656.16, 1662.12], "text": " Yep. Yeah. Like I said, sometimes it comes back to mission. Sometimes it comes back to"}, {"timestamp": [1662.12, 1667.2], "text": " special knowledge or special goals that you have. but the AI is just, right now,"}, {"timestamp": [1667.2, 1668.98], "text": " it's just a tool that's there to help you."}, {"timestamp": [1668.98, 1670.6], "text": " They will be more autonomous soon."}, {"timestamp": [1670.6, 1671.84], "text": " That's what I'm working on."}, {"timestamp": [1671.84, 1673.0], "text": " But yeah, for now it's there."}, {"timestamp": [1673.0, 1675.44], "text": " It's just a tool to help you go faster."}, {"timestamp": [1675.44, 1676.26], "text": " Yeah."}, {"timestamp": [1676.26, 1678.04], "text": " So if you're saying it's gonna change"}, {"timestamp": [1678.04, 1680.8], "text": " so many roles or professions,"}, {"timestamp": [1680.8, 1683.32], "text": " what do you think people would really do?"}, {"timestamp": [1683.32, 1686.3], "text": " Would they have new roles, new professions"}, {"timestamp": [1686.3, 1689.12], "text": " that we don't know of, or they will work less,"}, {"timestamp": [1689.12, 1690.88], "text": " they will have more free time?"}, {"timestamp": [1690.88, 1693.82], "text": " What do you think will be like five years from now?"}, {"timestamp": [1693.82, 1697.68], "text": " Yeah, so there's a little bit of a myth"}, {"timestamp": [1697.68, 1700.64], "text": " in that technology always creates more jobs,"}, {"timestamp": [1700.64, 1702.44], "text": " and that's an oversimplification."}, {"timestamp": [1702.44, 1704.32], "text": " So if you look in the past,"}, {"timestamp": [1704.32, 1705.76], "text": " yes, technology has created"}, {"timestamp": [1705.76, 1710.88], "text": " more jobs, but not directly. What technology does is that it lowers the cost of goods and services,"}, {"timestamp": [1710.88, 1716.96], "text": " which allows you to spend money elsewhere, which then creates new jobs. And so, as I mentioned,"}, {"timestamp": [1716.96, 1721.68], "text": " we should expect new technologies, powerful new technologies, again, to lower costs. That's why"}, {"timestamp": [1721.68, 1725.7], "text": " we use them. And so then if those costs of our basic goods"}, {"timestamp": [1725.7, 1729.9], "text": " and services goes down, then the cost of food,"}, {"timestamp": [1729.9, 1732.74], "text": " housing, healthcare, law, whatever you need,"}, {"timestamp": [1732.74, 1734.48], "text": " hopefully will be going down,"}, {"timestamp": [1734.48, 1736.12], "text": " which means that you need to work less"}, {"timestamp": [1736.12, 1737.52], "text": " to get your needs met."}, {"timestamp": [1737.52, 1740.64], "text": " But at the same time, if the demand for human labor"}, {"timestamp": [1740.64, 1743.32], "text": " goes down, then there's this offset, right?"}, {"timestamp": [1743.32, 1745.78], "text": " Because if you don't have a job, if you don't have money,"}, {"timestamp": [1745.78, 1748.28], "text": " you can't pay for anything anyways."}, {"timestamp": [1748.28, 1751.78], "text": " And so what I call this, I call it post-labor economics,"}, {"timestamp": [1751.78, 1755.78], "text": " where whether or not all human jobs go away,"}, {"timestamp": [1755.78, 1758.06], "text": " we should expect that some, many,"}, {"timestamp": [1758.06, 1760.3], "text": " or maybe even most human jobs go away."}, {"timestamp": [1760.3, 1761.34], "text": " And so what we're gonna have to do"}, {"timestamp": [1761.34, 1764.14], "text": " is we're gonna have to renegotiate the social contract."}, {"timestamp": [1764.14, 1768.2], "text": " And so the social contract right now is you work for money, you get money,"}, {"timestamp": [1768.2, 1772.4], "text": " and then the money that you have gives you the ability to demand goods and services,"}, {"timestamp": [1772.4, 1774.4], "text": " and that's how the world goes around."}, {"timestamp": [1774.4, 1778.0], "text": " But if you don't have a job, that entire social contract breaks down."}, {"timestamp": [1778.0, 1779.4], "text": " So we're going to need a new one."}, {"timestamp": [1779.4, 1782.6], "text": " And I don't know how it's going to look, but I'm just starting the conversation of"}, {"timestamp": [1782.6, 1788.44], "text": " we're going to need to be thinking long and hard about how this relationship between people, businesses, and governments"}, {"timestamp": [1788.44, 1791.68], "text": " change in the coming five to ten years and longer."}, {"timestamp": [1791.68, 1792.68], "text": " Yeah."}, {"timestamp": [1792.68, 1798.44], "text": " But do you really believe that the government will take care of us and give us a general"}, {"timestamp": [1798.44, 1801.36], "text": " income for anyone?"}, {"timestamp": [1801.36, 1807.0], "text": " And do we really want to trust them to give us what to eat?"}, {"timestamp": [1807.0, 1812.0], "text": " Yeah, you know, the fears of central management are pretty well founded,"}, {"timestamp": [1812.0, 1815.0], "text": " because throughout the 20th century, various countries around the world"}, {"timestamp": [1815.0, 1820.0], "text": " tried central management models, and sometimes it resulted in mass famine,"}, {"timestamp": [1820.0, 1823.0], "text": " sometimes it lowered the access of goods and services,"}, {"timestamp": [1823.0, 1832.36], "text": " and while some countries have single payer systems for health care that can, that can sometimes result in longer wait times and lower quality of care."}, {"timestamp": [1832.96, 1840.04], "text": " So what I hope is that the, the cost of some of our basic needs will be so low that it won't really matter."}, {"timestamp": [1840.48, 1843.56], "text": " And so what I mean by that is you don't pay for air, right?"}, {"timestamp": [1843.6, 1845.54], "text": " Air is so abundant that it's free."}, {"timestamp": [1845.54, 1847.92], "text": " What I'm hoping is that other goods and services"}, {"timestamp": [1847.92, 1851.48], "text": " like internet and water and food and housing"}, {"timestamp": [1851.48, 1853.74], "text": " and healthcare becomes so cheap"}, {"timestamp": [1853.74, 1856.06], "text": " that it doesn't really need to be managed."}, {"timestamp": [1856.06, 1857.74], "text": " Because right now in America,"}, {"timestamp": [1857.74, 1861.02], "text": " I think healthcare takes up like a third of our entire GDP,"}, {"timestamp": [1861.02, 1862.16], "text": " which is insane."}, {"timestamp": [1862.16, 1863.62], "text": " It should not be that expensive."}, {"timestamp": [1863.62, 1865.2], "text": " And so of course, when you have"}, {"timestamp": [1865.2, 1869.92], "text": " something that is that expensive, that is that scarce, you have to very carefully manage it."}, {"timestamp": [1869.92, 1876.08], "text": " But what I'm hoping is that through implementing artificial intelligence and automation,"}, {"timestamp": [1876.08, 1881.76], "text": " we can lower the cost of all of those things until they don't need to be quite, so that they're not"}, {"timestamp": [1881.76, 1890.1], "text": " as contentious to manage, basically. And so then then if that's the case, then it's basically the government will probably just subsidize businesses."}, {"timestamp": [1890.1, 1898.3], "text": " So rather than the government giving you money directly, that's one possibility, it'll probably happen or at least experiments will happen."}, {"timestamp": [1898.3, 1906.24], "text": " What I also expect is that businesses that have their margins thin too much, they'll probably be subsidized by the government"}, {"timestamp": [1906.24, 1908.24], "text": " because we still need those services."}, {"timestamp": [1908.24, 1910.94], "text": " And so then I suspect we'll see this hybrid model"}, {"timestamp": [1910.94, 1913.04], "text": " of neoliberalism where it's like,"}, {"timestamp": [1913.04, 1915.86], "text": " okay, let the business seek efficiency,"}, {"timestamp": [1915.86, 1919.12], "text": " but also then subsidize it so that it can stay afloat."}, {"timestamp": [1919.12, 1921.28], "text": " That's kind of what I anticipate right now."}, {"timestamp": [1922.52, 1924.08], "text": " But when I think about it,"}, {"timestamp": [1924.08, 1927.04], "text": " the money goes to the private sector,"}, {"timestamp": [1927.04, 1931.6], "text": " to companies like Microsoft, OpenAI, Google, so forth."}, {"timestamp": [1931.6, 1938.16], "text": " So they would need to have some kind of taxation on the AI in order to get these revenues,"}, {"timestamp": [1938.16, 1939.16], "text": " right?"}, {"timestamp": [1939.16, 1940.16], "text": " Yeah, yeah."}, {"timestamp": [1940.16, 1945.04], "text": " So whether there's, it's entirely possible that you don't need any special taxation."}, {"timestamp": [1945.04, 1949.28], "text": " You just need to raise the marginal tax rate, particularly on tech companies."}, {"timestamp": [1949.28, 1956.96], "text": " And then in order to offset the deflationary force from people losing jobs,"}, {"timestamp": [1956.96, 1960.44], "text": " you would probably then just have a redistributive policy,"}, {"timestamp": [1960.44, 1963.84], "text": " basically just taking money from one place and giving it to another"}, {"timestamp": [1963.84, 1965.7], "text": " in order to keep the economy churning."}, {"timestamp": [1966.02, 1971.06], "text": " That's probably the simplest way and we already have models for this. For instance, we have subsidies. We know how those work."}, {"timestamp": [1971.5, 1976.8], "text": " We know how negative tax incomes work. We know how unemployment insurance works."}, {"timestamp": [1977.26, 1980.48], "text": " So basically, I think that what we're gonna see is an incremental"}, {"timestamp": [1981.94, 1985.9], "text": " development of these existing systems to accommodate the changing economic"}, {"timestamp": [1985.9, 1987.22], "text": " landscape."}, {"timestamp": [1987.22, 1992.34], "text": " But I think we have the fundamental tools that we need to adapt the economy to a post-labor"}, {"timestamp": [1992.34, 1995.14], "text": " economic system."}, {"timestamp": [1995.14, 1997.56], "text": " As we said, you're very optimistic."}, {"timestamp": [1997.56, 1998.56], "text": " You mentioned that before."}, {"timestamp": [1998.56, 1999.56], "text": " Yes."}, {"timestamp": [1999.56, 2007.18], "text": " Okay, so how will AI impact the skills and education required for jobs in the future"}, {"timestamp": [2007.18, 2013.28], "text": " and the implication that it has on the workers and the employers?"}, {"timestamp": [2013.28, 2019.84], "text": " You know, the prevailing wisdom right now is that AI is not going to replace you, the"}, {"timestamp": [2019.84, 2022.28], "text": " person using AI is going to replace you."}, {"timestamp": [2022.28, 2026.56], "text": " And so the number one thing is, in terms of school, education requirements and training, is learning to replace you. And so the number one thing is in terms of school education"}, {"timestamp": [2026.56, 2030.96], "text": " requirements and training is learning to use AI tools. That's the number one thing right now."}, {"timestamp": [2032.08, 2036.56], "text": " Now some of the other projects that I've participated in or consulted on have to do with"}, {"timestamp": [2036.56, 2042.16], "text": " using AI to revolutionize education. And so one of the things that I'm really hopeful for is,"}, {"timestamp": [2042.88, 2046.76], "text": " so there's this problem, it's called Bloom's Two Sigma Problem."}, {"timestamp": [2046.76, 2047.96], "text": " And most people haven't heard of this,"}, {"timestamp": [2047.96, 2049.32], "text": " but you know what it is."}, {"timestamp": [2049.32, 2052.56], "text": " And everyone colloquially knows what this problem is."}, {"timestamp": [2052.56, 2055.08], "text": " And that is that if you have private tutoring,"}, {"timestamp": [2055.08, 2057.72], "text": " you score way higher in your grades."}, {"timestamp": [2057.72, 2059.96], "text": " Even if you're an average student,"}, {"timestamp": [2059.96, 2063.88], "text": " the value of having one-on-one mentoring and tutoring"}, {"timestamp": [2063.88, 2065.54], "text": " really takes you to the next level."}, {"timestamp": [2065.54, 2067.78], "text": " And so one of the things that I hope to see"}, {"timestamp": [2067.78, 2070.36], "text": " is that AI is going to close that gap"}, {"timestamp": [2070.36, 2071.68], "text": " of Bloom's two sigma problem."}, {"timestamp": [2071.68, 2075.42], "text": " So the idea is that if you have high-end tutoring,"}, {"timestamp": [2075.42, 2077.6], "text": " you score two standard deviations"}, {"timestamp": [2077.6, 2080.24], "text": " above what you otherwise would have, which is incredible."}, {"timestamp": [2080.24, 2083.0], "text": " And so if we can use AI to close the gap,"}, {"timestamp": [2083.0, 2086.44], "text": " to really ratchet up the value of education"}, {"timestamp": [2086.44, 2089.96], "text": " that everyone gets, whether it's primary education"}, {"timestamp": [2089.96, 2092.56], "text": " or continuing education or grad school or whatever,"}, {"timestamp": [2093.68, 2095.34], "text": " I already use AI extensively."}, {"timestamp": [2095.34, 2097.36], "text": " Anything new that I need to learn,"}, {"timestamp": [2097.36, 2100.1], "text": " I get on Perplexity and I search for the best articles"}, {"timestamp": [2100.1, 2103.22], "text": " and then I plug it all into chat GPT and Clawed"}, {"timestamp": [2103.22, 2105.52], "text": " and make sure that I understand these new topics."}, {"timestamp": [2105.52, 2107.52], "text": " And I think that once everyone is doing that"}, {"timestamp": [2107.52, 2110.68], "text": " and once these tools are deployed widespread,"}, {"timestamp": [2110.68, 2112.0], "text": " people are going to be able to engage"}, {"timestamp": [2112.0, 2113.44], "text": " with learning in a different way."}, {"timestamp": [2113.44, 2116.56], "text": " Now, you know, obviously that can help with your career,"}, {"timestamp": [2116.56, 2118.96], "text": " but it also just helps in life in general."}, {"timestamp": [2118.96, 2120.68], "text": " The more access to information that you have,"}, {"timestamp": [2120.68, 2123.76], "text": " the better off you are, generally speaking."}, {"timestamp": [2123.76, 2126.36], "text": " Yeah. I think that what you're saying is"}, {"timestamp": [2126.36, 2130.0], "text": " that it could close the gaps within society right now."}, {"timestamp": [2130.0, 2132.64], "text": " Only the wealthy people are, they"}, {"timestamp": [2132.64, 2136.2], "text": " could use private tutors and teachers."}, {"timestamp": [2136.2, 2139.0], "text": " And the people who don't have will"}, {"timestamp": [2139.0, 2142.08], "text": " have kids that will not have this benefit."}, {"timestamp": [2142.08, 2146.88], "text": " And if everybody could get that, the the kids who are talented and wise,"}, {"timestamp": [2146.88, 2152.96], "text": " and they don't have the money, would still be able to get into the good schools and to get"}, {"timestamp": [2152.96, 2161.12], "text": " a good education and to get better jobs afterwards. Yeah. And it's not necessarily just jobs."}, {"timestamp": [2162.24, 2166.72], "text": " Here's an example of, so I'm from the American South and we have rednecks here."}, {"timestamp": [2166.72, 2167.84], "text": " There's rednecks all over the world."}, {"timestamp": [2167.84, 2169.16], "text": " They're called different things."}, {"timestamp": [2169.16, 2172.0], "text": " But part of redneck culture is that you have to be"}, {"timestamp": [2172.0, 2173.36], "text": " very self-reliant."}, {"timestamp": [2173.36, 2175.46], "text": " And part of being self-reliant means you gotta know"}, {"timestamp": [2175.46, 2176.36], "text": " what you're doing."}, {"timestamp": [2176.36, 2179.2], "text": " You gotta be able to fix your own house, fix your own car."}, {"timestamp": [2179.2, 2181.44], "text": " You gotta be able to take care of whatever issues."}, {"timestamp": [2181.44, 2184.68], "text": " And so this is why I mentioned that like AI can help"}, {"timestamp": [2184.68, 2185.96], "text": " with all aspects of life."}, {"timestamp": [2185.96, 2188.4], "text": " We mentioned earlier about relationships, right?"}, {"timestamp": [2188.4, 2191.16], "text": " So just changing your orientation to learning"}, {"timestamp": [2191.16, 2193.72], "text": " rather than thinking of just school,"}, {"timestamp": [2193.72, 2197.02], "text": " getting comfortable with upskilling yourself"}, {"timestamp": [2197.02, 2198.88], "text": " for whatever you need."}, {"timestamp": [2198.88, 2200.16], "text": " You know, younger generations"}, {"timestamp": [2200.16, 2201.32], "text": " are pretty comfortable with this."}, {"timestamp": [2201.32, 2203.12], "text": " It's weird, they actually do most of their learning"}, {"timestamp": [2203.12, 2208.24], "text": " on TikTok today. So kids these days, they come up with the craziest ideas."}, {"timestamp": [2208.24, 2215.04], "text": " Yeah, but what you're saying gets me to think about another thing. We're saying as if"}, {"timestamp": [2215.04, 2222.16], "text": " the educational system is as is and you get a better way to do the education system. But"}, {"timestamp": [2222.16, 2226.16], "text": " actually all the system would change in a way that will not be these are"}, {"timestamp": [2226.16, 2230.4], "text": " the subjects you need to know, these are the tests you need to go through, these are like the SATs"}, {"timestamp": [2230.4, 2235.2], "text": " and so forth in order to get what you need. I guess that all the system would be redefined in"}, {"timestamp": [2235.2, 2242.64], "text": " a sense because there is no real meaning in order to just rethink and memorize information, I guess."}, {"timestamp": [2243.28, 2246.9], "text": " Yeah. Yeah. So one way that you can think about education or learning"}, {"timestamp": [2246.9, 2248.82], "text": " is there's kind of three pillars."}, {"timestamp": [2248.82, 2251.74], "text": " There's competencies, there's skills and knowledge."}, {"timestamp": [2251.74, 2255.1], "text": " So competency is like, are you competent at learning,"}, {"timestamp": [2255.1, 2257.06], "text": " at education, at educating yourself?"}, {"timestamp": [2257.06, 2259.44], "text": " Do you, are you competent, you know,"}, {"timestamp": [2259.44, 2262.06], "text": " with particular domains?"}, {"timestamp": [2262.06, 2264.46], "text": " And then skills are like communication skills,"}, {"timestamp": [2264.46, 2267.2], "text": " studying skills, project management skills. And then skills are like communication skills, studying skills, project management skills."}, {"timestamp": [2267.2, 2268.88], "text": " And then knowledge is just the content."}, {"timestamp": [2268.88, 2272.28], "text": " What are the facts and figures that you have memorized?"}, {"timestamp": [2272.28, 2275.28], "text": " And so if you think of education as those three pillars,"}, {"timestamp": [2275.28, 2278.0], "text": " one, that's a very simple model,"}, {"timestamp": [2278.0, 2281.24], "text": " but it's also easy to see how AI can help"}, {"timestamp": [2281.24, 2282.74], "text": " with each of those, right?"}, {"timestamp": [2282.74, 2283.68], "text": " If I'm learning something,"}, {"timestamp": [2283.68, 2285.5], "text": " sometimes I'll tell like the chatbot,"}, {"timestamp": [2285.5, 2286.64], "text": " like, all right, quiz me on this thing,"}, {"timestamp": [2286.64, 2288.48], "text": " test how much I know, right?"}, {"timestamp": [2288.48, 2289.68], "text": " So you're testing for knowledge"}, {"timestamp": [2289.68, 2291.1], "text": " and then you can also test for skills."}, {"timestamp": [2291.1, 2293.0], "text": " Like, did I figure this thing out right?"}, {"timestamp": [2293.0, 2295.1], "text": " Am I competent on this subject?"}, {"timestamp": [2295.1, 2297.28], "text": " And so that can really, really like"}, {"timestamp": [2297.28, 2300.2], "text": " just completely revolutionize our approach to education"}, {"timestamp": [2300.2, 2301.04], "text": " across the board."}, {"timestamp": [2301.04, 2301.86], "text": " Yeah."}, {"timestamp": [2301.86, 2302.7], "text": " Yeah."}, {"timestamp": [2302.7, 2304.08], "text": " So we have a question from Yasha."}, {"timestamp": [2304.08, 2307.68], "text": " Hi, Yasha. When will it be the norm"}, {"timestamp": [2307.68, 2313.12], "text": " that employers hire staff that studied AI as a prerequisite educational component?"}, {"timestamp": [2314.24, 2319.28], "text": " I think that we're starting to see it. If you go out on the job boards, you'll see"}, {"timestamp": [2319.92, 2327.24], "text": " we're just starting to see a surge in prompt engineers. And some prompt engineering jobs pay $300,000 a year."}, {"timestamp": [2327.24, 2329.28], "text": " So I could be doing that job because I"}, {"timestamp": [2329.28, 2331.12], "text": " led the charge on this."}, {"timestamp": [2331.12, 2334.28], "text": " But what they have said is they're like,"}, {"timestamp": [2334.28, 2336.96], "text": " one job description, I think it was at Claude, actually."}, {"timestamp": [2336.96, 2340.14], "text": " They said, we understand that this is an entirely new"}, {"timestamp": [2340.14, 2341.8], "text": " discipline, so you're not going to be"}, {"timestamp": [2341.8, 2344.0], "text": " able to have more than two years of experience"}, {"timestamp": [2344.0, 2345.04], "text": " because this job did not"}, {"timestamp": [2345.04, 2353.76], "text": " exist two years ago. With that being said, as we, we, we traverse the, the bell curve of adoption, we're right now just"}, {"timestamp": [2353.76, 2360.94], "text": " approaching the, the, the leading edge, the innovators. We're not quite at the early majority of adoption. But within the"}, {"timestamp": [2360.94, 2366.92], "text": " next maybe 5 years, we should see the early majority. And so you're gonna see this huge demand."}, {"timestamp": [2366.92, 2369.4], "text": " So story time at the beginning,"}, {"timestamp": [2369.4, 2371.88], "text": " sorry, at the beginning of my IT career,"}, {"timestamp": [2371.88, 2375.68], "text": " we were at the adoption curve of like Windows servers"}, {"timestamp": [2375.68, 2378.3], "text": " and VMware virtualization and then cloud."}, {"timestamp": [2378.3, 2382.4], "text": " And so the demand for those skills went up so fast"}, {"timestamp": [2382.4, 2384.48], "text": " that it was just like, if you've got the baseline,"}, {"timestamp": [2384.48, 2385.6], "text": " then it's like promotion,"}, {"timestamp": [2385.6, 2386.42], "text": " just left and right."}, {"timestamp": [2386.42, 2388.88], "text": " Like I changed job every 18 months"}, {"timestamp": [2388.88, 2391.48], "text": " and doubled my salary in two or three years."}, {"timestamp": [2391.48, 2393.6], "text": " And I think we're gonna see the same trend"}, {"timestamp": [2393.6, 2395.04], "text": " with any AI skills."}, {"timestamp": [2395.04, 2397.92], "text": " If you're already up to speed on prompt engineering"}, {"timestamp": [2397.92, 2399.88], "text": " and cognitive architectures and chat bots"}, {"timestamp": [2399.88, 2403.1], "text": " and whatever else, then you're gonna see a huge demand"}, {"timestamp": [2403.1, 2405.36], "text": " for those job skills or AI product,"}, {"timestamp": [2405.36, 2412.16], "text": " right? Just knowing how to implement and deploy AI into services. So yeah, I don't know if that"}, {"timestamp": [2412.16, 2416.48], "text": " directly answered your question, but that's kind of where I see things going. Yeah. Yeah. Thanks"}, {"timestamp": [2416.48, 2421.6], "text": " for everyone who's asking questions, and I'll show you too. So we're starting to think about"}, {"timestamp": [2421.6, 2425.1], "text": " the future of the automation of AI."}, {"timestamp": [2425.1, 2429.04], "text": " And I want to ask you, what are the potential implications"}, {"timestamp": [2429.04, 2432.52], "text": " of artificial general intelligence on the future?"}, {"timestamp": [2432.52, 2435.0], "text": " So first, describe what the meaning of that,"}, {"timestamp": [2435.0, 2438.4], "text": " and then what would be the implications?"}, {"timestamp": [2438.4, 2441.4], "text": " Yeah, so well, first, we have to say"}, {"timestamp": [2441.4, 2444.56], "text": " that definitions of AGI, or artificial general intelligence,"}, {"timestamp": [2444.56, 2445.9], "text": " vary widely."}, {"timestamp": [2445.9, 2449.24], "text": " Some people assume that it means that one machine is smarter than all humans combined"}, {"timestamp": [2449.24, 2450.24], "text": " forever."}, {"timestamp": [2450.24, 2454.4], "text": " Some people say that it's just as smart as one person, and many definitions are somewhere"}, {"timestamp": [2454.4, 2455.4], "text": " in between."}, {"timestamp": [2455.4, 2463.16], "text": " But basically, AGI is somewhere as intelligent as people, and then higher."}, {"timestamp": [2463.16, 2465.66], "text": " One thing that I think would probably surprise people"}, {"timestamp": [2465.66, 2469.16], "text": " is that on a personal level,"}, {"timestamp": [2469.16, 2471.76], "text": " I don't think AGI is gonna change that much for individuals,"}, {"timestamp": [2471.76, 2473.1], "text": " at least not at first."}, {"timestamp": [2473.1, 2475.54], "text": " And the reason is because the collective rest of humanity"}, {"timestamp": [2475.54, 2476.82], "text": " is smarter than you."}, {"timestamp": [2476.82, 2478.38], "text": " So we're already used to living in a world"}, {"timestamp": [2478.38, 2481.3], "text": " where there's a lot more intelligence than ourselves."}, {"timestamp": [2481.3, 2484.08], "text": " And so with that in mind,"}, {"timestamp": [2484.08, 2487.6], "text": " what AGI is gonna change in the long run is alleviating"}, {"timestamp": [2487.6, 2493.68], "text": " that scarcity of intellectual labor. So as we mentioned before, there's a shortage of doctors,"}, {"timestamp": [2493.68, 2498.96], "text": " lawyers, scientists, engineers. And so, you know, one of the biggest things that companies worry"}, {"timestamp": [2498.96, 2505.88], "text": " about and nations worry about is brain drain. If the experts leave, then you have to replace them with really expensive labor."}, {"timestamp": [2505.88, 2509.84], "text": " But if everyone can have an in-house expert,"}, {"timestamp": [2509.84, 2513.88], "text": " then there's gonna be like zero shortage"}, {"timestamp": [2513.88, 2516.4], "text": " of expert knowledge and capacity."}, {"timestamp": [2516.4, 2520.0], "text": " And that's really going to accelerate the global GDP,"}, {"timestamp": [2520.0, 2522.92], "text": " global economy, like we've never seen before."}, {"timestamp": [2522.92, 2525.96], "text": " And I know that's hyperbole, but like, you know,"}, {"timestamp": [2525.96, 2529.74], "text": " GDP over the last century went up by a thousand fold."}, {"timestamp": [2529.74, 2531.88], "text": " We're going to see GDP go up by a million fold"}, {"timestamp": [2531.88, 2536.04], "text": " in the next century, just because of alleviating those,"}, {"timestamp": [2536.04, 2539.24], "text": " the scarcity, the bottlenecks of human labor."}, {"timestamp": [2539.24, 2541.98], "text": " So how that's going to play out, like I said,"}, {"timestamp": [2541.98, 2543.84], "text": " I think the biggest thing that you're going to feel"}, {"timestamp": [2543.84, 2547.6], "text": " as an individual is that the cost of necessary goods and services is going to"}, {"timestamp": [2547.6, 2549.32], "text": " go down a lot."}, {"timestamp": [2549.32, 2556.28], "text": " That's what it looks like and feels like to you on an individual level when AGI happens"}, {"timestamp": [2556.28, 2560.48], "text": " and the cost, basically the price has collapsed of a lot of things."}, {"timestamp": [2560.48, 2562.88], "text": " I hope that's what happens."}, {"timestamp": [2562.88, 2566.4], "text": " So what is the big difference between what we have right now"}, {"timestamp": [2566.4, 2568.2], "text": " and this future capability?"}, {"timestamp": [2568.2, 2570.86], "text": " What is lacking for us in order to get there?"}, {"timestamp": [2572.0, 2573.36], "text": " There's a few things."}, {"timestamp": [2573.36, 2574.72], "text": " One is autonomy."}, {"timestamp": [2574.72, 2576.08], "text": " So again, one of the research,"}, {"timestamp": [2576.08, 2577.44], "text": " one of the topics that I research is"}, {"timestamp": [2577.44, 2579.5], "text": " how do you build machines that are fully autonomous"}, {"timestamp": [2579.5, 2580.76], "text": " and trustworthy?"}, {"timestamp": [2580.76, 2583.72], "text": " And so right now they're waiting for humans, right?"}, {"timestamp": [2583.72, 2587.48], "text": " If you have, if you hypothetically had chat GPT"}, {"timestamp": [2587.48, 2590.78], "text": " solving problems all day long without any human guidance,"}, {"timestamp": [2590.78, 2591.94], "text": " it could go way faster."}, {"timestamp": [2591.94, 2595.0], "text": " But right now it's constrained by our speed,"}, {"timestamp": [2595.0, 2596.3], "text": " which we're very slow."}, {"timestamp": [2596.3, 2598.22], "text": " It's also constrained by our creativity."}, {"timestamp": [2598.22, 2600.3], "text": " We don't even know the right questions to ask."}, {"timestamp": [2600.3, 2602.66], "text": " So part of creating autonomous machines"}, {"timestamp": [2602.66, 2604.78], "text": " is getting them to ask themselves the right questions"}, {"timestamp": [2604.78, 2609.92], "text": " and getting them to set the correct objectives for themselves so that they can do the research"}, {"timestamp": [2609.92, 2615.14], "text": " and do the work without any human intervention and so that they can do it safely and reliably."}, {"timestamp": [2615.14, 2620.1], "text": " That is probably one of the primary things because right now already tools like ChatGPT"}, {"timestamp": [2620.1, 2624.0], "text": " and Claude already know more than you or I do on an individual basis."}, {"timestamp": [2624.0, 2627.84], "text": " But getting that information out and then kind of setting it loose, right?"}, {"timestamp": [2627.84, 2633.4], "text": " Taking the leash off the dog so that, you know, but you don't want to do that"}, {"timestamp": [2633.4, 2634.84], "text": " if the dog is not well-trained, right?"}, {"timestamp": [2634.84, 2639.32], "text": " So that's where we're at right now is how do you train these digital animals so that"}, {"timestamp": [2639.32, 2641.64], "text": " they don't attack your neighbor or run away or whatever?"}, {"timestamp": [2642.16, 2647.72], "text": " So, but once that happens, you know, it's all bets are off, basically."}, {"timestamp": [2648.64, 2652.36], "text": " But don't you think that that we need to involve some kind of"}, {"timestamp": [2652.36, 2657.12], "text": " common sense, morality, what we think about values in life in"}, {"timestamp": [2657.12, 2660.56], "text": " order to decide what is the direction? I guess that this is"}, {"timestamp": [2660.56, 2663.44], "text": " something that we're supposed to have as humans, I guess."}, {"timestamp": [2664.96, 2668.04], "text": " Yeah, you know, and that's a great question."}, {"timestamp": [2668.04, 2674.24], "text": " And that's actually been a primary area of my own learning and research over the last almost four years now,"}, {"timestamp": [2674.52, 2677.48], "text": " is learning how do humans develop morality?"}, {"timestamp": [2677.48, 2679.56], "text": " How do we develop values and ethics?"}, {"timestamp": [2679.72, 2680.68], "text": " Where does it come from?"}, {"timestamp": [2680.68, 2682.44], "text": " Why does it even happen in the first place?"}, {"timestamp": [2682.72, 2686.06], "text": " And so one of the things that that kind of a pattern that"}, {"timestamp": [2686.06, 2690.42], "text": " emerged is that there's a few main things that morality and"}, {"timestamp": [2690.42, 2694.88], "text": " ethics and values evolve around, or emerge from. One is social"}, {"timestamp": [2694.88, 2697.98], "text": " cohesion, right? That's why we have crime and law. It's"}, {"timestamp": [2698.18, 2704.12], "text": " basically, in the old times, human tribes, we had two basic"}, {"timestamp": [2704.42, 2705.0], "text": " impulses"}, {"timestamp": [2705.38, 2707.82], "text": " to when someone transgressed against the tribe."}, {"timestamp": [2707.82, 2711.42], "text": " And that was you punish them to get them to stop"}, {"timestamp": [2711.42, 2713.82], "text": " whatever bad behavior it was, or you eject them."}, {"timestamp": [2713.82, 2716.62], "text": " You send them out of the tribe, you banish them for good."}, {"timestamp": [2716.62, 2719.42], "text": " And we have systemized that with prisons today"}, {"timestamp": [2719.42, 2721.64], "text": " because the idea of prisons is you're too dangerous"}, {"timestamp": [2721.64, 2724.1], "text": " for society, but we can't send you to Australia."}, {"timestamp": [2724.1, 2727.76], "text": " Australia is a nation now, right? That's what the did, is they just banished people they didn't like"}, {"timestamp": [2727.76, 2728.76], "text": " to Australia."}, {"timestamp": [2728.76, 2729.76], "text": " With Siberia, if you were."}, {"timestamp": [2729.76, 2734.88], "text": " Right, right. Australia, Siberia, or wherever. You can't banish people anymore. The entire"}, {"timestamp": [2734.88, 2740.76], "text": " world is spoken for. So now we have prisons, and prisons is the modern equivalent of exiling"}, {"timestamp": [2740.76, 2745.2], "text": " someone or banishing them from the tribe, or punishing them for behavior you don't like."}, {"timestamp": [2751.76, 2758.24], "text": " But looking at the first principles, why does this happen as an animal, as a species, is one area of research. Another is hygiene, actually. Hygiene and resource allocation are another big set of"}, {"timestamp": [2758.24, 2768.72], "text": " pillars that morality and ethics evolve around. Whether it's like sexual hygiene or scarce resources, like around food,"}, {"timestamp": [2768.72, 2773.6], "text": " for instance, or water. Anytime resources are scarce, that's where you see a lot of legislation"}, {"timestamp": [2773.6, 2779.2], "text": " and morality and ethics evolving around. And so those are just some examples. But honestly,"}, {"timestamp": [2779.2, 2784.48], "text": " one of the simplest things is appealing to universal frameworks. So after World War II,"}, {"timestamp": [2788.28, 2790.52], "text": " one of the things that we did was we came together, and we created what's called the Universal Declaration of Human"}, {"timestamp": [2790.52, 2794.94], "text": " Rights, the UDHR. And it is a list of 30 principles. It's not"}, {"timestamp": [2794.94, 2798.18], "text": " a constitution, it's just a list of 30 principles that all"}, {"timestamp": [2798.18, 2806.88], "text": " nations should aspire to uphold and reinforce. And this UDHR is all the language models"}, {"timestamp": [2806.88, 2810.02], "text": " already know it, you can go on a chat, GPT, or Claude, or, you"}, {"timestamp": [2810.02, 2813.34], "text": " know, whatever, all of them right now and ask them, what is"}, {"timestamp": [2813.34, 2816.14], "text": " UDHR? And how would you implement it? And this is a"}, {"timestamp": [2816.14, 2820.26], "text": " really powerful framework that can that can, it doesn't"}, {"timestamp": [2820.26, 2823.52], "text": " necessarily steer autonomy, but it creates really good"}, {"timestamp": [2823.52, 2826.34], "text": " boundaries of what to do and what not to do."}, {"timestamp": [2826.34, 2829.56], "text": " So yeah, this is an active area of research."}, {"timestamp": [2829.56, 2832.72], "text": " And all the experiments that I've done, like I said, there's papers coming out that I'm"}, {"timestamp": [2832.72, 2834.26], "text": " participating in."}, {"timestamp": [2834.26, 2839.12], "text": " And I think that we're going to really demonstrate that there's really powerful sociological,"}, {"timestamp": [2839.12, 2843.52], "text": " philosophical, moral, and ethical frameworks that already exist, that all we need to do"}, {"timestamp": [2843.52, 2845.72], "text": " is just implement them systematically"}, {"timestamp": [2845.72, 2847.26], "text": " into these AI systems."}, {"timestamp": [2847.26, 2850.18], "text": " And at least they'll understand what we need."}, {"timestamp": [2850.18, 2852.82], "text": " Whether or not the AI machines decide"}, {"timestamp": [2852.82, 2855.38], "text": " to abide by them in the long run, that's another problem."}, {"timestamp": [2855.38, 2857.3], "text": " But I'm not too worried about that one either."}, {"timestamp": [2857.3, 2858.14], "text": " Yeah."}, {"timestamp": [2858.14, 2861.78], "text": " It reminds me of the rules from Asimov book"}, {"timestamp": [2861.78, 2863.82], "text": " that you give for robots."}, {"timestamp": [2863.82, 2866.5], "text": " I guess that it is fires from there."}, {"timestamp": [2866.5, 2869.48], "text": " So we have another question from Daniel."}, {"timestamp": [2869.48, 2871.88], "text": " David, during your previous discussion on AGI"}, {"timestamp": [2871.88, 2873.08], "text": " and your YouTube channel,"}, {"timestamp": [2873.08, 2875.92], "text": " you projected an 18 month timeframe."}, {"timestamp": [2875.92, 2878.32], "text": " Are we still within that estimation?"}, {"timestamp": [2878.32, 2880.48], "text": " So first tell us what is the estimation"}, {"timestamp": [2880.48, 2883.04], "text": " and then you tell us if we're within that."}, {"timestamp": [2883.04, 2883.88], "text": " Yeah, yeah."}, {"timestamp": [2883.88, 2887.84], "text": " So for context, it was March or April of this year,"}, {"timestamp": [2887.84, 2889.4], "text": " I made a video on my YouTube channel"}, {"timestamp": [2889.4, 2891.84], "text": " and I said, AGI within 18 months,"}, {"timestamp": [2891.84, 2895.76], "text": " here's a bunch of projects and papers to back up that claim."}, {"timestamp": [2895.76, 2896.6], "text": " Excuse me."}, {"timestamp": [2896.6, 2899.2], "text": " And it was one of my most popular videos of all time."}, {"timestamp": [2899.2, 2904.2], "text": " And since then, we've had basically on a daily basis,"}, {"timestamp": [2904.6, 2907.6], "text": " there are at least 50 new AI papers"}, {"timestamp": [2907.6, 2910.18], "text": " that come out literally every day of the week."}, {"timestamp": [2910.18, 2913.84], "text": " On top of that, there's a lot more business investment,"}, {"timestamp": [2913.84, 2915.64], "text": " there's a lot more competitors,"}, {"timestamp": [2915.64, 2919.48], "text": " Microsoft OpenAI, Clawed, Google DeepMind,"}, {"timestamp": [2919.48, 2921.76], "text": " there's conversations on the national level"}, {"timestamp": [2921.76, 2924.48], "text": " and international level about AI research,"}, {"timestamp": [2924.48, 2927.04], "text": " the US Congress, EU, UN,"}, {"timestamp": [2927.04, 2929.36], "text": " literally everyone is paying attention to AI."}, {"timestamp": [2929.36, 2932.2], "text": " And so we're at this really powerful inflection point"}, {"timestamp": [2932.2, 2934.8], "text": " where people are aware of what's happening,"}, {"timestamp": [2934.8, 2936.92], "text": " they're investing in it, so follow the money, right?"}, {"timestamp": [2936.92, 2941.24], "text": " If the, where the money goes, results follow."}, {"timestamp": [2941.24, 2944.68], "text": " And the business incentive to do it is there."}, {"timestamp": [2944.68, 2945.04], "text": " And all of the conversations that to do it is there. And"}, {"timestamp": [2945.08, 2947.76], "text": " all of the conversations that I've had with business leaders,"}, {"timestamp": [2948.04, 2951.68], "text": " there is a lot of interest in literally every sector of the"}, {"timestamp": [2951.68, 2956.52], "text": " economy to make AI happen and to and to take it to whatever"}, {"timestamp": [2956.6, 2958.92], "text": " degree it can. And that's actually part of my mission is"}, {"timestamp": [2958.92, 2963.84], "text": " to help businesses understand how to implement AI safely and"}, {"timestamp": [2963.84, 2965.0], "text": " productively."}, {"timestamp": [2965.34, 2968.02], "text": " And so just because of the economic incentive"}, {"timestamp": [2968.02, 2971.96], "text": " to get to AGI, yes, it will happen by the end of 2024."}, {"timestamp": [2971.96, 2974.66], "text": " Arguably, you could say that it's happening right now."}, {"timestamp": [2974.66, 2977.08], "text": " It's just how smart is it and how fast is it"}, {"timestamp": [2977.08, 2978.18], "text": " and how cheap is it?"}, {"timestamp": [2978.18, 2980.44], "text": " So it'll get smarter, faster and cheaper"}, {"timestamp": [2980.44, 2983.98], "text": " over the next 12 to 16 months."}, {"timestamp": [2983.98, 2985.52], "text": " Yeah, I see."}, {"timestamp": [2985.52, 2989.0], "text": " We're going back to the fact that you're very pro AI"}, {"timestamp": [2989.0, 2990.64], "text": " and you're very optimistic"}, {"timestamp": [2990.64, 2994.68], "text": " and you think the risks are not as huge as people might think."}, {"timestamp": [2994.68, 2998.16], "text": " So how would you explain all the people are saying"}, {"timestamp": [2998.16, 3001.96], "text": " that we need to be aware and to get all the regulations"}, {"timestamp": [3001.96, 3004.12], "text": " and it could destroy us."}, {"timestamp": [3004.12, 3007.36], "text": " It's like the atomic bomb, so forth."}, {"timestamp": [3007.36, 3010.68], "text": " How do you relate to these claims?"}, {"timestamp": [3010.68, 3012.8], "text": " Well, so I'm glad you used the race car analogy"}, {"timestamp": [3012.8, 3014.12], "text": " because race cars have two pedals."}, {"timestamp": [3014.12, 3016.32], "text": " They have gas and they also have brakes."}, {"timestamp": [3016.32, 3018.56], "text": " You can't win the race without brakes."}, {"timestamp": [3018.56, 3020.88], "text": " If all you have is gas, you go into the wall."}, {"timestamp": [3020.88, 3025.68], "text": " And so regulations and research and checks and licensing and all that other kind of fun stuff, those are all part of the wall. And so regulations and research and checks and licensing"}, {"timestamp": [3025.68, 3027.8], "text": " and all that other kind of fun stuff,"}, {"timestamp": [3027.8, 3029.64], "text": " those are all part of the process."}, {"timestamp": [3029.64, 3031.6], "text": " You need gas and you need brakes."}, {"timestamp": [3031.6, 3035.48], "text": " And so in this case, the analogy of gas is you accelerate,"}, {"timestamp": [3035.48, 3038.2], "text": " you deploy AI, you research AI."}, {"timestamp": [3038.2, 3040.0], "text": " But at the same time, you have brakes"}, {"timestamp": [3040.0, 3042.08], "text": " that kind of slow things down to make sure"}, {"timestamp": [3042.08, 3044.92], "text": " that you have control, because that's why you have braking"}, {"timestamp": [3044.92, 3046.2], "text": " systems in cars, in race make sure that you have control. Because that's why you have braking systems in cars,"}, {"timestamp": [3046.2, 3048.68], "text": " in race cars, is to maintain control."}, {"timestamp": [3048.68, 3051.08], "text": " Because if you have too much inertia, too much momentum"}, {"timestamp": [3051.08, 3054.12], "text": " carrying you in one direction, you lose control."}, {"timestamp": [3054.12, 3055.92], "text": " And so if you need to change direction,"}, {"timestamp": [3055.92, 3058.16], "text": " you need to slow down, and then you change direction."}, {"timestamp": [3058.16, 3059.64], "text": " That's literally driving."}, {"timestamp": [3059.64, 3061.76], "text": " If you're going too fast around a curve,"}, {"timestamp": [3061.76, 3063.44], "text": " you drive off the road."}, {"timestamp": [3063.44, 3065.6], "text": " So what you do is you slow down to make sure"}, {"timestamp": [3065.6, 3069.38], "text": " that you can maintain control and change direction as needed."}, {"timestamp": [3069.38, 3071.38], "text": " On the other side, there's people that are worried"}, {"timestamp": [3071.38, 3073.56], "text": " about slowing down too much, because obviously,"}, {"timestamp": [3073.56, 3075.96], "text": " the slower you're going, the safer you are."}, {"timestamp": [3075.96, 3077.98], "text": " This is a principle that I abide by,"}, {"timestamp": [3077.98, 3082.24], "text": " which is I prefer to keep my body at low kinetic energy,"}, {"timestamp": [3082.24, 3084.04], "text": " because high kinetic energy, like skiing,"}, {"timestamp": [3084.04, 3085.44], "text": " is how you get hurt, or"}, {"timestamp": [3085.44, 3087.44], "text": " motorcycles or whatever."}, {"timestamp": [3087.44, 3091.1], "text": " And so, yeah, so lower energy is always safer."}, {"timestamp": [3091.1, 3095.6], "text": " So the idea is balancing safety versus getting there, right?"}, {"timestamp": [3095.6, 3097.92], "text": " Because we don't want it to take 10,000 years to get there."}, {"timestamp": [3097.92, 3101.08], "text": " We want to get there as soon as possible, but we also want to get there as safely as"}, {"timestamp": [3101.08, 3102.08], "text": " possible."}, {"timestamp": [3102.08, 3103.32], "text": " So that's kind of the dichotomy."}, {"timestamp": [3103.32, 3106.32], "text": " And while I am optimistic and I am for acceleration,"}, {"timestamp": [3106.32, 3110.32], "text": " I am also very much in favor of control, safety, stability,"}, {"timestamp": [3110.32, 3111.88], "text": " and steering correctly."}, {"timestamp": [3111.88, 3114.6], "text": " It's all about steering."}, {"timestamp": [3114.6, 3117.2], "text": " So steering equals regulation?"}, {"timestamp": [3117.2, 3118.52], "text": " How do you see the steering?"}, {"timestamp": [3118.52, 3120.48], "text": " They're slowing down."}, {"timestamp": [3120.48, 3121.44], "text": " That's a good question."}, {"timestamp": [3121.44, 3124.6], "text": " So steering, it's what are you steering towards, right?"}, {"timestamp": [3124.6, 3126.32], "text": " Because whenever you get in a car,"}, {"timestamp": [3126.32, 3127.6], "text": " you're trying to get somewhere."}, {"timestamp": [3127.6, 3129.72], "text": " And so knowing where you're going"}, {"timestamp": [3129.72, 3131.08], "text": " is what you're steering towards."}, {"timestamp": [3131.08, 3132.62], "text": " And you have to go around obstacles."}, {"timestamp": [3132.62, 3134.28], "text": " You have to make sure that you don't drive in the ditch."}, {"timestamp": [3134.28, 3136.82], "text": " And if, you know, if there's a detour,"}, {"timestamp": [3136.82, 3138.36], "text": " you'd go around the detour."}, {"timestamp": [3138.36, 3140.84], "text": " And so one of the conversations that we're having,"}, {"timestamp": [3140.84, 3143.48], "text": " and when I say we, I mean like all of us on YouTube"}, {"timestamp": [3143.48, 3144.96], "text": " and the researchers and stuff,"}, {"timestamp": [3144.96, 3145.0], "text": " the conversation that we're having is and when I say we, I mean like, all of us on YouTube and the researchers and stuff."}, {"timestamp": [3145.0, 3146.36], "text": " The conversation that we're having is,"}, {"timestamp": [3146.36, 3148.12], "text": " what are we steering towards?"}, {"timestamp": [3148.12, 3150.7], "text": " What is the outcome that we're looking for?"}, {"timestamp": [3150.7, 3153.24], "text": " And there's not really any consensus yet,"}, {"timestamp": [3153.24, 3155.28], "text": " but the message that I have is that,"}, {"timestamp": [3155.28, 3157.48], "text": " is that my mission is that we're steering"}, {"timestamp": [3157.48, 3159.68], "text": " towards what I call utopia."}, {"timestamp": [3159.68, 3161.56], "text": " And so utopia is a very loaded term,"}, {"timestamp": [3161.56, 3165.38], "text": " but I define utopia as high standard of living for everyone,"}, {"timestamp": [3165.38, 3169.7], "text": " high social mobility for everyone, and high individual liberty for everyone."}, {"timestamp": [3169.7, 3174.06], "text": " And so if we get to a point, if we agree that that is the direction that everyone wants"}, {"timestamp": [3174.06, 3178.66], "text": " to go, then once everyone agrees that's the destination, we can chart a course and we"}, {"timestamp": [3178.66, 3180.22], "text": " can steer towards that."}, {"timestamp": [3180.22, 3184.86], "text": " And it's not just AI, it's economics, it's all technology, it's government, literally"}, {"timestamp": [3184.86, 3187.6], "text": " everything orbits around what is the destination,"}, {"timestamp": [3187.6, 3189.4], "text": " what is the mission we're trying to achieve,"}, {"timestamp": [3189.4, 3190.7], "text": " and that's how you steer towards it."}, {"timestamp": [3190.7, 3194.2], "text": " But right now, there's not really any agreement on where we're going,"}, {"timestamp": [3194.2, 3197.3], "text": " and that's part of the reason that politics is so nasty right now."}, {"timestamp": [3197.3, 3199.4], "text": " That's part of the reason that there's wars and stuff,"}, {"timestamp": [3199.4, 3202.7], "text": " because humans, by and large, can't agree on which direction to go"}, {"timestamp": [3202.7, 3204.2], "text": " or how to get there."}, {"timestamp": [3204.2, 3206.68], "text": " Yeah, and what do you think about the meeting"}, {"timestamp": [3206.68, 3210.92], "text": " between Biden and all of the head of AI that they've done?"}, {"timestamp": [3210.92, 3213.02], "text": " Do you think that they would agree with that kind?"}, {"timestamp": [3213.02, 3215.28], "text": " I'm not sure if this is the direction"}, {"timestamp": [3215.28, 3216.4], "text": " that they're considering."}, {"timestamp": [3216.4, 3218.08], "text": " What do you think?"}, {"timestamp": [3218.08, 3220.4], "text": " Well, I don't always agree with what some"}, {"timestamp": [3220.4, 3223.92], "text": " of the tech leaders say or do, but sometimes I do."}, {"timestamp": [3223.92, 3226.56], "text": " And Sam Altman has talked a lot about how"}, {"timestamp": [3227.12, 3231.6], "text": " he believes that technology is the primary thing that increases quality of life for people."}, {"timestamp": [3231.6, 3236.4], "text": " And I tend to agree with that because 200 years ago, before modern medicine, I would have been"}, {"timestamp": [3236.4, 3244.88], "text": " dead like five times over by now. I would not be alive as 37 years old in 200 years ago. And so,"}, {"timestamp": [3244.56, 3248.7], "text": " as 37 years old in 200 years ago. And so I also wouldn't have a lot of the cool games"}, {"timestamp": [3248.7, 3251.42], "text": " and toys and experiences because also I wouldn't have been"}, {"timestamp": [3251.42, 3253.84], "text": " able to travel to France and Canada and everywhere else"}, {"timestamp": [3253.84, 3256.8], "text": " that I've been because jet airliners didn't exist"}, {"timestamp": [3256.8, 3258.92], "text": " 200 years ago, unless I was really wealthy,"}, {"timestamp": [3258.92, 3261.88], "text": " but even then it would have taken three months to travel."}, {"timestamp": [3261.88, 3266.24], "text": " So technology does, I think there is general consensus that technology"}, {"timestamp": [3266.24, 3271.56], "text": " improves the quality of life for people, or it can, again, it's dual use. At the same"}, {"timestamp": [3271.56, 3278.52], "text": " time, technology can increase prosperity, which is what businesses want. Another aspect,"}, {"timestamp": [3278.52, 3282.4], "text": " and this is the government's interest, is that, you know, because governments are trying"}, {"timestamp": [3282.4, 3285.2], "text": " to optimize for a few things. They want to increase their GDP."}, {"timestamp": [3285.2, 3287.7], "text": " They also want to increase their geopolitical power,"}, {"timestamp": [3287.7, 3290.6], "text": " their ability to project power, and their military power."}, {"timestamp": [3290.6, 3292.4], "text": " AI can help with all of those."}, {"timestamp": [3292.4, 3295.1], "text": " And so, there's a lot of alignment of incentives"}, {"timestamp": [3295.1, 3297.8], "text": " between us individuals, businesses, and governments."}, {"timestamp": [3297.8, 3300.6], "text": " And so, I see those as kind of the three pillars of society."}, {"timestamp": [3300.6, 3303.2], "text": " And if we can align all of our interests together,"}, {"timestamp": [3303.2, 3317.0], "text": " say, yes, we all want to be safer. we all want to have more technology that can help our way of life, we all want to have more economic productivity, if we can agree on all those things, then yes, we can move in the right direction."}, {"timestamp": [3317.0, 3326.2], "text": " Now, the wrench in the gears might be that some people want to stack the deck in their favor, And that's one thing that people are worried about right now. And so one of the ways that that could happen"}, {"timestamp": [3326.2, 3328.04], "text": " is called regulatory capture,"}, {"timestamp": [3328.04, 3332.16], "text": " where basically businesses try and get an enforced monopoly"}, {"timestamp": [3332.16, 3333.98], "text": " by manipulating government policy."}, {"timestamp": [3333.98, 3336.46], "text": " So that's one of the biggest things we need to worry about."}, {"timestamp": [3336.46, 3338.04], "text": " And this is true for all new technologies."}, {"timestamp": [3338.04, 3339.4], "text": " It's not just AI."}, {"timestamp": [3339.4, 3341.64], "text": " Regulatory capture, they did that for a while"}, {"timestamp": [3341.64, 3343.2], "text": " with radio frequencies, actually,"}, {"timestamp": [3343.2, 3344.92], "text": " where nobody was allowed to,"}, {"timestamp": [3344.92, 3346.88], "text": " unless you paid the government a lot of money,"}, {"timestamp": [3346.88, 3348.64], "text": " you'd get your radio station shut down."}, {"timestamp": [3348.64, 3350.96], "text": " Now over, of course, radio stations have been around"}, {"timestamp": [3350.96, 3353.0], "text": " for decades, more than a hundred years now."}, {"timestamp": [3353.0, 3355.8], "text": " Now we understand how to make sure that it's done fairly."}, {"timestamp": [3356.84, 3359.18], "text": " Some of the meetings that business leaders have had"}, {"timestamp": [3359.18, 3362.7], "text": " with Congress, US Congress, have talked about"}, {"timestamp": [3362.7, 3366.08], "text": " how to do that correctly and fairly, and they pointed to"}, {"timestamp": [3366.08, 3370.86], "text": " the failures that we had around the internet, namely around social media and other harms"}, {"timestamp": [3370.86, 3371.98], "text": " that have been done."}, {"timestamp": [3371.98, 3377.28], "text": " And so this is why politicians today are paying a little bit more attention to this new technology,"}, {"timestamp": [3377.28, 3382.52], "text": " because the idea, the prevailing idea in the 90s and early 2000s was government non-interference,"}, {"timestamp": [3382.52, 3383.6], "text": " particularly in America."}, {"timestamp": [3383.6, 3385.48], "text": " Europe is usually a little bit more progressive,"}, {"timestamp": [3385.48, 3387.84], "text": " but it was like, let the private industry"}, {"timestamp": [3387.84, 3391.48], "text": " figure it out for itself, but that didn't go well."}, {"timestamp": [3391.48, 3393.68], "text": " So now we're gonna see a little bit more."}, {"timestamp": [3393.68, 3394.64], "text": " You're right, now we're gonna see"}, {"timestamp": [3394.64, 3397.08], "text": " a little bit more government oversight,"}, {"timestamp": [3397.08, 3399.0], "text": " but we gotta make sure that all the right voices"}, {"timestamp": [3399.0, 3400.88], "text": " are at the table, not just the tech leaders."}, {"timestamp": [3400.88, 3403.68], "text": " We need to make sure that the voices of academics"}, {"timestamp": [3403.68, 3410.56], "text": " and you and me and that private citizens, that our interests are represented at the highest levels as well."}, {"timestamp": [3410.56, 3412.08], "text": " Good question."}, {"timestamp": [3412.08, 3420.12], "text": " Yeah. I don't know if that could be done. I feel that powerful men get more powerful"}, {"timestamp": [3420.12, 3426.96], "text": " through private sector or politics or whatever. And I feel that what you're describing is the other way around,"}, {"timestamp": [3426.96, 3429.44], "text": " meaning the power would go down and be equal,"}, {"timestamp": [3429.44, 3433.68], "text": " more equal and more available and accessible for people."}, {"timestamp": [3433.68, 3436.8], "text": " And for me, when I think about the fearful side,"}, {"timestamp": [3436.8, 3442.88], "text": " I think about these huge enterprises getting much, much bigger"}, {"timestamp": [3442.88, 3445.76], "text": " and having more and more control over our lives."}, {"timestamp": [3445.76, 3446.76], "text": " Yeah."}, {"timestamp": [3446.76, 3447.76], "text": " Maybe you're right."}, {"timestamp": [3447.76, 3452.28], "text": " Well, so you're right, though, because power begets more power, right?"}, {"timestamp": [3452.28, 3455.88], "text": " The more money you have, the more influence you have, the more you can consolidate it."}, {"timestamp": [3455.88, 3457.52], "text": " We've seen this many times through history."}, {"timestamp": [3457.52, 3461.7], "text": " This actually, the first, one of the first times this really happened in a big way that"}, {"timestamp": [3461.7, 3466.64], "text": " caused the collapse of society or contributed to the collapse of society was in ancient Rome."}, {"timestamp": [3466.64, 3469.12], "text": " So in ancient Rome, wealthy landowners"}, {"timestamp": [3469.12, 3471.28], "text": " used the wealth of their land to buy more land."}, {"timestamp": [3471.28, 3472.12], "text": " And guess what?"}, {"timestamp": [3472.12, 3473.32], "text": " The more land they had, the more wealth"}, {"timestamp": [3473.32, 3475.66], "text": " they had, which means that they could strong arm and get"}, {"timestamp": [3475.66, 3476.24], "text": " more land."}, {"timestamp": [3476.24, 3480.76], "text": " And so eventually, in ancient Rome, most of the valuable land"}, {"timestamp": [3480.76, 3482.6], "text": " was owned by a very few number of people,"}, {"timestamp": [3482.6, 3486.2], "text": " which completely made the Roman economy lopsided."}, {"timestamp": [3486.2, 3490.4], "text": " Now that didn't single-handedly cause the collapse of Rome, but it certainly contributed"}, {"timestamp": [3490.4, 3493.34], "text": " because then society was less and less fair."}, {"timestamp": [3493.34, 3497.08], "text": " And so this goes back to, okay, well what is fair?"}, {"timestamp": [3497.08, 3502.02], "text": " And so there's this policy that I'm working on and brainstorming, I call it the Fair Deal."}, {"timestamp": [3502.02, 3508.08], "text": " It's inspired by the New Deal from FDR in America in the past and the Square Deal"}, {"timestamp": [3508.32, 3511.32], "text": " by Teddy Roosevelt in the past. So the fair deal is about, let's"}, {"timestamp": [3511.32, 3514.12], "text": " have a not just a national conversation, but a global"}, {"timestamp": [3514.12, 3518.36], "text": " conversation about fairness. What is fair to businesses? What"}, {"timestamp": [3518.36, 3520.76], "text": " is fair to governments? But most importantly, what's fair to us?"}, {"timestamp": [3521.12, 3523.44], "text": " And that goes back to renegotiating that social"}, {"timestamp": [3523.44, 3525.44], "text": " contract that I mentioned, which is,"}, {"timestamp": [3526.88, 3532.08], "text": " what is the relationship and responsibilities of government, business, and voters or citizens?"}, {"timestamp": [3532.08, 3538.56], "text": " And so renegotiating that is one of the most important conversations. And like I said,"}, {"timestamp": [3538.56, 3546.32], "text": " I don't think it needs to be just a national conversation. I think it needs to be a global conversation of all citizens,"}, {"timestamp": [3546.32, 3549.36], "text": " of all nations, and between all nations around the world."}, {"timestamp": [3549.36, 3552.76], "text": " Because AI is going to really, really disrupt the status quo."}, {"timestamp": [3552.76, 3554.32], "text": " It's going to upset the apple cart."}, {"timestamp": [3554.32, 3558.96], "text": " And so we have an opportunity to move society to be more fair."}, {"timestamp": [3558.96, 3561.84], "text": " But of course, we have to decide, OK, what does fair mean?"}, {"timestamp": [3561.84, 3563.4], "text": " What does that look like?"}, {"timestamp": [3563.4, 3566.16], "text": " And that is an opportunity that we"}, {"timestamp": [3566.16, 3572.0], "text": " could miss. And so, you know, as optimistic as I am, I see a lot of potential for it to go well."}, {"timestamp": [3572.0, 3578.24], "text": " It could also go poorly if we fail to step up and say, you know, we're going to participate in"}, {"timestamp": [3578.24, 3583.28], "text": " making sure that this is more fair moving forward. So stay tuned. I'll have more information about"}, {"timestamp": [3583.28, 3586.72], "text": " the fair deal idea coming in the future."}, {"timestamp": [3586.72, 3588.28], "text": " In your YouTube channel?"}, {"timestamp": [3588.28, 3589.92], "text": " Yes, correct."}, {"timestamp": [3589.92, 3594.24], "text": " Okay. So we're almost done with time. It's been fascinating. I hope we will have another"}, {"timestamp": [3594.24, 3599.72], "text": " discussion, David. It's been very, very interesting for me and for the viewers. So let's finish"}, {"timestamp": [3599.72, 3605.28], "text": " with the last question that I have. What is your number one tip for entrepreneurs today?"}, {"timestamp": [3605.28, 3614.32], "text": " Oh, boy. If you're just getting started on an AI startup, double down on the experience and"}, {"timestamp": [3614.32, 3619.76], "text": " expertise you already have. And the reason that I say that is because generative AI has given a lot"}, {"timestamp": [3619.76, 3624.32], "text": " of people the ability to pick low-hanging fruit outside of their areas of expertise."}, {"timestamp": [3625.28, 3627.56], "text": " people the ability to pick low hanging fruit outside of their areas of expertise, all the low hanging fruit is gone."}, {"timestamp": [3627.56, 3629.68], "text": " So I can't remember her name right now."}, {"timestamp": [3629.68, 3633.12], "text": " The former CEO of Yahoo, she said that..."}, {"timestamp": [3633.12, 3634.12], "text": " Myers?"}, {"timestamp": [3634.12, 3636.32], "text": " Yeah, yeah, yeah, yeah."}, {"timestamp": [3636.32, 3641.36], "text": " She said that we're going to have a whole crop of failed startups."}, {"timestamp": [3641.36, 3645.6], "text": " It's going to burn through the startup area like a wildfire, but what's"}, {"timestamp": [3645.6, 3649.76], "text": " left is going to be the startups that were stronger."}, {"timestamp": [3649.76, 3653.48], "text": " And one thing that I've noticed about all of my clients, the ones that are doing the"}, {"timestamp": [3653.48, 3659.16], "text": " best, is that they are bringing pre-existing experience and expertise to the table, and"}, {"timestamp": [3659.16, 3662.36], "text": " they're just adding generative AI to their toolbox."}, {"timestamp": [3662.36, 3667.2], "text": " So what I caution people against doing right now is don't get into another domain that you"}, {"timestamp": [3667.2, 3670.64], "text": " have no business in, because you you have come to the false"}, {"timestamp": [3670.64, 3673.64], "text": " belief that just because it's easy to do on chat GPT, you can"}, {"timestamp": [3673.64, 3677.84], "text": " build a company around it. So really focus on the like, if"}, {"timestamp": [3677.84, 3681.72], "text": " you've got 20 years of experience in something, use"}, {"timestamp": [3681.72, 3684.4], "text": " that I have, there's a friend of mine, he lives just up the road."}, {"timestamp": [3684.96, 3685.08], "text": " His background is in gaming and VR. And he tried to do all kinds and something, use that. There's a friend of mine, he lives just up the road."}, {"timestamp": [3685.08, 3687.18], "text": " His background is in gaming and VR,"}, {"timestamp": [3687.18, 3689.28], "text": " and he tried to do all kinds of other stuff with AI."}, {"timestamp": [3689.28, 3691.84], "text": " I'm like, no, focus on gaming and VR,"}, {"timestamp": [3691.84, 3695.38], "text": " because you already have a decade of experience with this."}, {"timestamp": [3695.38, 3697.36], "text": " This will just turn it up faster."}, {"timestamp": [3697.36, 3699.92], "text": " So that's the primary tip that I give to pretty much anyone,"}, {"timestamp": [3699.92, 3703.6], "text": " clients or otherwise, for entrepreneurs today"}, {"timestamp": [3703.6, 3705.2], "text": " with generative AI."}, {"timestamp": [3705.2, 3707.4], "text": " Yeah, I totally agree with what you're saying."}, {"timestamp": [3707.4, 3713.0], "text": " You know, I'm creating a course on creating AI products and I always like try to focus"}, {"timestamp": [3713.0, 3718.68], "text": " on that's the technology, but the idea and the value that you bring is much more important"}, {"timestamp": [3718.68, 3719.68], "text": " than technologies."}, {"timestamp": [3719.68, 3724.64], "text": " This is just a tool to deliver what you want to deliver in the services or products that"}, {"timestamp": [3724.64, 3726.6], "text": " you really need to build."}, {"timestamp": [3726.6, 3727.44], "text": " So-"}, {"timestamp": [3727.44, 3728.28], "text": " Exactly, yep."}, {"timestamp": [3728.28, 3729.24], "text": " 100% agree."}, {"timestamp": [3729.24, 3733.24], "text": " Okay, so first I want to thank you for your time."}, {"timestamp": [3733.24, 3736.16], "text": " It's been very insightful, interesting talk for me"}, {"timestamp": [3736.16, 3737.08], "text": " and for the viewers."}, {"timestamp": [3737.08, 3739.28], "text": " So thank you, David, for your time."}, {"timestamp": [3739.28, 3740.6], "text": " You're welcome."}, {"timestamp": [3740.6, 3743.26], "text": " And last thing, where could people hear more"}, {"timestamp": [3743.26, 3746.48], "text": " about your YouTube channel and contact you?"}, {"timestamp": [3746.48, 3749.64], "text": " Yeah, so my primary platform is obviously YouTube."}, {"timestamp": [3749.64, 3752.88], "text": " Just search for David Shapiro AI, I come right up."}, {"timestamp": [3752.88, 3756.86], "text": " I'm also on Patreon if people want one-on-one conversations"}, {"timestamp": [3756.86, 3760.08], "text": " or consultations, just sign up on my Patreon."}, {"timestamp": [3760.08, 3762.24], "text": " And then also LinkedIn."}, {"timestamp": [3762.24, 3763.92], "text": " Primarily what I'm looking for on LinkedIn"}, {"timestamp": [3763.92, 3767.8], "text": " is policy and research connections."}, {"timestamp": [3767.8, 3770.16], "text": " So if you're in the university system"}, {"timestamp": [3770.16, 3772.56], "text": " or the government system, and you wanna collaborate"}, {"timestamp": [3772.56, 3775.2], "text": " on either cognitive architectures or the fair deal,"}, {"timestamp": [3775.2, 3777.54], "text": " that kind of stuff, reach out to me on LinkedIn."}, {"timestamp": [3777.54, 3780.4], "text": " But otherwise YouTube and Patreon are the primary ways"}, {"timestamp": [3780.4, 3782.68], "text": " for most people to connect."}, {"timestamp": [3782.68, 3786.08], "text": " So I really encourage people to do all of that. So thank"}, {"timestamp": [3786.08, 3790.16], "text": " you, David, again for your time. And I'm sure we're going to have another discussion if you'll"}, {"timestamp": [3790.16, 3796.8], "text": " be willing to do so. Yeah, hit me up whenever. Looking forward to it. Sure. Thanks. And to all"}, {"timestamp": [3796.8, 3803.68], "text": " you changemakers out there, thank you for joining us. See you another week. Bye-bye."}, {"timestamp": [3798.89, 3802.65], "text": " See you another week. Bye-bye."}]}