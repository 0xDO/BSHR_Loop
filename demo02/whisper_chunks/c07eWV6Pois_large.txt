{"text": " Hello everybody, Stuart from Riku here. Today I want to talk all about fine-tuning and we're going to show you how you can do fine-tuning with OpenAI without really knowing how to code by using Postman and sort of trying to make it as simple as possible for you to sort of follow along at home if you want to fine-tune yourself. So there are a few things that you'll need for this. You'll need Postman, which is an application that lets you send API requests. You'll need access to OpenAI of course, and you'll need access to a text editor. I like to use a text editor called Sublime because it is useful and easy to edit multiple pieces of text at the same time. And really it's that simple. So let's have a look at how the OpenAI documentation works with fine-tuning and then let's go through the process of actually doing the whole thing in one go. So it's super, super simple. Here we have the open AI documentation you'll see we are in the API documentation and you'll notice there is fine tunes down here and there is all the information that you need to create the fine tune and then there is the information that you need to actually get the ID of that fine-tune and to use it. So first of all when you are creating a fine-tune what you need is a file and you're probably thinking how the hell do I get the file and it's it's super simple because there is a step before the fine-tuning which probably trips a lot of people up and that is actually Uploading the file to open AI. So this is a step that you need to do. First of all It's another API request that you can do in postman We're going to show you how to do that and how simple it really is. So we go back to the open AI documentation and we can look at the files here and we see the upload file. And basically what we need to do, we need to send a POST request to this API, this URL. We need to include the header value, authorization, bearer, and our API key token. We need to put a purpose on it, and we need to put a file. And this is super simple to do, but just to go back a step, to get your API key from OpenAI, you can go to your account, API keys, you can click one. Here's one I've created today. I can copy the whole of this including the SK at the front and then I have that ready for where I need it within Postman and I will delete this by the end of this video so please don't try and use it yourself because it won't work. So once we have that API key, we can then go to Postman and we can start having fun with what we're doing. So first of all, we have the uploading files. We have that URL. We have it as a post request, which is what we wanted. We have the header. Ignore all of the stuff that Postman automatically puts. You don't have to do anything with that. And we are just going into the authorization. We added this, and we've added bearer, and then our API key token here. And what you need to do, you need to go to the body, you need to put form data here, you put purpose in the first one, and this is text, and you put the value as fine tune, and then you put file, and what you need to do when you have the file is, you see here we have text or file, we choose file and then it will give us something. So if I just do another one, file two here, and I hit file, it's then gonna give me the select files. So I can upload a file. And we need to make sure that we have the file in the right format and that's probably one of the major difficulties with fine-tuning with OpenAI so we're going to go over that in a second as well but you'll see here I have the file I have this ridingcoach.jsonl and I've hit send and it's uploaded that file for me and The response I get from this is I get the fact that it's successful. So it's a 200 request response which is great and I can come down and I can see this is the file ID which I will need for the fine-tuning in a minute It's given some other information such as the file name when it's created Uploaded, you know all of this fun stuff. But the only thing we really care about is this ID here. So Let's go back a step and let's look at how we get the JSON L file So when we are actually creating a JSON-L file, compared to sort of normal JSON, what you are doing is you're providing matches of JSON pairs. It's really just like one JSON pair, two JSON pairs, three JSON pairs, four JSON pairs. And because you're doing this in the JSON-L, JSON-L is pretty much JSON-List. So you're doing a list of these JSON pairs. And the way that it works for this fine-tuning is we have the prompt and we have the completion. And the way that I've done this is I've taken a few shortcuts today and I've taken information from a GitHub from somebody called David Shapiro. So David Shapiro has created this creative writing coach and he has a YouTube channel here where he talks about it and he has a part one and part two and you'll see it here. I will link this down below if you want to check it out. It's good to see the process of how he gets the data set together because really what he's done is he's gone to a Reddit, a subreddit where people put their stories and their writing and their fiction and he's taken that and he's created the data set because of that. So what we've done is we've gone to this GitHub, we've checked it out and we see that he has a Jason L. Where was it? It was somewhere. We had the creative writing coach Jason L here and we have all of these prompts and it's already done in the format that we need it to be. I've tweaked it slightly just because I like to have an input and output as a field so I'll show you how that looks as well but what you could do is if you really wanted to you could just copy this into a file, into a text editor, save it as a JSON-L, and you'd have something ready to fine tune exactly off the bat. You'll see from this data, there are 202 examples. So, you know, a lot of this fine tuning stuff, people sort of recommend that you have a minimum of say 50, but the more you have the better. So having 200, maybe 500, maybe a thousand, even more than that, you're going to get a better output, but it's also going to cost more to train if you're using OpenAI, and it takes longer to get the data set together. So that's some of the things to sort of keep in mind when you're when you're playing around with this. But because we've got this data set together. So that's some of the things to sort of keep in mind when you're playing around with this. But because we've got this data set already from David Shapiro, thank you David, awesome, and it saves me a lot of time in putting one together. What we can do is we can then sort of put this into our text editor like I have done here. And you're probably looking at this and thinking, oh my God, that is a lot of text. But let's go through it a little bit in more detail. You'll see that we have one. So this is all on the same line. And this is one complete example. We have the prompt. We have the prompt up until here, where we then have the completion. So this is what you are putting in to the AI. And when you hit generate, this is what you're expecting to come out, everything from this completion with the feedback. So what I've done and edited David Shapiro's work is I've added this story colon and I've added this completion colon at the at this this feedback colon. So we know when we put this in we're going to put a story and we're going to put story colon in first and when we get the output from the AI we're going to expect the AI to give us this feedback at the start. This is just personal preference you know there's no real reason why I've done this or why I haven't done this but it's just sort of handy to sort of work like that. And you'll see that we have, if I scroll right down, there's 202. So that matches the number of examples. And the other thing to note with preparing this data is that you need to make sure that you are making sure that everything is validated with JSON format. Which means if there are any line breaks at all, you need to change those line breaks for forward slash N. If you have quotation marks like this where we have hell at the top here, you need to make sure that you are formatting it in a way that works with the JSON. And there is always one handy way to check when you are doing these things and to see whether your example is valid JSON or not. And the way to do that is to copy the full example. So you'll see that I'm copying everything from one here. What I'm going to do is I'm going to go back to my browser. I'm going to go into this website which is jasonlint.com. I can delete everything in here. I can copy that. So this is everything from one and I can validate that JSON and if I get this valid JSON result That means that everything is cool and I don't have to worry about that so if you are building out if you're building out a longer data set and you're doing this, you know and Mistakes can happen and it's all about trying to identify and rectify those mistakes and it's not always obvious So if you are having an example data set of 50 examples or 100 examples, I know it could be a pain to copy each one and check the JSON individually, but if you are seeing that you are getting an error message saying that the JSON is not valid or whatever, then this is a way to check it quickly. You can just go to jasonlint.com, copy each example individually, wait to get the valid JSON message. If you don't get this is a way to check it quickly. You can just go to jasonlint.com, copy each example individually, wait to get the valid JSON message. If you don't get a valid JSON message, then there is something that you need to fix within that example. And that's just a quick way to sort of debug and make sure that your data set is as good as it should be. So if we come back in to our browser, we can then look at what we've got to do for the fine tuning. So to create a fine tune, what we need to do, we need to send a post request to this URL, and we need to keep, we need a header of content type application JSON. We need a header of authorization bearer and our API key token. And we need our training file. So we've already got the file ID because we got that from the previous step where we uploaded the file. So if we go into Postman now, we can do this and I guess one of the other things to note is there are a bunch of optional fields here. Notably we have an optional field called model where you can choose Ada, Babbage, Curie or DaVinci. There are more advanced settings like the number of epochs. The more epochs you have, the better the data set is going to, the better the fine-tune is gonna perform. So it's worth sort of having a look at that, but I believe the more epochs you choose, the higher the cost of the training. And the default is four, and we're just gonna use the default value. So ultimately, a lot of time, the default values are worth just sort of keeping as they are. But if we're going into more advanced fine tuning, then you might want to tweak some of these later. But what we're really looking at when we are creating this fine tune, we're going to be looking at the training file, which is the file ID. We're going to be looking at the training file, which is the file ID. We're going to be looking at the model, we're going to include this field because we're going to do this with DaVinci, and we are going to include the suffix. So we can just give it a name so that we know if we're creating multiple fine tunes, we know which one this is. And it's just nice for us in case we are having more of an issue with remembering our data. So if we go back into Postman now, we can look at this. So we have the uploading file, this is what we've just done. And what I like to do within Postman just to keep everything organized is to create workspaces, and then you can create a folder with everything that you need so that you can use it again and again and just tweak the values as you go. So we can take what we had from the uploading file. We have the file ID here. We're gonna copy this file ID, and we're gonna go to this create fine tune. And I'll show you all the settings here. We have the post request. This is post. We have the URL from documentation. We have the headers, content type, application, JSON, authorization, bearer, and our API key here. Remember, just ignore all the stuff that Postman puts there. It's irrelevant. You don't have to worry about that. And then we come into our body. And the body this time is gonna be raw. And because we have this content type application JSON, it's going to automatically assume that it is JSON. So it's gonna put this format, which just helps you to sort of see the data because it puts it in, you know, you have this red coloring and this blue coloring for the different body. Body parameters. So what we can do, we can come in, we can take our training file. We can paste we can paste that ID here, we can put the model as DaVinci, and we can put our suffix as Rikku Testing, or we could say, you know, Creative Writing Coach, anything that we'd wanna say, we could do so. And everything then is set up as we like. So what we can do is we can hit send on this request. So we hit send on the request. This is going to send all of that data to OpenAI and it's going to start training this file. So then we can see, you know, we're getting all of this data. We get the fine tune ID, which is important. This is a value that we want to keep. We have all the hyper parameters that we didn't edit. These are just the default values. We have some information on what we are doing, model, DaVinci, we're getting which file it is using, and we get the status. So we get the status as pending. This is all good. Looks great to me. So now that we've created the fine tune, it's going to actually do that. And it can take a bit of time to actually go through and get this correct, and to actually do the fine-tuning process. So we can go back to the OpenAI documentation, and we can see that there is a list of fine-tune, list fine-tunes where you're gonna get all of your fine-tunes that you've created from this one endpoint, or you're gonna get all of your fine tunes that you've created from this one endpoint. Or, if we want to get information from a specific fine tune, what we can do is we can send a GET request to this URL with our fine tune ID at the end. So we'd replace this bit here with our fine tune ID at the end so we'd replace this bit here with our fine tune ID and we just have our authorization bearer token as what we need to do. So let's have a look at doing that. If we go back to Postman, so we've copied our ID that we've got here from this create fine tune. We go to our info on specific fine tune. We can take this, make sure it's a get request. At the end, we paste in this ID and we have our authorization bearer set up. There is nothing in the body. And we can just hit send on this. And you'll see that you are getting the, you are getting information on it. So it says when it's created, it sends what status it is. So it says that this has been processed already. So it's running. You get the cost $24.53 to do this fine-tune. 200 examples. The examples are fairly large in size. So yeah I think that's a fair amount. And you can just wait until it says sort of completed or finished processing. And that's pretty much it with the fine tuning. And what we like to sort of show after this is if you come into OpenAI and you come into the playground what you will see is You will have your fine tunes appearing in here and Because this one is still fine tuning it won't appear yet, so we will have a DaVinci fine-tune appearing here when it is finished doing. This may take half an hour, it might take an hour, so it's just worth sort of going away and then coming back to it later. And what I'll do is I'll create a follow-up video where once this is processed, we will use that fine-tune, we will create some content with it and we'll also show you how you can put that within Riku for your use. So I hope this video has been useful. There hasn't really been any sort of coding involved. It's been really just the process of taking the data that we have, putting it into Postman, and hitting Send a few times, and taking the response from one API request, and taking the relevant data, like the fine-tune ID, and feeding it into the next request. And by doing this, you can create some really powerful, um, fine tune data sets, which are going to give you better outputs from your AI generations than just using a raw model. If you want to go really, really specific on a certain area. So this is sort of the bare bones basic on how to fine tune a model with OpenAI without using code and just sort of doing it as simple as possible. What we're going to do in the next video is we're going to show you how you can actually use this model within OpenAI's Playground and then also how we can import that model into Riku so that we can use it within the Rikku playground or for a share link or you know other ways that you can use the fine-tune model that you've just created. If you have any questions about fine-tuning with OpenAI please leave them in the comments below. Again thank you for David Shapiro for creating this data set, saves me a lot of time in actually creating one myself. And I'll provide links to Sublime, Postman, David Shapiro's YouTube, and Jason Lint, all of the tools that I use when I'm doing something like this. And I hope that it helps you also in creating your data sets and making them easy into fine-tuned models. And if you want to learn more about AI and be in a fun place with a fun community where we're really passionate about having all of the best large language models in a single place, consider signing up for Riku.ai today. You can take your fine-tuned models, you can add them to Riku, you can use them like any other model that you have. We have all of the best stuff from OpenAI, Cohere, AI21, LF Alpha, Muse API, all of the best open source models. And it's a really sort of fun place to build, experiment and use all of this AI within your business and within your life. So yeah, check it out today. Thank you. So yeah, check it out today. Thank you.", "chunks": [{"timestamp": [0.0, 6.24], "text": " Hello everybody, Stuart from Riku here. Today I want to talk all about fine-tuning and we're"}, {"timestamp": [6.24, 11.0], "text": " going to show you how you can do fine-tuning with OpenAI without really knowing how to"}, {"timestamp": [11.0, 16.56], "text": " code by using Postman and sort of trying to make it as simple as possible for you to sort"}, {"timestamp": [16.56, 29.56], "text": " of follow along at home if you want to fine-tune yourself. So there are a few things that you'll need for this. You'll need Postman, which is an application that lets you send API"}, {"timestamp": [29.56, 36.48], "text": " requests. You'll need access to OpenAI of course, and you'll need access to a text"}, {"timestamp": [36.48, 41.56], "text": " editor. I like to use a text editor called Sublime because it is useful and"}, {"timestamp": [41.56, 46.0], "text": " easy to edit multiple pieces of text at the same time."}, {"timestamp": [46.0, 48.5], "text": " And really it's that simple."}, {"timestamp": [48.5, 53.7], "text": " So let's have a look at how the OpenAI documentation works with fine-tuning"}, {"timestamp": [53.7, 59.2], "text": " and then let's go through the process of actually doing the whole thing in one go."}, {"timestamp": [59.2, 62.2], "text": " So it's super, super simple."}, {"timestamp": [62.2, 65.16], "text": " Here we have"}, {"timestamp": [65.4, 67.4], "text": " the open AI documentation"}, {"timestamp": [67.72, 75.28], "text": " you'll see we are in the API documentation and you'll notice there is fine tunes down here and"}, {"timestamp": [76.0, 79.56], "text": " there is all the information that you need to create the fine tune and"}, {"timestamp": [80.8, 86.36], "text": " then there is the information that you need to actually get the ID of that"}, {"timestamp": [86.36, 93.64], "text": " fine-tune and to use it. So first of all when you are creating a fine-tune what"}, {"timestamp": [93.64, 99.68], "text": " you need is a file and you're probably thinking how the hell do I get the file"}, {"timestamp": [99.68, 104.72], "text": " and it's it's super simple because there is a step before the fine-tuning which"}, {"timestamp": [104.72, 107.64], "text": " probably trips a lot of people up and that is actually"}, {"timestamp": [108.08, 113.98], "text": " Uploading the file to open AI. So this is a step that you need to do. First of all"}, {"timestamp": [114.0, 117.36], "text": " It's another API request that you can do in postman"}, {"timestamp": [117.4, 123.28], "text": " We're going to show you how to do that and how simple it really is. So we go back to the open AI"}, {"timestamp": [123.82, 129.8], "text": " documentation and we can look at the files here and we see"}, {"timestamp": [129.8, 136.8], "text": " the upload file. And basically what we need to do, we need to send a POST request to this"}, {"timestamp": [136.8, 147.64], "text": " API, this URL. We need to include the header value, authorization, bearer, and our API key token."}, {"timestamp": [147.64, 154.4], "text": " We need to put a purpose on it, and we need to put a file."}, {"timestamp": [154.4, 162.18], "text": " And this is super simple to do, but just to go back a step, to get your API key from OpenAI,"}, {"timestamp": [162.18, 165.72], "text": " you can go to your account, API keys, you can click"}, {"timestamp": [165.72, 173.6], "text": " one. Here's one I've created today. I can copy the whole of this including the SK"}, {"timestamp": [173.6, 179.2], "text": " at the front and then I have that ready for where I need it within Postman and I"}, {"timestamp": [179.2, 185.88], "text": " will delete this by the end of this video so please don't try and use it yourself because it won't work."}, {"timestamp": [185.88, 192.76], "text": " So once we have that API key, we can then go to Postman and we can start having fun"}, {"timestamp": [192.76, 200.88], "text": " with what we're doing. So first of all, we have the uploading files. We have that URL."}, {"timestamp": [200.88, 205.84], "text": " We have it as a post request, which is what we wanted. We have the header."}, {"timestamp": [205.84, 210.08], "text": " Ignore all of the stuff that Postman automatically puts."}, {"timestamp": [210.08, 212.02], "text": " You don't have to do anything with that."}, {"timestamp": [212.02, 215.2], "text": " And we are just going into the authorization."}, {"timestamp": [215.2, 219.68], "text": " We added this, and we've added bearer,"}, {"timestamp": [219.68, 223.02], "text": " and then our API key token here."}, {"timestamp": [223.02, 227.2], "text": " And what you need to do, you need to go to the body, you need"}, {"timestamp": [227.2, 234.48], "text": " to put form data here, you put purpose in the first one, and this is text, and you put"}, {"timestamp": [234.48, 245.06], "text": " the value as fine tune, and then you put file, and what you need to do when you have the file is,"}, {"timestamp": [248.14, 252.96], "text": " you see here we have text or file, we choose file and then it will give us something."}, {"timestamp": [252.96, 256.38], "text": " So if I just do another one, file two here,"}, {"timestamp": [258.0, 261.6], "text": " and I hit file, it's then gonna give me the select files."}, {"timestamp": [261.6, 264.28], "text": " So I can upload a file."}, {"timestamp": [264.28, 266.12], "text": " And we need to make sure that we have"}, {"timestamp": [266.12, 271.92], "text": " the file in the right format and that's probably one of the major difficulties"}, {"timestamp": [271.92, 277.28], "text": " with fine-tuning with OpenAI so we're going to go over that in a second as"}, {"timestamp": [277.28, 282.76], "text": " well but you'll see here I have the file I have this ridingcoach.jsonl and"}, {"timestamp": [282.76, 287.2], "text": " I've hit send and it's uploaded that file for me and"}, {"timestamp": [287.5, 294.96], "text": " The response I get from this is I get the fact that it's successful. So it's a 200 request response"}, {"timestamp": [295.42, 297.42], "text": " which is great and"}, {"timestamp": [297.52, 303.9], "text": " I can come down and I can see this is the file ID which I will need for the fine-tuning in a minute"}, {"timestamp": [304.22, 308.18], "text": " It's given some other information such as the file name when it's created"}, {"timestamp": [308.92, 315.44], "text": " Uploaded, you know all of this fun stuff. But the only thing we really care about is this ID here. So"}, {"timestamp": [316.32, 321.32], "text": " Let's go back a step and let's look at how we get the JSON L file"}, {"timestamp": [323.04, 328.9], "text": " So when we are actually creating a JSON-L file, compared to sort"}, {"timestamp": [328.9, 335.18], "text": " of normal JSON, what you are doing is you're providing matches of JSON pairs."}, {"timestamp": [335.18, 339.98], "text": " It's really just like one JSON pair, two JSON pairs, three JSON pairs, four JSON"}, {"timestamp": [339.98, 350.4], "text": " pairs. And because you're doing this in the JSON-L, JSON-L is pretty much JSON-List. So you're doing a list of these JSON pairs. And the way that it works for this"}, {"timestamp": [350.4, 356.92], "text": " fine-tuning is we have the prompt and we have the completion. And the way that"}, {"timestamp": [356.92, 361.52], "text": " I've done this is I've taken a few shortcuts today and I've taken"}, {"timestamp": [361.52, 365.0], "text": " information from a GitHub"}, {"timestamp": [365.04, 368.44], "text": " from somebody called David Shapiro."}, {"timestamp": [368.44, 372.44], "text": " So David Shapiro has created this creative writing coach"}, {"timestamp": [372.44, 376.44], "text": " and he has a YouTube channel here"}, {"timestamp": [376.44, 380.96], "text": " where he talks about it and he has a part one and part two"}, {"timestamp": [380.96, 382.32], "text": " and you'll see it here."}, {"timestamp": [382.32, 384.6], "text": " I will link this down below if you want to check it out."}, {"timestamp": [384.6, 387.26], "text": " It's good to see the process of how he gets the data set"}, {"timestamp": [387.26, 392.86], "text": " together because really what he's done is he's gone to a Reddit, a subreddit"}, {"timestamp": [392.86, 398.1], "text": " where people put their stories and their writing and their fiction and"}, {"timestamp": [398.1, 402.5], "text": " he's taken that and he's created the data set because of that. So what we've"}, {"timestamp": [402.5, 405.28], "text": " done is we've gone to this GitHub, we've checked it out"}, {"timestamp": [405.28, 418.48], "text": " and we see that he has a Jason L. Where was it? It was somewhere. We had the creative writing coach"}, {"timestamp": [418.48, 430.32], "text": " Jason L here and we have all of these prompts and it's already done in the format that we need it to be. I've tweaked it slightly just because I like to have an input and"}, {"timestamp": [430.32, 438.12], "text": " output as a field so I'll show you how that looks as well but what you could do"}, {"timestamp": [438.12, 446.9], "text": " is if you really wanted to you could just copy this into a file, into a text editor, save it as a JSON-L,"}, {"timestamp": [448.28, 450.4], "text": " and you'd have something ready to fine tune"}, {"timestamp": [450.4, 451.92], "text": " exactly off the bat."}, {"timestamp": [451.92, 456.92], "text": " You'll see from this data, there are 202 examples."}, {"timestamp": [457.4, 460.72], "text": " So, you know, a lot of this fine tuning stuff,"}, {"timestamp": [460.72, 465.94], "text": " people sort of recommend that you have a minimum of say 50, but the more you have"}, {"timestamp": [465.94, 470.86], "text": " the better. So having 200, maybe 500, maybe a thousand, even more than that,"}, {"timestamp": [470.86, 474.94], "text": " you're going to get a better output, but it's also going to cost more to train if"}, {"timestamp": [474.94, 480.88], "text": " you're using OpenAI, and it takes longer to get the data set together. So"}, {"timestamp": [480.88, 484.7], "text": " that's some of the things to sort of keep in mind when you're when you're"}, {"timestamp": [484.7, 489.98], "text": " playing around with this. But because we've got this data set together. So that's some of the things to sort of keep in mind when you're playing around with this. But because we've got this data set already from David Shapiro, thank"}, {"timestamp": [489.98, 495.74], "text": " you David, awesome, and it saves me a lot of time in putting one together. What we can"}, {"timestamp": [495.74, 504.68], "text": " do is we can then sort of put this into our text editor like I have done here. And you're"}, {"timestamp": [504.68, 506.36], "text": " probably looking at this and thinking,"}, {"timestamp": [506.36, 508.7], "text": " oh my God, that is a lot of text."}, {"timestamp": [508.7, 512.08], "text": " But let's go through it a little bit in more detail."}, {"timestamp": [512.08, 513.88], "text": " You'll see that we have one."}, {"timestamp": [513.88, 516.14], "text": " So this is all on the same line."}, {"timestamp": [517.0, 518.92], "text": " And this is one complete example."}, {"timestamp": [518.92, 520.12], "text": " We have the prompt."}, {"timestamp": [521.04, 525.0], "text": " We have the prompt up until here,"}, {"timestamp": [525.5, 528.26], "text": " where we then have the completion."}, {"timestamp": [528.26, 533.08], "text": " So this is what you are putting in to the AI."}, {"timestamp": [534.22, 536.78], "text": " And when you hit generate,"}, {"timestamp": [536.78, 540.58], "text": " this is what you're expecting to come out,"}, {"timestamp": [540.58, 543.46], "text": " everything from this completion with the feedback."}, {"timestamp": [543.46, 545.08], "text": " So what I've done and edited"}, {"timestamp": [545.08, 553.3], "text": " David Shapiro's work is I've added this story colon and I've added this"}, {"timestamp": [553.3, 560.86], "text": " completion colon at the at this this feedback colon. So we know when we put"}, {"timestamp": [560.86, 564.1], "text": " this in we're going to put a story and we're going to put story colon in first"}, {"timestamp": [564.1, 568.1], "text": " and when we get the output from the AI we're going to expect"}, {"timestamp": [568.1, 574.04], "text": " the AI to give us this feedback at the start. This is just personal preference"}, {"timestamp": [574.04, 578.88], "text": " you know there's no real reason why I've done this or why I haven't done this but"}, {"timestamp": [578.88, 587.2], "text": " it's just sort of handy to sort of work like that. And you'll see that we have, if I scroll"}, {"timestamp": [587.2, 595.12], "text": " right down, there's 202. So that matches the number of examples. And the other"}, {"timestamp": [595.12, 601.28], "text": " thing to note with preparing this data is that you need to make sure that you"}, {"timestamp": [601.28, 606.42], "text": " are making sure that everything is validated with JSON"}, {"timestamp": [606.42, 611.7], "text": " format. Which means if there are any line breaks at all, you need to change those"}, {"timestamp": [611.7, 618.7], "text": " line breaks for forward slash N. If you have quotation marks like this where we"}, {"timestamp": [618.7, 626.0], "text": " have hell at the top here, you need to make sure that you are formatting it in a way that works with the JSON."}, {"timestamp": [626.0, 632.0], "text": " And there is always one handy way to check when you are doing these things"}, {"timestamp": [632.0, 636.0], "text": " and to see whether your example is valid JSON or not."}, {"timestamp": [636.0, 641.0], "text": " And the way to do that is to copy the full example."}, {"timestamp": [641.0, 644.0], "text": " So you'll see that I'm copying everything from one here."}, {"timestamp": [644.0, 650.2], "text": " What I'm going to do is I'm going to go back to my browser. I'm going to go into"}, {"timestamp": [650.2, 656.74], "text": " this website which is jasonlint.com. I can delete everything in here. I can"}, {"timestamp": [656.74, 663.16], "text": " copy that. So this is everything from one and I can validate that JSON and if I"}, {"timestamp": [663.16, 665.52], "text": " get this valid JSON result"}, {"timestamp": [665.64, 670.06], "text": " That means that everything is cool and I don't have to worry about that"}, {"timestamp": [670.16, 676.16], "text": " so if you are building out if you're building out a longer data set and you're doing this, you know and"}, {"timestamp": [677.24, 683.78], "text": " Mistakes can happen and it's all about trying to identify and rectify those mistakes and it's not always obvious"}, {"timestamp": [683.84, 685.64], "text": " So if you are having an"}, {"timestamp": [685.64, 690.72], "text": " example data set of 50 examples or 100 examples, I know it could be a pain to"}, {"timestamp": [690.72, 695.32], "text": " copy each one and check the JSON individually, but if you are seeing that"}, {"timestamp": [695.32, 699.2], "text": " you are getting an error message saying that the JSON is not valid or whatever,"}, {"timestamp": [699.2, 704.96], "text": " then this is a way to check it quickly. You can just go to jasonlint.com, copy"}, {"timestamp": [704.96, 705.24], "text": " each example individually, wait to get the valid JSON message. If you don't get this is a way to check it quickly. You can just go to jasonlint.com, copy each"}, {"timestamp": [705.24, 709.12], "text": " example individually, wait to get the valid JSON message. If you don't get a"}, {"timestamp": [709.12, 712.8], "text": " valid JSON message, then there is something that you need to fix within"}, {"timestamp": [712.8, 718.8], "text": " that example. And that's just a quick way to sort of debug and make sure that your"}, {"timestamp": [718.8, 729.2], "text": " data set is as good as it should be. So if we come back in to our browser, we can then look at what"}, {"timestamp": [729.2, 734.04], "text": " we've got to do for the fine tuning. So to create a fine tune, what we need to do, we"}, {"timestamp": [734.04, 745.0], "text": " need to send a post request to this URL, and we need to keep, we need a header of content type application JSON."}, {"timestamp": [745.1, 749.26], "text": " We need a header of authorization bearer"}, {"timestamp": [749.26, 751.54], "text": " and our API key token."}, {"timestamp": [751.54, 754.04], "text": " And we need our training file."}, {"timestamp": [755.46, 758.06], "text": " So we've already got the file ID"}, {"timestamp": [758.06, 759.86], "text": " because we got that from the previous step"}, {"timestamp": [759.86, 761.54], "text": " where we uploaded the file."}, {"timestamp": [761.54, 766.68], "text": " So if we go into Postman now, we can do this and I guess"}, {"timestamp": [766.68, 772.8], "text": " one of the other things to note is there are a bunch of optional fields here."}, {"timestamp": [772.8, 777.76], "text": " Notably we have an optional field called model where you can choose Ada, Babbage,"}, {"timestamp": [777.76, 786.8], "text": " Curie or DaVinci. There are more advanced settings like the number of epochs. The more epochs you have,"}, {"timestamp": [786.8, 790.64], "text": " the better the data set is going to,"}, {"timestamp": [790.64, 792.86], "text": " the better the fine-tune is gonna perform."}, {"timestamp": [792.86, 796.04], "text": " So it's worth sort of having a look at that,"}, {"timestamp": [796.04, 799.32], "text": " but I believe the more epochs you choose,"}, {"timestamp": [799.32, 802.2], "text": " the higher the cost of the training."}, {"timestamp": [802.2, 803.8], "text": " And the default is four,"}, {"timestamp": [803.8, 812.08], "text": " and we're just gonna use the default value. So ultimately, a lot of time, the default values are worth just sort of keeping as they are."}, {"timestamp": [812.08, 817.92], "text": " But if we're going into more advanced fine tuning, then you might want to tweak some of these later."}, {"timestamp": [817.92, 821.76], "text": " But what we're really looking at when we are creating this fine tune, we're going to be"}, {"timestamp": [821.76, 825.36], "text": " looking at the training file, which is the file ID. We're going to be looking at the training file, which is the file ID."}, {"timestamp": [828.48, 836.08], "text": " We're going to be looking at the model, we're going to include this field because we're going to do this with DaVinci, and we are going to include the suffix. So we can just give it a name"}, {"timestamp": [836.08, 849.52], "text": " so that we know if we're creating multiple fine tunes, we know which one this is. And it's just nice for us in case we are having more of an issue with remembering"}, {"timestamp": [849.52, 850.92], "text": " our data."}, {"timestamp": [850.92, 857.0], "text": " So if we go back into Postman now, we can look at this."}, {"timestamp": [857.0, 861.28], "text": " So we have the uploading file, this is what we've just done."}, {"timestamp": [861.28, 865.22], "text": " And what I like to do within Postman just to keep everything organized"}, {"timestamp": [865.22, 866.86], "text": " is to create workspaces,"}, {"timestamp": [866.86, 868.22], "text": " and then you can create a folder"}, {"timestamp": [868.22, 869.88], "text": " with everything that you need"}, {"timestamp": [869.88, 871.66], "text": " so that you can use it again and again"}, {"timestamp": [871.66, 873.76], "text": " and just tweak the values as you go."}, {"timestamp": [873.76, 876.9], "text": " So we can take what we had from the uploading file."}, {"timestamp": [876.9, 879.02], "text": " We have the file ID here."}, {"timestamp": [879.02, 881.3], "text": " We're gonna copy this file ID,"}, {"timestamp": [881.3, 883.14], "text": " and we're gonna go to this create fine tune."}, {"timestamp": [883.14, 885.12], "text": " And I'll show you all the settings here."}, {"timestamp": [885.12, 886.76], "text": " We have the post request."}, {"timestamp": [886.76, 888.22], "text": " This is post."}, {"timestamp": [888.22, 890.66], "text": " We have the URL from documentation."}, {"timestamp": [891.6, 895.12], "text": " We have the headers, content type, application,"}, {"timestamp": [895.12, 899.74], "text": " JSON, authorization, bearer, and our API key here."}, {"timestamp": [899.74, 901.58], "text": " Remember, just ignore all the stuff"}, {"timestamp": [901.58, 903.08], "text": " that Postman puts there."}, {"timestamp": [903.08, 904.28], "text": " It's irrelevant."}, {"timestamp": [904.28, 905.68], "text": " You don't have to worry about that."}, {"timestamp": [906.92, 908.68], "text": " And then we come into our body."}, {"timestamp": [908.68, 911.8], "text": " And the body this time is gonna be raw."}, {"timestamp": [911.8, 916.12], "text": " And because we have this content type application JSON,"}, {"timestamp": [916.12, 920.06], "text": " it's going to automatically assume that it is JSON."}, {"timestamp": [920.06, 921.8], "text": " So it's gonna put this format,"}, {"timestamp": [921.8, 925.36], "text": " which just helps you to sort of see the data"}, {"timestamp": [925.6, 929.64], "text": " because it puts it in, you know, you have this red coloring and this blue coloring"}, {"timestamp": [929.9, 932.7], "text": " for the different body."}, {"timestamp": [936.14, 937.14], "text": " Body parameters."}, {"timestamp": [938.54, 942.86], "text": " So what we can do, we can come in, we can take our training file."}, {"timestamp": [943.84, 946.24], "text": " We can paste we can paste that ID here,"}, {"timestamp": [947.9, 950.56], "text": " we can put the model as DaVinci,"}, {"timestamp": [951.74, 955.72], "text": " and we can put our suffix as Rikku Testing,"}, {"timestamp": [955.72, 960.42], "text": " or we could say, you know, Creative Writing Coach,"}, {"timestamp": [960.42, 964.18], "text": " anything that we'd wanna say, we could do so."}, {"timestamp": [965.3, 969.68], "text": " And everything then is set up as we like."}, {"timestamp": [969.68, 972.9], "text": " So what we can do is we can hit send on this request."}, {"timestamp": [973.98, 976.04], "text": " So we hit send on the request."}, {"timestamp": [976.04, 980.52], "text": " This is going to send all of that data to OpenAI"}, {"timestamp": [980.52, 984.46], "text": " and it's going to start training this file."}, {"timestamp": [984.46, 988.64], "text": " So then we can see, you know, we're getting all of this data."}, {"timestamp": [988.64, 993.08], "text": " We get the fine tune ID, which is important."}, {"timestamp": [993.08, 995.14], "text": " This is a value that we want to keep."}, {"timestamp": [995.14, 998.52], "text": " We have all the hyper parameters that we didn't edit."}, {"timestamp": [998.52, 1000.36], "text": " These are just the default values."}, {"timestamp": [1000.36, 1003.72], "text": " We have some information on what we are doing,"}, {"timestamp": [1003.72, 1005.28], "text": " model, DaVinci,"}, {"timestamp": [1005.28, 1011.68], "text": " we're getting which file it is using, and we get the status."}, {"timestamp": [1011.68, 1014.28], "text": " So we get the status as pending."}, {"timestamp": [1014.28, 1016.28], "text": " This is all good."}, {"timestamp": [1016.28, 1018.28], "text": " Looks great to me."}, {"timestamp": [1018.28, 1021.68], "text": " So now that we've created the fine tune,"}, {"timestamp": [1021.68, 1024.52], "text": " it's going to actually do that."}, {"timestamp": [1024.52, 1028.12], "text": " And it can take a bit of time to actually go through"}, {"timestamp": [1028.12, 1031.4], "text": " and get this correct, and to actually do"}, {"timestamp": [1031.4, 1033.14], "text": " the fine-tuning process."}, {"timestamp": [1033.14, 1036.64], "text": " So we can go back to the OpenAI documentation,"}, {"timestamp": [1036.64, 1040.54], "text": " and we can see that there is a list of fine-tune,"}, {"timestamp": [1040.54, 1042.0], "text": " list fine-tunes where you're gonna get"}, {"timestamp": [1042.0, 1044.88], "text": " all of your fine-tunes that you've created"}, {"timestamp": [1044.88, 1046.3], "text": " from this one endpoint, or you're gonna get all of your fine tunes that you've created from this one endpoint."}, {"timestamp": [1046.3, 1050.8], "text": " Or, if we want to get information from a specific fine tune,"}, {"timestamp": [1050.8, 1061.6], "text": " what we can do is we can send a GET request to this URL with our fine tune ID at the end."}, {"timestamp": [1061.6, 1065.34], "text": " So we'd replace this bit here with our fine tune ID at the end so we'd replace this bit here with our fine tune ID and we"}, {"timestamp": [1065.34, 1072.12], "text": " just have our authorization bearer token as what we need to do. So let's have a"}, {"timestamp": [1072.12, 1088.36], "text": " look at doing that. If we go back to Postman, so we've copied our ID that we've got here from this create fine tune."}, {"timestamp": [1088.36, 1092.16], "text": " We go to our info on specific fine tune."}, {"timestamp": [1092.16, 1097.6], "text": " We can take this, make sure it's a get request."}, {"timestamp": [1097.6, 1105.0], "text": " At the end, we paste in this ID and we have our authorization bearer set up."}, {"timestamp": [1105.0, 1106.44], "text": " There is nothing in the body."}, {"timestamp": [1107.72, 1109.62], "text": " And we can just hit send on this."}, {"timestamp": [1111.36, 1115.2], "text": " And you'll see that you are getting the,"}, {"timestamp": [1116.22, 1118.02], "text": " you are getting information on it."}, {"timestamp": [1118.02, 1122.4], "text": " So it says when it's created, it sends what status it is."}, {"timestamp": [1122.4, 1124.9], "text": " So it says that this has been processed already."}, {"timestamp": [1126.4, 1138.6], "text": " So it's running. You get the cost $24.53 to do this fine-tune. 200 examples. The examples"}, {"timestamp": [1138.6, 1145.0], "text": " are fairly large in size. So yeah I think that's a fair amount."}, {"timestamp": [1145.0, 1152.0], "text": " And you can just wait until it says sort of completed or finished processing."}, {"timestamp": [1152.0, 1156.0], "text": " And that's pretty much it with the fine tuning."}, {"timestamp": [1156.0, 1162.0], "text": " And what we like to sort of show after this is"}, {"timestamp": [1162.0, 1166.28], "text": " if you come into"}, {"timestamp": [1171.84, 1175.24], "text": " OpenAI and you come into the playground what you will see is"}, {"timestamp": [1179.08, 1180.28], "text": " You will have your fine tunes appearing in"}, {"timestamp": [1182.28, 1182.48], "text": " here and"}, {"timestamp": [1186.18, 1192.22], "text": " Because this one is still fine tuning it won't appear yet, so we will have a DaVinci fine-tune appearing here when it is finished doing. This may"}, {"timestamp": [1192.22, 1196.26], "text": " take half an hour, it might take an hour, so it's just worth sort of going away"}, {"timestamp": [1196.26, 1199.74], "text": " and then coming back to it later. And what I'll do is I'll create a follow-up"}, {"timestamp": [1199.74, 1205.88], "text": " video where once this is processed, we will use that fine-tune, we will create some"}, {"timestamp": [1205.88, 1212.24], "text": " content with it and we'll also show you how you can put that within Riku for"}, {"timestamp": [1212.24, 1217.88], "text": " your use. So I hope this video has been useful. There hasn't really been any sort"}, {"timestamp": [1217.88, 1226.48], "text": " of coding involved. It's been really just the process of taking the data that we have,"}, {"timestamp": [1226.48, 1231.8], "text": " putting it into Postman, and hitting Send a few times,"}, {"timestamp": [1231.8, 1235.36], "text": " and taking the response from one API request,"}, {"timestamp": [1235.36, 1238.72], "text": " and taking the relevant data, like the fine-tune ID,"}, {"timestamp": [1238.72, 1241.24], "text": " and feeding it into the next request."}, {"timestamp": [1241.24, 1245.84], "text": " And by doing this, you can create some really powerful, um,"}, {"timestamp": [1245.92, 1250.68], "text": " fine tune data sets, which are going to give you better outputs from your AI"}, {"timestamp": [1250.68, 1255.04], "text": " generations than just using a raw model. If you want to go really, really"}, {"timestamp": [1255.04, 1262.68], "text": " specific on a certain area. So this is sort of the bare bones basic on how to"}, {"timestamp": [1262.7, 1266.24], "text": " fine tune a model with OpenAI without"}, {"timestamp": [1266.24, 1271.28], "text": " using code and just sort of doing it as simple as possible. What we're going to"}, {"timestamp": [1271.28, 1275.84], "text": " do in the next video is we're going to show you how you can actually use this"}, {"timestamp": [1275.84, 1280.28], "text": " model within OpenAI's Playground and then also how we can import that model"}, {"timestamp": [1280.28, 1286.62], "text": " into Riku so that we can use it within the Rikku playground or for a"}, {"timestamp": [1286.62, 1291.3], "text": " share link or you know other ways that you can use the fine-tune model that"}, {"timestamp": [1291.3, 1296.86], "text": " you've just created. If you have any questions about fine-tuning with OpenAI"}, {"timestamp": [1296.86, 1301.9], "text": " please leave them in the comments below. Again thank you for David Shapiro for"}, {"timestamp": [1301.9, 1306.68], "text": " creating this data set, saves me a lot of time in actually creating one myself."}, {"timestamp": [1306.68, 1311.16], "text": " And I'll provide links to Sublime, Postman,"}, {"timestamp": [1311.16, 1315.92], "text": " David Shapiro's YouTube, and Jason Lint,"}, {"timestamp": [1315.92, 1317.36], "text": " all of the tools that I use"}, {"timestamp": [1317.36, 1318.96], "text": " when I'm doing something like this."}, {"timestamp": [1318.96, 1321.76], "text": " And I hope that it helps you also"}, {"timestamp": [1321.76, 1323.14], "text": " in creating your data sets"}, {"timestamp": [1323.14, 1327.36], "text": " and making them easy into fine-tuned models."}, {"timestamp": [1327.36, 1333.44], "text": " And if you want to learn more about AI and be in a fun place with a fun community where we're"}, {"timestamp": [1333.44, 1337.28], "text": " really passionate about having all of the best large language models in a single place,"}, {"timestamp": [1337.28, 1342.64], "text": " consider signing up for Riku.ai today. You can take your fine-tuned models, you can add them to"}, {"timestamp": [1342.64, 1345.5], "text": " Riku, you can use them like any other model that you have."}, {"timestamp": [1345.5, 1353.2], "text": " We have all of the best stuff from OpenAI, Cohere, AI21, LF Alpha, Muse API, all of the best open source models."}, {"timestamp": [1353.2, 1359.8], "text": " And it's a really sort of fun place to build, experiment and use all of this AI within your business and within your life."}, {"timestamp": [1359.8, 1362.6], "text": " So yeah, check it out today. Thank you."}, {"timestamp": [1358.41, 1360.41], "text": " So yeah, check it out today."}, {"timestamp": [1360.41, 1361.25], "text": " Thank you."}]}