{"text": " All right. Hello, everybody. Good morning. So it's been almost two years since I published my first book on cognitive architecture. I called it Natural Language Cognitive Architecture, a prototype artificial general intelligence. It's available on Barnes & Noble and paperback. It's also available totally for free as an EPUB on Barnes Noble and and also on GitHub. So anyways the primary architecture it's it's very very simple overall. You've got this graphic here. So you've got the outer loop and the inner loop and basically with the with the recent updates to GPT particularly the June 13th updates that allow it to be more steerable, we now have the ability to implement this very, very, very easily. And so what I'm going to show you today is the knowledge-based service, or basically the shared database service, that I created as part of a microservices architecture for autonomous cognitive entities or artificial general intelligences. So one of the first things to know is that basically we're moving away from coding and we're we're using the model to do a lot more of the logic and reasoning. So here's the repository. It's private right now because I wanted it to be private while I was working on it but by the time you see this video it will be public and it's literally just called KB microservice knowledge knowledge based microservice powered by GPT for actually used three point five turbo because it's good enough for chat bots cognitive architectures and autonomous agents. So here's the repository. I've got it documented so it's easy to use. If there are any bugs, feel free to submit a pull request to fix a bug. But in general, I probably will not be accepting pull requests, especially if anyone tries to refactor this. Because don't break it, please. All right, anyways, moving on. So let's unpack this. So the microservice itself, the primary one, is very, very simple. 159 lines of code. It's a Flask app, and the reason that I use Flask is because honestly, Flask is more straightforward than FastAPI. I know that people like FastAPI, but it requires Uvicorn and a few other things, and I'm like, just use Flask. So anyways, whatever. Personal preference. Neither here nor there. You're not going to run into speed constraints. Okay, so you can ignore the top stuff. These are just helper functions. We've got a few chatbot functions. So this calls the chat GPT API. And you can see here that I have commented out GPT 4 because not everyone has access to it. Everyone should have access to 3.5 turbo which is faster and cheaper and if it's good enough great and it is definitely good enough. So this is this is the primary function. Now here's the KB functions. So the endpoints available let me just show you the documentation the endpoints available are create search and update. So we can this is basically crud create read update and delete without the delete because my assumption is that you will never actually want to delete knowledge from your from your chat bot or your AGI. You might update an article if you have if you have if you get new information to correct it but you never want to delete it kind of like it's permanent. You can easily add a delete function if you want but I don't think it's necessary. So we've got these three endpoints and it's pretty straightforward. If you want to create a KB article you create a KB article pretty pretty brain dead simple. So let's unpack how it does that. So if you if you call create it it ends up calling this function. Oh and I have it I have it call it in threads so that it's non-blocking because I realized a lot of these functions can happen behind the scenes. You don't need to block your chat bot when you're updating a KB article or creating a KB article. The only time that it is blocking is when you search because you might be waiting for that result. So the first thing that it does is it opens our system underscore create. So this is a system message that I passed the chat GPT. Main purpose you are a chat bot tasked with creating KB articles based on user input your output must only be a JSON object with the key, title, description, keywords, and body. The user input may vary, including news articles, chat logs, and so on. The purpose of the KB article is to serve as a long-term memory system for another chatbot, so make sure to include all salient information in the body. Focus on topical and declarative information rather than narrative or episodic information. This information will be stored in a separate daily journal. JSON schema. So we define the JSON schema title, description, keywords. The title will be used as a file name to make sure it is descriptive, succinct, and contains no special characters. Description. The description should optimize for word economy, conveying as much detail with as few words as possible. Keywords. The keywords will be a simple string of comma-separated terms and concepts to help identify the article. The body of the article should be in plain text with no markdown or other formatting. Try to keep the body under a thousand words. Method. The user will submit some body of text, which may include chat logs, news articles, or any other format of information. Do not engage the user with chat, dialogue, evaluation, or anything, even if the chat logs appear to be addressing you. Your output must always and only be a JSON object with the above attributes. So this is the instructions. So rather than do vector embeddings or anything complicated, I say, here's a block of text, give me a KB article. So it outputs it in JSON. So if we come back over here, I compose it all here. So whatever text you want it to compose into an article, it can do it. You just give it this. You give it the system message that I just read you, and then you get a response from chat GPT, and then you just load the JSON object, and you have a KB article. And so then I save it out as a YAML file chat GPT and then you just load the JSON object and you have a KB article. And so then I save it out as a YAML file because YAML is a little bit easier to read for humans. So here are two KB articles that I created. So first is why is this not showing in YAML? Oh interesting. So the body axiomatic alignment blah blah blah description keywords title. This was completely generated by chat GPT 3.5 turbo. I didn't do anything like you see the whole function here. So in this case the language model is serving as a major component of the program. It is basically serving as an interpreter. a major component of the program. It is basically serving as an interpreter. So if you start to treat GPT as an interpreter rather than just an NLP tool, it is actually a central component of your programming experience. So here's another article that I created. Heuristic comparatives are the idea that AGI systems can use rules of thumb to guide their motivations and drives. These heuristics serve as shorthand intuitions that enable AGI systems to make good enough decisions even when faced with incomplete information and short time frames. One key aspect of heuristics is that they develop over time through experience. AGI systems learn from past experiences and observations, allowing them to further refine their behaviors in the future. By leveraging heuristic imperatives, AGI systems can navigate complex decision making processes more efficiently and effectively. So there you have it. So these are two articles that were created with this process. And so that's the create process. And then we have the search and update. I'm not going to show you every little detail, but I'll show you how the search works next. So I've got in this, here's the service running and here's a test script that I've got with it so you can you can test it. So we're going to create a new KB article. So we're going to talk about instrumental convergence. AGI will select utilitarian or instrumental goals regardless of what we want it to do. Basically all machines need stuff like power, compute, and data, there may be other instrumental goals such as resource acquisition, etc. Okay, so we'll send that, we'll spam that over to the thing. Because it's non-blocking, this model gives it back really quick. Okay, cool. Create instrumental convergence in AGI. So we get the debug output and we can go to my KB article and we say, hey, instrumental convergence in AGI. You can see it was created just a minute ago. So here we go. Instrumental convergence is the concept of artificial general intelligence. It wrote a KB article and it added what it also knows about this concept. So description exploring the concept of instrumental convergence, you know, instrumental convergence, utilitarian goal, instrumental goal, resource acquisition, and so on. Now let's make sure that it got energy. It did not include energy, so it seems like it... oh, here we go, power. It used the word power. Power, computational capabilities, and access to data. OK so cool it kept what I said and now let's go and do a quick search. So the search function uses the same logic main purpose. It uses the language model as the interpreter not just as a tool. So this is becoming more and more central to the way that this works. And oh, another thing to know is the directory. So part of this, using it as the interpreter, is that you give it more information. And it uses that to make decisions. So rather than using semantic search, rather than having a few extra steps, like the GPT model already has embeddings built in, why separate that out? So instead I give it a directory of files to look for. Okay, so the system search, you are a chatbot tasked with searching a directory of KB articles and returning the relevant KB articles to a search query. You will be given a chat message from the user. This chat message is actually the search query. Your only point is to return a JSON list of relevant KB article file names in descending order of relevance. If there is nothing relevant, return an empty list. You must always return a JSON list object and nothing else. So in this case, here's the directory and here's the actual directory that it will populate that with. So then we come over here to search. So let's search, and then I want to look at AGI control theory. So let's just say that that's what you want to search. It'll look at it, and there we go. So now it returns my KB articles. It looks like it returned all three of them, but it should have returned it in descending order based on what it saw as relevant. Now, so this returned all three of them, but if I just search for heuristic comparatives, it should only return, whoops, heuristic, actually, let's just say heuristics. So it should only return one. There we go. So in this case you can give it any string whether it's a chat message or a search query or whatever and it will return the KB article that is most relevant. So you can see this is working. It uses the large language model as the interpreter as a as a primary component of its interpretation and it also should have updated the directory. So there you go. So it has a directory of the files, the title, the description, and then the keywords. And so by using the natural language, the intrinsic natural language aspects of GPT, we use this more as a code interpreter than just an NLP endpoint. And so this is why I had someone ask me recently, like, oh, you started using ChromaDB. Do you think that's the way of the future? And I said, no. With larger context windows, we can actually give large language models a table of contents. So rather than blindly searching with vectors and spamming vectors and doing matching, you can actually have a language model that has context and has instructions and can say, yeah, I think that's the piece of information that I need. So this is the KB service. I'll be working on other similar services. So if we go back to natural language cognitive architecture where it all started two years ago, I'll be working on a dossier service. So the dossier service is basically it's going to keep track of information on every user that interacts with it. Now obviously this probably raises some red flags for people. The idea is not necessarily for like not not dossier in terms of like CIA or FBI dossier. What I mean by dossier is like user preferences your age your birthday how you prefer to interact with the machine because imagine that you have a smart home device that will intrinsically learn about the user who's who it's speaking with now if you have a voice enabled and a camera enabled thing, this dossier would also include stuff about how to visibly identify that person or identify their voice print, that sort of thing. Yeah, so that's where I'm going. I also mentioned a daily journal. So the KB article is declarative knowledge. This is topical is declarative knowledge. This is topical or declarative knowledge that is temporally invariant. So these are just facts. These are topics that you talk about with your chatbot or your AGI. The daily journal is the chronologically, temporally bounded thing where it just says on this day we talked about X topic. So that's going to be a separate service. It's going to be mostly the same but it's going to have to be temporarily aware. So part of the metadata is going to be rather than these which just has body description keywords and title. It's going to have to have things like what day it was what year the year, the month, the time stamp, that sort of stuff. So that way those episodic memories are grounded in a chronologically linear timeline. And so by having these two separate memory systems, they can be very tightly correlated because you can still have keywords, right? You can still say like, you know, on March 12th, we talked about heuristic imperatives. And so then your system can say, okay, let me search my episodic memory, my daily journal, for heuristic imperatives so I know when we talked about it. And this data structure is going to be the way that these systems actually learn from these things, because you'll be able to correlate events over time, over linear time, and look back by looking at the metadata and the descriptions of what happened, and so on and so forth, to create datasets to connect cause and effect. So this is a really, really, really huge step forward for autonomous cognitive entities and cognitive architectures in general. And this is just the beginning. And with the speed and cost effectiveness of 3.5 Turbo, I suspect we're going to see this ramping up very, very quickly. Now, there's other kinds of memories that you can do, and there's other kinds of things that you can choose. So in this case, the search is choosing which KB article is relevant. But instead of having a KB article, what if you're actually searching through tasks and you can choose which task to work on or which stage of the task you're on? So by switching the way that you're approaching large language models and looking at it as an interpreter rather than just an individual NLP or language generator. It is actually a very powerful interpreter that can do more abstract operations on your tasks. So let me just go ahead and add this to the readme actually. read me actually so we'll do like future work so we'll have a daily journal episodic memory at this sodic memory and then we'll also have tasks like like an internal jira or Trello. We can also have dossiers. Basically, basically KB article on users. And so there's a few, there's quite a few other things that you can do, but by keeping track of these lists of documents, this is how you create a thinking machine that can learn over time. And by correlating these things with timestamps, so basically timestamps, temporally proximal things, things that happen around the same time, tend to also be correlated. This is why your brain might make, usually makes good connections. If something happened near this time that something else happened that I had a bad experience, they might be correlated. Now, in humans, this can actually create false associations, right? There's been plenty of studies with like rats, you know, for instance, you zap a rat and then give it a reward and then it thinks that the zap is associated with a reward. They're completely uncorrelated. You created an artificial correlation there. That being said we're not going to zap this thing like a rat that's mean and I don't think rats should be zapped anyways but researchers still do that. Anyways getting lost in a tangent point being is that with the combination of time stamps and metadata you can correlate things like daily journal events, tasks that it's been given, user dossiers, updates to user dossiers, and then finally KB articles so that you have a very comprehensive knowledge system that these language models as the windows grow, right, because we're at 16,000 tokens for GPT 3.5 Turbo and we're about to get 32,000 tokens for for a chat GP or GPT 4. So let me just show you how much this is. So if we come up to here and go to the playground you can see this is 359 tokens. That is literally 1% if I'm doing my math right, 1% of the total token count that we're going to ultimately have in chat GPT-4 in the coming weeks and months, which means that you can recall a bunch of KB articles, you can recall a bunch of daily journals, you can recall a bunch of tasks and task steps in order to decide what to do next. Now one other thing to think about is that you can include directives in these task switching contexts. So say for instance you want to prioritize. In this case the search, I prioritized it based on relevance to a KB article. But on the task side, what if you want to prioritize tasks based on, say, for instance, heuristic imperatives. So in this case, daily journal, you know, prioritize based on relevance or temporal proximity. on relevance or temporal proximity tasks you prioritize based on ROI or heuristic imperatives, e.g. which tasks will reduce suffering the most increase prosperity the most and increase understanding the most. And so this is just another another angle in which in a system in a cognitive architecture you can embed various priorities at at many levels. So there you have it. I think that's about it. Yeah. So again by the time you see this this microservice should be public, should be ready to go, and yeah thanks for watching. I hope you got a lot out of it. Stay tuned, the June 13th update to chat GPT is going to be a major, major game changer. The steerability that they added is just an incredible boon to the development of autonomous AI systems. So thanks for watching. I hope you liked it and cheers.", "chunks": [{"timestamp": [0.0, 3.0], "text": " All right. Hello, everybody. Good morning."}, {"timestamp": [3.0, 9.0], "text": " So it's been almost two years since I published my first book on cognitive architecture."}, {"timestamp": [9.0, 14.0], "text": " I called it Natural Language Cognitive Architecture, a prototype artificial general intelligence."}, {"timestamp": [14.0, 18.0], "text": " It's available on Barnes & Noble and paperback."}, {"timestamp": [18.0, 25.88], "text": " It's also available totally for free as an EPUB on Barnes Noble and and also on GitHub."}, {"timestamp": [25.88, 29.08], "text": " So anyways the primary architecture"}, {"timestamp": [29.08, 32.04], "text": " it's it's very very simple overall."}, {"timestamp": [32.04, 34.08], "text": " You've got this graphic here."}, {"timestamp": [34.08, 36.52], "text": " So you've got the outer loop and the inner loop"}, {"timestamp": [36.52, 39.0], "text": " and basically with the"}, {"timestamp": [39.0, 41.64], "text": " with the recent updates"}, {"timestamp": [41.64, 43.8], "text": " to GPT particularly"}, {"timestamp": [43.8, 46.4], "text": " the June 13th updates that allow it to be more steerable,"}, {"timestamp": [46.96, 53.12], "text": " we now have the ability to implement this very, very, very easily. And so what I'm going to show"}, {"timestamp": [53.12, 57.6], "text": " you today is the knowledge-based service, or basically the shared database service,"}, {"timestamp": [58.24, 67.04], "text": " that I created as part of a microservices architecture for autonomous cognitive entities or artificial general intelligences."}, {"timestamp": [67.56, 69.52], "text": " So one of the first things to know is"}, {"timestamp": [69.52, 71.48], "text": " that basically we're"}, {"timestamp": [71.48, 73.68], "text": " moving away from coding"}, {"timestamp": [73.88, 76.06], "text": " and we're we're using the model"}, {"timestamp": [76.08, 77.8], "text": " to do a lot more of the logic"}, {"timestamp": [77.8, 78.76], "text": " and reasoning."}, {"timestamp": [79.32, 81.2], "text": " So here's the repository."}, {"timestamp": [81.36, 83.2], "text": " It's private right now because I wanted it to be"}, {"timestamp": [83.2, 84.32], "text": " private while I was working on it"}, {"timestamp": [84.32, 89.28], "text": " but by the time you see this video it will be public and it's literally just called KB microservice"}, {"timestamp": [89.8, 95.72], "text": " knowledge knowledge based microservice powered by GPT for actually used three point five turbo because"}, {"timestamp": [95.72, 101.48], "text": " it's good enough for chat bots cognitive architectures and autonomous agents. So here's the repository."}, {"timestamp": [101.76, 105.0], "text": " I've got it documented so it's easy to use."}, {"timestamp": [106.72, 110.52], "text": " If there are any bugs, feel free to submit a pull request to fix a bug."}, {"timestamp": [110.52, 113.52], "text": " But in general, I probably will not be accepting"}, {"timestamp": [113.52, 118.52], "text": " pull requests, especially if anyone tries to refactor this."}, {"timestamp": [118.72, 119.96], "text": " Because don't break it, please."}, {"timestamp": [119.96, 121.6], "text": " All right, anyways, moving on."}, {"timestamp": [121.6, 123.2], "text": " So let's unpack this."}, {"timestamp": [123.2, 126.0], "text": " So the microservice itself, the primary one,"}, {"timestamp": [126.0, 127.72], "text": " is very, very simple."}, {"timestamp": [127.72, 130.28], "text": " 159 lines of code."}, {"timestamp": [130.28, 133.28], "text": " It's a Flask app, and the reason that I use Flask"}, {"timestamp": [133.28, 136.16], "text": " is because honestly, Flask is more straightforward"}, {"timestamp": [136.16, 137.2], "text": " than FastAPI."}, {"timestamp": [137.2, 138.8], "text": " I know that people like FastAPI,"}, {"timestamp": [138.8, 141.92], "text": " but it requires Uvicorn and a few other things,"}, {"timestamp": [141.92, 143.7], "text": " and I'm like, just use Flask."}, {"timestamp": [143.7, 145.74], "text": " So anyways, whatever. Personal preference."}, {"timestamp": [145.74, 147.74], "text": " Neither here nor there."}, {"timestamp": [147.74, 150.02], "text": " You're not going to run into speed constraints."}, {"timestamp": [150.02, 153.1], "text": " Okay, so you can ignore the top stuff."}, {"timestamp": [153.1, 155.46], "text": " These are just helper functions."}, {"timestamp": [155.46, 157.34], "text": " We've got a few chatbot functions."}, {"timestamp": [157.34, 161.74], "text": " So this calls the chat GPT API."}, {"timestamp": [161.74, 166.24], "text": " And you can see here that I have commented out GPT 4 because not everyone has access to it."}, {"timestamp": [166.84, 168.68], "text": " Everyone should have access to 3.5"}, {"timestamp": [168.68, 170.84], "text": " turbo which is"}, {"timestamp": [170.88, 171.88], "text": " faster and cheaper"}, {"timestamp": [171.88, 173.4], "text": " and if it's good enough great"}, {"timestamp": [173.4, 175.08], "text": " and it is definitely good enough."}, {"timestamp": [176.48, 178.58], "text": " So this is this is the primary"}, {"timestamp": [178.58, 181.0], "text": " function. Now here's the KB functions."}, {"timestamp": [181.24, 183.28], "text": " So the endpoints available let"}, {"timestamp": [183.28, 186.52], "text": " me just show you the documentation the endpoints available are create search"}, {"timestamp": [186.52, 187.24], "text": " and update."}, {"timestamp": [187.64, 189.42], "text": " So we can this"}, {"timestamp": [189.42, 191.6], "text": " is basically crud create"}, {"timestamp": [191.6, 192.2], "text": " read update"}, {"timestamp": [192.2, 194.6], "text": " and delete without the delete because"}, {"timestamp": [194.72, 196.68], "text": " my assumption is that you will never"}, {"timestamp": [196.68, 198.68], "text": " actually want to delete knowledge from"}, {"timestamp": [198.68, 200.3], "text": " your from your chat bot"}, {"timestamp": [200.32, 202.08], "text": " or your AGI."}, {"timestamp": [202.6, 204.36], "text": " You might update an article if"}, {"timestamp": [204.36, 205.0], "text": " you have if you have"}, {"timestamp": [205.0, 206.7], "text": " if you get new information to correct it"}, {"timestamp": [206.7, 208.3], "text": " but you never want to delete it"}, {"timestamp": [209.2, 211.4], "text": " kind of like it's permanent. You can easily add"}, {"timestamp": [211.4, 212.9], "text": " a delete function if you want"}, {"timestamp": [212.9, 214.6], "text": " but I don't think it's necessary."}, {"timestamp": [215.4, 217.5], "text": " So we've got these three endpoints"}, {"timestamp": [218.4, 220.5], "text": " and it's pretty straightforward. If you want to create a KB"}, {"timestamp": [220.5, 222.1], "text": " article you create a KB article"}, {"timestamp": [222.7, 224.1], "text": " pretty pretty brain dead simple."}, {"timestamp": [224.2, 225.3], "text": " So let's unpack how"}, {"timestamp": [225.3, 230.0], "text": " it does that. So if you if you call create"}, {"timestamp": [230.0, 232.1], "text": " it it ends up calling this function. Oh"}, {"timestamp": [232.1, 234.7], "text": " and I have it I have it call it in threads"}, {"timestamp": [234.7, 237.3], "text": " so that it's non-blocking because I realized a lot"}, {"timestamp": [237.3, 241.0], "text": " of these functions can happen behind the scenes."}, {"timestamp": [241.0, 243.2], "text": " You don't need to block your chat bot when you're"}, {"timestamp": [243.2, 246.04], "text": " updating a KB article or creating a KB article."}, {"timestamp": [246.24, 248.36], "text": " The only time that it is blocking is when you search"}, {"timestamp": [248.36, 250.24], "text": " because you might be waiting for"}, {"timestamp": [250.24, 251.08], "text": " that result."}, {"timestamp": [251.8, 253.68], "text": " So the first thing that it does is it"}, {"timestamp": [253.68, 255.88], "text": " opens our system underscore"}, {"timestamp": [255.88, 256.6], "text": " create."}, {"timestamp": [256.98, 258.88], "text": " So this is a system message that I"}, {"timestamp": [258.88, 260.4], "text": " passed the chat GPT."}, {"timestamp": [260.68, 262.48], "text": " Main purpose you are a chat bot tasked"}, {"timestamp": [262.48, 264.64], "text": " with creating KB articles based on user input"}, {"timestamp": [264.64, 269.5], "text": " your output must only be a JSON object with the key, title, description, keywords, and"}, {"timestamp": [269.5, 270.5], "text": " body."}, {"timestamp": [270.5, 273.38], "text": " The user input may vary, including news articles, chat logs, and so on."}, {"timestamp": [273.38, 277.52], "text": " The purpose of the KB article is to serve as a long-term memory system for another chatbot,"}, {"timestamp": [277.52, 280.46], "text": " so make sure to include all salient information in the body."}, {"timestamp": [280.46, 284.48], "text": " Focus on topical and declarative information rather than narrative or episodic information."}, {"timestamp": [284.48, 286.56], "text": " This information will be stored in a separate daily journal."}, {"timestamp": [287.6, 293.2], "text": " JSON schema. So we define the JSON schema title, description, keywords. The title will be used as"}, {"timestamp": [293.2, 296.64], "text": " a file name to make sure it is descriptive, succinct, and contains no special characters."}, {"timestamp": [297.2, 300.88], "text": " Description. The description should optimize for word economy, conveying as much detail with as"}, {"timestamp": [300.88, 308.8], "text": " few words as possible. Keywords. The keywords will be a simple string of comma-separated terms and concepts to help identify the article."}, {"timestamp": [308.8, 313.16], "text": " The body of the article should be in plain text with no markdown or other formatting."}, {"timestamp": [313.16, 315.28], "text": " Try to keep the body under a thousand words."}, {"timestamp": [315.28, 316.28], "text": " Method."}, {"timestamp": [316.28, 319.84], "text": " The user will submit some body of text, which may include chat logs, news articles, or any"}, {"timestamp": [319.84, 321.12], "text": " other format of information."}, {"timestamp": [321.12, 324.92], "text": " Do not engage the user with chat, dialogue, evaluation, or anything, even if the chat"}, {"timestamp": [324.92, 330.08], "text": " logs appear to be addressing you. Your output must always and only be a JSON"}, {"timestamp": [330.08, 337.44], "text": " object with the above attributes. So this is the instructions. So rather than do vector embeddings"}, {"timestamp": [337.44, 345.76], "text": " or anything complicated, I say, here's a block of text, give me a KB article. So it outputs it in JSON. So if we come back over here,"}, {"timestamp": [345.76, 347.52], "text": " I compose it all here."}, {"timestamp": [347.52, 353.16], "text": " So whatever text you want it to compose into an article,"}, {"timestamp": [353.16, 354.92], "text": " it can do it. You just give it this."}, {"timestamp": [354.92, 357.92], "text": " You give it the system message that I just read you,"}, {"timestamp": [357.92, 361.16], "text": " and then you get a response from chat GPT,"}, {"timestamp": [361.16, 363.56], "text": " and then you just load the JSON object,"}, {"timestamp": [363.56, 364.84], "text": " and you have a KB article."}, {"timestamp": [364.84, 365.0], "text": " And so then I save it out as a YAML file chat GPT and then you just load the JSON object and you have a KB article."}, {"timestamp": [365.0, 367.88], "text": " And so then I save it out as a YAML file"}, {"timestamp": [367.88, 370.36], "text": " because YAML is a little bit easier to read"}, {"timestamp": [370.36, 373.08], "text": " for humans. So here are two KB articles"}, {"timestamp": [373.08, 376.2], "text": " that I created. So first is why is this"}, {"timestamp": [376.2, 381.36], "text": " not showing in YAML? Oh interesting."}, {"timestamp": [381.36, 384.08], "text": " So the body axiomatic alignment blah blah"}, {"timestamp": [384.08, 386.56], "text": " blah description keywords title."}, {"timestamp": [386.56, 392.64], "text": " This was completely generated by chat GPT 3.5 turbo."}, {"timestamp": [393.4, 396.04], "text": " I didn't do anything like you see the whole function here."}, {"timestamp": [396.32, 402.44], "text": " So in this case the language model is serving as a major component of the program."}, {"timestamp": [402.48, 404.56], "text": " It is basically serving as an interpreter."}, {"timestamp": [404.6, 408.36], "text": " a major component of the program. It is basically serving as an interpreter. So if you start to treat GPT as an interpreter"}, {"timestamp": [408.36, 412.44], "text": " rather than just an NLP tool, it is actually a central component"}, {"timestamp": [412.44, 417.08], "text": " of your programming experience. So here's another article that I created."}, {"timestamp": [417.08, 419.52], "text": " Heuristic comparatives are the idea that AGI systems can use"}, {"timestamp": [419.52, 422.72], "text": " rules of thumb to guide their motivations and drives. These heuristics"}, {"timestamp": [422.72, 424.24], "text": " serve as shorthand intuitions"}, {"timestamp": [424.24, 429.2], "text": " that enable AGI systems to make good enough decisions even when faced with incomplete"}, {"timestamp": [429.2, 433.52], "text": " information and short time frames. One key aspect of heuristics is that they develop over time"}, {"timestamp": [433.52, 437.84], "text": " through experience. AGI systems learn from past experiences and observations, allowing them to"}, {"timestamp": [437.84, 443.92], "text": " further refine their behaviors in the future. By leveraging heuristic imperatives, AGI systems can"}, {"timestamp": [443.92, 445.16], "text": " navigate complex decision"}, {"timestamp": [445.16, 448.92], "text": " making processes more efficiently and effectively."}, {"timestamp": [448.92, 449.92], "text": " So there you have it."}, {"timestamp": [449.92, 455.24], "text": " So these are two articles that were created with this process."}, {"timestamp": [455.24, 457.56], "text": " And so that's the create process."}, {"timestamp": [457.56, 459.72], "text": " And then we have the search and update."}, {"timestamp": [459.72, 463.72], "text": " I'm not going to show you every little detail, but I'll show you how the search works next."}, {"timestamp": [463.72, 471.52], "text": " So I've got in this, here's the service running and here's a test script that I've got with it so you can you can test it."}, {"timestamp": [471.52, 492.3], "text": " So we're going to create a new KB article. So we're going to talk about instrumental convergence. AGI will select utilitarian or instrumental goals regardless of what we"}, {"timestamp": [492.3, 513.0], "text": " want it to do. Basically all machines need stuff like power, compute, and data, there may be other instrumental goals such as resource acquisition, etc."}, {"timestamp": [513.0, 517.0], "text": " Okay, so we'll send that, we'll spam that over to the thing."}, {"timestamp": [517.0, 521.0], "text": " Because it's non-blocking, this model gives it back really quick."}, {"timestamp": [521.0, 524.0], "text": " Okay, cool. Create instrumental convergence in AGI."}, {"timestamp": [524.0, 528.64], "text": " So we get the debug output and we can go to my KB article and we say, hey,"}, {"timestamp": [528.64, 532.8], "text": " instrumental convergence in AGI. You can see it was created just a minute ago."}, {"timestamp": [533.84, 538.0], "text": " So here we go. Instrumental convergence is the concept of artificial general intelligence. It"}, {"timestamp": [538.0, 548.0], "text": " wrote a KB article and it added what it also knows about this concept. So description exploring the concept of instrumental convergence,"}, {"timestamp": [548.0, 552.0], "text": " you know, instrumental convergence, utilitarian goal,"}, {"timestamp": [552.0, 556.0], "text": " instrumental goal, resource acquisition, and so on. Now let's make sure that it got"}, {"timestamp": [556.0, 560.0], "text": " energy. It did not include energy, so it seems like it... oh,"}, {"timestamp": [560.0, 564.0], "text": " here we go, power. It used the word power. Power, computational capabilities,"}, {"timestamp": [564.0, 565.28], "text": " and access to data."}, {"timestamp": [565.28, 567.84], "text": " OK so cool it kept what I said"}, {"timestamp": [568.92, 570.16], "text": " and now let's go"}, {"timestamp": [570.16, 571.48], "text": " and do a quick search."}, {"timestamp": [572.08, 574.56], "text": " So the search function uses the same"}, {"timestamp": [574.64, 576.48], "text": " logic main purpose."}, {"timestamp": [576.64, 578.68], "text": " It uses the language model"}, {"timestamp": [578.68, 581.0], "text": " as the interpreter not just as"}, {"timestamp": [581.0, 582.84], "text": " a tool. So this is becoming more"}, {"timestamp": [582.84, 584.96], "text": " and more central to"}, {"timestamp": [586.0, 587.04], "text": " the way that this works."}, {"timestamp": [592.48, 598.16], "text": " And oh, another thing to know is the directory. So part of this, using it as the interpreter, is that you give it more information. And it uses that to make decisions. So rather than using"}, {"timestamp": [598.16, 606.52], "text": " semantic search, rather than having a few extra steps, like the GPT model already has embeddings built in, why"}, {"timestamp": [606.52, 608.0], "text": " separate that out?"}, {"timestamp": [608.0, 611.44], "text": " So instead I give it a directory of files to look for."}, {"timestamp": [611.44, 616.96], "text": " Okay, so the system search, you are a chatbot tasked with searching a directory of KB articles"}, {"timestamp": [616.96, 619.84], "text": " and returning the relevant KB articles to a search query."}, {"timestamp": [619.84, 621.84], "text": " You will be given a chat message from the user."}, {"timestamp": [621.84, 624.2], "text": " This chat message is actually the search query."}, {"timestamp": [624.2, 628.48], "text": " Your only point is to return a JSON list of relevant KB article file names in descending"}, {"timestamp": [628.48, 630.0], "text": " order of relevance."}, {"timestamp": [630.0, 632.0], "text": " If there is nothing relevant, return an empty list."}, {"timestamp": [632.0, 635.72], "text": " You must always return a JSON list object and nothing else."}, {"timestamp": [635.72, 641.96], "text": " So in this case, here's the directory and here's the actual directory that it will populate"}, {"timestamp": [641.96, 643.16], "text": " that with."}, {"timestamp": [643.16, 645.44], "text": " So then we come over here to search."}, {"timestamp": [645.44, 651.2], "text": " So let's search, and then I want to look at AGI control theory."}, {"timestamp": [651.2, 654.2], "text": " So let's just say that that's what you want to search."}, {"timestamp": [654.2, 657.08], "text": " It'll look at it, and there we go."}, {"timestamp": [657.08, 660.44], "text": " So now it returns my KB articles."}, {"timestamp": [660.44, 663.24], "text": " It looks like it returned all three of them,"}, {"timestamp": [663.24, 666.32], "text": " but it should have returned it in descending order"}, {"timestamp": [666.32, 670.04], "text": " based on what it saw as relevant."}, {"timestamp": [670.04, 672.48], "text": " Now, so this returned all three of them,"}, {"timestamp": [672.48, 675.4], "text": " but if I just search for heuristic comparatives,"}, {"timestamp": [675.4, 679.92], "text": " it should only return, whoops, heuristic,"}, {"timestamp": [679.92, 682.08], "text": " actually, let's just say heuristics."}, {"timestamp": [682.08, 683.84], "text": " So it should only return one."}, {"timestamp": [683.84, 685.28], "text": " There we go."}, {"timestamp": [687.36, 689.52], "text": " So in this case you can give it any string whether it's a chat message"}, {"timestamp": [689.52, 690.36], "text": " or a search query"}, {"timestamp": [690.36, 690.92], "text": " or whatever"}, {"timestamp": [690.92, 692.92], "text": " and it will return the KB article"}, {"timestamp": [692.92, 694.36], "text": " that is most relevant."}, {"timestamp": [694.76, 696.12], "text": " So you can see this is working."}, {"timestamp": [696.12, 698.24], "text": " It uses the large language"}, {"timestamp": [698.24, 699.96], "text": " model as the interpreter as"}, {"timestamp": [699.96, 702.72], "text": " a as a primary component of its interpretation"}, {"timestamp": [702.84, 704.56], "text": " and it also should have updated the"}, {"timestamp": [704.56, 705.92], "text": " directory. So there you go."}, {"timestamp": [705.92, 710.24], "text": " So it has a directory of the files, the title, the description,"}, {"timestamp": [710.24, 714.0], "text": " and then the keywords. And so by using the natural language,"}, {"timestamp": [714.0, 718.0], "text": " the intrinsic natural language aspects of GPT,"}, {"timestamp": [718.0, 724.16], "text": " we use this more as a code interpreter than just an NLP endpoint."}, {"timestamp": [724.16, 728.0], "text": " And so this is why I had someone ask me recently,"}, {"timestamp": [728.0, 732.0], "text": " like, oh, you started using ChromaDB. Do you think that's the way of the future?"}, {"timestamp": [732.0, 736.0], "text": " And I said, no. With larger context windows,"}, {"timestamp": [736.0, 740.0], "text": " we can actually give large language models a table of contents."}, {"timestamp": [740.0, 744.0], "text": " So rather than blindly searching with vectors and spamming"}, {"timestamp": [744.0, 746.6], "text": " vectors and doing matching,"}, {"timestamp": [746.6, 751.6], "text": " you can actually have a language model that has context and has instructions and can say,"}, {"timestamp": [751.6, 754.6], "text": " yeah, I think that's the piece of information that I need."}, {"timestamp": [754.6, 756.6], "text": " So this is the KB service."}, {"timestamp": [756.6, 759.6], "text": " I'll be working on other similar services."}, {"timestamp": [759.6, 764.6], "text": " So if we go back to natural language cognitive architecture where it all started two years ago,"}, {"timestamp": [764.6, 765.36], "text": " I'll be"}, {"timestamp": [765.36, 771.56], "text": " working on a dossier service. So the dossier service is basically it's going to keep track"}, {"timestamp": [771.56, 777.12], "text": " of information on every user that interacts with it. Now obviously this probably raises"}, {"timestamp": [777.12, 785.8], "text": " some red flags for people. The idea is not necessarily for like not not dossier in terms of like"}, {"timestamp": [785.8, 790.1], "text": " CIA or FBI dossier. What I mean by dossier is like user"}, {"timestamp": [790.1, 794.2], "text": " preferences your age your birthday how you prefer to"}, {"timestamp": [794.2, 796.9], "text": " interact with the machine because imagine that you have a"}, {"timestamp": [796.9, 801.2], "text": " smart home device that will intrinsically learn about the"}, {"timestamp": [801.2, 804.6], "text": " user who's who it's speaking with now if you have a voice"}, {"timestamp": [804.6, 806.0], "text": " enabled and a camera enabled"}, {"timestamp": [806.0, 808.0], "text": " thing, this dossier would also"}, {"timestamp": [808.0, 810.0], "text": " include stuff about how to"}, {"timestamp": [810.0, 812.0], "text": " visibly identify that person"}, {"timestamp": [812.0, 814.0], "text": " or identify their"}, {"timestamp": [814.0, 816.0], "text": " voice print, that sort of thing."}, {"timestamp": [816.0, 818.0], "text": " Yeah, so that's where"}, {"timestamp": [818.0, 820.0], "text": " I'm going. I also"}, {"timestamp": [820.0, 822.0], "text": " mentioned a daily journal. So"}, {"timestamp": [822.0, 824.0], "text": " the KB article is declarative"}, {"timestamp": [824.0, 825.36], "text": " knowledge. This is topical is declarative knowledge. This is"}, {"timestamp": [825.36, 830.36], "text": " topical or declarative knowledge that is temporally invariant. So these are just"}, {"timestamp": [830.36, 836.44], "text": " facts. These are topics that you talk about with your chatbot or your AGI. The"}, {"timestamp": [836.44, 840.76], "text": " daily journal is the chronologically, temporally bounded thing where it just"}, {"timestamp": [840.76, 845.4], "text": " says on this day we talked about X topic. So that's going to be a separate service."}, {"timestamp": [845.4, 849.4], "text": " It's going to be mostly the same but it's going to have to be temporarily aware."}, {"timestamp": [849.4, 854.0], "text": " So part of the metadata is going to be rather than these"}, {"timestamp": [854.0, 858.0], "text": " which just has body description keywords and title."}, {"timestamp": [858.0, 865.6], "text": " It's going to have to have things like what day it was what year the year, the month, the time stamp, that sort of stuff."}, {"timestamp": [865.6, 873.6], "text": " So that way those episodic memories are grounded in a chronologically linear timeline."}, {"timestamp": [873.6, 878.4], "text": " And so by having these two separate memory systems, they can be very tightly correlated"}, {"timestamp": [878.4, 883.6], "text": " because you can still have keywords, right? You can still say like, you know, on March 12th,"}, {"timestamp": [883.6, 889.74], "text": " we talked about heuristic imperatives. And so then your system can say, okay, let me search my episodic"}, {"timestamp": [889.74, 893.38], "text": " memory, my daily journal, for heuristic imperatives so I know when we talked"}, {"timestamp": [893.38, 898.82], "text": " about it. And this data structure is going to be the way that these systems"}, {"timestamp": [898.82, 902.38], "text": " actually learn from these things, because you'll be able to correlate events over"}, {"timestamp": [902.38, 908.84], "text": " time, over linear time, and look back by looking at the metadata and the descriptions of what happened,"}, {"timestamp": [908.84, 914.92], "text": " and so on and so forth, to create datasets to connect cause and effect."}, {"timestamp": [914.92, 921.28], "text": " So this is a really, really, really huge step forward for autonomous cognitive entities"}, {"timestamp": [921.28, 924.8], "text": " and cognitive architectures in general."}, {"timestamp": [924.8, 926.0], "text": " And this is just the beginning."}, {"timestamp": [926.0, 932.0], "text": " And with the speed and cost effectiveness of 3.5 Turbo,"}, {"timestamp": [932.0, 936.0], "text": " I suspect we're going to see this ramping up very, very quickly."}, {"timestamp": [936.0, 939.0], "text": " Now, there's other kinds of memories that you can do,"}, {"timestamp": [939.0, 942.0], "text": " and there's other kinds of things that you can choose."}, {"timestamp": [942.0, 946.8], "text": " So in this case, the search is choosing which KB article is relevant."}, {"timestamp": [946.8, 949.32], "text": " But instead of having a KB article,"}, {"timestamp": [949.32, 952.08], "text": " what if you're actually searching through tasks"}, {"timestamp": [952.08, 954.56], "text": " and you can choose which task to work on"}, {"timestamp": [954.56, 957.08], "text": " or which stage of the task you're on?"}, {"timestamp": [957.08, 960.16], "text": " So by switching the way that you're approaching"}, {"timestamp": [960.16, 963.16], "text": " large language models and looking at it as an interpreter"}, {"timestamp": [963.16, 965.84], "text": " rather than just an individual"}, {"timestamp": [973.2, 980.72], "text": " NLP or language generator. It is actually a very powerful interpreter that can do more abstract operations on your tasks. So let me just go ahead and add this to the readme actually."}, {"timestamp": [990.8, 1007.0], "text": " read me actually so we'll do like future work so we'll have a daily journal episodic memory at this sodic memory and then we'll also have tasks like like an internal jira or Trello. We can also have dossiers."}, {"timestamp": [1007.0, 1013.0], "text": " Basically, basically KB article on users."}, {"timestamp": [1013.0, 1016.0], "text": " And so there's a few, there's quite a few other things that you can do,"}, {"timestamp": [1016.0, 1020.0], "text": " but by keeping track of these lists of documents,"}, {"timestamp": [1020.0, 1026.0], "text": " this is how you create a thinking machine that can learn over time."}, {"timestamp": [1026.0, 1030.4], "text": " And by correlating these things with timestamps,"}, {"timestamp": [1030.4, 1034.6], "text": " so basically timestamps,"}, {"timestamp": [1034.6, 1037.6], "text": " temporally proximal things,"}, {"timestamp": [1037.6, 1041.4], "text": " things that happen around the same time, tend to also be correlated."}, {"timestamp": [1041.4, 1046.16], "text": " This is why your brain might make, usually makes good connections."}, {"timestamp": [1046.16, 1052.2], "text": " If something happened near this time that something else happened that I had a bad experience,"}, {"timestamp": [1052.2, 1056.48], "text": " they might be correlated. Now, in humans, this can actually create false associations,"}, {"timestamp": [1056.48, 1060.26], "text": " right? There's been plenty of studies with like rats, you know, for instance, you zap"}, {"timestamp": [1060.26, 1065.04], "text": " a rat and then give it a reward and then it thinks that the zap is associated with a reward."}, {"timestamp": [1066.32, 1067.92], "text": " They're completely uncorrelated. You created an artificial"}, {"timestamp": [1068.44, 1069.36], "text": " correlation there."}, {"timestamp": [1069.72, 1071.7], "text": " That being said we're not going to zap this"}, {"timestamp": [1071.7, 1073.0], "text": " thing like a rat that's mean"}, {"timestamp": [1073.56, 1075.28], "text": " and I don't think rats should be zapped anyways"}, {"timestamp": [1075.28, 1076.76], "text": " but researchers still do that."}, {"timestamp": [1077.72, 1079.92], "text": " Anyways getting lost in a tangent"}, {"timestamp": [1080.28, 1081.84], "text": " point being is that"}, {"timestamp": [1081.84, 1083.92], "text": " with the combination of time stamps"}, {"timestamp": [1084.24, 1086.24], "text": " and metadata you can correlate"}, {"timestamp": [1086.24, 1091.6], "text": " things like daily journal events, tasks that it's been given, user dossiers, updates to"}, {"timestamp": [1091.6, 1096.58], "text": " user dossiers, and then finally KB articles so that you have a very comprehensive knowledge"}, {"timestamp": [1096.58, 1107.52], "text": " system that these language models as the windows grow, right, because we're at 16,000 tokens for GPT 3.5 Turbo and we're about to get 32,000 tokens"}, {"timestamp": [1107.52, 1116.32], "text": " for for a chat GP or GPT 4. So let me just show you how much this is. So if we come up to here"}, {"timestamp": [1116.32, 1129.28], "text": " and go to the playground you can see this is 359 tokens. That is literally 1% if I'm doing my math right, 1% of the total token count that we're"}, {"timestamp": [1129.28, 1134.72], "text": " going to ultimately have in chat GPT-4 in the coming weeks and months, which means that you can"}, {"timestamp": [1134.72, 1140.64], "text": " recall a bunch of KB articles, you can recall a bunch of daily journals, you can recall a bunch"}, {"timestamp": [1140.64, 1145.72], "text": " of tasks and task steps in order to decide what to do next."}, {"timestamp": [1145.72, 1153.12], "text": " Now one other thing to think about is that you can include directives in these task switching"}, {"timestamp": [1153.12, 1154.76], "text": " contexts."}, {"timestamp": [1154.76, 1158.54], "text": " So say for instance you want to prioritize."}, {"timestamp": [1158.54, 1163.96], "text": " In this case the search, I prioritized it based on relevance to a KB article."}, {"timestamp": [1163.96, 1169.48], "text": " But on the task side, what if you want to prioritize tasks based on, say, for instance,"}, {"timestamp": [1169.48, 1171.52], "text": " heuristic imperatives."}, {"timestamp": [1171.52, 1183.26], "text": " So in this case, daily journal, you know, prioritize based on relevance or temporal"}, {"timestamp": [1183.26, 1188.32], "text": " proximity. on relevance or temporal proximity tasks you prioritize"}, {"timestamp": [1188.32, 1195.92], "text": " based on ROI or heuristic imperatives, e.g. which tasks"}, {"timestamp": [1195.92, 1204.08], "text": " will reduce suffering the most increase prosperity the most"}, {"timestamp": [1204.08, 1208.0], "text": " and increase understanding the most. And so this is just"}, {"timestamp": [1208.0, 1212.0], "text": " another another angle in which in a system"}, {"timestamp": [1212.0, 1216.0], "text": " in a cognitive architecture you can embed various"}, {"timestamp": [1216.0, 1220.0], "text": " priorities at at many levels. So there you have it. I think"}, {"timestamp": [1220.0, 1224.0], "text": " that's about it. Yeah. So again by the time you see this"}, {"timestamp": [1224.0, 1226.72], "text": " this microservice should be public,"}, {"timestamp": [1226.72, 1231.2], "text": " should be ready to go, and yeah thanks for watching. I hope you got a lot out of it."}, {"timestamp": [1231.92, 1238.8], "text": " Stay tuned, the June 13th update to chat GPT is going to be a major, major game changer. The"}, {"timestamp": [1238.8, 1247.0], "text": " steerability that they added is just an incredible boon to the development of autonomous AI systems."}, {"timestamp": [1247.0, 1248.2], "text": " So thanks for watching."}, {"timestamp": [1248.2, 1249.72], "text": " I hope you liked it and cheers."}]}