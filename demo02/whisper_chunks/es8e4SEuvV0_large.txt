{"text": " I'm back. Okay, so I know that I said I would take like two to four months off, but apparently something has changed in my brain and I'm not going to take that long anymore. I have continued reading Brain Trust and as what always happens whenever I read cognition or neuroscience, I'm inspired to do more work. So I want to bring you up to speed with what I worked on last night. And I didn't share it because one, it is a politically sensitive thing. I did check OpenAI's guidelines for content sharing and publication. And you're not supposed to share anything that is part of a political campaign. So I think this is okay. But basically what I did was I took the Supreme Court opinion on Dobbs vs. Jackson, which is more conventionally known as Overturning Roe vs. Wade. So it is crazy long, it's 454,000 characters long, and I ran it through my recursive summarizer and After four iterations, I got down to the Supreme Court has well here. Let me just go here The Supreme Court has overturned Roe vs. Wade, which means that states are now able to ban abortion This will have a particularly hard impact on low-income women who will not be able to afford to travel to states where abortion is still Legal many will be forced to turn to illegal and unsafe abortions, which could lead to their death. So that was the ultimate result of recursively summarizing this document, which is a very impactful summary. It occurred to me, though, that just recursively summarizing something from an arbitrary length down to something super concise, okay, that's great, but you lose a lot of resolution. And then there is a huge need for answering questions from arbitrary volumes of data. This is an unsolved problem and it is a non-trivial problem. So what do I mean by answering questions from arbitrary data sources or an arbitrary number of documents? Whether you are a business or whether you're building artificial cognitive entities or chatbot assistants, you're going to have a huge amount of data to filter through. Oh, and actually before we get started, I just wanted to go ahead and plug my Discord server that I just started up. The join link will be in the comments. This is a really smart bunch of people who are all doing really great stuff. So if you wanna join my research Discord, please feel free to jump in. Make sure you check out the rules first, though there are only four rules. Keep it cool, be kind, discussion not debate, agree to disagree, and beliefs and evidence. Other than that, pretty much everything goes. We want it to be chill and friendly and productive. This is not a place to prove that you're right, to prove that other people are wrong. It's not a place to show off or anything like that. We are here to make the biggest difference possible for the world. Okay. Now that that plug is out of the way, multi-document answering. So OpenAI originally had their answers endpoint, which you could have an arbitrary number of documents and then it would search for the right document and give you an answer. They deprecated that because nobody used it, but it occurred to me that maybe there is something here because say for instance you've got a robot, right, like you imagine that you've got a domestic robot and you want it to like keep track of like, oh hey what did I tell you a year ago, right, or you have a business assistant that you want to be able to have intuitive discussions with. Managing large amounts of knowledge of memories is going to be critical for this. And if you just summarize an arbitrarily large amount of data, okay, that's fine. But you lose a lot of information and you can't interact with it. So this is going to be one of my pair programming sessions. Y'all always tell me that you love watching me just take an initial stab at something. So let me just tell you or show you where we're starting. So one, I'm gonna borrow some code from my recursive summarizer, but also I'm gonna borrow some code from my recursive summarizer, but also I'm going to borrow some code from my ACOG experiment. Because one of the things that I did here is I've got this function that allows you to stack memories and also embed memories. So I'll be borrowing some code from this as well. So we'll start here. Both of these are publicly available under the MIT license, so you're welcome to play along if you want. this as well. So we'll start here. Both of these are publicly available under the MIT license, so you're welcome to play along if you want. So without further ado, let's go to my multi-document answering. So I've already borrowed this code to recursively summarize something. So basically what I'm going to do is, because we've got a good example to start with, I'll go ahead and just grab this document and we'll start here. So we'll take that from the recursive summarizer. Because let me just show you, this is, it's 454,000 characters long and it is dense. It has a lot of information. So this is a Supreme Court opinion. And in order to have a, in order to allow people to better engage with political discourse or other information problems, wouldn't it be great if you had a really powerful chatbot that could answer questions for you and summarize things and like, tell me what this is all about. So that's what I'm gonna try and do. And obviously this is a non-trivial problem. I do not expect to finish it today, but we'll see how far we get. Okay, so recursively summarize, first things first, we're not going to just summarize everything. So we're gonna have to throw out some of this. Let's go ahead and rename this to input.text. That's fine. No. All right. So all text equals open file, input chunks equals text wrap. So what this does is it breaks it up into chunks of 3,000 characters. So what this first one is going to do is, my intuition is that what we should do is go ahead and make an index and rather than make like an inverted index that you'd use like in store in a database or whatever, we're going to do a vector based index. So let me show you, let's see where did it go, my ACOG experiment. So the inner loop. So what I've done here is we get embeddings from OpenAI and this one I did with Ada. We'll probably do Babbage or something. Well, no, just for search, I think Ada is probably fine. So we'll copy this function. Say, all right, we'll grab a GPT-3 embedding. We'll also go ahead and grab the similarity function, because it's just a real simple numpy, where you give the dot product of two vectors, and then the dot product gives you how similar those two vectors are. It's super simple. Okay, search index. Let's see. Oh yeah, so this was the function that I wrote to actually search it. So we will copy this function as well. So basically what this function does is you give it a text that you're gonna try and match, and then you pass it the index, which is in this case, it's a, what was it? Let me make sure I'm remembering this correctly. So search index, the nexus index, update index, yes. And update index, how was that made? So we list all the files and then we, okay, yeah, so this is all it is. It's a list of dictionaries where you've got a file name and a vector, so that's it. Okay, so we'll probably do it a little bit differently where I'll just have the whole thing in memory and instead of having a file name, I'll just have the chunk of text. So it'll all be in memory. Actually no, it should be on a file so that way it can be saved. Okay. So the first thing we're going to have to do here is just build index. I had this function as an update index because this was supposed to be for an artificial cognitive entity, which means it has to index its memories as they're accumulated. So that's an even more complicated problem. Okay, still following along? Good. Okay, so we've got chunks, text wrap, so we've got all the chunks, the result, there we go, that's fine. Open file, we don't need to do this. We don't need to run it through a prompt, All we need to do is get the embedding. Now, embeddings, if I remember correctly, you can get multiple embeddings at once, I think. Open AI embeddings. Let's see. Take a look at it. Input simple document goes here. Cause if we've got like 150 different, chunks to do. All right, I'm not seeing anything that does multiple embeddings. I'm not gonna worry about it right now. We'll just do one embedding at a time, that's fine. And actually, I don't even think we'll need the search in this one. So I can probably take that out. Okay, so we'll comment this out for chunk in chunks. We actually just need the embedding. So we'll say, GPT-3 embedding, so content, yes. Embedding equals GPT-3 embedding, and then we'll do chunk.encode. Oh, here, we'll just copy this. So what I had to do here, this particular bit, this, I found that sometimes there are Unicode characters that GPT-3 cannot handle and it errors out. And so what I found, what I started doing is just adding this little bit of code to change it. So you're basically encoding it from Unicode to ASCII, which is simpler, and then you decode it back into just a regular string variable. And that seems to prevent any GPT-3 problems. Okay, so we got the embedding, and we don't need a summary because essentially an embedding is a type of summary. It's just, it's a numerical summary. Okay, so what we're gonna do then is instead like what we did here, where it's just alluding to a file name because with an ACOG, here, let me just show you. With an artificial cognitive entity, you might have a list of... Where did it go? Did I delete all the memories? I might have deleted all the memories. Or no, I haven't gotten started yet. So basically what you do is you have a log. So all the memories, all the experiences of an ACOG is just going to be like a list of log files. And they could be multimodal files, right? You could have audio, video, text, whatever other sensory information it's got. You can also have output information. But the point is, it'll all be accumulated there, and then you can represent it as a vector, which is a way of representing the semantic meaning of it. Okay, so we can say, content equals chunk. So that'll be just the bit of text. And then we will say the vector equals the embedding. I prefer the word vector because, one, it's two syllables and it's easier to say. You've got vector. Embedding is too slow. And maybe that's just me being weird but my brain I prefer the word vector it's easier to say okay so then what we'll do is we will we will save this as a JSON file I think JSON so that way it'll be it'll be readable yeah I think that'll be the way it'll be readable. Yeah, I think that'll be the way to go. Let me make sure that we've got, let's see, import JSON. And I always have to do this, because I can't ever remember it. With open, we're gonna say index.json, write binary. I think that's it. Encoding equals UTF-8. Where was the last time that I used this function where I saved JSON? It's not here. It's probably going to be something older. Where did I save JSON? It might have been here. Do I have a JSON file here? I have JSON L. That might Do I have a JSON file here? I have JSON-L. That might be close enough. Format training data. Import JSON, okay. Yeah, that's fine, okay. Oh wait, no, that's dumping it to string, so I'll need JSON.dumps. I think that's the one that's dumping it to string. So I'll need json.dumps. I think that's the one that dumps it to file. As outfile. Let's see. Literally typed out json. Json.dumps, and then I believe it'll be result outfile. And then what was it like indent equals two. I'm totally misremembering this. I need to make sure that I get this right though. Cause nothing is worse than like, really? I don't believe that. Code, there we go. Hey, there we go. Return JSON dumps. No, that's a flask response. That can't be right. No, that's a flask response. That can't be right. There we go. JSON.dump. That's all writing it as JSONL. That can't be right. Yeah, there we go. JSON.dump data outfile indent one. Okay. Hey, I've go. JSON.dump data out file indent one. Okay. Hey, I've almost remembered it. Right, not quite, but almost. We'll do it. We'll leave it indent two, that's fine. Okay, because nothing is worse than, oh, and not write binary, this is just text. Yeah. And actually, I think, maybe, let's say I don't think I need to do the separators, that's fine. And it's always as right and not encoded as UTF-8. Okay, so let me remove the encoding as UTF-8. Okay, we'll leave it at that, that should work. Okay, so all text, we open it, we get the embedding, we append this to the result, so the result will be a list of dictionaries with some text and then a vector. And so that'll be our database. Yeah, and we don't even need to build the index because we're building it now. So let me just go ahead and delete this function because that's noise. Search index, we can delete that because that's noise. We can delete similarity because we don't even use that. We don't use completion. Do I use save file? I don't use save file anywhere. All I use is open file. Okay. We don't need that. I think that's about it. Don't need re. I think we just use text wrap, JSON. I don't even use OS anymore. Clean this up. Okay, that should be fine. Let's go to multi-document answering and we'll just call this build the index. There we go. Keep it in editor. No, we'll just reopen it. Okay, so this will generate a JSON file that will have, it'll be a list of chunks of text that are 3000 characters long, each of them with an embedding. We can probably do it a little bit longer. Let's do 4000 characters, because it's roughly three or four characters per token. So this will be roughly 1000 tokens, which will be a quarter of, well, hmm, I wonder if we can do longer. No, this will be a quarter of, well, hmm, I wonder if we can do longer. No, this would be fine because we still need some room to work around it if we have one of these chunks. This will be our knowledge base. So let me make sure this will work. I'll let it run. CD, multi-document answering, Python build index. Did I get it right the first time? No. Save GPT-3 log is not defined. Ah, see that's what I did wrong. I'm not going to worry about saving every single log. This is a normal list, that's fine. Okay, let's try again. And then, oh, I don't have any output, do I? Yeah, I need some kind of output so that I can see what it's doing because otherwise I'm gonna be confused. So what I often do for things like this, just to do a sanity check is I'll set it to a variable so then I can just print the variable and then we'll do comma and then new line, new line, new line so I can see what it's actually generating. Because sometimes if you do it wrong, your brain just is not working with you today. Well mine is working with me today. Sometimes it isn't. But sometimes your brain just isn't working and the variable isn't what you thought it was. But in this case, I think it's all right because this is relatively straightforward. Okay. Python, build index. Oh, wow. That's fast. That's really fast. The embeddings endpoint is quick, dang. Oh, I wonder if it's because I'm using the ADA endpoint. Yeah, I bet that's why it's so fast. Dag gum, is it already done? Index dot JSON, okay. So we've taken an input from 440 kilobytes and made it into more than three and a half megabytes. Oh, perfect. So there we go. Look, it worked. It worked. It worked. Okay. So this is what it looks like now. Let me zoom out a little bit, because you don't need to see it in detail. So you've got content which is just the chunk of text. There we go. I can speak. Then a semantic vector. So the semantic vector is the mathematical, the numerical representation of this meaning. So it's basically this is a pair. This is the human readable text and then this is the machine readable representation. And so then we've got a whole bunch of those. And this file could be compressed, but what I did was when I put the indent here to say indent equals two, so that makes it more more human friendly right so you can see that you know the data is structured so like for every layer of embedding there's two spaces so the the the root list is at index zero and then we've got two spaces for the first dictionary and then we've got another two spaces for the for the the nested've got another two spaces for the nested list. So you can clearly see the levels of nesting. Okay, so we've got our index. That was much faster than I thought it would be. Let's zoom back in. Wow, I was hoping that I'd have a mental break to be able to keep thinking. Okay, so I'm going gonna actually pause this for a second just because you don't need to see me like gathering my thoughts. Typically, when I run these loops, I have like a few minutes to gather my thoughts. So I'm gonna pause the video for just a second and we'll be right back as I mentally plan the next step. Okay, and we're back. As with all things, data prep is the biggest thing, biggest problem, so we're closer to being done than you might have guessed. I started on the next part, so we've built the index, it was way faster than I thought. Now we're going to answer questions. And so what I did was I just created, wrote a quick thing to open the index that we just created and then we'll do an infinite loop where we will just ask questions. So this is based on the artificial cognitive entity thing where it's basically just searching for a particular set of memories, right? This same paradigm should work anywhere. So what we're gonna do is we're going to, we're gonna take whatever our question is and we're going to get the vector from it. And so we'll just get a vector and then we'll match which all the thing, all the parts that are closest. And actually here, let's go ahead and just do a separate function. So def and then we will, well, let's just copy this function because it's pretty close to what we need. So instead what we'll do is we will do, let's see, results equals search index, and then we'll do query. So count, we'll say 10, we'll say top 10. We don't have timestamps, so we'll get rid of that. So vector equals GPT-3 embedding the text, so that's the query. Scores, okay, so for I in nexus index so we'll actually call this data we'll just replace that with data all right so for I and data if I equals vector this is identical skip it we don't need to worry about that because we don't have we're not worried about sequential memories in this. This is not a robot or anything like that. So score equals similarity between our query and the actual what we're looking for. And the vector is the right name. Okay. We don't need file name. So this, we'll change this to content. Content. Yeah, so basically what we'll do is we'll just create a similarity score for all of them. Ordered equals, all right, so content and score. So after the, because once we get the score, we don't care about the vector anymore. We just say, okay, we're gonna create a new, we're gonna create a new list that'll be the same length as our database, but we're gonna sort it by whichever one is closest. Let's see. We don't need that because we already have the content. And we're just going to assume that, because we know our database is longer than 10. So basically why I'm saying 10 is we're just gonna say, okay, so if we have 10 chunks that are 4,000 characters long, that's 40,000 characters, which is roughly 10,000 tokens. And so we know that we have to solve the problem of what if we have, even after searching, we have a larger corpus than we can feed into GPT-3 in one go. How do we handle that? So with that in mind, what we're gonna do is we get the results. So this is a much compressed search where we're gonna end up with 10 results that could answer the question. Actually, let's make this a little bit more challenging. We'll do 20. So we'll have the top 20 chunks of text that should answer our question. Now the longer your question is, the more specific your question is, the better the search is going to be. OK. So results equals search index, query, and then we pass along the data, which the data is our master index. So that's this here, which has the entirety of the Supreme Court opinion, paired down into vectors. Okay, so with that, we then have to actually ask or answer questions. So this is where we get into prompt engineering. So let me go to Playground and we'll go grab, let's just grab an arbitrary chunk of text. Yes, login, that's fine. All right, so this is where, let's see, answer the following question. Let's see. Answer the question, the blah, blah, blah from the passage. No, use the following passage to answer the question. We'll figure that out in a second. Actually no, we'll We'll do question first, so that it knows what the question, and then passage, and then answer. Okay, so the passage is this, so this is probably what we'll do. All right, so let's think of a question that would two cases arrive within the word balance scare quotes. The majority is a dirty word, moderation is a foreign concept. The majority would allow the states to ban abortion because it does not think forced childbirth would equate to equality and freedom. So, the question will be, why did the courts decide to allow states to ban abortion. All right, so this is a question that is partially answered by this thing. So then let's see how it just answers. This is just right off the cuff. And so you see, oh, so remember I said these are 4,000 character chunks, and you see it's right at 1,000 tokens, so that's 8 cents. Could be cheaper, could be more expensive, whatever. Answer. Did it give up? Oh, there we go. According to the passage, the courts decided to allow states to ban abortion because they believe a woman's freedom and equality are not involved in the decision to bear a child. Ouch! Okay, yeah. Because we're making it concise, let's use the following passage to use the following passage to give a detailed answer to the question. So we'll say detailed answer. Because here's the thing, we're going to basically recursively answer this several times. And so we'll consolidate it down. So let's see if this is any better or different. Oh this is good. Okay. Wow. Yikes. Shots fired. Okay. I like this better. So we'll use this as our prompt because again the idea here is not to summarize it as concisely as possible the idea is to extract information from a much larger document and pare it down and because we're gonna we're gonna basically take the top 20 we're gonna need to pare it down a few times. So this answer was about 200 tokens so if we take 20 times 200 that's 4,000 tokens so that's still going to be like a full thing and that's that's assuming that it doesn't actually make it much longer because some of the answers might be might be longer. Okay so we'll do this this will be our question answering prompt. OK, so passage will remove this. So we'll do passage detailed answer. OK. And so this will be prompt answer. OK, so this is our this is our first tier, first level of answering. And so what we'll do then is for all 20 of those top results, we'll ask the same question and then accumulate those answers together and kind of summarize them all together to kind of merge it into a single thing. Okay, so here's how we're going to do that. We basically will borrow the recursive summarization thing that I've done before. So let's open this, recursively summarize. Yes, yay, fine. And actually I think we will need the prompt here as well. Yeah, write a concise summary. Yeah, yeah, yeah, yeah, okay. So that's that. And then we'll also need the GPT-3 completion. So we will need this. So let's grab the completion. Okay, so with those results, so for result in results, then we need actually here, answers equals list, prompt equals open file. This would be, what was it? Prompt answer.text.replace passage with, and that'll be result.content. Yeah, yeah. And that'll be result.content. Yeah, yeah. Okay, so that should give us the answer. And then the answer equals GPT-3 completion prompt. And since this is already run through, I don't think we need to do the thing that I did in the index, because we've already cleaned up the chunks, right? We've already cleaned it up. So it should be encoded in a way that is friendly with GPT-3. OK. So then we get an answer to the question. And so then we do answers.appendAnswer. So that should be fine. answers.appendAnswer. So that should be fine. Let's do printAnswer. And we'll do new line, new line, just to give it a little bit of vertical space so it's clear, so it will see that it's accumulating the answers. And then, so this object here, this list, will have all of the answers, because we're basically asking the same question, but we're going to be asking it of different chunks of text. And so it's like, okay, how do we get this nebulous combination of things together? So then what we'll do is we will do, we'll borrow the same exact thing that we did for the summarization, right? And so we'll take, we'll take TextWrap. So we'll make sure that we've got TextWrap here. So let's go back to the recursively summarize. So we'll do import, whoops, do not delete that. Import TextWrap. And since the DaVinci Instruct has a token limit of 4,000, so 4,000 tokens times four characters, that's 16,000 characters. So we can get a pretty big chunk of text. So we'll do a text wrap of 10,000 characters. Okay, so I'll do answer the same question for all returned chunks. And then we will do summarize the answers together. And so here we say, oops, that's already here. Oops, that's already here. We are taking, here, let me do a time check real quick because we're close enough to the end. Yeah, this will be a longer video, but we're closer to the end. This is going way better than I thought, knock on wood, that this actually works. Okay, so summarize the answers together. Right, that's what I was doing. Kind of lost my train of thought there for a second. Okay, so for, no. We need to join it all into one chunk. Okay, so all answers equals, what is it? Dot join answers. I think that's how that works. Let me do a quick Python. L equals, we'll do bacon, bacon and burger. And then we'll do new line, new line, dot join L. and then we'll do newline.joinl. Oh, right, s equals print, print, print s. Okay, yes, that is right. Make sure I get the syntax correct. Okay, so basically what we're doing is we're joining all the answers together into one big block. So regardless of how long it is, we can say, okay, let's take all these answers and then kind of squish them together. I'll probably only do one pass, but you would technically want to do this multiple times. So chunks equals text wrap. Make sure I use this correctly, text wrap dot wrap. And so we'll do all answers. And I said 10,000, not 21,000, 10,000. That's the correct number of zeros, I think. Four zeros, yeah. Okay, so then for chunk in chunks, we also need a, we'll say final equals list. So for chunk in chunks, we are just gonna summarize it all together. So we'll borrow this prompt. Instead of a concise summary, we'll do detailed summary because we're just gonna take all the different answers and kind of merge it into one. So let's go ahead and save this. Detailed summary, detailed summary, and we'll save this under, excuse me, multi-document answering, and we'll do prompt summary dot text. Okay. So basically what we're going to do is we're going to take for each of the chunks of the answers, and you can do this recursively, right, until you get it into one thing. We're gonna do the same thing here. So prompt equals open file prompt instead of answer we'll do prompt summary and we'll replace. So the thing to summarize result content, that should be good. And then we will do summary equals GPT-3 completion prompt. And then we will do final dot append summary. Okay, so that should be that. And this one does save it out to GPT-3 logs. Let me make sure that that is there. GPT-3 logs. Okay, so then once it's done, we will do print. We'll do new line, new line. And then we'll do, actually here, we can just go ahead and do that to give us a little bit of white space. And then we'll do final dot no. We'll do new line, new line dot join final. There we go. So that'll actually look like a final answer. We'll see if this works. Might not, may or may not. We'll have it output. The first one, I'll just have it outputting each answer as it goes so that we can see it. Wow, why am I nervous? This is crazy. Am I missing anything? Send it. Python, answer questions. Why did the Supreme Court strike down Roe v. Wade? Well, it didn't like that. Okay, something went wrong. It looks like it didn't return anything here. It looks like it didn't return anything here. So I probably did something wrong with the search. Okay. Print results. And then we'll just do an exit here because that's where I think it's broken. Whoops. Answer questions. Why did the Supreme Court overturn Roe v. Wade? Yeah, okay, so the search is broken. My intuition was correct. Okay, so vector equals GPT-3 embedding for the text. So that's the query, right? So the query is there. And then the scores. So for I and data, so that's a list. Make sure that I pass that correctly. Okay, let's print out score just to make sure that it's actually, Y. out score just to make sure that it's actually...why? Okay, we're getting scores, so that's correct. And then reverse equals true results list. Oh, I just declared an empty list. Well, there's your problem. Okay, so we need, we just, whoops, get rid of that and the ordered. And then so we do ordered zero to that. Okay, so that should be correct. I think I fixed it. Famous last words. So we do ordered zero to that. Okay, so that should be correct. I think I fixed it. Famous last words. Okay, so let's CLS. Why did the Supreme Court overturn Roe v. Wade? Oh, it's taking longer. Bueller. Oh, see, I needed to add in a few more things. Okay, import re from time import time and sleep. Okay, so basically what happened was it got to where it's trying to give me the answers and then it blew up because I forgot to import re or regex, which is I used to clean it up. And then I also didn't import sleep as well as time because I use time for the for the file names. OK, let's try this again. Almost there. Answer questions. Your question is, why did the Supreme Port overturn Roe v. Wade? Ooh, sorry, that was probably loud. Okay. Now it's thinking. Okay. So it's providing some answers. Cool, cool, cool. satisfactory answers. Why did you freeze? If it blows up, I'll be sad. Now so this is kind of a boilerplate. Ooh, that was a long answer. Okay. Nope, it didn't like that. So I need to fix, I do need to add in some of the, darn. Okay. Okay, so that's the bug that I was telling you about. Error communicating char map cannot encode character. Okay, so we need to, for all of the prompts, we do need to add back in this bit here, just for whatever reason, there are some things that it doesn't like getting in there. All right, so we'll come back here. We'll do prompt equals prompt.encode slash decode. This is just a reusable string, so every time we talk to GPT-3, we can run this prompt real quick. we talk to GPT-3 we can run this prompt real quick. And then, you know, actually even smarter, we do it here. Do it once instead of multiple times. Okay, maybe that's what I'll do. I'll just have this in all of my GPT-3 completion functions from now on. Let's do that. And then we'll also do that in the embedding one. So we'll do that here. And instead of prompt, we'll do content, just to ensure that everything is encoded in a way that GPT-3 will be happy with. Yeah, okay. So we've got the answers and then we should be good here. Okay, let's try it again. Enter your question here. Let's ask, let's not give it such a softball question because we saw that it was answering. So what are the historical precedents that the Supreme Court looked at when determining whether or not to overturn Roe v. Wade? So this is a much more complex question. So we've got some keywords in there like, egregiously wrong and cause significant negative consequences, ouch. Okay, so we'll see if this less, this more hardball question is gonna produce satisfactory results. Because that first question that I was asking was answered explicitly many times in the document, but this one requires a little bit more interpretation, let's say. And we see it's going through. Fundamental right that is deeply rooted in history. Okay, sound basis and precedent. States could not ban abortion as it violated a woman's right. Okay. Because basically I'm asking for like historical precedent. So we'll see if it's good. And it does look like it's talking about some previous decisions, you know, like 1973 That's somewhere in history There's a long long response Courts decided to allow states because they believed it is a woman's right to choose See that doesn't make any sense though allow states to ban abortion because it's a woman's right to choose Well, just if the states can it, that doesn't make sense. Because it looks like it's giving an explanation as to why the states allowed it, but it's not actually explaining the historical precedent. So it may or may not actually understand what I was asking. While it's going through this, let's look through the GPT-3 logs. This is why I love doing this. So use the following passage to give a detailed answer to the question. Why... Wait, did I give it the wrong... it's still asking an older question. Hold on. Why did the courts decide to allow... that's not the question that I put in, was it? Am I losing my mind? Yeah, enter your question here. What are the historical precedents? That's what I'm looking for. Why didn't it ask that question? Hold on. What have I done wrong here? Oh. Ha! I know what I did wrong. I didn't actually populate the question. Yikes. Yeah. So, here's what I did wrong. If I look at the actual prompt, so this is the summary, but yeah, I have the question hard-coded. Yeah, okay. So query, you have to populate that. I'm not losing my mind. I just didn't actually populate the query because I get the query and then I ignore it. Okay, so we will do this. We'll just also do replace query with query. And I think that's it. Yeah, OK. But first, let's see. So we know a question that it did ask. It asked, why did the courts decide to allow states to ban abortion? Okay, that's a softball question. Let's see what the final answer was that it gave us. Okay. The Supreme Court has overturned a lower court ruling that has struck down a Mississippi law that would have banned most abortions after 15 weeks of pregnancy. The 5-4 decision, with Justice Amy Coney Barrett joining the court's three other conservatives in the majority, is a major victory for abortion opponents and a blow to abortion rights advocates. The decision does not immediately impact abortion laws in other states, but it paves the way for more restrictions on abortions to be enacted. The majority opinion written by Justice Clarison's Thomas states that the Constitution does not protect a woman's right to an abortion. Thomas writes that the court's previous decisions on the matter Roe v. Wade and Planned Parenthood versus Casey were wrongly decided and should be overruled. Wow, that is a really good answer to that question. Yeah, okay, in Dobbs versus Jackson Health Organization, the Supreme Court considered a challenge to a Mississippi law regulating abortion, the law known as the Gestational Age Act, prohibit abortion after 15 weeks of pregnancy. The court first noted that abortion is a matter of great social significance and moral substance and that laws regulating abortion are entitled to a strong presumption of validity. The court then went on to explain that the Mississippi legislature had identified legitimate interests in protecting the life of the unborn, which provided a rational basis for the Gestational Age Act. The court therefore concluded that the act was constitutional and reversed the decision of the lower court. The court also made clear that its decision should not be interpreted as endorsing any particular view of abortion, but rather as affirming the right of each state to make its own laws on the matter.\" That is a phenomenal set of answers. Wow. Okay. So that, these answers are, I'm getting chills. This set of answers is a wonderful, wonderful example of an answer to the question that was asked. Okay. So, however, that was a hard-coded question. So let me, I'm closing some things that I don't need. Answer questions.py, so we've got the index, we can close all that. Okay, so I've got, the query is now gonna be populated. So let's now, okay, CLS. Okay, so now that the question should be properly populated, let's do this again. Python, answer questions. What historical precedence answer questions. What historical precedence did the Supreme Court consider when deciding to overturn Roe v. Wade? Okay, this is a harder question. And so Then what we'll do is while that's running, let's see, 220, so we'll see. It'll take a second. Okay. Question. Yeah, there we go. Okay, so it made it into the prompt. It says, the Supreme Court considered several historical precedents. Look at this, it's working. Oh, man. Okay. Important precedents. Look at this, it's working. Oh man, okay. Important precedents, Corston. Okay, so it looks at those other precedents. If you read the actual thing, which I don't expect anyone to, it talked about like 30 odd things in the past, like going all the way back to common law in the 13th century in England. So let's see, yeah, Plessy and Brown versus Board of Education, yeah, this is doing pretty good. Okay, so let's see if it picks up on the common law in England. Commerce Clause, Hang on, I got a message Okay, I'm going to mute my phone, sorry Fourteenth Amendment Ummm Ch-ch-ch-ch-ch Supreme Court, several, Roe v. Wade, Roe v. Wade, does not have the right to be sterilized without consent. So it looks like it's mostly keying in onto the initial one, and it's kind of saying the same things over and over again. But we'll see, we'll see in the final result. Brown vs. Board of Education. Also, okay, so it's picking up on some other ones. Religious schools. Yeah, Establishment Clause of the First Amendment. Okay, it is looking at deeper history. This is looking like a success. It does look like it is. Final answer, the Supreme Court has overturned a lower ruling banning abortion. Okay, cool. The majority opinion written by Justice Brett Kavanaugh. I thought it was by Clarence Thomas. So it might be... let's see. But he says those decisions are not inexorable commands and the decisions should be overturned reasonably for ex-state interest. Okay, so it's not actually talking about the historical things. The dissent in Dobbs v. Jackson argues the long history of abortion justifies the court decision to recognize. Okay, so it, okay, I think something was lost. Let's look at the last few inputs. So let's grab Let's look at the last few inputs. So let's grab, okay, so that one is one of these. So write a detailed summary. It looks like it got cut off. Interesting. And it did it twice. Huh, okay, something went wrong when I was trying to get the summary at the very end. Let me pause this because, well, it's an hour long. I know you guys are going to want to see this. So I'm going to pause it and see if I can't figure out why the summary at the end went wrong. Okay, I'm looking through this and it's not making any sense. Also, you probably noticed a wardrobe change. I realized that because I had been sitting outside at a coffee shop earlier I had pit stains and that was probably pretty gross. And black hides that. Okay, so I copied the console output to a text file, and it did pick up on one thing that I had hoped it would, which was common law, history in England. So it did see all that, right? So we got all these answers, there should be 20 answers, Griswold versus Connecticut, okay, so it saw all those. It got all kinds of stuff from all throughout history. But then when it got to the final answer, it just gave me a summary. And some of which was not even in here, so I'm like, where did that come from? Okay, so we've got this. We get all the answers, right? So the answers, these are the answers. They should be appended here. So answers equals list, answers. All answers is join this, right? And then chunks equals text wrap. A wrap, all answers with 10,000, 10,000 characters, final list, prompt equals open file, prompt summary, summary result, oh, that's what I did wrong. This right here, darn it. Ugh, so simple. So simple. So we got all the chunks, but then I didn't pass the right chunks in. This is why you test your code, kids. Okay, so for chunk in chunks, there we go. We summarize them all together. So let's rerun this. Yeah, let me, I'll pause the video just because you don't need to sit and watch it rerun again. But I will copy this question and I'll rerun it and then I'll show you the final result and we should be done. All right gang, I think it worked. The final thing, so there is... Oh, here, let me just copy this out into a text file. So enter your question here. We'll grab this. Okay. All right. So reading through it, enter your question here. What historical precedents? It did get the common law, so the Supreme Court considered several historical precedents. First, they considered the pre-constitutional common law history in England, which showed that abortion was largely prohibited in most American states as of 1868. So it got way back in history. So that's good. That was one of the key things that I remember from my previous work that I was like, wow, they went way back. Okay, final answer. The Supreme Court overturned Roe v. Wade by considering several historical precedents. The first precedent was the principle of stare decisis, I think I'm saying that right, which requires respect for the court's precedents and for the accumulated wisdom of the judges who have previously addressed the same issue. The court found that Roe was an egregiously wrong decision that had caused significant negative consequences and that overruling it would not unduly upset the legitimate reliance interest. The second precedent was the history of stereodecesis in the court, which establishes that a constitutional precedent may be overruled only when it is egregiously wrong and has caused significant negative consequences, and overruling it would not unduly, okay, it's kind of repeating itself. Applying these factors, the court concluded that Roe met all three criteria and thus deserved to be overturned. The third precedent was the fact that at the time of Roe, 30 states still prohibited abortion at all stages. This showed that the Roe decision was out of step with public opinion at the time. The fourth precedent was the fact that, in the years prior to Roe, about a third of the states had liberalized their laws. This showed that there was a trend towards liberalization that was interrupted by Roe. The fifth and final precedent was the fact that Roe abruptly ended the political process of liberalizing abortion laws. This made it clear that Roe was not just wrong, but egregiously wrong, and that it needed to be overturned in order to allow the democratic process to continue. That is a phenomenal explanation. The Supreme Court overturns Roe v. Wade, taking into consideration several historical precedents. This is the second chunk. Firstly, they look at the precedent set by Roe itself, was incorrectly decided, erroneous historical narrative. Secondly, they look at the precedent set by Casey, which revised the textual basis for the abortion right, silently abandoned Roe's erroneous historical narrative. Finally, they look at the precedent set by Janus and Ramos, which held that states cannot protect fetal life prior to viability. All these factors led... Okay, so the final summarization needs a little bit of work, but still, in terms of giving you an answer as to, like, asking the question, what were the historical precedents, this was amazing. I am super satisfied with this. So, I'll call it a day there. Thanks for watching. This was amazing. I am super satisfied with this. So I'll call it a day there. Thanks for watching.", "chunks": [{"timestamp": [0.0, 3.56], "text": " I'm back."}, {"timestamp": [3.56, 9.92], "text": " Okay, so I know that I said I would take like two to four months off, but apparently something"}, {"timestamp": [9.92, 14.56], "text": " has changed in my brain and I'm not going to take that long anymore."}, {"timestamp": [14.56, 20.44], "text": " I have continued reading Brain Trust and as what always happens whenever I read cognition"}, {"timestamp": [20.44, 23.88], "text": " or neuroscience, I'm inspired to do more work."}, {"timestamp": [23.88, 25.64], "text": " So I want to bring you up to speed"}, {"timestamp": [25.64, 27.36], "text": " with what I worked on last night."}, {"timestamp": [27.36, 29.84], "text": " And I didn't share it because one,"}, {"timestamp": [29.84, 32.66], "text": " it is a politically sensitive thing."}, {"timestamp": [32.66, 34.92], "text": " I did check OpenAI's guidelines"}, {"timestamp": [34.92, 37.24], "text": " for content sharing and publication."}, {"timestamp": [37.24, 39.28], "text": " And you're not supposed to share anything"}, {"timestamp": [39.28, 42.26], "text": " that is part of a political campaign."}, {"timestamp": [42.26, 44.4], "text": " So I think this is okay."}, {"timestamp": [44.4, 48.8], "text": " But basically what I did was I took the Supreme"}, {"timestamp": [48.8, 54.18], "text": " Court opinion on Dobbs vs. Jackson, which is more conventionally known as Overturning"}, {"timestamp": [54.18, 65.52], "text": " Roe vs. Wade. So it is crazy long, it's 454,000 characters long, and I ran it through my recursive summarizer and"}, {"timestamp": [70.46, 71.3], "text": " After four iterations, I got down to the Supreme Court has well here. Let me just go here"}, {"timestamp": [75.76, 75.9], "text": " The Supreme Court has overturned Roe vs. Wade, which means that states are now able to ban abortion"}, {"timestamp": [82.36, 86.8], "text": " This will have a particularly hard impact on low-income women who will not be able to afford to travel to states where abortion is still Legal many will be forced to turn to illegal and unsafe abortions, which could lead to their"}, {"timestamp": [86.8, 87.8], "text": " death."}, {"timestamp": [87.8, 93.96], "text": " So that was the ultimate result of recursively summarizing this document, which is a very"}, {"timestamp": [93.96, 96.98], "text": " impactful summary."}, {"timestamp": [96.98, 101.68], "text": " It occurred to me, though, that just recursively summarizing something from an arbitrary length"}, {"timestamp": [101.68, 106.96], "text": " down to something super concise, okay, that's great, but you lose a lot of resolution."}, {"timestamp": [107.72, 116.56], "text": " And then there is a huge need for answering questions from arbitrary volumes of data."}, {"timestamp": [117.48, 120.6], "text": " This is an unsolved problem and it is a non-trivial problem."}, {"timestamp": [120.6, 124.6], "text": " So what do I mean by answering questions from arbitrary data sources"}, {"timestamp": [124.6, 125.74], "text": " or an arbitrary number"}, {"timestamp": [125.74, 129.5], "text": " of documents?"}, {"timestamp": [129.5, 136.44], "text": " Whether you are a business or whether you're building artificial cognitive entities or"}, {"timestamp": [136.44, 142.76], "text": " chatbot assistants, you're going to have a huge amount of data to filter through."}, {"timestamp": [142.76, 145.0], "text": " Oh, and actually before we get started,"}, {"timestamp": [145.0, 148.56], "text": " I just wanted to go ahead and plug my Discord server"}, {"timestamp": [148.56, 149.84], "text": " that I just started up."}, {"timestamp": [151.0, 153.48], "text": " The join link will be in the comments."}, {"timestamp": [153.48, 155.38], "text": " This is a really smart bunch of people"}, {"timestamp": [155.38, 156.84], "text": " who are all doing really great stuff."}, {"timestamp": [156.84, 160.46], "text": " So if you wanna join my research Discord,"}, {"timestamp": [161.6, 163.38], "text": " please feel free to jump in."}, {"timestamp": [163.38, 164.76], "text": " Make sure you check out the rules first,"}, {"timestamp": [164.76, 170.02], "text": " though there are only four rules. Keep it cool, be kind, discussion not debate, agree to"}, {"timestamp": [170.02, 176.04], "text": " disagree, and beliefs and evidence. Other than that, pretty much everything goes. We"}, {"timestamp": [176.04, 179.98], "text": " want it to be chill and friendly and productive. This is not a place to prove"}, {"timestamp": [179.98, 183.74], "text": " that you're right, to prove that other people are wrong. It's not a place to"}, {"timestamp": [183.74, 185.4], "text": " show off or anything like that."}, {"timestamp": [185.4, 189.28], "text": " We are here to make the biggest difference possible for the world."}, {"timestamp": [189.28, 190.32], "text": " Okay."}, {"timestamp": [190.32, 194.36], "text": " Now that that plug is out of the way, multi-document answering."}, {"timestamp": [194.36, 200.4], "text": " So OpenAI originally had their answers endpoint, which you could have an arbitrary number of"}, {"timestamp": [200.4, 204.84], "text": " documents and then it would search for the right document and give you an answer."}, {"timestamp": [204.84, 211.28], "text": " They deprecated that because nobody used it, but it occurred to me that maybe there is something"}, {"timestamp": [211.28, 217.28], "text": " here because say for instance you've got a robot, right, like you imagine that you've got a domestic"}, {"timestamp": [217.28, 223.44], "text": " robot and you want it to like keep track of like, oh hey what did I tell you a year ago, right, or"}, {"timestamp": [224.0, 226.72], "text": " you have a business assistant"}, {"timestamp": [226.72, 231.6], "text": " that you want to be able to have intuitive discussions with. Managing large amounts of"}, {"timestamp": [231.6, 238.84], "text": " knowledge of memories is going to be critical for this. And if you just summarize an arbitrarily"}, {"timestamp": [238.84, 245.64], "text": " large amount of data, okay, that's fine. But you lose a lot of information and you can't interact with it."}, {"timestamp": [245.64, 250.64], "text": " So this is going to be one of my pair programming sessions."}, {"timestamp": [251.66, 254.32], "text": " Y'all always tell me that you love watching me"}, {"timestamp": [254.32, 256.36], "text": " just take an initial stab at something."}, {"timestamp": [256.36, 259.44], "text": " So let me just tell you or show you where we're starting."}, {"timestamp": [259.44, 261.52], "text": " So one, I'm gonna borrow some code"}, {"timestamp": [261.52, 263.44], "text": " from my recursive summarizer,"}, {"timestamp": [263.44, 269.32], "text": " but also I'm gonna borrow some code from my recursive summarizer, but also I'm going to borrow some code from my ACOG experiment."}, {"timestamp": [269.32, 271.7], "text": " Because one of the things that I did here"}, {"timestamp": [271.7, 277.54], "text": " is I've got this function that allows you to stack memories"}, {"timestamp": [277.54, 278.8], "text": " and also embed memories."}, {"timestamp": [278.8, 281.6], "text": " So I'll be borrowing some code from this as well."}, {"timestamp": [281.6, 282.48], "text": " So we'll start here."}, {"timestamp": [282.48, 284.84], "text": " Both of these are publicly available under the MIT"}, {"timestamp": [284.84, 285.28], "text": " license, so you're welcome to play along if you want. this as well. So we'll start here. Both of these are publicly available under the MIT"}, {"timestamp": [285.28, 292.16], "text": " license, so you're welcome to play along if you want. So without further ado, let's go"}, {"timestamp": [292.16, 299.16], "text": " to my multi-document answering. So I've already borrowed this code to recursively summarize"}, {"timestamp": [299.16, 306.52], "text": " something. So basically what I'm going to do is, because we've got a good example to start with, I'll"}, {"timestamp": [306.52, 311.8], "text": " go ahead and just grab this document and we'll start here."}, {"timestamp": [311.8, 313.72], "text": " So we'll take that from the recursive summarizer."}, {"timestamp": [313.72, 320.04], "text": " Because let me just show you, this is, it's 454,000 characters long and it is dense."}, {"timestamp": [320.04, 327.4], "text": " It has a lot of information. So this is a Supreme Court opinion. And in order to have a,"}, {"timestamp": [328.74, 331.36], "text": " in order to allow people to better engage"}, {"timestamp": [331.36, 335.74], "text": " with political discourse or other information problems,"}, {"timestamp": [335.74, 338.76], "text": " wouldn't it be great if you had a really powerful chatbot"}, {"timestamp": [338.76, 342.2], "text": " that could answer questions for you and summarize things"}, {"timestamp": [342.2, 345.52], "text": " and like, tell me what this is all about."}, {"timestamp": [345.52, 346.72], "text": " So that's what I'm gonna try and do."}, {"timestamp": [346.72, 349.24], "text": " And obviously this is a non-trivial problem."}, {"timestamp": [349.24, 351.08], "text": " I do not expect to finish it today,"}, {"timestamp": [351.08, 353.12], "text": " but we'll see how far we get."}, {"timestamp": [353.12, 357.54], "text": " Okay, so recursively summarize, first things first,"}, {"timestamp": [358.88, 360.92], "text": " we're not going to just summarize everything."}, {"timestamp": [360.92, 364.04], "text": " So we're gonna have to throw out some of this."}, {"timestamp": [366.28, 377.16], "text": " Let's go ahead and rename this to input.text. That's fine. No. All right. So all text equals open file, input chunks equals text wrap."}, {"timestamp": [377.16, 387.68], "text": " So what this does is it breaks it up into chunks of 3,000 characters. So what this first one is going to do is, my"}, {"timestamp": [387.68, 392.4], "text": " intuition is that what we should do is go ahead and make an index and"}, {"timestamp": [392.4, 396.78], "text": " rather than make like an inverted index that you'd use like in store in a"}, {"timestamp": [396.78, 408.16], "text": " database or whatever, we're going to do a vector based index. So let me show you, let's see where did it go, my ACOG experiment. So the"}, {"timestamp": [408.16, 418.88], "text": " inner loop. So what I've done here is we get embeddings from OpenAI"}, {"timestamp": [418.88, 426.2], "text": " and this one I did with Ada. We'll probably do Babbage or something. Well, no, just for search, I think Ada is probably fine."}, {"timestamp": [426.2, 427.28], "text": " So we'll copy this function."}, {"timestamp": [431.48, 435.0], "text": " Say, all right, we'll grab a GPT-3 embedding."}, {"timestamp": [435.0, 437.76], "text": " We'll also go ahead and grab the similarity function,"}, {"timestamp": [437.76, 440.16], "text": " because it's just a real simple numpy, where"}, {"timestamp": [440.16, 442.64], "text": " you give the dot product of two vectors,"}, {"timestamp": [442.64, 446.64], "text": " and then the dot product gives you how similar those two vectors are."}, {"timestamp": [446.64, 447.84], "text": " It's super simple."}, {"timestamp": [449.06, 451.28], "text": " Okay, search index."}, {"timestamp": [451.28, 452.46], "text": " Let's see."}, {"timestamp": [452.46, 454.36], "text": " Oh yeah, so this was the function"}, {"timestamp": [454.36, 456.12], "text": " that I wrote to actually search it."}, {"timestamp": [457.08, 459.84], "text": " So we will copy this function as well."}, {"timestamp": [461.3, 462.88], "text": " So basically what this function does"}, {"timestamp": [462.88, 465.0], "text": " is you give it a text"}, {"timestamp": [465.68, 467.96], "text": " that you're gonna try and match,"}, {"timestamp": [467.96, 469.84], "text": " and then you pass it the index,"}, {"timestamp": [470.68, 473.72], "text": " which is in this case, it's a, what was it?"}, {"timestamp": [474.88, 477.04], "text": " Let me make sure I'm remembering this correctly."}, {"timestamp": [477.04, 482.04], "text": " So search index, the nexus index, update index, yes."}, {"timestamp": [483.82, 485.88], "text": " And update index, how was that made?"}, {"timestamp": [485.88, 490.58], "text": " So we list all the files and then we,"}, {"timestamp": [490.58, 492.0], "text": " okay, yeah, so this is all it is."}, {"timestamp": [492.0, 496.18], "text": " It's a list of dictionaries where you've got a file name"}, {"timestamp": [496.18, 497.74], "text": " and a vector, so that's it."}, {"timestamp": [497.74, 500.68], "text": " Okay, so we'll probably do it a little bit differently"}, {"timestamp": [500.68, 502.38], "text": " where I'll just have the whole thing in memory"}, {"timestamp": [502.38, 504.0], "text": " and instead of having a file name,"}, {"timestamp": [504.0, 509.6], "text": " I'll just have the chunk of text. So it'll all be in memory. Actually no, it should"}, {"timestamp": [509.6, 514.6], "text": " be on a file so that way it can be saved. Okay. So the first thing we're going to have"}, {"timestamp": [514.6, 528.92], "text": " to do here is just build index."}, {"timestamp": [531.24, 533.52], "text": " I had this function as an update index"}, {"timestamp": [533.52, 534.6], "text": " because this was supposed to be"}, {"timestamp": [534.6, 536.32], "text": " for an artificial cognitive entity,"}, {"timestamp": [536.32, 538.16], "text": " which means it has to index its memories"}, {"timestamp": [538.16, 539.24], "text": " as they're accumulated."}, {"timestamp": [539.24, 541.4], "text": " So that's an even more complicated problem."}, {"timestamp": [543.56, 550.0], "text": " Okay, still following along? Good. Okay, so we've got chunks, text"}, {"timestamp": [550.0, 556.48], "text": " wrap, so we've got all the chunks, the result, there we go, that's fine. Open file, we don't"}, {"timestamp": [556.48, 566.76], "text": " need to do this. We don't need to run it through a prompt, All we need to do is get the embedding."}, {"timestamp": [566.76, 571.14], "text": " Now, embeddings, if I remember correctly,"}, {"timestamp": [571.14, 575.6], "text": " you can get multiple embeddings at once, I think."}, {"timestamp": [575.6, 578.54], "text": " Open AI embeddings."}, {"timestamp": [584.56, 585.0], "text": " Let's see. Take a look at it."}, {"timestamp": [592.0, 594.84], "text": " Input simple document goes here."}, {"timestamp": [597.52, 602.52], "text": " Cause if we've got like 150 different, chunks to do."}, {"timestamp": [604.08, 605.38], "text": " All right, I'm not seeing anything"}, {"timestamp": [605.38, 606.54], "text": " that does multiple embeddings."}, {"timestamp": [606.54, 608.02], "text": " I'm not gonna worry about it right now."}, {"timestamp": [608.02, 610.58], "text": " We'll just do one embedding at a time, that's fine."}, {"timestamp": [611.98, 612.9], "text": " And actually, I don't even think"}, {"timestamp": [612.9, 615.1], "text": " we'll need the search in this one."}, {"timestamp": [615.1, 616.5], "text": " So I can probably take that out."}, {"timestamp": [616.5, 620.22], "text": " Okay, so we'll comment this out for chunk in chunks."}, {"timestamp": [620.22, 623.38], "text": " We actually just need the embedding."}, {"timestamp": [623.38, 626.5], "text": " So we'll say,"}, {"timestamp": [630.16, 633.18], "text": " GPT-3 embedding, so content, yes."}, {"timestamp": [638.12, 640.72], "text": " Embedding equals GPT-3 embedding,"}, {"timestamp": [640.72, 644.48], "text": " and then we'll do chunk.encode."}, {"timestamp": [644.48, 646.04], "text": " Oh, here, we'll just copy this."}, {"timestamp": [647.24, 651.18], "text": " So what I had to do here, this particular bit,"}, {"timestamp": [652.28, 655.72], "text": " this, I found that sometimes there are Unicode characters"}, {"timestamp": [655.72, 658.64], "text": " that GPT-3 cannot handle and it errors out."}, {"timestamp": [658.64, 660.7], "text": " And so what I found, what I started doing"}, {"timestamp": [660.7, 665.56], "text": " is just adding this little bit of code to change it."}, {"timestamp": [665.56, 668.92], "text": " So you're basically encoding it from Unicode to ASCII,"}, {"timestamp": [668.92, 669.76], "text": " which is simpler,"}, {"timestamp": [669.76, 671.32], "text": " and then you decode it back"}, {"timestamp": [671.32, 673.36], "text": " into just a regular string variable."}, {"timestamp": [673.36, 676.8], "text": " And that seems to prevent any GPT-3 problems."}, {"timestamp": [677.8, 681.16], "text": " Okay, so we got the embedding,"}, {"timestamp": [681.16, 682.34], "text": " and we don't need a summary"}, {"timestamp": [682.34, 685.96], "text": " because essentially an embedding is a type of summary."}, {"timestamp": [685.96, 688.76], "text": " It's just, it's a numerical summary."}, {"timestamp": [688.76, 692.8], "text": " Okay, so what we're gonna do then is instead"}, {"timestamp": [692.8, 695.76], "text": " like what we did here, where it's just alluding"}, {"timestamp": [695.76, 697.76], "text": " to a file name because with an ACOG,"}, {"timestamp": [697.76, 699.12], "text": " here, let me just show you."}, {"timestamp": [700.12, 702.36], "text": " With an artificial cognitive entity,"}, {"timestamp": [702.36, 705.36], "text": " you might have a list of..."}, {"timestamp": [705.36, 708.8], "text": " Where did it go? Did I delete all the memories? I might have deleted all the memories."}, {"timestamp": [708.8, 712.96], "text": " Or no, I haven't gotten started yet. So basically what you do is you have a log."}, {"timestamp": [712.96, 718.32], "text": " So all the memories, all the experiences of an ACOG is just going to be like a list of log files."}, {"timestamp": [719.04, 724.88], "text": " And they could be multimodal files, right? You could have audio, video, text, whatever other"}, {"timestamp": [724.88, 726.0], "text": " sensory information it's got."}, {"timestamp": [726.0, 728.0], "text": " You can also have output information."}, {"timestamp": [728.0, 733.0], "text": " But the point is, it'll all be accumulated there, and then you can represent it as a vector,"}, {"timestamp": [733.0, 737.0], "text": " which is a way of representing the semantic meaning of it."}, {"timestamp": [737.0, 749.6], "text": " Okay, so we can say, content equals chunk."}, {"timestamp": [749.6, 752.32], "text": " So that'll be just the bit of text."}, {"timestamp": [752.32, 759.48], "text": " And then we will say the vector equals the embedding."}, {"timestamp": [759.48, 761.88], "text": " I prefer the word vector because, one, it's two syllables"}, {"timestamp": [761.88, 762.84], "text": " and it's easier to say."}, {"timestamp": [762.84, 763.92], "text": " You've got vector."}, {"timestamp": [763.92, 768.52], "text": " Embedding is too slow. And maybe that's just me being weird but my"}, {"timestamp": [768.52, 774.06], "text": " brain I prefer the word vector it's easier to say okay so then what we'll do"}, {"timestamp": [774.06, 781.92], "text": " is we will we will save this as a JSON file I think JSON so that way it'll be"}, {"timestamp": [781.92, 785.54], "text": " it'll be readable yeah I think that'll be the way it'll be readable."}, {"timestamp": [788.22, 793.22], "text": " Yeah, I think that'll be the way to go. Let me make sure that we've got, let's see, import JSON."}, {"timestamp": [794.76, 797.0], "text": " And I always have to do this,"}, {"timestamp": [797.0, 798.88], "text": " because I can't ever remember it."}, {"timestamp": [800.08, 808.32], "text": " With open, we're gonna say index.json,"}, {"timestamp": [808.32, 810.48], "text": " write binary."}, {"timestamp": [810.48, 812.32], "text": " I think that's it."}, {"timestamp": [812.32, 814.48], "text": " Encoding equals UTF-8."}, {"timestamp": [817.6, 819.84], "text": " Where was the last time that I used this function"}, {"timestamp": [819.84, 823.32], "text": " where I saved JSON?"}, {"timestamp": [823.32, 824.88], "text": " It's not here."}, {"timestamp": [824.88, 827.0], "text": " It's probably going to be something older. Where did I save"}, {"timestamp": [832.44, 839.44], "text": " JSON? It might have been here. Do I have a JSON file here? I have JSON L. That might"}, {"timestamp": [844.2, 845.88], "text": " Do I have a JSON file here? I have JSON-L."}, {"timestamp": [845.88, 847.4], "text": " That might be close enough."}, {"timestamp": [847.4, 849.16], "text": " Format training data."}, {"timestamp": [849.16, 850.88], "text": " Import JSON, okay."}, {"timestamp": [854.46, 855.8], "text": " Yeah, that's fine, okay."}, {"timestamp": [861.2, 863.44], "text": " Oh wait, no, that's dumping it to string,"}, {"timestamp": [863.44, 865.98], "text": " so I'll need JSON.dumps. I think that's the one that's dumping it to string. So I'll need json.dumps."}, {"timestamp": [865.98, 868.18], "text": " I think that's the one that dumps it to file."}, {"timestamp": [873.06, 874.38], "text": " As outfile."}, {"timestamp": [875.62, 876.5], "text": " Let's see."}, {"timestamp": [878.66, 880.3], "text": " Literally typed out json."}, {"timestamp": [880.3, 885.0], "text": " Json.dumps, and then I believe it'll be result outfile."}, {"timestamp": [887.44, 892.44], "text": " And then what was it like indent equals two."}, {"timestamp": [892.62, 894.58], "text": " I'm totally misremembering this."}, {"timestamp": [898.02, 900.42], "text": " I need to make sure that I get this right though."}, {"timestamp": [903.06, 905.0], "text": " Cause nothing is worse than like,"}, {"timestamp": [908.52, 909.52], "text": " really?"}, {"timestamp": [909.52, 910.36], "text": " I don't believe that."}, {"timestamp": [910.36, 911.34], "text": " Code, there we go."}, {"timestamp": [912.92, 914.16], "text": " Hey, there we go."}, {"timestamp": [914.16, 916.08], "text": " Return JSON dumps."}, {"timestamp": [920.24, 921.64], "text": " No, that's a flask response."}, {"timestamp": [921.64, 922.64], "text": " That can't be right."}, {"timestamp": [921.68, 922.68], "text": " No, that's a flask response. That can't be right."}, {"timestamp": [929.76, 930.6], "text": " There we go."}, {"timestamp": [930.6, 931.44], "text": " JSON.dump."}, {"timestamp": [934.2, 937.08], "text": " That's all writing it as JSONL."}, {"timestamp": [937.08, 938.08], "text": " That can't be right."}, {"timestamp": [942.16, 943.24], "text": " Yeah, there we go."}, {"timestamp": [943.24, 946.6], "text": " JSON.dump data outfile indent one. Okay. Hey, I've go. JSON.dump data out file indent one."}, {"timestamp": [946.6, 947.58], "text": " Okay."}, {"timestamp": [947.58, 949.62], "text": " Hey, I've almost remembered it."}, {"timestamp": [949.62, 951.7], "text": " Right, not quite, but almost."}, {"timestamp": [952.7, 953.54], "text": " We'll do it."}, {"timestamp": [953.54, 954.88], "text": " We'll leave it indent two, that's fine."}, {"timestamp": [954.88, 957.54], "text": " Okay, because nothing is worse than,"}, {"timestamp": [957.54, 960.14], "text": " oh, and not write binary, this is just text."}, {"timestamp": [961.74, 963.18], "text": " Yeah."}, {"timestamp": [963.18, 964.74], "text": " And actually, I think,"}, {"timestamp": [965.0, 970.52], "text": " maybe,"}, {"timestamp": [972.34, 973.26], "text": " let's say I don't think I need to do the separators, that's fine."}, {"timestamp": [974.18, 977.68], "text": " And it's always as right and not encoded as UTF-8."}, {"timestamp": [977.68, 980.7], "text": " Okay, so let me remove the encoding as UTF-8."}, {"timestamp": [983.88, 985.0], "text": " Okay, we'll leave it at that, that should work."}, {"timestamp": [986.72, 989.64], "text": " Okay, so all text, we open it, we get the embedding,"}, {"timestamp": [989.64, 991.54], "text": " we append this to the result,"}, {"timestamp": [991.54, 993.74], "text": " so the result will be a list of dictionaries"}, {"timestamp": [993.74, 998.02], "text": " with some text and then a vector."}, {"timestamp": [998.02, 999.58], "text": " And so that'll be our database."}, {"timestamp": [1001.62, 1004.32], "text": " Yeah, and we don't even need to build the index"}, {"timestamp": [1004.32, 1006.06], "text": " because we're building it now."}, {"timestamp": [1006.06, 1008.56], "text": " So let me just go ahead and delete this function"}, {"timestamp": [1008.56, 1010.18], "text": " because that's noise."}, {"timestamp": [1010.18, 1013.52], "text": " Search index, we can delete that because that's noise."}, {"timestamp": [1013.52, 1017.04], "text": " We can delete similarity because we don't even use that."}, {"timestamp": [1017.04, 1018.76], "text": " We don't use completion."}, {"timestamp": [1020.96, 1021.96], "text": " Do I use save file?"}, {"timestamp": [1021.96, 1024.28], "text": " I don't use save file anywhere."}, {"timestamp": [1024.28, 1026.32], "text": " All I use is open file."}, {"timestamp": [1026.32, 1027.14], "text": " Okay."}, {"timestamp": [1028.04, 1030.94], "text": " We don't need that."}, {"timestamp": [1032.24, 1033.56], "text": " I think that's about it."}, {"timestamp": [1033.56, 1034.64], "text": " Don't need re."}, {"timestamp": [1036.42, 1040.32], "text": " I think we just use text wrap, JSON."}, {"timestamp": [1040.32, 1042.08], "text": " I don't even use OS anymore."}, {"timestamp": [1042.08, 1043.0], "text": " Clean this up."}, {"timestamp": [1043.0, 1045.62], "text": " Okay, that should be fine."}, {"timestamp": [1045.62, 1047.98], "text": " Let's go to multi-document answering"}, {"timestamp": [1047.98, 1051.66], "text": " and we'll just call this build the index."}, {"timestamp": [1053.06, 1054.18], "text": " There we go."}, {"timestamp": [1054.18, 1055.06], "text": " Keep it in editor."}, {"timestamp": [1055.06, 1057.62], "text": " No, we'll just reopen it."}, {"timestamp": [1057.62, 1060.82], "text": " Okay, so this will generate a JSON file"}, {"timestamp": [1060.82, 1063.54], "text": " that will have, it'll be a list of chunks of text"}, {"timestamp": [1063.54, 1065.42], "text": " that are 3000 characters long,"}, {"timestamp": [1065.42, 1068.24], "text": " each of them with an embedding."}, {"timestamp": [1068.24, 1071.36], "text": " We can probably do it a little bit longer."}, {"timestamp": [1072.82, 1074.8], "text": " Let's do 4000 characters,"}, {"timestamp": [1074.8, 1077.84], "text": " because it's roughly three or four characters per token."}, {"timestamp": [1077.84, 1081.0], "text": " So this will be roughly 1000 tokens,"}, {"timestamp": [1081.0, 1084.5], "text": " which will be a quarter of, well, hmm,"}, {"timestamp": [1084.5, 1086.38], "text": " I wonder if we can do longer. No, this will be a quarter of, well, hmm, I wonder if we can do longer."}, {"timestamp": [1086.38, 1087.86], "text": " No, this would be fine"}, {"timestamp": [1087.86, 1090.54], "text": " because we still need some room to work around it"}, {"timestamp": [1090.54, 1092.1], "text": " if we have one of these chunks."}, {"timestamp": [1092.1, 1094.66], "text": " This will be our knowledge base."}, {"timestamp": [1094.66, 1095.9], "text": " So let me make sure this will work."}, {"timestamp": [1095.9, 1097.34], "text": " I'll let it run."}, {"timestamp": [1097.34, 1101.42], "text": " CD, multi-document answering, Python build index."}, {"timestamp": [1102.26, 1104.78], "text": " Did I get it right the first time?"}, {"timestamp": [1104.78, 1110.36], "text": " No. Save GPT-3 log is not defined. Ah,"}, {"timestamp": [1110.36, 1117.76], "text": " see that's what I did wrong. I'm not going to worry about saving every single log. This"}, {"timestamp": [1117.76, 1126.62], "text": " is a normal list, that's fine. Okay, let's try again."}, {"timestamp": [1129.86, 1131.12], "text": " And then, oh, I don't have any output, do I?"}, {"timestamp": [1133.72, 1135.52], "text": " Yeah, I need some kind of output so that I can see what it's doing"}, {"timestamp": [1135.52, 1138.02], "text": " because otherwise I'm gonna be confused."}, {"timestamp": [1139.26, 1141.38], "text": " So what I often do for things like this,"}, {"timestamp": [1141.38, 1147.16], "text": " just to do a sanity check is I'll set it to a variable so then"}, {"timestamp": [1147.16, 1153.4], "text": " I can just print the variable and then we'll do comma and then new line, new line, new"}, {"timestamp": [1153.4, 1159.36], "text": " line so I can see what it's actually generating."}, {"timestamp": [1159.36, 1164.6], "text": " Because sometimes if you do it wrong, your brain just is not working with you today."}, {"timestamp": [1164.6, 1166.46], "text": " Well mine is working with me today."}, {"timestamp": [1166.46, 1168.26], "text": " Sometimes it isn't."}, {"timestamp": [1168.26, 1172.44], "text": " But sometimes your brain just isn't working and the variable isn't what you thought it"}, {"timestamp": [1172.44, 1173.44], "text": " was."}, {"timestamp": [1173.44, 1177.6], "text": " But in this case, I think it's all right because this is relatively straightforward."}, {"timestamp": [1177.6, 1178.6], "text": " Okay."}, {"timestamp": [1178.6, 1180.72], "text": " Python, build index."}, {"timestamp": [1180.72, 1182.28], "text": " Oh, wow."}, {"timestamp": [1182.28, 1184.56], "text": " That's fast."}, {"timestamp": [1184.56, 1185.62], "text": " That's really fast."}, {"timestamp": [1188.5, 1191.58], "text": " The embeddings endpoint is quick, dang."}, {"timestamp": [1192.5, 1195.34], "text": " Oh, I wonder if it's because I'm using the ADA endpoint."}, {"timestamp": [1195.34, 1197.3], "text": " Yeah, I bet that's why it's so fast."}, {"timestamp": [1198.86, 1201.38], "text": " Dag gum, is it already done?"}, {"timestamp": [1201.38, 1203.66], "text": " Index dot JSON, okay."}, {"timestamp": [1203.66, 1208.24], "text": " So we've taken an input from 440 kilobytes and made it into"}, {"timestamp": [1210.48, 1215.12], "text": " more than three and a half megabytes. Oh, perfect. So there we go. Look, it worked. It worked. It"}, {"timestamp": [1215.12, 1221.36], "text": " worked. Okay. So this is what it looks like now. Let me zoom out a little bit, because you don't"}, {"timestamp": [1221.36, 1226.6], "text": " need to see it in detail. So you've got content which is just the chunk of text."}, {"timestamp": [1226.6, 1227.86], "text": " There we go. I can speak."}, {"timestamp": [1227.86, 1229.98], "text": " Then a semantic vector."}, {"timestamp": [1229.98, 1233.6], "text": " So the semantic vector is the mathematical,"}, {"timestamp": [1233.6, 1238.5], "text": " the numerical representation of this meaning."}, {"timestamp": [1238.5, 1241.8], "text": " So it's basically this is a pair."}, {"timestamp": [1241.8, 1244.36], "text": " This is the human readable text and then this"}, {"timestamp": [1244.36, 1247.12], "text": " is the machine readable representation."}, {"timestamp": [1247.12, 1250.08], "text": " And so then we've got a whole bunch of those."}, {"timestamp": [1251.08, 1253.88], "text": " And this file could be compressed,"}, {"timestamp": [1253.88, 1258.48], "text": " but what I did was when I put the indent here"}, {"timestamp": [1259.92, 1261.94], "text": " to say indent equals two,"}, {"timestamp": [1261.94, 1265.52], "text": " so that makes it more more human friendly right so you"}, {"timestamp": [1265.52, 1269.9], "text": " can see that you know the data is structured so like for every layer of"}, {"timestamp": [1269.9, 1277.6], "text": " embedding there's two spaces so the the the root list is at index zero and then"}, {"timestamp": [1277.6, 1283.84], "text": " we've got two spaces for the first dictionary and then we've got another"}, {"timestamp": [1283.84, 1287.12], "text": " two spaces for the for the the nested've got another two spaces for the nested list."}, {"timestamp": [1287.12, 1290.12], "text": " So you can clearly see the levels of nesting."}, {"timestamp": [1290.12, 1292.16], "text": " Okay, so we've got our index."}, {"timestamp": [1292.16, 1294.88], "text": " That was much faster than I thought it would be."}, {"timestamp": [1294.88, 1295.88], "text": " Let's zoom back in."}, {"timestamp": [1295.88, 1304.44], "text": " Wow, I was hoping that I'd have a mental break to be able to keep thinking."}, {"timestamp": [1304.44, 1306.92], "text": " Okay, so I'm going gonna actually pause this for a second"}, {"timestamp": [1306.92, 1308.12], "text": " just because you don't need to see me"}, {"timestamp": [1308.12, 1310.2], "text": " like gathering my thoughts."}, {"timestamp": [1310.2, 1312.06], "text": " Typically, when I run these loops,"}, {"timestamp": [1312.06, 1314.32], "text": " I have like a few minutes to gather my thoughts."}, {"timestamp": [1314.32, 1316.12], "text": " So I'm gonna pause the video for just a second"}, {"timestamp": [1316.12, 1319.4], "text": " and we'll be right back as I mentally plan the next step."}, {"timestamp": [1322.24, 1323.36], "text": " Okay, and we're back."}, {"timestamp": [1324.64, 1330.74], "text": " As with all things, data prep is the biggest thing, biggest problem, so we're closer to"}, {"timestamp": [1330.74, 1333.46], "text": " being done than you might have guessed."}, {"timestamp": [1333.46, 1338.5], "text": " I started on the next part, so we've built the index, it was way faster than I thought."}, {"timestamp": [1338.5, 1340.06], "text": " Now we're going to answer questions."}, {"timestamp": [1340.06, 1346.88], "text": " And so what I did was I just created, wrote a quick thing to open the index that we just created"}, {"timestamp": [1346.88, 1349.08], "text": " and then we'll do an infinite loop"}, {"timestamp": [1349.08, 1351.4], "text": " where we will just ask questions."}, {"timestamp": [1351.4, 1356.4], "text": " So this is based on the artificial cognitive entity thing"}, {"timestamp": [1356.4, 1358.92], "text": " where it's basically just searching"}, {"timestamp": [1360.36, 1364.72], "text": " for a particular set of memories, right?"}, {"timestamp": [1364.72, 1368.32], "text": " This same paradigm should work anywhere."}, {"timestamp": [1368.32, 1370.72], "text": " So what we're gonna do is we're going to,"}, {"timestamp": [1372.08, 1374.16], "text": " we're gonna take whatever our question is"}, {"timestamp": [1375.76, 1378.26], "text": " and we're going to get the vector from it."}, {"timestamp": [1380.6, 1384.32], "text": " And so we'll just get a vector and then we'll match"}, {"timestamp": [1384.32, 1388.18], "text": " which all the thing, all the parts that are closest."}, {"timestamp": [1389.4, 1390.62], "text": " And actually here, let's go ahead"}, {"timestamp": [1390.62, 1392.34], "text": " and just do a separate function."}, {"timestamp": [1392.34, 1397.34], "text": " So def and then we will,"}, {"timestamp": [1399.1, 1400.62], "text": " well, let's just copy this function"}, {"timestamp": [1400.62, 1402.34], "text": " because it's pretty close to what we need."}, {"timestamp": [1402.34, 1406.26], "text": " So instead what we'll do is we will do,"}, {"timestamp": [1406.26, 1409.18], "text": " let's see, results equals search index,"}, {"timestamp": [1409.18, 1410.42], "text": " and then we'll do query."}, {"timestamp": [1411.7, 1415.1], "text": " So count, we'll say 10, we'll say top 10."}, {"timestamp": [1415.1, 1417.2], "text": " We don't have timestamps, so we'll get rid of that."}, {"timestamp": [1417.2, 1419.78], "text": " So vector equals GPT-3 embedding the text,"}, {"timestamp": [1419.78, 1421.46], "text": " so that's the query."}, {"timestamp": [1421.46, 1431.6], "text": " Scores, okay, so for I in nexus index so we'll actually call this data"}, {"timestamp": [1431.6, 1439.24], "text": " we'll just replace that with data all right so for I and data if I equals"}, {"timestamp": [1439.24, 1444.56], "text": " vector this is identical skip it we don't need to worry about that because"}, {"timestamp": [1448.0, 1451.0], "text": " we don't have we're not worried about sequential memories in this. This is not a robot or anything like that."}, {"timestamp": [1451.0, 1459.0], "text": " So score equals similarity between our query and the actual what we're looking for."}, {"timestamp": [1459.0, 1465.76], "text": " And the vector is the right name. Okay."}, {"timestamp": [1467.96, 1471.1], "text": " We don't need file name. So this, we'll change this to content."}, {"timestamp": [1473.64, 1474.48], "text": " Content."}, {"timestamp": [1478.12, 1479.96], "text": " Yeah, so basically what we'll do is"}, {"timestamp": [1479.96, 1483.24], "text": " we'll just create a similarity score for all of them."}, {"timestamp": [1483.24, 1486.2], "text": " Ordered equals, all right, so content and score."}, {"timestamp": [1486.2, 1488.16], "text": " So after the, because once we get the score,"}, {"timestamp": [1488.16, 1489.98], "text": " we don't care about the vector anymore."}, {"timestamp": [1489.98, 1493.36], "text": " We just say, okay, we're gonna create a new,"}, {"timestamp": [1493.36, 1495.0], "text": " we're gonna create a new list"}, {"timestamp": [1495.0, 1497.0], "text": " that'll be the same length as our database,"}, {"timestamp": [1497.0, 1501.84], "text": " but we're gonna sort it by whichever one is closest."}, {"timestamp": [1503.36, 1504.92], "text": " Let's see."}, {"timestamp": [1504.92, 1507.6], "text": " We don't need that because we already have the content."}, {"timestamp": [1510.26, 1512.46], "text": " And we're just going to assume"}, {"timestamp": [1514.3, 1518.3], "text": " that, because we know our database is longer than 10."}, {"timestamp": [1520.06, 1522.46], "text": " So basically why I'm saying 10 is we're just gonna say,"}, {"timestamp": [1522.46, 1524.42], "text": " okay, so if we have 10 chunks"}, {"timestamp": [1524.42, 1527.76], "text": " that are 4,000 characters long, that's 40,000 characters,"}, {"timestamp": [1527.76, 1531.44], "text": " which is roughly 10,000 tokens."}, {"timestamp": [1531.44, 1534.8], "text": " And so we know that we have to solve the problem of"}, {"timestamp": [1534.8, 1537.7], "text": " what if we have, even after searching,"}, {"timestamp": [1537.7, 1539.98], "text": " we have a larger corpus"}, {"timestamp": [1539.98, 1542.56], "text": " than we can feed into GPT-3 in one go."}, {"timestamp": [1542.56, 1544.56], "text": " How do we handle that?"}, {"timestamp": [1544.56, 1547.08], "text": " So with that in mind,"}, {"timestamp": [1547.08, 1550.88], "text": " what we're gonna do is we get the results."}, {"timestamp": [1550.88, 1554.56], "text": " So this is a much compressed search"}, {"timestamp": [1554.56, 1557.06], "text": " where we're gonna end up with 10 results"}, {"timestamp": [1557.06, 1558.48], "text": " that could answer the question."}, {"timestamp": [1558.48, 1560.76], "text": " Actually, let's make this a little bit more challenging."}, {"timestamp": [1560.76, 1562.04], "text": " We'll do 20."}, {"timestamp": [1562.04, 1568.96], "text": " So we'll have the top 20 chunks of text that should answer our question."}, {"timestamp": [1568.96, 1573.8], "text": " Now the longer your question is, the more specific your question is, the better the"}, {"timestamp": [1573.8, 1575.4], "text": " search is going to be."}, {"timestamp": [1575.4, 1576.4], "text": " OK."}, {"timestamp": [1576.4, 1580.6], "text": " So results equals search index, query, and then we pass along the data, which the data"}, {"timestamp": [1580.6, 1582.26], "text": " is our master index."}, {"timestamp": [1582.26, 1587.38], "text": " So that's this here, which has the entirety of the Supreme Court opinion,"}, {"timestamp": [1587.38, 1589.44], "text": " paired down into vectors."}, {"timestamp": [1589.44, 1591.32], "text": " Okay, so with that,"}, {"timestamp": [1591.32, 1596.12], "text": " we then have to actually ask or answer questions."}, {"timestamp": [1596.12, 1599.56], "text": " So this is where we get into prompt engineering."}, {"timestamp": [1599.56, 1602.48], "text": " So let me go to Playground"}, {"timestamp": [1603.54, 1616.24], "text": " and we'll go grab, let's just grab an arbitrary chunk of text."}, {"timestamp": [1616.24, 1621.28], "text": " Yes, login, that's fine."}, {"timestamp": [1621.28, 1627.1], "text": " All right, so this is where,"}, {"timestamp": [1628.02, 1629.7], "text": " let's see,"}, {"timestamp": [1633.26, 1637.02], "text": " answer the following question."}, {"timestamp": [1637.86, 1639.46], "text": " Let's see."}, {"timestamp": [1640.68, 1642.02], "text": " Answer the question,"}, {"timestamp": [1644.74, 1645.0], "text": " the blah, blah, blah from the passage."}, {"timestamp": [1645.0, 1650.0], "text": " No, use the following passage"}, {"timestamp": [1650.0, 1655.0], "text": " to answer the question."}, {"timestamp": [1655.0, 1660.0], "text": " We'll figure that out in a second."}, {"timestamp": [1660.0, 1666.98], "text": " Actually no, we'll We'll do question first, so that it knows what the question,"}, {"timestamp": [1666.98, 1669.86], "text": " and then passage, and then answer."}, {"timestamp": [1673.18, 1674.94], "text": " Okay, so the passage is this,"}, {"timestamp": [1674.94, 1676.72], "text": " so this is probably what we'll do."}, {"timestamp": [1676.72, 1678.32], "text": " All right, so let's think of a question"}, {"timestamp": [1678.32, 1682.14], "text": " that would two cases arrive"}, {"timestamp": [1682.14, 1684.52], "text": " within the word balance scare quotes."}, {"timestamp": [1685.0, 1689.0], "text": " The majority is a dirty word, moderation is a foreign concept."}, {"timestamp": [1689.0, 1721.06], "text": " The majority would allow the states to ban abortion because it does not think forced childbirth would equate to equality and freedom. So, the question will be, why did the courts decide"}, {"timestamp": [1721.06, 1725.0], "text": " to allow states to ban abortion."}, {"timestamp": [1726.54, 1728.44], "text": " All right, so this is a question"}, {"timestamp": [1728.44, 1731.56], "text": " that is partially answered by this thing."}, {"timestamp": [1732.44, 1735.88], "text": " So then let's see how it just answers."}, {"timestamp": [1735.88, 1738.64], "text": " This is just right off the cuff."}, {"timestamp": [1738.64, 1740.94], "text": " And so you see, oh, so remember I said"}, {"timestamp": [1740.94, 1742.96], "text": " these are 4,000 character chunks,"}, {"timestamp": [1742.96, 1747.08], "text": " and you see it's right at 1,000 tokens, so that's 8 cents."}, {"timestamp": [1749.2, 1751.84], "text": " Could be cheaper, could be more expensive, whatever."}, {"timestamp": [1753.4, 1754.24], "text": " Answer."}, {"timestamp": [1757.36, 1758.2], "text": " Did it give up?"}, {"timestamp": [1758.2, 1759.02], "text": " Oh, there we go."}, {"timestamp": [1759.02, 1759.86], "text": " According to the passage,"}, {"timestamp": [1759.86, 1761.68], "text": " the courts decided to allow states to ban abortion"}, {"timestamp": [1761.68, 1763.24], "text": " because they believe a woman's freedom and equality"}, {"timestamp": [1763.24, 1766.24], "text": " are not involved in the decision to bear a child."}, {"timestamp": [1766.24, 1774.24], "text": " Ouch! Okay, yeah."}, {"timestamp": [1774.8, 1777.84], "text": " Because we're making it concise,"}, {"timestamp": [1777.84, 1784.08], "text": " let's use the following passage to"}, {"timestamp": [1788.76, 1791.4], "text": " use the following passage to give a detailed answer to the question."}, {"timestamp": [1791.4, 1794.04], "text": " So we'll say detailed answer."}, {"timestamp": [1794.04, 1797.2], "text": " Because here's the thing, we're going to basically recursively"}, {"timestamp": [1797.2, 1799.56], "text": " answer this several times."}, {"timestamp": [1799.56, 1802.48], "text": " And so we'll consolidate it down."}, {"timestamp": [1802.48, 1808.28], "text": " So let's see if this is any better or different. Oh this is"}, {"timestamp": [1808.28, 1821.48], "text": " good. Okay. Wow. Yikes. Shots fired. Okay. I like this better. So we'll use this as"}, {"timestamp": [1821.48, 1825.64], "text": " our prompt because again the idea here is not to summarize"}, {"timestamp": [1825.64, 1829.76], "text": " it as concisely as possible the idea is to extract information from a much"}, {"timestamp": [1829.76, 1834.16], "text": " larger document and pare it down and because we're gonna we're gonna"}, {"timestamp": [1834.16, 1839.0], "text": " basically take the top 20 we're gonna need to pare it down a few times. So this"}, {"timestamp": [1839.0, 1847.62], "text": " answer was about 200 tokens so if we take 20 times 200 that's 4,000 tokens so that's still"}, {"timestamp": [1847.62, 1852.18], "text": " going to be like a full thing and that's that's assuming that it doesn't actually"}, {"timestamp": [1852.18, 1858.02], "text": " make it much longer because some of the answers might be might be longer. Okay so"}, {"timestamp": [1858.02, 1867.08], "text": " we'll do this this will be our question answering prompt. OK, so passage will remove"}, {"timestamp": [1867.08, 1868.08], "text": " this."}, {"timestamp": [1868.2, 1870.64], "text": " So we'll do passage"}, {"timestamp": [1870.72, 1872.0], "text": " detailed answer."}, {"timestamp": [1873.08, 1874.08], "text": " OK."}, {"timestamp": [1874.96, 1876.16], "text": " And so this will be"}, {"timestamp": [1878.28, 1879.96], "text": " prompt answer."}, {"timestamp": [1880.72, 1882.6], "text": " OK, so this is our this is our first"}, {"timestamp": [1882.88, 1884.72], "text": " tier, first level of"}, {"timestamp": [1885.64, 1891.44], "text": " answering. And so what we'll do then is for all 20 of those top results, we'll ask the same question"}, {"timestamp": [1891.44, 1897.2], "text": " and then accumulate those answers together and kind of summarize them all together to"}, {"timestamp": [1897.2, 1900.08], "text": " kind of merge it into a single thing."}, {"timestamp": [1900.08, 1909.0], "text": " Okay, so here's how we're going to do that. We basically will borrow the recursive summarization thing that I've done before."}, {"timestamp": [1909.0, 1913.0], "text": " So let's open this, recursively summarize."}, {"timestamp": [1913.0, 1915.0], "text": " Yes, yay, fine."}, {"timestamp": [1915.0, 1919.0], "text": " And actually I think we will need the prompt here as well."}, {"timestamp": [1919.0, 1921.0], "text": " Yeah, write a concise summary."}, {"timestamp": [1921.0, 1926.08], "text": " Yeah, yeah, yeah, yeah, okay."}, {"timestamp": [1929.68, 1930.98], "text": " So that's that."}, {"timestamp": [1930.98, 1934.36], "text": " And then we'll also need the GPT-3 completion."}, {"timestamp": [1936.02, 1937.52], "text": " So we will need this."}, {"timestamp": [1938.84, 1942.68], "text": " So let's grab the completion."}, {"timestamp": [1943.88, 1946.0], "text": " Okay, so with those results,"}, {"timestamp": [1946.0, 1950.66], "text": " so for result in results,"}, {"timestamp": [1952.1, 1954.92], "text": " then we need actually here,"}, {"timestamp": [1955.98, 1957.52], "text": " answers equals list,"}, {"timestamp": [1959.38, 1962.04], "text": " prompt equals open file."}, {"timestamp": [1963.56, 1964.4], "text": " This would be,"}, {"timestamp": [1966.36, 1971.36], "text": " what was it? Prompt answer.text.replace passage with,"}, {"timestamp": [1982.22, 1984.32], "text": " and that'll be result.content."}, {"timestamp": [1985.0, 1987.6], "text": " Yeah, yeah. And that'll be result.content."}, {"timestamp": [1988.88, 1991.16], "text": " Yeah, yeah. Okay, so that should give us the answer."}, {"timestamp": [1991.16, 1996.16], "text": " And then the answer equals GPT-3 completion prompt."}, {"timestamp": [1997.24, 1999.72], "text": " And since this is already run through,"}, {"timestamp": [1999.72, 2001.92], "text": " I don't think we need to do the thing"}, {"timestamp": [2001.92, 2003.98], "text": " that I did in the index,"}, {"timestamp": [2003.98, 2006.44], "text": " because we've already cleaned up the chunks, right?"}, {"timestamp": [2006.44, 2007.6], "text": " We've already cleaned it up."}, {"timestamp": [2007.6, 2014.4], "text": " So it should be encoded in a way that is friendly with GPT-3."}, {"timestamp": [2014.4, 2015.34], "text": " OK."}, {"timestamp": [2015.34, 2019.04], "text": " So then we get an answer to the question."}, {"timestamp": [2019.04, 2021.04], "text": " And so then we do answers.appendAnswer."}, {"timestamp": [2025.0, 2025.5], "text": " So that should be fine. answers.appendAnswer."}, {"timestamp": [2027.0, 2028.3], "text": " So that should be fine."}, {"timestamp": [2030.94, 2033.1], "text": " Let's do printAnswer."}, {"timestamp": [2038.1, 2038.54], "text": " And we'll do new line, new line,"}, {"timestamp": [2040.22, 2041.46], "text": " just to give it a little bit of vertical space so it's clear, so it will see"}, {"timestamp": [2041.46, 2044.7], "text": " that it's accumulating the answers."}, {"timestamp": [2044.7, 2050.0], "text": " And then, so this object here, this list,"}, {"timestamp": [2050.0, 2052.0], "text": " will have all of the answers,"}, {"timestamp": [2052.0, 2054.0], "text": " because we're basically asking the same question,"}, {"timestamp": [2054.0, 2057.0], "text": " but we're going to be asking it of different chunks of text."}, {"timestamp": [2057.0, 2063.0], "text": " And so it's like, okay, how do we get this nebulous combination of things together?"}, {"timestamp": [2063.0, 2067.62], "text": " So then what we'll do is we will do,"}, {"timestamp": [2067.62, 2069.9], "text": " we'll borrow the same exact thing that we did"}, {"timestamp": [2069.9, 2073.76], "text": " for the summarization, right?"}, {"timestamp": [2073.76, 2075.86], "text": " And so we'll take,"}, {"timestamp": [2077.96, 2079.6], "text": " we'll take TextWrap."}, {"timestamp": [2079.6, 2083.32], "text": " So we'll make sure that we've got TextWrap here."}, {"timestamp": [2083.32, 2086.4], "text": " So let's go back to the recursively summarize."}, {"timestamp": [2086.4, 2089.68], "text": " So we'll do import, whoops, do not delete that."}, {"timestamp": [2089.68, 2091.08], "text": " Import TextWrap."}, {"timestamp": [2093.08, 2097.14], "text": " And since the DaVinci Instruct has a token limit of 4,000,"}, {"timestamp": [2099.28, 2103.52], "text": " so 4,000 tokens times four characters,"}, {"timestamp": [2103.52, 2105.84], "text": " that's 16,000 characters."}, {"timestamp": [2105.84, 2109.52], "text": " So we can get a pretty big chunk of text."}, {"timestamp": [2109.52, 2114.52], "text": " So we'll do a text wrap of 10,000 characters."}, {"timestamp": [2116.16, 2121.16], "text": " Okay, so I'll do answer the same question"}, {"timestamp": [2122.36, 2125.0], "text": " for all returned chunks."}, {"timestamp": [2126.0, 2131.0], "text": " And then we will do summarize the answers together."}, {"timestamp": [2135.74, 2140.74], "text": " And so here we say, oops, that's already here."}, {"timestamp": [2142.34, 2146.3], "text": " Oops, that's already here."}, {"timestamp": [2150.14, 2151.3], "text": " We are taking, here, let me do a time check real quick because we're close enough to the end."}, {"timestamp": [2151.3, 2152.46], "text": " Yeah, this will be a longer video,"}, {"timestamp": [2152.46, 2153.68], "text": " but we're closer to the end."}, {"timestamp": [2153.68, 2156.22], "text": " This is going way better than I thought,"}, {"timestamp": [2156.22, 2159.86], "text": " knock on wood, that this actually works."}, {"timestamp": [2159.86, 2162.14], "text": " Okay, so summarize the answers together."}, {"timestamp": [2162.14, 2163.3], "text": " Right, that's what I was doing."}, {"timestamp": [2163.3, 2166.5], "text": " Kind of lost my train of thought there for a second."}, {"timestamp": [2166.5, 2170.48], "text": " Okay, so for, no."}, {"timestamp": [2171.38, 2173.72], "text": " We need to join it all into one chunk."}, {"timestamp": [2173.72, 2178.28], "text": " Okay, so all answers equals, what is it?"}, {"timestamp": [2181.0, 2184.42], "text": " Dot join answers."}, {"timestamp": [2184.42, 2186.02], "text": " I think that's how that works."}, {"timestamp": [2188.82, 2192.4], "text": " Let me do a quick Python."}, {"timestamp": [2192.4, 2195.68], "text": " L equals, we'll do bacon,"}, {"timestamp": [2198.14, 2201.84], "text": " bacon and burger."}, {"timestamp": [2201.84, 2204.94], "text": " And then we'll do new line, new line,"}, {"timestamp": [2205.0, 2210.06], "text": " dot join L. and then we'll do newline.joinl."}, {"timestamp": [2215.06, 2215.88], "text": " Oh, right, s equals print, print, print s."}, {"timestamp": [2217.56, 2219.66], "text": " Okay, yes, that is right. Make sure I get the syntax correct."}, {"timestamp": [2219.66, 2221.0], "text": " Okay, so basically what we're doing"}, {"timestamp": [2221.0, 2223.0], "text": " is we're joining all the answers together"}, {"timestamp": [2223.0, 2224.8], "text": " into one big block."}, {"timestamp": [2224.8, 2231.32], "text": " So regardless of how long it is, we can say, okay, let's take all these answers and then"}, {"timestamp": [2231.32, 2234.92], "text": " kind of squish them together."}, {"timestamp": [2234.92, 2240.64], "text": " I'll probably only do one pass, but you would technically want to do this multiple times."}, {"timestamp": [2240.64, 2248.28], "text": " So chunks equals text wrap. Make sure I use this correctly, text wrap dot wrap."}, {"timestamp": [2251.5, 2253.46], "text": " And so we'll do all answers."}, {"timestamp": [2253.46, 2257.92], "text": " And I said 10,000, not 21,000, 10,000."}, {"timestamp": [2257.92, 2260.02], "text": " That's the correct number of zeros, I think."}, {"timestamp": [2260.02, 2261.06], "text": " Four zeros, yeah."}, {"timestamp": [2261.98, 2265.94], "text": " Okay, so then for chunk in chunks,"}, {"timestamp": [2265.94, 2269.74], "text": " we also need a, we'll say final equals list."}, {"timestamp": [2271.26, 2273.18], "text": " So for chunk in chunks,"}, {"timestamp": [2273.18, 2275.74], "text": " we are just gonna summarize it all together."}, {"timestamp": [2277.6, 2279.56], "text": " So we'll borrow this prompt."}, {"timestamp": [2279.56, 2284.12], "text": " Instead of a concise summary, we'll do detailed summary"}, {"timestamp": [2284.12, 2287.32], "text": " because we're just gonna take all the different answers"}, {"timestamp": [2287.32, 2290.46], "text": " and kind of merge it into one."}, {"timestamp": [2290.46, 2292.64], "text": " So let's go ahead and save this."}, {"timestamp": [2293.58, 2296.94], "text": " Detailed summary, detailed summary,"}, {"timestamp": [2296.94, 2299.68], "text": " and we'll save this under, excuse me,"}, {"timestamp": [2301.98, 2304.22], "text": " multi-document answering,"}, {"timestamp": [2304.22, 2310.0], "text": " and we'll do prompt summary dot text."}, {"timestamp": [2310.0, 2318.0], "text": " Okay. So basically what we're going to do is we're going to take for each of the chunks of the answers,"}, {"timestamp": [2318.0, 2325.4], "text": " and you can do this recursively, right, until you get it into one thing. We're gonna do the same thing here."}, {"timestamp": [2325.4, 2328.64], "text": " So prompt equals open file prompt"}, {"timestamp": [2328.64, 2331.28], "text": " instead of answer we'll do prompt summary"}, {"timestamp": [2331.28, 2333.46], "text": " and we'll replace."}, {"timestamp": [2336.92, 2341.84], "text": " So the thing to summarize result content,"}, {"timestamp": [2341.84, 2344.0], "text": " that should be good."}, {"timestamp": [2344.0, 2346.0], "text": " And then we will do"}, {"timestamp": [2347.0, 2348.88], "text": " summary equals"}, {"timestamp": [2350.08, 2351.56], "text": " GPT-3 completion"}, {"timestamp": [2352.96, 2353.8], "text": " prompt."}, {"timestamp": [2355.36, 2357.52], "text": " And then we will do"}, {"timestamp": [2357.52, 2358.36], "text": " final"}, {"timestamp": [2360.26, 2361.6], "text": " dot"}, {"timestamp": [2361.6, 2362.44], "text": " append"}, {"timestamp": [2363.32, 2364.76], "text": " summary."}, {"timestamp": [2364.76, 2367.32], "text": " Okay, so that should be that."}, {"timestamp": [2367.32, 2370.84], "text": " And this one does save it out to GPT-3 logs."}, {"timestamp": [2370.84, 2372.72], "text": " Let me make sure that that is there."}, {"timestamp": [2375.16, 2377.24], "text": " GPT-3 logs."}, {"timestamp": [2379.36, 2384.28], "text": " Okay, so then once it's done,"}, {"timestamp": [2384.28, 2385.0], "text": " we will do print."}, {"timestamp": [2390.68, 2394.08], "text": " We'll do new line, new line."}, {"timestamp": [2394.08, 2396.0], "text": " And then we'll do, actually here,"}, {"timestamp": [2396.0, 2398.1], "text": " we can just go ahead and do that"}, {"timestamp": [2398.1, 2401.16], "text": " to give us a little bit of white space."}, {"timestamp": [2401.16, 2405.0], "text": " And then we'll do final dot no."}, {"timestamp": [2408.8, 2413.72], "text": " We'll do new line, new line dot join final."}, {"timestamp": [2413.72, 2414.72], "text": " There we go."}, {"timestamp": [2414.72, 2418.2], "text": " So that'll actually look like a final answer."}, {"timestamp": [2418.2, 2419.64], "text": " We'll see if this works."}, {"timestamp": [2419.64, 2421.24], "text": " Might not, may or may not."}, {"timestamp": [2422.64, 2423.52], "text": " We'll have it output."}, {"timestamp": [2423.52, 2427.84], "text": " The first one, I'll just have it outputting each answer as it goes"}, {"timestamp": [2427.84, 2429.68], "text": " so that we can see it."}, {"timestamp": [2430.86, 2432.62], "text": " Wow, why am I nervous?"}, {"timestamp": [2433.46, 2434.62], "text": " This is crazy."}, {"timestamp": [2435.72, 2437.56], "text": " Am I missing anything?"}, {"timestamp": [2438.94, 2440.42], "text": " Send it."}, {"timestamp": [2440.42, 2442.5], "text": " Python, answer questions."}, {"timestamp": [2444.0, 2448.9], "text": " Why did the Supreme Court strike down Roe v. Wade?"}, {"timestamp": [2454.38, 2455.94], "text": " Well, it didn't like that."}, {"timestamp": [2455.94, 2457.44], "text": " Okay, something went wrong."}, {"timestamp": [2460.22, 2463.02], "text": " It looks like it didn't return anything here."}, {"timestamp": [2465.0, 2466.92], "text": " It looks like it didn't return anything here."}, {"timestamp": [2470.06, 2470.96], "text": " So I probably did something wrong with the search."}, {"timestamp": [2472.52, 2475.4], "text": " Okay."}, {"timestamp": [2476.58, 2477.74], "text": " Print results."}, {"timestamp": [2479.4, 2481.96], "text": " And then we'll just do an exit here because that's where I think it's broken."}, {"timestamp": [2481.96, 2482.8], "text": " Whoops."}, {"timestamp": [2484.04, 2485.5], "text": " Answer questions."}, {"timestamp": [2485.5, 2490.5], "text": " Why did the Supreme Court overturn Roe v. Wade?"}, {"timestamp": [2493.08, 2495.6], "text": " Yeah, okay, so the search is broken."}, {"timestamp": [2496.7, 2498.36], "text": " My intuition was correct."}, {"timestamp": [2499.58, 2503.22], "text": " Okay, so vector equals GPT-3 embedding for the text."}, {"timestamp": [2503.22, 2505.12], "text": " So that's the query, right?"}, {"timestamp": [2505.12, 2506.6], "text": " So the query is there."}, {"timestamp": [2508.88, 2509.72], "text": " And then the scores."}, {"timestamp": [2509.72, 2512.68], "text": " So for I and data, so that's a list."}, {"timestamp": [2512.68, 2514.74], "text": " Make sure that I pass that correctly."}, {"timestamp": [2519.2, 2523.44], "text": " Okay, let's print out score just to make sure"}, {"timestamp": [2523.44, 2524.84], "text": " that it's actually,"}, {"timestamp": [2527.0, 2537.58], "text": " Y. out score just to make sure that it's actually...why? Okay, we're getting scores, so that's correct."}, {"timestamp": [2537.58, 2543.12], "text": " And then reverse equals true results list."}, {"timestamp": [2543.12, 2546.6], "text": " Oh, I just declared an empty list."}, {"timestamp": [2547.64, 2549.68], "text": " Well, there's your problem."}, {"timestamp": [2549.68, 2552.16], "text": " Okay, so we need, we just, whoops,"}, {"timestamp": [2552.16, 2554.66], "text": " get rid of that and the ordered."}, {"timestamp": [2559.46, 2562.34], "text": " And then so we do ordered zero to that."}, {"timestamp": [2562.34, 2564.96], "text": " Okay, so that should be correct."}, {"timestamp": [2564.96, 2565.0], "text": " I think I fixed it. Famous last words. So we do ordered zero to that. Okay, so that should be correct."}, {"timestamp": [2565.0, 2566.0], "text": " I think I fixed it."}, {"timestamp": [2567.2, 2568.92], "text": " Famous last words."}, {"timestamp": [2568.92, 2573.92], "text": " Okay, so let's CLS."}, {"timestamp": [2575.24, 2580.24], "text": " Why did the Supreme Court overturn Roe v. Wade?"}, {"timestamp": [2584.4, 2588.92], "text": " Oh, it's taking longer."}, {"timestamp": [2588.92, 2592.52], "text": " Bueller."}, {"timestamp": [2592.52, 2609.44], "text": " Oh, see, I needed to add in a few more things. Okay, import re from time import time and sleep."}, {"timestamp": [2614.56, 2617.16], "text": " Okay, so basically what happened was it got to"}, {"timestamp": [2617.16, 2619.44], "text": " where it's trying to give me the answers"}, {"timestamp": [2619.44, 2623.84], "text": " and then it blew up because I forgot to import re"}, {"timestamp": [2628.36, 2636.68], "text": " or regex, which is I used to clean it up. And then I also didn't import sleep as well as time because I use time for the for the"}, {"timestamp": [2636.68, 2637.68], "text": " file names."}, {"timestamp": [2637.68, 2641.56], "text": " OK, let's try this again."}, {"timestamp": [2641.56, 2642.96], "text": " Almost there."}, {"timestamp": [2642.96, 2649.92], "text": " Answer questions. Your question is, why did the Supreme Port overturn Roe v. Wade?"}, {"timestamp": [2655.56, 2658.24], "text": " Ooh, sorry, that was probably loud."}, {"timestamp": [2658.24, 2659.08], "text": " Okay."}, {"timestamp": [2663.2, 2664.58], "text": " Now it's thinking."}, {"timestamp": [2667.96, 2669.96], "text": " Okay. So it's providing some answers."}, {"timestamp": [2669.96, 2693.6], "text": " Cool, cool, cool. satisfactory answers."}, {"timestamp": [2693.6, 2695.98], "text": " Why did you freeze?"}, {"timestamp": [2695.98, 2698.08], "text": " If it blows up, I'll be sad."}, {"timestamp": [2698.08, 2700.12], "text": " Now so this is kind of a boilerplate."}, {"timestamp": [2700.12, 2712.6], "text": " Ooh, that was a long answer. Okay."}, {"timestamp": [2713.7, 2718.6], "text": " Nope, it didn't like that. So I need to fix, I do need to add in some of the, darn."}, {"timestamp": [2718.6, 2719.44], "text": " Okay."}, {"timestamp": [2722.52, 2725.0], "text": " Okay, so that's the bug that I was telling you about."}, {"timestamp": [2726.36, 2731.06], "text": " Error communicating char map cannot encode character."}, {"timestamp": [2731.06, 2734.56], "text": " Okay, so we need to, for all of the prompts,"}, {"timestamp": [2734.56, 2738.1], "text": " we do need to add back in this bit here,"}, {"timestamp": [2738.1, 2739.86], "text": " just for whatever reason,"}, {"timestamp": [2739.86, 2744.86], "text": " there are some things that it doesn't like getting in there."}, {"timestamp": [2747.0, 2749.16], "text": " All right, so we'll come back here."}, {"timestamp": [2749.16, 2757.68], "text": " We'll do prompt equals prompt.encode slash decode."}, {"timestamp": [2757.68, 2761.52], "text": " This is just a reusable string, so every time we talk to GPT-3,"}, {"timestamp": [2761.52, 2763.2], "text": " we can run this prompt real quick."}, {"timestamp": [2772.16, 2773.12], "text": " we talk to GPT-3 we can run this prompt real quick. And then, you know, actually even smarter,"}, {"timestamp": [2786.24, 2787.48], "text": " we do it here. Do it once instead of multiple times. Okay, maybe that's what I'll do. I'll just have this in all of my GPT-3 completion functions from now on."}, {"timestamp": [2787.48, 2788.4], "text": " Let's do that."}, {"timestamp": [2789.08, 2792.68], "text": " And then we'll also do that in the embedding one."}, {"timestamp": [2794.68, 2796.72], "text": " So we'll do that here."}, {"timestamp": [2796.72, 2799.34], "text": " And instead of prompt, we'll do content,"}, {"timestamp": [2800.38, 2804.16], "text": " just to ensure that everything is encoded in a way"}, {"timestamp": [2804.16, 2806.14], "text": " that GPT-3 will be happy with."}, {"timestamp": [2807.22, 2809.28], "text": " Yeah, okay."}, {"timestamp": [2809.28, 2811.18], "text": " So we've got the answers"}, {"timestamp": [2813.06, 2815.62], "text": " and then we should be good here."}, {"timestamp": [2815.62, 2816.86], "text": " Okay, let's try it again."}, {"timestamp": [2819.78, 2821.04], "text": " Enter your question here."}, {"timestamp": [2821.04, 2823.3], "text": " Let's ask, let's not give it such a softball question"}, {"timestamp": [2823.3, 2824.82], "text": " because we saw that it was answering."}, {"timestamp": [2824.82, 2829.56], "text": " So what are the historical precedents"}, {"timestamp": [2829.56, 2833.36], "text": " that the Supreme Court looked at"}, {"timestamp": [2836.16, 2841.16], "text": " when determining whether or not to overturn Roe v. Wade?"}, {"timestamp": [2843.24, 2846.54], "text": " So this is a much more complex question."}, {"timestamp": [2847.44, 2849.9], "text": " So we've got some keywords in there like,"}, {"timestamp": [2850.98, 2852.96], "text": " egregiously wrong and cause significant"}, {"timestamp": [2852.96, 2854.76], "text": " negative consequences, ouch."}, {"timestamp": [2854.76, 2859.18], "text": " Okay, so we'll see if this less,"}, {"timestamp": [2859.18, 2862.16], "text": " this more hardball question is gonna produce"}, {"timestamp": [2862.16, 2863.8], "text": " satisfactory results."}, {"timestamp": [2863.8, 2866.04], "text": " Because that first question that I"}, {"timestamp": [2866.04, 2877.6], "text": " was asking was answered explicitly many times in the document, but this one requires a little"}, {"timestamp": [2877.6, 2882.08], "text": " bit more interpretation, let's say."}, {"timestamp": [2882.08, 2886.16], "text": " And we see it's going through. Fundamental right that is deeply"}, {"timestamp": [2886.16, 2893.16], "text": " rooted in history. Okay, sound basis and precedent. States could not ban abortion as it violated"}, {"timestamp": [2893.16, 2900.64], "text": " a woman's right. Okay. Because basically I'm asking for like historical precedent. So we'll"}, {"timestamp": [2900.64, 2906.98], "text": " see if it's good. And it does look like it's talking about some previous decisions, you know, like 1973"}, {"timestamp": [2906.98, 2908.98], "text": " That's somewhere in history"}, {"timestamp": [2909.42, 2911.42], "text": " There's a long long response"}, {"timestamp": [2911.9, 2915.1], "text": " Courts decided to allow states because they believed it is a woman's right to choose"}, {"timestamp": [2917.14, 2922.34], "text": " See that doesn't make any sense though allow states to ban abortion because it's a woman's right to choose"}, {"timestamp": [2922.34, 2926.68], "text": " Well, just if the states can it, that doesn't make sense."}, {"timestamp": [2941.68, 2943.32], "text": " Because it looks like it's giving an explanation"}, {"timestamp": [2943.32, 2945.72], "text": " as to why the states allowed it, but it's"}, {"timestamp": [2945.72, 2948.64], "text": " not actually explaining the historical precedent."}, {"timestamp": [2948.64, 2952.6], "text": " So it may or may not actually understand what I was asking."}, {"timestamp": [2952.6, 2955.8], "text": " While it's going through this, let's look through the GPT-3 logs."}, {"timestamp": [2955.8, 2958.04], "text": " This is why I love doing this."}, {"timestamp": [2958.04, 2961.16], "text": " So use the following passage to give a detailed answer to the question."}, {"timestamp": [2961.16, 2962.16], "text": " Why..."}, {"timestamp": [2962.16, 2973.04], "text": " Wait, did I give it the wrong... it's still asking an older question."}, {"timestamp": [2973.04, 2977.08], "text": " Hold on."}, {"timestamp": [2977.08, 2992.96], "text": " Why did the courts decide to allow... that's not the question that I put in, was it?"}, {"timestamp": [2992.96, 2995.16], "text": " Am I losing my mind?"}, {"timestamp": [2995.16, 2997.44], "text": " Yeah, enter your question here."}, {"timestamp": [2997.44, 2999.68], "text": " What are the historical precedents?"}, {"timestamp": [2999.68, 3000.68], "text": " That's what I'm looking for."}, {"timestamp": [3000.68, 3003.68], "text": " Why didn't it ask that question?"}, {"timestamp": [3003.68, 3004.68], "text": " Hold on."}, {"timestamp": [3004.68, 3006.84], "text": " What have I done wrong here?"}, {"timestamp": [3006.84, 3007.84], "text": " Oh."}, {"timestamp": [3007.84, 3008.84], "text": " Ha!"}, {"timestamp": [3008.84, 3010.68], "text": " I know what I did wrong."}, {"timestamp": [3010.68, 3012.88], "text": " I didn't actually populate the question."}, {"timestamp": [3012.88, 3013.88], "text": " Yikes."}, {"timestamp": [3013.88, 3014.88], "text": " Yeah."}, {"timestamp": [3014.88, 3018.48], "text": " So, here's what I did wrong."}, {"timestamp": [3018.48, 3025.0], "text": " If I look at the actual prompt, so this is the summary, but yeah,"}, {"timestamp": [3026.3, 3027.92], "text": " I have the question hard-coded."}, {"timestamp": [3030.42, 3031.34], "text": " Yeah, okay."}, {"timestamp": [3033.1, 3036.62], "text": " So query, you have to populate that."}, {"timestamp": [3036.62, 3038.98], "text": " I'm not losing my mind."}, {"timestamp": [3038.98, 3041.26], "text": " I just didn't actually populate the query"}, {"timestamp": [3041.26, 3044.24], "text": " because I get the query and then I ignore it."}, {"timestamp": [3044.24, 3047.6], "text": " Okay, so we will do this."}, {"timestamp": [3047.6, 3054.84], "text": " We'll just also do replace query with query."}, {"timestamp": [3057.84, 3061.12], "text": " And I think that's it."}, {"timestamp": [3061.12, 3062.64], "text": " Yeah, OK."}, {"timestamp": [3062.64, 3063.96], "text": " But first, let's see."}, {"timestamp": [3063.96, 3067.7], "text": " So we know a question that it did ask."}, {"timestamp": [3067.7, 3072.68], "text": " It asked, why did the courts decide to allow states to ban abortion?"}, {"timestamp": [3072.68, 3074.76], "text": " Okay, that's a softball question."}, {"timestamp": [3074.76, 3077.88], "text": " Let's see what the final answer was that it gave us."}, {"timestamp": [3077.88, 3079.12], "text": " Okay."}, {"timestamp": [3079.12, 3082.3], "text": " The Supreme Court has overturned a lower court ruling that has struck down a Mississippi"}, {"timestamp": [3082.3, 3086.84], "text": " law that would have banned most abortions after 15 weeks of pregnancy."}, {"timestamp": [3086.84, 3091.2], "text": " The 5-4 decision, with Justice Amy Coney Barrett joining the court's three other conservatives"}, {"timestamp": [3091.2, 3096.72], "text": " in the majority, is a major victory for abortion opponents and a blow to abortion rights advocates."}, {"timestamp": [3096.72, 3100.4], "text": " The decision does not immediately impact abortion laws in other states, but it paves the way"}, {"timestamp": [3100.4, 3103.4], "text": " for more restrictions on abortions to be enacted."}, {"timestamp": [3103.4, 3106.64], "text": " The majority opinion written by Justice Clarison's Thomas"}, {"timestamp": [3106.64, 3108.52], "text": " states that the Constitution does not protect"}, {"timestamp": [3108.52, 3110.12], "text": " a woman's right to an abortion."}, {"timestamp": [3110.12, 3112.2], "text": " Thomas writes that the court's previous decisions"}, {"timestamp": [3112.2, 3113.88], "text": " on the matter Roe v. Wade and Planned Parenthood"}, {"timestamp": [3113.88, 3117.3], "text": " versus Casey were wrongly decided and should be overruled."}, {"timestamp": [3117.3, 3119.84], "text": " Wow, that is a really good answer to that question."}, {"timestamp": [3122.16, 3128.88], "text": " Yeah, okay, in Dobbs versus Jackson Health Organization, the Supreme Court considered a challenge to a"}, {"timestamp": [3128.88, 3133.04], "text": " Mississippi law regulating abortion, the law known as the Gestational Age Act, prohibit"}, {"timestamp": [3133.04, 3135.6], "text": " abortion after 15 weeks of pregnancy."}, {"timestamp": [3135.6, 3139.98], "text": " The court first noted that abortion is a matter of great social significance and moral substance"}, {"timestamp": [3139.98, 3144.6], "text": " and that laws regulating abortion are entitled to a strong presumption of validity."}, {"timestamp": [3144.6, 3148.92], "text": " The court then went on to explain that the Mississippi legislature had identified legitimate"}, {"timestamp": [3148.92, 3153.72], "text": " interests in protecting the life of the unborn, which provided a rational basis for the Gestational"}, {"timestamp": [3153.72, 3155.0], "text": " Age Act."}, {"timestamp": [3155.0, 3158.6], "text": " The court therefore concluded that the act was constitutional and reversed the decision"}, {"timestamp": [3158.6, 3160.04], "text": " of the lower court."}, {"timestamp": [3160.04, 3163.88], "text": " The court also made clear that its decision should not be interpreted as endorsing any"}, {"timestamp": [3163.88, 3166.96], "text": " particular view of abortion, but rather as affirming the right of each state to make"}, {"timestamp": [3166.96, 3168.7], "text": " its own laws on the matter.\""}, {"timestamp": [3168.7, 3171.32], "text": " That is a phenomenal set of answers."}, {"timestamp": [3171.32, 3172.32], "text": " Wow."}, {"timestamp": [3172.32, 3173.32], "text": " Okay."}, {"timestamp": [3173.32, 3177.12], "text": " So that, these answers are, I'm getting chills."}, {"timestamp": [3177.12, 3182.48], "text": " This set of answers is a wonderful, wonderful example of an answer to the question that"}, {"timestamp": [3182.48, 3183.48], "text": " was asked."}, {"timestamp": [3183.48, 3184.48], "text": " Okay."}, {"timestamp": [3184.48, 3187.4], "text": " So, however, that was a hard-coded question."}, {"timestamp": [3187.4, 3190.6], "text": " So let me, I'm closing some things that I don't need."}, {"timestamp": [3193.72, 3196.32], "text": " Answer questions.py, so we've got the index,"}, {"timestamp": [3196.32, 3197.44], "text": " we can close all that."}, {"timestamp": [3197.44, 3202.44], "text": " Okay, so I've got, the query is now gonna be populated."}, {"timestamp": [3202.72, 3205.9], "text": " So let's now,"}, {"timestamp": [3208.26, 3210.16], "text": " okay, CLS."}, {"timestamp": [3210.16, 3212.24], "text": " Okay, so now that the question"}, {"timestamp": [3212.24, 3216.06], "text": " should be properly populated,"}, {"timestamp": [3216.06, 3219.6], "text": " let's do this again."}, {"timestamp": [3219.6, 3221.04], "text": " Python, answer questions."}, {"timestamp": [3222.28, 3224.64], "text": " What historical precedence"}, {"timestamp": [3234.56, 3248.72], "text": " answer questions. What historical precedence did the Supreme Court consider when deciding to overturn Roe v. Wade? Okay, this is a harder question. And so Then what we'll do is while that's running, let's see, 220, so we'll see."}, {"timestamp": [3248.72, 3249.72], "text": " It'll take a second."}, {"timestamp": [3249.72, 3250.72], "text": " Okay."}, {"timestamp": [3250.72, 3251.72], "text": " Question."}, {"timestamp": [3251.72, 3252.72], "text": " Yeah, there we go."}, {"timestamp": [3252.72, 3255.8], "text": " Okay, so it made it into the prompt."}, {"timestamp": [3255.8, 3260.96], "text": " It says, the Supreme Court considered several historical precedents."}, {"timestamp": [3260.96, 3262.52], "text": " Look at this, it's working."}, {"timestamp": [3262.52, 3264.28], "text": " Oh, man."}, {"timestamp": [3264.28, 3266.8], "text": " Okay. Important precedents. Look at this, it's working. Oh man, okay. Important precedents,"}, {"timestamp": [3266.8, 3272.48], "text": " Corston. Okay, so it looks at those other precedents. If you read the actual thing,"}, {"timestamp": [3272.48, 3278.88], "text": " which I don't expect anyone to, it talked about like 30 odd things in the past, like"}, {"timestamp": [3278.88, 3289.4], "text": " going all the way back to common law in the 13th century in England. So let's see, yeah, Plessy and Brown versus"}, {"timestamp": [3289.4, 3295.48], "text": " Board of Education, yeah, this is doing pretty good. Okay, so let's see if"}, {"timestamp": [3295.48, 3306.0], "text": " it picks up on the common law in England. Commerce Clause, Hang on, I got a message"}, {"timestamp": [3308.0, 3310.0], "text": " Okay, I'm going to mute my phone, sorry"}, {"timestamp": [3318.0, 3320.0], "text": " Fourteenth Amendment"}, {"timestamp": [3320.0, 3322.0], "text": " Ummm"}, {"timestamp": [3322.0, 3324.0], "text": " Ch-ch-ch-ch-ch"}, {"timestamp": [3324.0, 3329.12], "text": " Supreme Court, several, Roe v. Wade, Roe v. Wade, does not have the right to be sterilized"}, {"timestamp": [3329.12, 3331.96], "text": " without consent."}, {"timestamp": [3331.96, 3339.56], "text": " So it looks like it's mostly keying in onto the initial one, and it's kind of saying the"}, {"timestamp": [3339.56, 3342.32], "text": " same things over and over again."}, {"timestamp": [3342.32, 3349.88], "text": " But we'll see, we'll see in the final result. Brown vs. Board of"}, {"timestamp": [3349.88, 3357.8], "text": " Education. Also, okay, so it's picking up on some other ones. Religious schools. Yeah,"}, {"timestamp": [3357.8, 3368.84], "text": " Establishment Clause of the First Amendment. Okay, it is looking at deeper history."}, {"timestamp": [3368.84, 3372.72], "text": " This is looking like a success."}, {"timestamp": [3372.72, 3376.3], "text": " It does look like it is."}, {"timestamp": [3376.3, 3380.76], "text": " Final answer, the Supreme Court has overturned a lower ruling banning abortion."}, {"timestamp": [3380.76, 3382.56], "text": " Okay, cool."}, {"timestamp": [3382.56, 3385.0], "text": " The majority opinion written by Justice Brett Kavanaugh."}, {"timestamp": [3385.0, 3389.0], "text": " I thought it was by Clarence Thomas."}, {"timestamp": [3389.0, 3392.0], "text": " So it might be... let's see."}, {"timestamp": [3392.0, 3395.0], "text": " But he says those decisions are not inexorable commands"}, {"timestamp": [3395.0, 3399.0], "text": " and the decisions should be overturned reasonably for ex-state interest."}, {"timestamp": [3399.0, 3406.32], "text": " Okay, so it's not actually talking about the historical things."}, {"timestamp": [3408.8, 3411.8], "text": " The dissent in Dobbs v. Jackson argues the long history of abortion justifies"}, {"timestamp": [3411.8, 3413.84], "text": " the court decision to recognize."}, {"timestamp": [3414.88, 3419.88], "text": " Okay, so it, okay, I think something was lost."}, {"timestamp": [3420.28, 3422.64], "text": " Let's look at the last few inputs."}, {"timestamp": [3425.0, 3426.64], "text": " So let's grab Let's look at the last few inputs."}, {"timestamp": [3431.64, 3433.12], "text": " So let's grab, okay, so that one is one of these."}, {"timestamp": [3435.52, 3436.72], "text": " So write a detailed summary."}, {"timestamp": [3439.08, 3439.9], "text": " It looks like it got cut off. Interesting."}, {"timestamp": [3444.26, 3447.0], "text": " And it did it twice."}, {"timestamp": [3447.0, 3456.36], "text": " Huh, okay, something went wrong when I was trying to get the summary at the very end."}, {"timestamp": [3456.36, 3459.76], "text": " Let me pause this because, well, it's an hour long."}, {"timestamp": [3459.76, 3461.4], "text": " I know you guys are going to want to see this."}, {"timestamp": [3461.4, 3467.0], "text": " So I'm going to pause it and see if I can't figure out why the summary at the end went wrong."}, {"timestamp": [3467.0, 3471.7], "text": " Okay, I'm looking through this and it's not making any sense. Also, you probably noticed"}, {"timestamp": [3471.7, 3475.38], "text": " a wardrobe change. I realized that because I had been sitting outside at a coffee shop"}, {"timestamp": [3475.38, 3479.92], "text": " earlier I had pit stains and that was probably pretty gross. And black hides that."}, {"timestamp": [3479.92, 3485.0], "text": " Okay, so I copied the console output to a text file,"}, {"timestamp": [3486.56, 3489.6], "text": " and it did pick up on one thing that I had hoped it would,"}, {"timestamp": [3489.6, 3493.0], "text": " which was common law, history in England."}, {"timestamp": [3493.0, 3495.16], "text": " So it did see all that, right?"}, {"timestamp": [3495.16, 3498.66], "text": " So we got all these answers, there should be 20 answers,"}, {"timestamp": [3500.08, 3503.4], "text": " Griswold versus Connecticut, okay, so it saw all those."}, {"timestamp": [3503.4, 3507.8], "text": " It got all kinds of stuff from all throughout history."}, {"timestamp": [3507.8, 3513.6], "text": " But then when it got to the final answer, it just gave me a summary."}, {"timestamp": [3513.6, 3517.92], "text": " And some of which was not even in here, so I'm like, where did that come from?"}, {"timestamp": [3517.92, 3521.96], "text": " Okay, so we've got this."}, {"timestamp": [3521.96, 3523.32], "text": " We get all the answers, right?"}, {"timestamp": [3523.32, 3525.92], "text": " So the answers, these are the answers."}, {"timestamp": [3525.92, 3528.92], "text": " They should be appended here."}, {"timestamp": [3528.92, 3532.04], "text": " So answers equals list, answers."}, {"timestamp": [3532.04, 3537.32], "text": " All answers is join this, right?"}, {"timestamp": [3537.32, 3545.0], "text": " And then chunks equals text wrap. A wrap, all answers with 10,000, 10,000 characters,"}, {"timestamp": [3547.82, 3552.82], "text": " final list, prompt equals open file, prompt summary,"}, {"timestamp": [3556.26, 3558.98], "text": " summary result, oh, that's what I did wrong."}, {"timestamp": [3558.98, 3561.38], "text": " This right here, darn it."}, {"timestamp": [3563.98, 3566.68], "text": " Ugh, so simple. So simple."}, {"timestamp": [3566.68, 3567.62], "text": " So we got all the chunks,"}, {"timestamp": [3567.62, 3569.82], "text": " but then I didn't pass the right chunks in."}, {"timestamp": [3570.88, 3572.78], "text": " This is why you test your code, kids."}, {"timestamp": [3572.78, 3576.44], "text": " Okay, so for chunk in chunks, there we go."}, {"timestamp": [3576.44, 3578.84], "text": " We summarize them all together."}, {"timestamp": [3578.84, 3580.3], "text": " So let's rerun this."}, {"timestamp": [3582.4, 3589.56], "text": " Yeah, let me, I'll pause the video just because you don't need to sit and watch it rerun again."}, {"timestamp": [3589.56, 3595.56], "text": " But I will copy this question and I'll rerun it and then I'll show you the final result"}, {"timestamp": [3595.56, 3598.0], "text": " and we should be done."}, {"timestamp": [3598.0, 3601.28], "text": " All right gang, I think it worked."}, {"timestamp": [3601.28, 3603.48], "text": " The final thing, so there is..."}, {"timestamp": [3603.48, 3608.5], "text": " Oh, here, let me just copy this out into a text file."}, {"timestamp": [3608.5, 3613.24], "text": " So enter your question here."}, {"timestamp": [3613.24, 3621.16], "text": " We'll grab this."}, {"timestamp": [3621.16, 3623.64], "text": " Okay."}, {"timestamp": [3623.64, 3624.64], "text": " All right."}, {"timestamp": [3624.64, 3626.14], "text": " So reading through it, enter your question here."}, {"timestamp": [3626.14, 3629.78], "text": " What historical precedents?"}, {"timestamp": [3629.78, 3632.14], "text": " It did get the common law, so the Supreme Court"}, {"timestamp": [3632.14, 3634.46], "text": " considered several historical precedents."}, {"timestamp": [3634.46, 3636.94], "text": " First, they considered the pre-constitutional common law"}, {"timestamp": [3636.94, 3639.36], "text": " history in England, which showed that abortion was largely"}, {"timestamp": [3639.36, 3642.1], "text": " prohibited in most American states as of 1868."}, {"timestamp": [3642.1, 3643.66], "text": " So it got way back in history."}, {"timestamp": [3643.66, 3644.86], "text": " So that's good."}, {"timestamp": [3644.86, 3645.32], "text": " That was"}, {"timestamp": [3645.32, 3649.0], "text": " one of the key things that I remember from my previous work that I was like, wow, they"}, {"timestamp": [3649.0, 3650.44], "text": " went way back."}, {"timestamp": [3650.44, 3656.36], "text": " Okay, final answer. The Supreme Court overturned Roe v. Wade by considering several historical"}, {"timestamp": [3656.36, 3660.72], "text": " precedents. The first precedent was the principle of stare decisis, I think I'm saying that"}, {"timestamp": [3660.72, 3668.88], "text": " right, which requires respect for the court's precedents and for the accumulated wisdom of the judges who have previously addressed the same issue. The court found that Roe"}, {"timestamp": [3668.88, 3673.36], "text": " was an egregiously wrong decision that had caused significant negative consequences"}, {"timestamp": [3673.36, 3680.8], "text": " and that overruling it would not unduly upset the legitimate reliance interest."}, {"timestamp": [3680.8, 3695.0], "text": " The second precedent was the history of stereodecesis in the court, which establishes that a constitutional precedent may be overruled only when it is egregiously wrong and has caused significant negative consequences, and overruling it would not unduly, okay, it's kind of repeating itself."}, {"timestamp": [3695.0, 3701.0], "text": " Applying these factors, the court concluded that Roe met all three criteria and thus deserved to be overturned."}, {"timestamp": [3701.0, 3705.36], "text": " The third precedent was the fact that at the time of Roe, 30 states still prohibited"}, {"timestamp": [3705.36, 3707.68], "text": " abortion at all stages."}, {"timestamp": [3707.68, 3711.76], "text": " This showed that the Roe decision was out of step with public opinion at the time."}, {"timestamp": [3711.76, 3715.28], "text": " The fourth precedent was the fact that, in the years prior to Roe, about a third of the"}, {"timestamp": [3715.28, 3717.7], "text": " states had liberalized their laws."}, {"timestamp": [3717.7, 3721.54], "text": " This showed that there was a trend towards liberalization that was interrupted by Roe."}, {"timestamp": [3721.54, 3730.08], "text": " The fifth and final precedent was the fact that Roe abruptly ended the political process of liberalizing abortion laws. This made it clear"}, {"timestamp": [3730.08, 3733.6], "text": " that Roe was not just wrong, but egregiously wrong, and that it needed to be overturned in"}, {"timestamp": [3733.6, 3738.16], "text": " order to allow the democratic process to continue. That is a phenomenal explanation."}, {"timestamp": [3739.28, 3743.28], "text": " The Supreme Court overturns Roe v. Wade, taking into consideration several historical precedents."}, {"timestamp": [3743.28, 3750.9], "text": " This is the second chunk. Firstly, they look at the precedent set by Roe itself, was incorrectly decided, erroneous"}, {"timestamp": [3750.9, 3751.9], "text": " historical narrative."}, {"timestamp": [3751.9, 3755.52], "text": " Secondly, they look at the precedent set by Casey, which revised the textual basis for"}, {"timestamp": [3755.52, 3761.44], "text": " the abortion right, silently abandoned Roe's erroneous historical narrative."}, {"timestamp": [3761.44, 3768.64], "text": " Finally, they look at the precedent set by Janus and Ramos, which held that states cannot protect fetal life prior to viability. All these factors led..."}, {"timestamp": [3768.64, 3774.4], "text": " Okay, so the final summarization needs a little bit of work, but still, in terms of"}, {"timestamp": [3774.96, 3780.08], "text": " giving you an answer as to, like, asking the question, what were the historical precedents,"}, {"timestamp": [3780.08, 3789.12], "text": " this was amazing. I am super satisfied with this. So, I'll call it a day there. Thanks for watching."}, {"timestamp": [3784.43, 3787.75], "text": " This was amazing."}, {"timestamp": [3787.75, 3790.31], "text": " I am super satisfied with this."}, {"timestamp": [3790.31, 3791.95], "text": " So I'll call it a day there."}, {"timestamp": [3791.95, 3792.63], "text": " Thanks for watching."}]}