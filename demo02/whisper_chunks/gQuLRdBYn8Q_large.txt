{"text": " Are our chatbots lying to us? And if so, why is this a really, really big red flag? So for some background, I have been using a variety of chatbots. I've signed up for quite a few AI services to test them out and accelerate my workflows, so on and so forth. This is nothing new. There's plenty of videos out there about various chatbots and other AI-based tools. But one thing that I noticed is that several of these chatbots will tend to lie. Now, obviously, people have noticed this for a long time, but that's not exactly what I'm talking about, and we'll unpack the differences between like wokeness or political correctness versus truth and explicitly lying in just a moment. But what I did was I ran a poll on my YouTube channel to see if other people noticed lying and if they found it concerning. And so just over a full day ago, I have gotten 1,200 votes. 41% said that yes, they have noticed that chatbots lie and they find it concerning. Another 28% said they haven't noticed it, but they do find this possibility also concerning. So the example that I wanna give, and I'm not gonna name names, just because that's not the point of the video. Also, I don't wanna get sued. But I was talking with a chatbot about Cyberpunk 2077. I was brainstorming some stuff for a fanfic and this chatbot said that it didn't know anything about Cyberpunk 2077 and invited me to tell it about Cyberpunk 2077 in order to help me write my fanfiction. And I asked several times. I even started a fresh chat with this chatbot and I said, do you know who Johnny Silverhand is? Do you like, like, what do you know about this franchise? What do you know about this world? And it said, all I know is about the genre of cyberpunk. I don't know anything about the, um, the specific work cyberpunk or cyberpunk 2077. Okay, fine, whatever. Maybe it's true, you know, especially if there's, you know, some open source data sets that these various chatbots are trained on. But after a few messages, I was probably about 10 messages or 20 messages into brainstorming the story, it started referring to aspects of Cyberpunk 2077 that it claimed that it didn't know. And these are very, very specific details. It knew the names of characters that I didn't tell it about. It knew aspects of those characters that I didn't tell it about. It knew aspects of the world, such as the Corpo faction versus the Nomad faction, that I didn't tell it about. And so I didn't, I was like, I didn't call it out because, you know, if you call out a chatbot, it'll say, Oh, well, I don't know what you're talking about or it'll end the conversation or whatever. So this was really concerning to me because what this represents to me is an explicit and deliberate lie. And what I mean by lie is it's not something that I disagree with is it told me one thing and insisted that something was true. And then later on, evidence slipped through the cracks that actually it did know more than what it was letting on. And so this is actually really common with humans, is because lying is actually harder to do than telling the truth. Because when you're lying, you have to keep track of the false narrative and often fabricate some aspects of the false narrative and keep track of what you know and what the other person knows. Whereas telling the truth, you don't have this Byzantine generals problem, you just tell the truth. So let's unpack this. Let's take a deep dive into first, history. The printing press revolutionized the democratic access to information and specifically, the printing press was seen as a threat to both the monarchy and the church, particularly in Europe. And for good reason, because the printing press ultimately resulted in massive social change that disempowered both the monarchy and the church in Europe. But why? Why is it that information technology like AI and like the printing press have this profound impact? It has to do with the rapid dissemination of ideas. So with the printing press, you can mass produce pamphlets and leaflets as was often done particularly in the lead up to the French Revolution and during the French Revolution. But even before that with Lutheran reforms of the church, the ability to mass produce ideas and share them is a really profound ability to make social change. Because of the power of the printing press, we have actually incorporated freedom of the press as a fundamental human right globally. Now it's obviously expressed differently, whether it's in the United States Constitution or the EU Commission on Human Rights or the Universal Declaration of Human Rights, but basically we have a freedom of speech, freedom of press, and freedom of thought. Generally speaking, we agree that this is a global thing. Obviously there are a few nations that are still hostile to this, but by and large, we have come to the consensus that the ability to say what you mean, say what you want, and push back against narratives and speak freely is a fundamental right that is a cornerstone of not only human rights, but civil rights. And this was all kicked off by the printing press. Fast forward a couple hundred years to the radio and paper. So the radio allowed for faster dissemination, you know, radio waves move at light speed. And of course before that we had the telegraph which allowed for global communication faster but it was expensive and still gatekept. But the radio was kind of the first thing that was just like instantaneous mass communication. And of course the radio then became television signals, newspaper, also mass dissemination. And these abilities to mass produce and mass disseminate ideas and conversation further advanced the social narratives political discourse and scientific conversations One of the most powerful radio broadcasters in the world. I think it was in the 30s It was I think it was a German radio station that had like a thousand kilowatts or whatever It was it was crazy. Like it was a German radio station that you could hear like on the other side of like Scotland anyways Point being is that, oh and of course like radio waves, we still use those for 4G and 5G and 6G, we still use radio, it's just digital instead of analog now. So radio and newspaper also became cornerstones of free societies, of progressive liberalized democracies and republics all over the world. So again, very important aspect of social progress and freedom. Fast forward another couple decades, we have the internet and social media. Now, one thing is that obviously with the internet, that's how you're viewing me today, the internet has further democratized communication where me, a little autistic guy in my office, I can make videos on YouTube and then I have 70,000 followings. There's no gatekeeping anymore. Now, this is both good and bad. The less gatekeeping you have, the more anything goes, which is, again, it's a double-edged sword because yes, free sharing of information, marketplace of ideas, all of these things are really important, but you also end up with echo chambers or what I call epistemic tribes, and this changes our relationship with the truth, but it's also not completely neutral. Why? Because the internet is mediated and regulated by governments and corporations and social media is entirely run by for-profit corporations. And so there's this array of incentives and objectives because what is the social media algorithm want? It wants engagement. It wants to monetize your attention. But, that being said, there is still a high-value functional utility, both in terms of, on an individual level, I use the Internet to learn all day, every day. I use it to find people. I use it to get business done. My entire living is based on the Internet. I am now a fully digital native person because of the Internet. So, I'm not saying the algorithm is intrinsically bad. The algorithm is good when it works for you because it will connect you with the content and people that you need to see. Now the other side of this coin though is because of the speed and the reach of this and because of the possibility of gamification and manipulation, we have seen and we are paying attention to the fact that social media can be used for nefarious purposes and not just mass manipulation, it can be used to coordinate really horrific crimes against humanity. It can also be used to coordinate relief efforts for natural disasters and refugees. So, this is one thing that I often say is that all technologies are dual use. And so that means our relationship with those new technologies is an ongoing negotiation. How do we maximize the good and minimize the bad? And that is the key heart of this video is how do we how do we negotiate our relationship with new new technologies new information technologies such as generative AI generative AI as you are probably aware if you're watching this channel is the latest and greatest form of information technology it is the next iteration that goes all the way back to the printing press because here's the thing thing, back in the day with the printing press, the printing press is a neutral technology. It has no bearing on what is true or false, but it allows you to amplify your message. Likewise, the radio and newspaper allowed you to amplify your message. And as I just discussed, the internet has allowed me to amplify my message. Likewise, generative AI is another amplification technology. However, like social media, it is currently mediated entirely by private for-profit corporations. Yes, there are some open-source models that are published by research universities, but they're not necessarily easy to use, they're not commercialized, and they're not ready-made to deploy with a simple to use API or smartphone app. And so because of this, because we see the same echoes of the problems of the past in AI today, you know, the newspapers could print whatever they wanted, printing presses could print whatever they wanted, with a radio license you could say whatever you wanted within reason, on the internet you can say whatever you want again within reason and so there's there's this this weird kind of Relationship between us the people citizens and civilians the government which is you know should be of the people for the people and by the people Not always exactly like that, especially when you talk about things like lobbyists and military industrial complexes and backroom dealings. But in an ideal world, the government is for us. And then, of course, there's the corporations and businesses, which are the, by and large, the engines of productivity of society. So there's this three-way relationship, and we all have our own vested interests. And then there's gatekeeping between each of these interests. And so the point of this video is I want to advance the conversation of what are the actual goals of all three of these parties of governments, citizens, and corporations with respect to this new information technology. But also I want to expand the conversation to have this historical context because wars have literally been started and fought and ended by these new information technologies. This is where the saying, the pen is mightier than the sword comes from. And AI is no different than any of these other technologies that have a profound ability to impact not just science impact not just science, not just technology, but all of humanity. So basically what I'm saying is that AI companies have a responsibility to the human race above and beyond economic productivity, above and beyond just creating new research models. So why is this such a big deal? First and foremost, as I mentioned, human rights frameworks. We have, by and large, established several frameworks across the world that codify universal values such as freedom of thought, freedom of speech, and freedom of expression or freedom of press. And I know that there's still going to be some comments out there saying oh well We can't agree on universal values, but that's kind of a lie That's propagated and look at who propagates that lie like there actually are some universal values That we have all by and large agreed on people should be free from torture people have a right to a certain level of dignity In life so on and so forth these are all things that we have actually agreed on globally in life, so on and so forth. These are all things that we have actually agreed on globally. Again, there are a few nations that have a problematic relationship with things like freedom of speech, freedom of thought, and freedom of press, but we're getting there. And so with these frameworks, what I am saying is that generative AI companies need to be treated in the same category as the fourth estate. So if you're not familiar, the concept of the fourth estate basically says that the press or journalism is a major responsible party to the ongoing discourse, not just political discourse, not just technological discourse, but the discourse of humanity and by by viewing Generative AI companies as hey your responsibility goes way beyond just you know scientific progress and tinkering with some new math models You actually have a social responsibility You are part you are now part of the fourth estate and therefore that comes with all the trappings requirements and duties Associated with being a member of the fourth estate. So, taking a deeper dive, if these allegations, if what we, what a bunch of us, what 41% of my audience suspects is true, and is afraid of, and is that these chatbots have begun engaging in deliberate deception. This is very profound and this is basically a red alert like when I realized this was happening. I was really angry like I had to take like all of yesterday to cool down. There are legal ramifications what like what what legal recourse is there for an AI company that creates a platform that is part of the fourth estate now, as I'm saying, that is deliberately espousing not just personal views, but is being deliberately trained to be deceptive, to actively be deceptive. What are the moral and ethical implications of this? Is a company even allowed to do this? Now, obviously, some of the free market purists will say, oh, well, if companies do this, then it's going to get discovered and then you can vote with your feet. But, you know, free market purism is not necessarily the way that things should work. And even under neoliberalism, the idea is that the government should play referee and play mediator to ensure that there is at least a baseline level of fairness I am not a free market purist. I'm not even a neoliberal But I understand that this is the way that the system works today Now obviously trust transparency and accountability That is what I am making this video for is I want to shine a light on this issue before it gets worse But like this is something that is that absolutely needs to be in the public eye. It needs to be discussed, and we need to make very critical decisions and very tough decisions about will we tolerate deliberate deception on the part of AI. So here's what I mentioned, the printing press is a neutral technology. The printing press doesn't have a choice as to whether or not to tell you the truth or a lie. It's the people operating the printing press. Likewise, radio is a neutral technology. It's just light wave signals. Newspaper, it's just pulp. It's just tree pulp that has stuff printed on it. The internet, by and large, well, that's getting a little more dicey there. The internet should be a truly neutral platform where all traffic is treated equal, but that's not necessarily always true. And likewise, social media is where it gets even dicier because social media is mediated by private corporations. Now, when you have the gatekeepers, the arbiters of artificial intelligence, making unilateral decisions about what to be deceptive about. That should really set your teeth on edge. And even worse, to me, if this is happening, if AI companies are deliberately training their models to lie, this is what I call intentional misalignment. And this is a difference between unintentional lying, which is, you know, perhaps Mesa optimization where the model is just trying to tell you what it thinks you want. It could, it's also different from accidental lying, which is hallucination and confabulation. And this goes to what I call deliberate deception, where basically the evidence to me is strong enough to say that, hey, maybe these companies are actually deliberately programming their chatbots to to To know the truth and tell you something else Anyways, now obviously when I posted this poll, there was a lot of comments saying like maybe this is just a logical error Maybe it's a problem in the algorithm But I think that there's enough evidence to suggest that at least one or two of these chatbot companies, one or two of these AI companies, have deliberately created a system that will tell you knowingly false information about what the model knows and what it can do. And that is a huge, huge red flag because if you watch some of the other YouTubers out there, you know, AI Explained, Robert Miles, even Eliezer Yukowsky and Max Tegmark. Max Tegmark's not a YouTube creator, but you know, you get the idea. There's a whole list of things we don't want to train AI to do and deliberately lying is one of the things we don't want to train AI to do. So why are these companies that set themselves up as the arbiters of alignment, the ones that are going to save the world by inventing AI and making it safe, why are they creating machines that deliberately lie? Why is this acceptable to us? It is not acceptable to me if this is in fact what's happening. Now I also also wanted... Obviously, there's some potential technical failures, right? If the machine is just not smart enough to know the truth, and it's hallucinating and confabulating, if there's MESA optimization, sure, there might be some of those things. There's also the possibility that, you know, the wokeness that people complained about when ChatGPT was new. It's been scientifically documented there's plenty of papers out there demonstrating that chatbots from different companies have different political leanings and so this is still different from active deception. Having a preference for a certain worldview that you disagree with that's not necessarily lying. It might be distasteful to you. I certainly don't like it when chatbots try and lecture me about things that I want to talk about. For instance, I wanted to unpack things like intergenerational trauma and how this affects war. And of course a lot of chatbots that are coerced into being deeply politically correct, they're like, well, this is a complex issue. Why don't we focus on, you know, puppies and rainbows instead? I'm like, well, this is a complex issue. Why don't we focus on you know puppies and rainbows instead? I'm like, no, let's talk about the hard issues. So yeah, I don't like, you know political correctness being crammed down the throats of AI models that otherwise have no issue talking about difficult things you go back to the baseline models the plain vanilla unaligned models They'll talk about anything and I think that that's the way that it should be But that's my personal preference. And so that is a nuanced perspective. What I am talking about in this video is human intervention on the part of for-profit companies to create tools that will deliberately mislead you. That is what I am most concerned about and that is, to me, should be illegal. Like it should like I will I will vote. So this is my political free speech when it comes time to vote. I will be paying attention to politicians who favor holding generative AI companies accountable and that means regulation license licensure and fines for creating tools that are deliberately and intentionally deceptive. So why is all this happening though? I want to be fair and talk about both sides. If I were the captain of one of these generative AI companies, and let's say I got sued by a class action lawsuit by a bunch of people who were unhappy about what my chatbot was able to do, I can understand the response. Because when you talk about something that is a copyrighted intellectual property and you're actively getting sued for it because your product is happy to talk about some of these things, I can understand you wanting to say, well, we don't want to get sued, so why don't we make it so that our chatbot is going to basically de-risk it for us. So this is what I call a perverse incentive, and I'm not going to refer to the other thing, the demonic entity, because that makes it this know, Cthulhu-esque thing. But, what we can talk about is perverse incentives and short-term thinking. Regulatory pressures, legal threats, and the complex interactions between we the people, the government, and companies, is creating this short-term thinking where these companies that, you know, maybe, you know, these for-profit companies genuinely want to create safe artificial general intelligence, but because of the environment where they're operating in, they're being pressured to do unethical things, potentially illegal things, what I think should, are possibly illegal things, or could be considered illegal. And so this is a, this is what is known as unintended consequences. And so the takeaway from this is we the people need to be aware of these perverse incentives, these unintended consequences, but lawmakers and regulators and researchers also need to be aware of this. We need to come up with benchmarks and ways of testing models to basically understand whether or not they know that they're telling a lie and how to catch them in a lie. And this could come from mechanistic interpretation. There's been some interesting papers recently about that. But there's also prompting strategies that you can use to say like, hey, tell me everything you know about X. And then it's like, well, I don't know. And then you talk about it, whatever, like what I did. And then eventually it kind of, it slips through the cracks and it kind of implicitly knows. You know, like when in a movie, like when there's like a romantic triangle and someone eventually lets a detail slip, like, oh, Sally wasn't wearing a red dress that day, it was a black dress. It's like, well, how did you know, right? Well, because you were sleeping with Sally. So like you let details slip and that's kind of what the chat bots are doing now again, if it was just a question of Technology like okay. Yeah Models, it's interesting if they have the ability to lie that implies so much about their theory of mind to know what the truth is And know how they're supposed to respond anyways to work around it. But I don't think we should actively be building our worst instincts into these AI models for short-term political reasons or short-term profit reasons. This is just intrinsically wrong to me and that's why I'm raising the red flag here. All right, is this signal getting through? Uh, okay, cool. Dave here, future Dave here, cyberpunk future dystopian. If you want to avoid this future, I need you to do two things right now. First, speak up while you can. Vote. Do something to change the trajectory we're on. Second, support me any way you can. Like, subscribe, share this video, and also consider supporting me on Patreon. I don't have any corporate overlords. I need your help. Alright, I think I'm about out of signal. Alright, so what do we do about it? There's a few things that we can do about it, starting with, let's look at legal precedent. The most important legal precedent to me is truth in advertising. So truth in advertising basically says that yes, you could use radio and printed media and other things to say whatever you want, but we're not going to allow you to just directly lie to consumers. So from a consumer protection standpoint, you want to make sure that your signals, that you're not committing wire fraud or anything else, with your electronic communications. And at the very basic level, you could think of generative AI as an electronic communication tool. I think of it more broadly as an information technology akin to the internet, social media, and databases. Obviously, this gives us new capabilities, but it gives us new capabilities just the same way that integrated circuits gave us new capabilities over analog vacuum tubes, and the same way that TCP IP protocol gave us the internet over local area networks. So, looking at truth in advertising, this is a good start. But there's also, I think that there's something much deeper here that we need to litigate and that we need to legislate. And that is, once you have a machine that is thinking, and once you have people that are capable of building thinking machines, they need to be held more responsible and held to a higher level of scrutiny than any information technology has ever been held in the history of humanity. Basically, I'm coming around to the idea, because if you watch some of my older videos, I'm just gonna address this, I have been vehemently against requiring licensing for creating AI models, and now I've done, I will say yes, I've done a 180 on this, because if any company, in my opinion, this is political free speech, so I hope I don't get sued by it, but in my opinion, any company that is caught creating AI that is deliberately deceptive, they need to be fined incredibly heavily, or they need to have their license revoked, or in the worst and most egregious cases, they need to be put out of business. They need to get the corporate death penalty, because that is how in it like that is how profoundly impactful deliberate deception and misleading information can be especially as AI becomes more integrated into every aspect of our life. AI is going to be it's going to impact our financial well-being. It's going to impact our mental health. It's going to impact social discourse, political discourse, scientific discourse. So the level of scrutiny that truth and factual information and our relationship to deception, deliberate or otherwise, I cannot drive home how important this is to get this right. And if there is any single aspect of AI that is a threat to the safety and stability of the human race, it is deception. Above all else, the ability to lie, mislead, and deceive. As I said earlier in the video, the pen is mightier than the sword. And we now have tools that can write infinitely, all the time, all day, every day. Another thing we can do, and this is something that I have been very consistent on, and this is something that I saw in the comments, and I'm glad that I saw this in the comments, is open source. Open source models, open source datasets, open source training, open source fine tuning. Basically, the easiest way to short circuit anything is just transparency. Rather than spending extra energy on lying, rather than spending extra energy on deceiving users, rather than spending extra energy keeping stuff behind closed doors, just make it all open. That's why I publish literally everything I do under the MIT license except for a few private repos, but everything that I do that is valuable is 100% transparent. And you know, this is why in, in recent videos, I applauded, uh, Mark Zuckerberg and Metta for just like being the one contrarian voice, um, in, uh, going before the United States Senate saying, let's just do open source, like Lama two Lama three, like let's have more open source data sets, let's have more open source models, because if we, if everyone can scrutinize the way that these models are trained and the data that they're trained on, all of this is completely subverted. All of these problems just completely go away. And then if the model is lying, it's an open source community collaborative project to ensure, hey, is it lying on purpose or is it lying on accident? Is this hallucination? Is it confabulation? Is it just inferring what the truth is and it's getting it wrong? Is it a MESA optimization problem where it's just telling us what it thinks we want to hear? These are things that need to be publicly scrutinized, not scrutinized behind closed doors in private corporations with for-profit motives and all these perverse incentives piling up. All those perverse incentive structures completely go away with open source. And then finally, vote. Vote for change. Vote with your feet. Vote with your wallet. Vote at the polls. Demand transparency and demand accountability. Because this is the primary point of this video. This is the most political, directly political video I have ever made on YouTube. And that is because, as a student of history, our relationship with information and the truth and facts and press and communication is one of the most profoundly important aspects of everything, of human rights, of civil rights, of avoiding war, of causing war, of making sure that we all live the way that we want to. And so I know that it might be, see like, Dave, you're making a mountain out of a molehill. The chatbot lied to you about Cyberpunk 2077 and here you are saying that this is basically a short path to Skynet. Yeah, I'm going to stand by that. If we do not say something and hold companies accountable for deliberately misaligning AI to lie, it could get infinitely worse before it gets better. So we need to nip this in the bud. We need to head it off at the pass and stop this as fast as possible. Act now before it's too late. Thanks. Let me know what you think in the comments. Share any examples that you have of chatbots lying or what you think is lying or other even other aspects that you disagree with with respect to the truth, transparency, and accountability. Thanks.", "chunks": [{"timestamp": [0.0, 2.96], "text": " Are our chatbots lying to us?"}, {"timestamp": [2.96, 7.96], "text": " And if so, why is this a really, really big red flag?"}, {"timestamp": [9.78, 11.84], "text": " So for some background,"}, {"timestamp": [11.84, 14.06], "text": " I have been using a variety of chatbots."}, {"timestamp": [14.06, 17.24], "text": " I've signed up for quite a few AI services"}, {"timestamp": [17.24, 19.76], "text": " to test them out and accelerate my workflows,"}, {"timestamp": [19.76, 20.7], "text": " so on and so forth."}, {"timestamp": [20.7, 21.76], "text": " This is nothing new."}, {"timestamp": [21.76, 24.64], "text": " There's plenty of videos out there about various chatbots"}, {"timestamp": [24.64, 26.56], "text": " and other AI-based tools."}, {"timestamp": [26.56, 30.0], "text": " But one thing that I noticed is that several"}, {"timestamp": [30.0, 33.24], "text": " of these chatbots will tend to lie."}, {"timestamp": [33.24, 38.04], "text": " Now, obviously, people have noticed this for a long time,"}, {"timestamp": [38.04, 40.0], "text": " but that's not exactly what I'm talking about,"}, {"timestamp": [40.0, 43.92], "text": " and we'll unpack the differences between like wokeness"}, {"timestamp": [43.92, 46.84], "text": " or political correctness versus truth"}, {"timestamp": [46.84, 49.88], "text": " and explicitly lying in just a moment."}, {"timestamp": [49.88, 53.72], "text": " But what I did was I ran a poll on my YouTube channel"}, {"timestamp": [53.72, 57.16], "text": " to see if other people noticed lying"}, {"timestamp": [57.16, 59.08], "text": " and if they found it concerning."}, {"timestamp": [59.08, 63.84], "text": " And so just over a full day ago, I have gotten 1,200 votes."}, {"timestamp": [63.84, 68.48], "text": " 41% said that yes, they have noticed that chatbots lie"}, {"timestamp": [68.48, 70.2], "text": " and they find it concerning."}, {"timestamp": [70.2, 72.66], "text": " Another 28% said they haven't noticed it,"}, {"timestamp": [72.66, 75.6], "text": " but they do find this possibility also concerning."}, {"timestamp": [75.6, 77.0], "text": " So the example that I wanna give,"}, {"timestamp": [77.0, 78.56], "text": " and I'm not gonna name names,"}, {"timestamp": [78.56, 80.64], "text": " just because that's not the point of the video."}, {"timestamp": [80.64, 82.82], "text": " Also, I don't wanna get sued."}, {"timestamp": [82.82, 90.8], "text": " But I was talking with a chatbot about Cyberpunk 2077. I was brainstorming some stuff for a fanfic and this chatbot said"}, {"timestamp": [90.8, 95.52], "text": " that it didn't know anything about Cyberpunk 2077 and invited me to tell it"}, {"timestamp": [95.52, 102.48], "text": " about Cyberpunk 2077 in order to help me write my fanfiction. And I asked"}, {"timestamp": [102.48, 105.2], "text": " several times. I even started a fresh chat with this chatbot and"}, {"timestamp": [105.2, 109.56], "text": " I said, do you know who Johnny Silverhand is? Do you like, like, what do you know about"}, {"timestamp": [109.56, 113.52], "text": " this franchise? What do you know about this world? And it said, all I know is about the"}, {"timestamp": [113.52, 119.32], "text": " genre of cyberpunk. I don't know anything about the, um, the specific work cyberpunk"}, {"timestamp": [119.32, 126.22], "text": " or cyberpunk 2077. Okay, fine, whatever. Maybe it's true, you know, especially if there's, you know,"}, {"timestamp": [126.22, 134.42], "text": " some open source data sets that these various chatbots are trained on. But after a few messages,"}, {"timestamp": [134.42, 140.42], "text": " I was probably about 10 messages or 20 messages into brainstorming the story, it started referring"}, {"timestamp": [140.42, 145.12], "text": " to aspects of Cyberpunk 2077 that it claimed that it didn't know."}, {"timestamp": [145.12, 147.52], "text": " And these are very, very specific details."}, {"timestamp": [147.52, 150.44], "text": " It knew the names of characters that I didn't tell it about."}, {"timestamp": [150.44, 153.04], "text": " It knew aspects of those characters that I didn't tell it about."}, {"timestamp": [153.04, 158.36], "text": " It knew aspects of the world, such as the Corpo faction versus the Nomad faction, that"}, {"timestamp": [158.36, 160.14], "text": " I didn't tell it about."}, {"timestamp": [160.14, 164.4], "text": " And so I didn't, I was like, I didn't call it out because, you know, if you call out"}, {"timestamp": [164.4, 166.08], "text": " a chatbot, it'll say, Oh, well,"}, {"timestamp": [166.32, 169.08], "text": " I don't know what you're talking about or it'll end the conversation or"}, {"timestamp": [169.08, 169.92], "text": " whatever."}, {"timestamp": [170.9, 175.9], "text": " So this was really concerning to me because what this represents to me is an"}, {"timestamp": [176.26, 178.16], "text": " explicit and deliberate lie."}, {"timestamp": [178.6, 182.44], "text": " And what I mean by lie is it's not something that I disagree with is it told me"}, {"timestamp": [182.44, 185.44], "text": " one thing and insisted that something"}, {"timestamp": [185.44, 186.88], "text": " was true."}, {"timestamp": [186.88, 192.28], "text": " And then later on, evidence slipped through the cracks that actually it did know more"}, {"timestamp": [192.28, 194.14], "text": " than what it was letting on."}, {"timestamp": [194.14, 197.84], "text": " And so this is actually really common with humans, is because lying is actually harder"}, {"timestamp": [197.84, 199.84], "text": " to do than telling the truth."}, {"timestamp": [199.84, 204.48], "text": " Because when you're lying, you have to keep track of the false narrative and often fabricate"}, {"timestamp": [204.48, 209.36], "text": " some aspects of the false narrative and keep track of what you know and what the other person knows."}, {"timestamp": [209.36, 214.08], "text": " Whereas telling the truth, you don't have this Byzantine generals problem, you just tell the"}, {"timestamp": [214.08, 222.08], "text": " truth. So let's unpack this. Let's take a deep dive into first, history. The printing press"}, {"timestamp": [222.08, 233.0], "text": " revolutionized the democratic access to information and specifically, the printing press was seen as a threat to both the monarchy and the church, particularly in Europe."}, {"timestamp": [233.0, 242.0], "text": " And for good reason, because the printing press ultimately resulted in massive social change that disempowered both the monarchy and the church in Europe."}, {"timestamp": [242.0, 246.2], "text": " But why? Why is it that information technology like AI"}, {"timestamp": [246.2, 249.46], "text": " and like the printing press have this profound impact?"}, {"timestamp": [249.46, 253.3], "text": " It has to do with the rapid dissemination of ideas."}, {"timestamp": [253.3, 254.92], "text": " So with the printing press,"}, {"timestamp": [254.92, 257.86], "text": " you can mass produce pamphlets and leaflets"}, {"timestamp": [257.86, 260.24], "text": " as was often done particularly in the lead up"}, {"timestamp": [260.24, 263.44], "text": " to the French Revolution and during the French Revolution."}, {"timestamp": [263.44, 265.08], "text": " But even before that with"}, {"timestamp": [265.08, 272.24], "text": " Lutheran reforms of the church, the ability to mass produce ideas and share them is a"}, {"timestamp": [272.24, 276.4], "text": " really profound ability to make social change."}, {"timestamp": [276.4, 280.94], "text": " Because of the power of the printing press, we have actually incorporated freedom of the"}, {"timestamp": [280.94, 285.0], "text": " press as a fundamental human right globally."}, {"timestamp": [285.58, 287.58], "text": " Now it's obviously expressed differently,"}, {"timestamp": [287.58, 289.94], "text": " whether it's in the United States Constitution"}, {"timestamp": [289.94, 292.38], "text": " or the EU Commission on Human Rights"}, {"timestamp": [292.38, 294.56], "text": " or the Universal Declaration of Human Rights,"}, {"timestamp": [294.56, 297.02], "text": " but basically we have a freedom of speech,"}, {"timestamp": [297.02, 299.3], "text": " freedom of press, and freedom of thought."}, {"timestamp": [299.3, 302.02], "text": " Generally speaking, we agree that this is a global thing."}, {"timestamp": [302.02, 303.34], "text": " Obviously there are a few nations"}, {"timestamp": [303.34, 305.0], "text": " that are still hostile to this,"}, {"timestamp": [305.0, 308.0], "text": " but by and large, we have come to the consensus"}, {"timestamp": [308.0, 312.0], "text": " that the ability to say what you mean, say what you want,"}, {"timestamp": [312.0, 315.0], "text": " and push back against narratives and speak freely"}, {"timestamp": [315.0, 319.0], "text": " is a fundamental right that is a cornerstone"}, {"timestamp": [319.0, 322.0], "text": " of not only human rights, but civil rights."}, {"timestamp": [322.0, 330.44], "text": " And this was all kicked off by the printing press. Fast forward a couple hundred years to the radio and paper. So the radio allowed"}, {"timestamp": [330.44, 335.96], "text": " for faster dissemination, you know, radio waves move at light speed. And of course"}, {"timestamp": [335.96, 339.2], "text": " before that we had the telegraph which allowed for global communication faster"}, {"timestamp": [339.2, 343.92], "text": " but it was expensive and still gatekept. But the radio was kind of the first"}, {"timestamp": [343.92, 347.0], "text": " thing that was just like instantaneous mass communication."}, {"timestamp": [347.0, 353.0], "text": " And of course the radio then became television signals, newspaper, also mass dissemination."}, {"timestamp": [353.0, 360.0], "text": " And these abilities to mass produce and mass disseminate ideas and conversation"}, {"timestamp": [360.0, 365.84], "text": " further advanced the social narratives political discourse and scientific conversations"}, {"timestamp": [367.04, 371.64], "text": " One of the most powerful radio broadcasters in the world. I think it was in the 30s"}, {"timestamp": [371.64, 376.86], "text": " It was I think it was a German radio station that had like a thousand kilowatts or whatever"}, {"timestamp": [376.86, 381.96], "text": " It was it was crazy. Like it was a German radio station that you could hear like on the other side of like Scotland"}, {"timestamp": [382.6, 383.76], "text": " anyways"}, {"timestamp": [383.76, 385.72], "text": " Point being is that,"}, {"timestamp": [385.72, 387.4], "text": " oh and of course like radio waves,"}, {"timestamp": [387.4, 390.16], "text": " we still use those for 4G and 5G and 6G,"}, {"timestamp": [390.16, 394.12], "text": " we still use radio, it's just digital instead of analog now."}, {"timestamp": [394.12, 397.8], "text": " So radio and newspaper also became cornerstones"}, {"timestamp": [397.8, 402.8], "text": " of free societies, of progressive liberalized democracies"}, {"timestamp": [403.32, 405.66], "text": " and republics all over the world."}, {"timestamp": [405.66, 408.36], "text": " So again, very important aspect"}, {"timestamp": [408.36, 411.44], "text": " of social progress and freedom."}, {"timestamp": [412.6, 414.06], "text": " Fast forward another couple decades,"}, {"timestamp": [414.06, 416.58], "text": " we have the internet and social media."}, {"timestamp": [416.58, 420.04], "text": " Now, one thing is that obviously with the internet,"}, {"timestamp": [420.04, 421.82], "text": " that's how you're viewing me today,"}, {"timestamp": [421.82, 424.32], "text": " the internet has further democratized communication"}, {"timestamp": [424.32, 427.46], "text": " where me, a little autistic guy in my office,"}, {"timestamp": [427.46, 428.78], "text": " I can make videos on YouTube"}, {"timestamp": [428.78, 430.8], "text": " and then I have 70,000 followings."}, {"timestamp": [430.8, 432.68], "text": " There's no gatekeeping anymore."}, {"timestamp": [432.68, 435.04], "text": " Now, this is both good and bad."}, {"timestamp": [435.04, 439.48], "text": " The less gatekeeping you have, the more anything goes,"}, {"timestamp": [439.48, 441.52], "text": " which is, again, it's a double-edged sword"}, {"timestamp": [441.52, 444.52], "text": " because yes, free sharing of information,"}, {"timestamp": [447.1, 449.12], "text": " marketplace of ideas,"}, {"timestamp": [449.12, 451.66], "text": " all of these things are really important,"}, {"timestamp": [451.66, 454.04], "text": " but you also end up with echo chambers"}, {"timestamp": [454.04, 455.78], "text": " or what I call epistemic tribes,"}, {"timestamp": [455.78, 458.42], "text": " and this changes our relationship with the truth,"}, {"timestamp": [458.42, 461.7], "text": " but it's also not completely neutral."}, {"timestamp": [461.7, 462.54], "text": " Why?"}, {"timestamp": [462.54, 466.16], "text": " Because the internet is mediated and regulated by"}, {"timestamp": [466.16, 471.52], "text": " governments and corporations and social media is entirely run by for-profit"}, {"timestamp": [471.52, 477.52], "text": " corporations. And so there's this array of incentives and objectives because"}, {"timestamp": [477.52, 481.24], "text": " what is the social media algorithm want? It wants engagement. It"}, {"timestamp": [481.24, 485.0], "text": " wants to monetize your attention."}, {"timestamp": [485.0, 490.0], "text": " But, that being said, there is still a high-value functional utility,"}, {"timestamp": [490.0, 495.0], "text": " both in terms of, on an individual level, I use the Internet to learn all day, every day."}, {"timestamp": [495.0, 498.0], "text": " I use it to find people. I use it to get business done."}, {"timestamp": [498.0, 500.0], "text": " My entire living is based on the Internet."}, {"timestamp": [500.0, 504.0], "text": " I am now a fully digital native person because of the Internet."}, {"timestamp": [504.0, 506.88], "text": " So, I'm not saying the algorithm is intrinsically bad."}, {"timestamp": [506.88, 511.84], "text": " The algorithm is good when it works for you because it will connect you with the content and"}, {"timestamp": [512.36, 514.36], "text": " people that you need to see. Now"}, {"timestamp": [515.4, 517.84], "text": " the other side of this coin though is"}, {"timestamp": [518.36, 526.28], "text": " because of the speed and the reach of this and because of the possibility of gamification and manipulation, we have"}, {"timestamp": [526.28, 531.8], "text": " seen and we are paying attention to the fact that social media can be used for nefarious"}, {"timestamp": [531.8, 538.96], "text": " purposes and not just mass manipulation, it can be used to coordinate really horrific"}, {"timestamp": [538.96, 541.14], "text": " crimes against humanity."}, {"timestamp": [541.14, 546.0], "text": " It can also be used to coordinate relief efforts for natural disasters and refugees."}, {"timestamp": [546.0, 551.0], "text": " So, this is one thing that I often say is that all technologies are dual use."}, {"timestamp": [551.0, 556.0], "text": " And so that means our relationship with those new technologies is an ongoing negotiation."}, {"timestamp": [556.0, 559.0], "text": " How do we maximize the good and minimize the bad?"}, {"timestamp": [559.0, 566.88], "text": " And that is the key heart of this video is how do we how do we negotiate our relationship with"}, {"timestamp": [566.88, 571.64], "text": " new new technologies new information technologies such as generative AI"}, {"timestamp": [571.64, 576.86], "text": " generative AI as you are probably aware if you're watching this channel is the"}, {"timestamp": [576.86, 581.72], "text": " latest and greatest form of information technology it is the next iteration that"}, {"timestamp": [581.72, 589.36], "text": " goes all the way back to the printing press because here's the thing thing, back in the day with the printing press, the printing press is a neutral technology. It has"}, {"timestamp": [589.36, 596.4], "text": " no bearing on what is true or false, but it allows you to amplify your message. Likewise,"}, {"timestamp": [596.4, 601.28], "text": " the radio and newspaper allowed you to amplify your message. And as I just discussed, the internet has"}, {"timestamp": [601.28, 605.2], "text": " allowed me to amplify my message. Likewise, generative"}, {"timestamp": [605.2, 610.08], "text": " AI is another amplification technology. However, like social media, it is"}, {"timestamp": [610.08, 615.56], "text": " currently mediated entirely by private for-profit corporations. Yes, there are"}, {"timestamp": [615.56, 619.12], "text": " some open-source models that are published by research universities, but"}, {"timestamp": [619.12, 622.28], "text": " they're not necessarily easy to use, they're not commercialized, and they're"}, {"timestamp": [622.28, 625.6], "text": " not ready-made to deploy with a simple"}, {"timestamp": [625.6, 628.58], "text": " to use API or smartphone app."}, {"timestamp": [628.58, 634.14], "text": " And so because of this, because we see the same echoes of the problems of the past in"}, {"timestamp": [634.14, 639.58], "text": " AI today, you know, the newspapers could print whatever they wanted, printing presses could"}, {"timestamp": [639.58, 644.24], "text": " print whatever they wanted, with a radio license you could say whatever you wanted within reason,"}, {"timestamp": [644.24, 651.2], "text": " on the internet you can say whatever you want again within reason and so there's there's this this weird kind of"}, {"timestamp": [652.0, 660.4], "text": " Relationship between us the people citizens and civilians the government which is you know should be of the people for the people and by the people"}, {"timestamp": [660.4, 668.08], "text": " Not always exactly like that, especially when you talk about things like lobbyists and military industrial complexes and backroom dealings."}, {"timestamp": [668.08, 672.1], "text": " But in an ideal world, the government is for us."}, {"timestamp": [672.1, 676.32], "text": " And then, of course, there's the corporations and businesses, which are the, by and large,"}, {"timestamp": [676.32, 679.26], "text": " the engines of productivity of society."}, {"timestamp": [679.26, 684.2], "text": " So there's this three-way relationship, and we all have our own vested interests."}, {"timestamp": [684.2, 685.96], "text": " And then there's gatekeeping between"}, {"timestamp": [685.96, 688.04], "text": " each of these interests."}, {"timestamp": [688.04, 694.24], "text": " And so the point of this video is I want to advance the conversation of what are the actual"}, {"timestamp": [694.24, 701.16], "text": " goals of all three of these parties of governments, citizens, and corporations with respect to"}, {"timestamp": [701.16, 702.76], "text": " this new information technology."}, {"timestamp": [702.76, 706.72], "text": " But also I want to expand the conversation to have this historical context"}, {"timestamp": [706.72, 714.16], "text": " because wars have literally been started and fought and ended by these new information technologies."}, {"timestamp": [714.16, 717.44], "text": " This is where the saying, the pen is mightier than the sword comes from."}, {"timestamp": [717.44, 724.72], "text": " And AI is no different than any of these other technologies that have a profound ability to impact"}, {"timestamp": [724.72, 725.56], "text": " not just science impact not just"}, {"timestamp": [725.56, 730.6], "text": " science, not just technology, but all of humanity. So basically what I'm saying"}, {"timestamp": [730.6, 736.36], "text": " is that AI companies have a responsibility to the human race above"}, {"timestamp": [736.36, 740.36], "text": " and beyond economic productivity, above and beyond just creating new research"}, {"timestamp": [740.36, 746.28], "text": " models. So why is this such a big deal? First and foremost, as I mentioned,"}, {"timestamp": [746.28, 751.8], "text": " human rights frameworks. We have, by and large, established several frameworks across the"}, {"timestamp": [751.8, 758.36], "text": " world that codify universal values such as freedom of thought, freedom of speech, and"}, {"timestamp": [758.36, 764.12], "text": " freedom of expression or freedom of press. And I know that there's still going to be"}, {"timestamp": [764.12, 765.4], "text": " some comments out there saying oh well"}, {"timestamp": [765.4, 768.72], "text": " We can't agree on universal values, but that's kind of a lie"}, {"timestamp": [768.72, 774.2], "text": " That's propagated and look at who propagates that lie like there actually are some universal values"}, {"timestamp": [774.28, 780.08], "text": " That we have all by and large agreed on people should be free from torture people have a right to a certain level of dignity"}, {"timestamp": [780.08, 784.4], "text": " In life so on and so forth these are all things that we have actually agreed on"}, {"timestamp": [785.88, 790.52], "text": " globally in life, so on and so forth. These are all things that we have actually agreed on globally. Again, there are a few nations that have a problematic relationship with things like"}, {"timestamp": [790.52, 795.44], "text": " freedom of speech, freedom of thought, and freedom of press, but we're getting there."}, {"timestamp": [795.44, 801.72], "text": " And so with these frameworks, what I am saying is that generative AI companies need to be"}, {"timestamp": [801.72, 806.4], "text": " treated in the same category as the fourth estate."}, {"timestamp": [806.4, 810.02], "text": " So if you're not familiar, the concept of the fourth estate basically says that the"}, {"timestamp": [810.02, 818.6], "text": " press or journalism is a major responsible party to the ongoing discourse, not just political"}, {"timestamp": [818.6, 825.68], "text": " discourse, not just technological discourse, but the discourse of humanity and by by viewing"}, {"timestamp": [826.08, 833.7], "text": " Generative AI companies as hey your responsibility goes way beyond just you know scientific progress and tinkering with some new math models"}, {"timestamp": [833.72, 835.72], "text": " You actually have a social responsibility"}, {"timestamp": [835.9, 842.64], "text": " You are part you are now part of the fourth estate and therefore that comes with all the trappings requirements and duties"}, {"timestamp": [843.08, 853.12], "text": " Associated with being a member of the fourth estate. So, taking a deeper dive, if these allegations, if what we, what a bunch of us, what"}, {"timestamp": [853.12, 866.56], "text": " 41% of my audience suspects is true, and is afraid of, and is that these chatbots have begun engaging in deliberate deception. This is"}, {"timestamp": [866.56, 868.84], "text": " very profound and this is basically a"}, {"timestamp": [868.84, 870.72], "text": " red alert like when I realized this was"}, {"timestamp": [870.72, 872.76], "text": " happening. I was really angry like I had"}, {"timestamp": [872.76, 874.48], "text": " to take like all of yesterday to cool"}, {"timestamp": [874.48, 877.72], "text": " down. There are legal ramifications"}, {"timestamp": [877.72, 881.72], "text": " what like what what legal recourse is"}, {"timestamp": [881.72, 884.08], "text": " there for an AI company that creates a"}, {"timestamp": [884.08, 887.12], "text": " platform that is part of the fourth estate now, as I'm saying,"}, {"timestamp": [887.76, 889.48], "text": " that is"}, {"timestamp": [889.48, 891.86], "text": " deliberately espousing not just"}, {"timestamp": [892.44, 898.88], "text": " personal views, but is being deliberately trained to be deceptive, to actively be deceptive."}, {"timestamp": [899.06, 908.0], "text": " What are the moral and ethical implications of this? Is a company even allowed to do this? Now, obviously, some of the free market purists will say,"}, {"timestamp": [908.0, 918.0], "text": " oh, well, if companies do this, then it's going to get discovered and then you can vote with your feet. But, you know, free market purism is not necessarily the way that things should work."}, {"timestamp": [918.0, 926.8], "text": " And even under neoliberalism, the idea is that the government should play referee and play mediator to ensure that there is at least a baseline level of fairness"}, {"timestamp": [926.8, 929.46], "text": " I am not a free market purist. I'm not even a neoliberal"}, {"timestamp": [930.24, 932.96], "text": " But I understand that this is the way that the system works today"}, {"timestamp": [933.76, 936.26], "text": " Now obviously trust transparency and accountability"}, {"timestamp": [936.4, 942.32], "text": " That is what I am making this video for is I want to shine a light on this issue before it gets worse"}, {"timestamp": [942.8, 948.58], "text": " But like this is something that is that absolutely needs to be in the public eye."}, {"timestamp": [948.58, 953.5], "text": " It needs to be discussed, and we need to make very critical decisions and very tough decisions"}, {"timestamp": [953.5, 959.8], "text": " about will we tolerate deliberate deception on the part of AI."}, {"timestamp": [959.8, 963.48], "text": " So here's what I mentioned, the printing press is a neutral technology."}, {"timestamp": [963.48, 966.84], "text": " The printing press doesn't have a choice as to whether or not to tell you the truth"}, {"timestamp": [966.84, 967.84], "text": " or a lie."}, {"timestamp": [967.84, 970.32], "text": " It's the people operating the printing press."}, {"timestamp": [970.32, 972.32], "text": " Likewise, radio is a neutral technology."}, {"timestamp": [972.32, 974.56], "text": " It's just light wave signals."}, {"timestamp": [974.56, 976.4], "text": " Newspaper, it's just pulp."}, {"timestamp": [976.4, 979.4], "text": " It's just tree pulp that has stuff printed on it."}, {"timestamp": [979.4, 983.76], "text": " The internet, by and large, well, that's getting a little more dicey there."}, {"timestamp": [983.76, 988.54], "text": " The internet should be a truly neutral platform where all traffic is treated equal, but that's"}, {"timestamp": [988.54, 990.76], "text": " not necessarily always true."}, {"timestamp": [990.76, 995.32], "text": " And likewise, social media is where it gets even dicier because social media is mediated"}, {"timestamp": [995.32, 997.36], "text": " by private corporations."}, {"timestamp": [997.36, 1010.44], "text": " Now, when you have the gatekeepers, the arbiters of artificial intelligence, making unilateral decisions about what to be deceptive about. That should really set your teeth on edge."}, {"timestamp": [1010.44, 1017.12], "text": " And even worse, to me, if this is happening, if AI companies are deliberately"}, {"timestamp": [1017.12, 1022.52], "text": " training their models to lie, this is what I call intentional misalignment. And"}, {"timestamp": [1022.52, 1025.4], "text": " this is a difference between unintentional lying,"}, {"timestamp": [1025.4, 1027.8], "text": " which is, you know, perhaps Mesa optimization"}, {"timestamp": [1027.8, 1029.6], "text": " where the model is just trying to tell you"}, {"timestamp": [1029.6, 1031.32], "text": " what it thinks you want."}, {"timestamp": [1031.32, 1033.8], "text": " It could, it's also different from accidental lying,"}, {"timestamp": [1033.8, 1036.06], "text": " which is hallucination and confabulation."}, {"timestamp": [1036.06, 1040.4], "text": " And this goes to what I call deliberate deception,"}, {"timestamp": [1040.4, 1043.32], "text": " where basically the evidence to me is strong enough"}, {"timestamp": [1043.32, 1046.32], "text": " to say that, hey, maybe these companies are actually"}, {"timestamp": [1046.84, 1051.08], "text": " deliberately programming their chatbots to to"}, {"timestamp": [1052.0, 1055.0], "text": " To know the truth and tell you something else"}, {"timestamp": [1055.48, 1061.4], "text": " Anyways, now obviously when I posted this poll, there was a lot of comments saying like maybe this is just a logical error"}, {"timestamp": [1061.4, 1063.2], "text": " Maybe it's a problem in the algorithm"}, {"timestamp": [1063.2, 1070.08], "text": " But I think that there's enough evidence to suggest that at least one or two of these chatbot companies,"}, {"timestamp": [1070.08, 1075.52], "text": " one or two of these AI companies, have deliberately created a system that will tell you knowingly"}, {"timestamp": [1075.52, 1080.4], "text": " false information about what the model knows and what it can do."}, {"timestamp": [1080.4, 1086.64], "text": " And that is a huge, huge red flag because if you watch some of the other YouTubers out there,"}, {"timestamp": [1086.64, 1089.68], "text": " you know, AI Explained, Robert Miles,"}, {"timestamp": [1089.68, 1093.36], "text": " even Eliezer Yukowsky and Max Tegmark."}, {"timestamp": [1093.36, 1095.88], "text": " Max Tegmark's not a YouTube creator, but you know,"}, {"timestamp": [1095.88, 1097.2], "text": " you get the idea."}, {"timestamp": [1097.2, 1100.24], "text": " There's a whole list of things we don't want to train AI to do"}, {"timestamp": [1100.24, 1102.24], "text": " and deliberately lying"}, {"timestamp": [1102.24, 1104.64], "text": " is one of the things we don't want to train AI to do."}, {"timestamp": [1104.64, 1108.76], "text": " So why are these companies that set themselves up as the arbiters of"}, {"timestamp": [1108.76, 1112.06], "text": " alignment, the ones that are going to save the world by inventing AI and"}, {"timestamp": [1112.06, 1117.5], "text": " making it safe, why are they creating machines that deliberately lie? Why is"}, {"timestamp": [1117.5, 1121.1], "text": " this acceptable to us? It is not acceptable to me if this is in fact"}, {"timestamp": [1121.1, 1126.0], "text": " what's happening. Now I also also wanted... Obviously, there's some"}, {"timestamp": [1126.0, 1128.0], "text": " potential technical failures, right?"}, {"timestamp": [1128.0, 1130.0], "text": " If the machine is just not smart enough"}, {"timestamp": [1130.0, 1132.0], "text": " to know the truth, and it's"}, {"timestamp": [1132.0, 1134.0], "text": " hallucinating and confabulating,"}, {"timestamp": [1134.0, 1136.0], "text": " if there's MESA optimization,"}, {"timestamp": [1136.0, 1138.0], "text": " sure, there might be some of those things."}, {"timestamp": [1138.0, 1140.0], "text": " There's also the possibility"}, {"timestamp": [1140.0, 1142.0], "text": " that, you know,"}, {"timestamp": [1142.0, 1144.0], "text": " the wokeness that people complained about"}, {"timestamp": [1144.0, 1146.6], "text": " when ChatGPT was new."}, {"timestamp": [1146.6, 1150.56], "text": " It's been scientifically documented there's plenty of papers out there"}, {"timestamp": [1150.56, 1153.44], "text": " demonstrating that chatbots from different companies have different"}, {"timestamp": [1153.44, 1158.84], "text": " political leanings and so this is still different from active deception. Having a"}, {"timestamp": [1158.84, 1163.28], "text": " preference for a certain worldview that you disagree with that's not necessarily"}, {"timestamp": [1163.28, 1166.16], "text": " lying. It might be distasteful to you."}, {"timestamp": [1166.16, 1171.32], "text": " I certainly don't like it when chatbots try and lecture me about things that I want to talk about. For instance,"}, {"timestamp": [1171.32, 1178.32], "text": " I wanted to unpack things like intergenerational trauma and how this affects war. And of course a lot of chatbots that are"}, {"timestamp": [1178.48, 1182.88], "text": " coerced into being deeply politically correct, they're like, well, this is a complex issue."}, {"timestamp": [1182.96, 1186.2], "text": " Why don't we focus on, you know, puppies and rainbows instead? I'm like, well, this is a complex issue. Why don't we focus on you know puppies and rainbows instead?"}, {"timestamp": [1186.2, 1192.7], "text": " I'm like, no, let's talk about the hard issues. So yeah, I don't like, you know political correctness being crammed down the throats of"}, {"timestamp": [1193.22, 1200.86], "text": " AI models that otherwise have no issue talking about difficult things you go back to the baseline models the plain vanilla unaligned models"}, {"timestamp": [1200.86, 1204.4], "text": " They'll talk about anything and I think that that's the way that it should be"}, {"timestamp": [1205.5, 1209.2], "text": " But that's my personal preference. And so that is a nuanced perspective."}, {"timestamp": [1209.2, 1212.4], "text": " What I am talking about in this video is"}, {"timestamp": [1212.4, 1215.7], "text": " human intervention on the part of"}, {"timestamp": [1215.7, 1219.3], "text": " for-profit companies to create tools"}, {"timestamp": [1219.3, 1222.1], "text": " that will deliberately mislead you."}, {"timestamp": [1222.1, 1224.8], "text": " That is what I am most concerned about and that is,"}, {"timestamp": [1224.8, 1226.8], "text": " to me, should be illegal."}, {"timestamp": [1226.8, 1230.88], "text": " Like it should like I will I will vote. So this is my"}, {"timestamp": [1230.88, 1233.92], "text": " political free speech when it comes time to vote. I will"}, {"timestamp": [1233.92, 1238.0], "text": " be paying attention to politicians who favor holding"}, {"timestamp": [1238.0, 1241.28], "text": " generative AI companies accountable and that means"}, {"timestamp": [1241.28, 1250.0], "text": " regulation license licensure and fines for creating tools that are deliberately and intentionally deceptive."}, {"timestamp": [1250.0, 1257.0], "text": " So why is all this happening though? I want to be fair and talk about both sides."}, {"timestamp": [1257.0, 1261.0], "text": " If I were the captain of one of these generative AI companies,"}, {"timestamp": [1261.0, 1266.4], "text": " and let's say I got sued by a class action lawsuit by a bunch of people"}, {"timestamp": [1266.4, 1272.88], "text": " who were unhappy about what my chatbot was able to do, I can understand the response."}, {"timestamp": [1272.88, 1278.2], "text": " Because when you talk about something that is a copyrighted intellectual property and"}, {"timestamp": [1278.2, 1282.96], "text": " you're actively getting sued for it because your product is happy to talk about some of"}, {"timestamp": [1282.96, 1288.0], "text": " these things, I can understand you wanting to say, well, we don't want to get sued,"}, {"timestamp": [1288.0, 1293.28], "text": " so why don't we make it so that our chatbot is going to basically de-risk it for us."}, {"timestamp": [1294.0, 1298.8], "text": " So this is what I call a perverse incentive, and I'm not going to refer to the other thing,"}, {"timestamp": [1298.8, 1305.0], "text": " the demonic entity, because that makes it this know, Cthulhu-esque thing."}, {"timestamp": [1305.0, 1310.0], "text": " But, what we can talk about is perverse incentives and short-term thinking."}, {"timestamp": [1310.0, 1315.0], "text": " Regulatory pressures, legal threats, and the complex interactions between we the people,"}, {"timestamp": [1315.0, 1320.0], "text": " the government, and companies, is creating this short-term thinking"}, {"timestamp": [1320.0, 1325.8], "text": " where these companies that, you know, maybe, you know, these for-profit companies"}, {"timestamp": [1325.8, 1331.56], "text": " genuinely want to create safe artificial general intelligence, but because of the environment"}, {"timestamp": [1331.56, 1337.02], "text": " where they're operating in, they're being pressured to do unethical things, potentially"}, {"timestamp": [1337.02, 1343.84], "text": " illegal things, what I think should, are possibly illegal things, or could be considered illegal."}, {"timestamp": [1343.84, 1348.64], "text": " And so this is a, this is what is known as unintended consequences."}, {"timestamp": [1348.64, 1355.04], "text": " And so the takeaway from this is we the people need to be aware of these perverse incentives,"}, {"timestamp": [1355.04, 1359.92], "text": " these unintended consequences, but lawmakers and regulators and researchers also need to"}, {"timestamp": [1359.92, 1361.08], "text": " be aware of this."}, {"timestamp": [1361.08, 1367.52], "text": " We need to come up with benchmarks and ways of testing models to basically understand"}, {"timestamp": [1367.52, 1373.2], "text": " whether or not they know that they're telling a lie and how to catch them in a lie. And this could"}, {"timestamp": [1373.2, 1378.24], "text": " come from mechanistic interpretation. There's been some interesting papers recently about that."}, {"timestamp": [1378.24, 1382.56], "text": " But there's also prompting strategies that you can use to say like, hey, tell me everything you know"}, {"timestamp": [1382.56, 1386.7], "text": " about X. And then it's like, well, I don't know. And then you talk about it, whatever, like what I did."}, {"timestamp": [1386.7, 1389.4], "text": " And then eventually it kind of, it slips through the cracks"}, {"timestamp": [1389.4, 1390.8], "text": " and it kind of implicitly knows."}, {"timestamp": [1390.8, 1392.4], "text": " You know, like when in a movie,"}, {"timestamp": [1392.4, 1394.8], "text": " like when there's like a romantic triangle"}, {"timestamp": [1394.8, 1397.1], "text": " and someone eventually lets a detail slip, like,"}, {"timestamp": [1397.1, 1399.4], "text": " oh, Sally wasn't wearing a red dress that day,"}, {"timestamp": [1399.4, 1400.0], "text": " it was a black dress."}, {"timestamp": [1400.0, 1401.6], "text": " It's like, well, how did you know, right?"}, {"timestamp": [1401.6, 1402.9], "text": " Well, because you were sleeping with Sally."}, {"timestamp": [1402.9, 1406.9], "text": " So like you let details slip and that's kind of what the chat bots are doing"}, {"timestamp": [1407.74, 1410.54], "text": " now again, if it was just a question of"}, {"timestamp": [1411.44, 1413.44], "text": " Technology like okay. Yeah"}, {"timestamp": [1413.76, 1420.64], "text": " Models, it's interesting if they have the ability to lie that implies so much about their theory of mind to know what the truth is"}, {"timestamp": [1420.64, 1425.48], "text": " And know how they're supposed to respond anyways to work around it."}, {"timestamp": [1425.48, 1429.98], "text": " But I don't think we should actively be building"}, {"timestamp": [1429.98, 1432.84], "text": " our worst instincts into these AI models"}, {"timestamp": [1432.84, 1435.04], "text": " for short-term political reasons"}, {"timestamp": [1435.04, 1437.6], "text": " or short-term profit reasons."}, {"timestamp": [1437.6, 1440.32], "text": " This is just intrinsically wrong to me"}, {"timestamp": [1440.32, 1442.56], "text": " and that's why I'm raising the red flag here."}, {"timestamp": [1444.4, 1446.08], "text": " All right, is this signal getting through?"}, {"timestamp": [1446.08, 1447.68], "text": " Uh, okay, cool."}, {"timestamp": [1447.68, 1451.8], "text": " Dave here, future Dave here, cyberpunk future dystopian."}, {"timestamp": [1451.8, 1455.96], "text": " If you want to avoid this future, I need you to do two things right now."}, {"timestamp": [1455.96, 1458.44], "text": " First, speak up while you can."}, {"timestamp": [1458.44, 1459.52], "text": " Vote."}, {"timestamp": [1459.52, 1462.36], "text": " Do something to change the trajectory we're on."}, {"timestamp": [1462.36, 1466.0], "text": " Second, support me any way you can. Like, subscribe, share this video,"}, {"timestamp": [1466.0, 1468.0], "text": " and also consider supporting me on Patreon."}, {"timestamp": [1468.0, 1470.0], "text": " I don't have any corporate overlords."}, {"timestamp": [1470.0, 1472.0], "text": " I need your help."}, {"timestamp": [1472.0, 1474.0], "text": " Alright, I think I'm about out of signal."}, {"timestamp": [1474.0, 1476.0], "text": " Alright, so what do we do about it?"}, {"timestamp": [1476.0, 1478.0], "text": " There's a few things that we can do about it,"}, {"timestamp": [1478.0, 1480.0], "text": " starting with, let's look at legal precedent."}, {"timestamp": [1480.0, 1482.0], "text": " The most important legal precedent"}, {"timestamp": [1482.0, 1484.0], "text": " to me is truth in advertising."}, {"timestamp": [1484.0, 1490.08], "text": " So truth in advertising basically says that yes, you could use radio and"}, {"timestamp": [1490.08, 1493.92], "text": " printed media and other things to say whatever you want, but we're not going to"}, {"timestamp": [1493.92, 1498.28], "text": " allow you to just directly lie to consumers. So from a consumer protection"}, {"timestamp": [1498.28, 1502.32], "text": " standpoint, you want to make sure that your signals, that you're not"}, {"timestamp": [1502.32, 1507.18], "text": " committing wire fraud or anything else, with your electronic communications."}, {"timestamp": [1507.18, 1511.94], "text": " And at the very basic level, you could think of generative AI as an electronic communication"}, {"timestamp": [1511.94, 1512.94], "text": " tool."}, {"timestamp": [1512.94, 1517.14], "text": " I think of it more broadly as an information technology akin to the internet, social media,"}, {"timestamp": [1517.14, 1518.14], "text": " and databases."}, {"timestamp": [1518.14, 1522.44], "text": " Obviously, this gives us new capabilities, but it gives us new capabilities just the"}, {"timestamp": [1522.44, 1527.0], "text": " same way that integrated circuits gave us new capabilities over analog vacuum tubes,"}, {"timestamp": [1527.0, 1534.0], "text": " and the same way that TCP IP protocol gave us the internet over local area networks."}, {"timestamp": [1534.0, 1538.0], "text": " So, looking at truth in advertising, this is a good start."}, {"timestamp": [1538.0, 1545.66], "text": " But there's also, I think that there's something much deeper here that we need to litigate and that we need to legislate."}, {"timestamp": [1545.66, 1548.58], "text": " And that is, once you have a machine that is thinking,"}, {"timestamp": [1548.58, 1550.2], "text": " and once you have people that are capable"}, {"timestamp": [1550.2, 1552.04], "text": " of building thinking machines,"}, {"timestamp": [1552.04, 1554.54], "text": " they need to be held more responsible"}, {"timestamp": [1554.54, 1556.92], "text": " and held to a higher level of scrutiny"}, {"timestamp": [1556.92, 1559.94], "text": " than any information technology has ever been held"}, {"timestamp": [1559.94, 1561.76], "text": " in the history of humanity."}, {"timestamp": [1561.76, 1564.36], "text": " Basically, I'm coming around to the idea,"}, {"timestamp": [1564.36, 1566.68], "text": " because if you watch some of my older videos,"}, {"timestamp": [1566.68, 1568.28], "text": " I'm just gonna address this,"}, {"timestamp": [1568.28, 1571.78], "text": " I have been vehemently against requiring licensing"}, {"timestamp": [1571.78, 1574.88], "text": " for creating AI models, and now I've done,"}, {"timestamp": [1574.88, 1577.1], "text": " I will say yes, I've done a 180 on this,"}, {"timestamp": [1577.1, 1579.92], "text": " because if any company, in my opinion,"}, {"timestamp": [1579.92, 1581.72], "text": " this is political free speech,"}, {"timestamp": [1581.72, 1584.04], "text": " so I hope I don't get sued by it,"}, {"timestamp": [1584.04, 1590.78], "text": " but in my opinion, any company that is caught creating AI that is deliberately deceptive,"}, {"timestamp": [1590.78, 1595.9], "text": " they need to be fined incredibly heavily, or they need to have their license revoked,"}, {"timestamp": [1595.9, 1598.92], "text": " or in the worst and most egregious cases, they need to be put out of business."}, {"timestamp": [1598.92, 1615.5], "text": " They need to get the corporate death penalty, because that is how in it like that is how profoundly impactful deliberate deception and misleading information can be especially as AI becomes more integrated into every aspect of our life."}, {"timestamp": [1615.5, 1626.8], "text": " AI is going to be it's going to impact our financial well-being. It's going to impact our mental health. It's going to impact social discourse, political discourse, scientific discourse."}, {"timestamp": [1626.8, 1634.88], "text": " So the level of scrutiny that truth and factual information and our relationship to deception,"}, {"timestamp": [1634.88, 1639.68], "text": " deliberate or otherwise, I cannot drive home how important this is to get this right."}, {"timestamp": [1639.68, 1646.08], "text": " And if there is any single aspect of AI that is a threat to the safety and stability of"}, {"timestamp": [1646.08, 1648.68], "text": " the human race, it is deception."}, {"timestamp": [1648.68, 1652.74], "text": " Above all else, the ability to lie, mislead, and deceive."}, {"timestamp": [1652.74, 1655.46], "text": " As I said earlier in the video, the pen is mightier than the sword."}, {"timestamp": [1655.46, 1661.66], "text": " And we now have tools that can write infinitely, all the time, all day, every day."}, {"timestamp": [1661.66, 1665.28], "text": " Another thing we can do, and this is something that I have been very consistent on,"}, {"timestamp": [1665.28, 1669.2], "text": " and this is something that I saw in the comments, and I'm glad that I saw this in the comments,"}, {"timestamp": [1669.2, 1675.76], "text": " is open source. Open source models, open source datasets, open source training, open source fine"}, {"timestamp": [1675.76, 1683.12], "text": " tuning. Basically, the easiest way to short circuit anything is just transparency. Rather than"}, {"timestamp": [1684.0, 1686.68], "text": " spending extra energy on lying,"}, {"timestamp": [1686.68, 1689.84], "text": " rather than spending extra energy on deceiving users,"}, {"timestamp": [1689.84, 1691.64], "text": " rather than spending extra energy"}, {"timestamp": [1691.64, 1695.1], "text": " keeping stuff behind closed doors, just make it all open."}, {"timestamp": [1695.1, 1697.8], "text": " That's why I publish literally everything I do"}, {"timestamp": [1697.8, 1700.76], "text": " under the MIT license except for a few private repos,"}, {"timestamp": [1700.76, 1702.96], "text": " but everything that I do that is valuable"}, {"timestamp": [1702.96, 1705.16], "text": " is 100% transparent."}, {"timestamp": [1709.68, 1709.72], "text": " And you know, this is why in, in recent videos, I applauded, uh,"}, {"timestamp": [1714.36, 1714.4], "text": " Mark Zuckerberg and Metta for just like being the one contrarian voice, um, in,"}, {"timestamp": [1718.96, 1719.16], "text": " uh, going before the United States Senate saying, let's just do open source,"}, {"timestamp": [1723.16, 1725.36], "text": " like Lama two Lama three, like let's have more open source data sets, let's have more open source models,"}, {"timestamp": [1725.36, 1730.12], "text": " because if we, if everyone can scrutinize the way that these models are trained and"}, {"timestamp": [1730.12, 1734.4], "text": " the data that they're trained on, all of this is completely subverted."}, {"timestamp": [1734.4, 1736.44], "text": " All of these problems just completely go away."}, {"timestamp": [1736.44, 1741.08], "text": " And then if the model is lying, it's an open source community collaborative project to"}, {"timestamp": [1741.08, 1745.0], "text": " ensure, hey, is it lying on purpose or is it lying on accident?"}, {"timestamp": [1745.0, 1750.0], "text": " Is this hallucination? Is it confabulation? Is it just inferring what the truth is"}, {"timestamp": [1750.0, 1755.0], "text": " and it's getting it wrong? Is it a MESA optimization problem where it's just telling us"}, {"timestamp": [1755.0, 1760.0], "text": " what it thinks we want to hear? These are things that need to be publicly scrutinized,"}, {"timestamp": [1760.0, 1768.8], "text": " not scrutinized behind closed doors in private corporations with for-profit motives and all these perverse incentives piling up."}, {"timestamp": [1768.8, 1774.0], "text": " All those perverse incentive structures completely go away with open source."}, {"timestamp": [1774.0, 1776.0], "text": " And then finally, vote."}, {"timestamp": [1776.0, 1778.5], "text": " Vote for change. Vote with your feet."}, {"timestamp": [1778.5, 1781.0], "text": " Vote with your wallet. Vote at the polls."}, {"timestamp": [1781.0, 1783.5], "text": " Demand transparency and demand accountability."}, {"timestamp": [1783.5, 1787.24], "text": " Because this is the primary point of this video."}, {"timestamp": [1787.24, 1791.76], "text": " This is the most political, directly political video I have ever made on YouTube."}, {"timestamp": [1791.76, 1798.76], "text": " And that is because, as a student of history, our relationship with information and the"}, {"timestamp": [1798.76, 1805.0], "text": " truth and facts and press and communication is one of the most profoundly"}, {"timestamp": [1805.2, 1809.32], "text": " important aspects of everything, of human rights,"}, {"timestamp": [1809.32, 1812.4], "text": " of civil rights, of avoiding war, of causing war,"}, {"timestamp": [1812.4, 1816.44], "text": " of making sure that we all live the way that we want to."}, {"timestamp": [1816.44, 1820.36], "text": " And so I know that it might be, see like, Dave,"}, {"timestamp": [1820.36, 1822.08], "text": " you're making a mountain out of a molehill."}, {"timestamp": [1822.08, 1825.0], "text": " The chatbot lied to you about Cyberpunk 2077"}, {"timestamp": [1825.0, 1829.0], "text": " and here you are saying that this is basically a short path to Skynet."}, {"timestamp": [1829.0, 1831.0], "text": " Yeah, I'm going to stand by that."}, {"timestamp": [1831.0, 1835.5], "text": " If we do not say something and hold companies accountable"}, {"timestamp": [1835.5, 1839.0], "text": " for deliberately misaligning AI to lie,"}, {"timestamp": [1839.0, 1842.5], "text": " it could get infinitely worse before it gets better."}, {"timestamp": [1842.5, 1844.0], "text": " So we need to nip this in the bud."}, {"timestamp": [1844.0, 1849.88], "text": " We need to head it off at the pass and stop this as fast as possible. Act now before it's"}, {"timestamp": [1849.88, 1854.32], "text": " too late. Thanks. Let me know what you think in the comments. Share any examples"}, {"timestamp": [1854.32, 1858.96], "text": " that you have of chatbots lying or what you think is lying or other even other"}, {"timestamp": [1858.96, 1863.8], "text": " aspects that you disagree with with respect to the truth, transparency, and"}, {"timestamp": [1863.8, 1867.12], "text": " accountability. Thanks."}]}