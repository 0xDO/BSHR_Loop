{"text": " Hello everybody, David Shapiro here with a update. So we're going to cover two things today real quick. The big thing is I mentioned in a previous video we need Gaia, a global AI agency, and we're working towards that. And so I created a public repository of news and summaries, basically where I'm collecting evidence and news that is very encouraging because it's all moving in the right direction. We've got everything from the Future of Life Institute open letter to pause giant models, news out of the UK, the EU, which yes, I know the UK left the EU. I made a mistake of forgetting about Brexit in a previous video. The UN Secretary General talking about, yes, he's amenable to the idea of an international AI watchdog. The United States Senate, their hearing on AI, the EU AI Act, the US House of Representatives and Senate having now basically matched actions with words. So after the hearing, both the US House of Representatives and the Senate have introduced legislation or commissions or policies. So we'll go over all those in much greater detail in just a moment. But before we dive into that, I've been working on this thing. I had this idea for a long time, and it's basically we can use large language models like GPT because they are trained on so much text data. They're trained on data from around the globe. Granted, it is primarily English, so there is definitely some's definitely some bias cultural bias in there however that being said it has read so much about the world that it knows more about religion politics psychology culture history than any one person so as far as having the ability to take perspectives it's actually pretty good and so rather than you know walk you through the code I'll just show you what I've got working so far so basically what I have it do is actually first I need to make sure well that's fine. So basically what I what I have it I have it do what it does anyways is I have it synthesize a persona. And so this persona is a whole bunch of random stuff like variables that it can pick to basically create a synthetic person. in the manipulation way, but it has geographic origins, ethnicities, cultures, languages, political dispositions, different factors about the person, such as their physical health, their mental health, other habits, preferences, that sort of thing. And so basically what it does is to create a persona, is it'll grab one of one one of these variables or one option from each set of variables and then create a profile or a dossier in order to like take the perspective of that person and then it will talk through on a particular issue and I picked UBI because I've been on a economics and UBI tick lately. And so I wanted to basically come up with a way of automatically understanding what the concerns that everyone is going to have could be, but not just elucidate or articulate the problems that they will have or the concerns that they will have or you know the concerns that they'll have over a policy like UBI, but how do we actually arrive at consensus? And consensus is not necessarily, so a lot of people have misconception about consensus. Consensus doesn't mean unanimous agreement. Consensus means that it gets to a point that is good enough that people will kind of stop fighting it. It's about compromise. And so anytime that there's been any kind of contentious policy or legislation, even including the United States Constitution, nobody was happy with it because they had to come to consensus in order to get something that everyone would tolerate, everyone would accept. So it wasn't perfect to anyone's mind, but it was something that they would all accept. And so the idea is, okay, let's take this random profile of a person so that we can get a global representation of all perspectives, regardless of how small they are. Because the thing is, when you look at some of these things like atheist, Islam, Christianity, Buddhist, right, some of these are over-represented in some areas and some of them are under-represented. Same thing for political leanings. I even include libertarians and anarchists and statists and communists and reactionaries and populists and nationalists and fascists. I don't know if fascism is in here. Fascism isn't in here. So fascist perspectives don't get represented, but nationalists do, so close enough. Authoritarians get represented. So the idea is that we can get a very well-rounded representation of all human perspectives, more or less. There's obviously gonna be some flaws with this because it is the first edition, first example, but the idea is that you can get a very, very diverse set of perspectives on a particular issue. And then, once you get those perspectives, you can then work through and figure out, okay, what kind of policy is this person most likely to accept? And so, by then generating a whole bunch of potential policies you can say OK well let's look at let's look at the commonality between all of these and let's get really creative. So let me just go ahead and show you how this works. All right. So the first thing it does is it grabs a random persona so you see where it's like you know heavy social media user there West Asian cultural background is West Asian their geographic origin is from North Africa. So imagine a West Asian family in North Africa. They're a wealthy family, they're heavy social media user, so on and so forth. Okay, so I ask what would this person think about UBI? And because ChatGPT is so heavily trained to be a helpful assistant, I can't, I couldn And because ChatGPT is so heavily trained to be a helpful assistant, I couldn't get ChatGPT to take that perspective, but what I could do is say, advocate zealously on behalf of this person, and that got really good results. So let's see, as an advocate for this persona, I would say that they might have mixed feelings about UBI. On one hand, they are wealthy and underemployed, which might lead them to see UBI as unnecessary for themselves and potentially harmful to their financial status if it results in higher taxes. They also might be concerned about the potential for UBI to discourage work and productivity, given their own success and wealth-oriented aspirations. On the other hand, their experience with financial stress and their social concerns might make them sympathetic to the idea of UBI as a means of reducing poverty and inequality. However, their nationalist political affiliation might make them more inclined to support policies that prioritize the needs and interests of their own country and its citizens, which could include skepticism towards UBI if they perceive it as benefiting outsiders as a form of globalist policy. So you see it has a very nuanced way of saying, okay, this person has lots of different beliefs and it's pretty complex. Let's see. Okay, so given their wealth-oriented aspirations, nationalist political affiliation, and their experience with financial stress, they might resonate with a fiscal policy or UBI implementation that is designed to stimulate economic growth and productivity, while also addressing social inequality within their own country. For instance, they might support a UBI program that is funded through progressive taxation where the wealthy pay a higher percentage of their income taxes. This would align with their social concerns and their belief in the importance of addressing inequality. However, they would likely want assurances that this would not unduly burden them or negatively impact their own financial status. They might also resonate with a UBI program that includes work incentives or requirements to address their concerns about discouraging work and productivity. For instance, they might support a UBI that is conditional on recipients engaging in some kind of work, education or community service. So this is a theme that keeps emerging because I've run this experiment a few times. I don't know if that's the underlying training of chat GPT or if it's just this is the most logical way forward where basically either you have a requirement or an incentive or reward so basically like you get everyone gets a baseline UBI but if you volunteer you get more UBI right it's like a kind of adjusting your tax returns here in America. Okay so finally given their nationalist policy they want to UBI that prioritizes the needs and interests of their own country's citizens. So this could be something like a tax break if you buy local or any number of ways. So then I ask it to say, all right, come up with a policy that this person might like. And so in this case, it said the National Prosperity Dividend, which that sounds rather authoritarian, but OK, we'll go with it. So the NPD, which that's also the acronym for narcissistic personality disorder. Oh boy. Maybe let's workshop that before we go live with it. Anyways, so the NPD is a form of universal basic income that is designed to stimulate economic growth, reduce social inequality, and prioritize the needs and interests. Okay, so you get that. So it's predicated on their engaging in some form of work, education, or community service, part-time work, vocational training, higher ed, so on and so forth. You know, actually like that particular thing, because this is a recurring theme, I'm not certain that that's actually a bad idea where like you incentivize people to continue to better themselves even if it's a small carrot. Like you know, hey if you're in if you're if you're going to higher education even if you know you're the college degree you're getting might not ever do anything you get an extra $500 a month you will at least be a better informed citizen and a better civic participant. Who knows? I don't know. Incentivize the behavior you want to see. Oh, here we go. The NPD would also include a patriotic bonus. Yikes. An additional payment for those who contribute significantly to the country's economy, culture, or society. Okay. I wouldn't call it a patriotic bonus. That's a little totalitarian, but I get the idea. So this would include entrepreneurs, artists, scientists, and community leaders. So actually I think Ireland already has something like this where basically if you are a professional artist or author or whatever, a creative type, you get a stipend. I don't know what they call it in Ireland but there is precedent for this being a thing so like if you were if you're a content creator or cultural commentator or whatever you could get a little bit an additional stipend. So all right so there you have it and then if we run it again so we do a clear screen if we run it again let's see we get a young adult who's wealthy from Eastern Europe, whose culture is indigenous South American. Interesting. They like gaming. They speak Spanish. That makes sense if they're from South America. They do not care about the community and they are a very fragile person. They're an angry, fragile person who's who is educated. They've been very experienced. They had a good childhood. Sorry, they've had a good life experience. They're presently single. They're a progressive atheist. Yeah, this actually sounds... oh, and they're worried about their career interesting okay so let's see I'm not gonna read the whole thing to you like I did the first one you get the idea but so you see how it takes into account like the last one they were nationalist and blah blah blah and this one is progressive given their moderate intolerance they might prefer UBI that includes some form of means testing means testing keeps come up keeps coming up as well. Let's see, skeptical about whether everyone deserves UBI. Ouch. There's some people on Reddit that this sounds like, and that's not to trash people on Reddit. I actually learned a lot from some people on Reddit. But yeah, so UBI to reduce overconsumption and promote more sustainable lifestyles. Yeah, so this actually keeps coming up as well where for some people means testing sustainability. So basically like you might get an additional UBI bonus if you live sustainably or you know whatever. So basically like discourage overconsumption. That's a trend that keeps coming up. So okay, the progressive environmental You you UBI the Pui be the PB Would be funded primary through a progressive tax system where the wealthiest individuals and okay. Yeah, blah blah blah I Haven't seen too much in terms of funding One of them did say fund it through carbon taxes of funding, one of them did say fund it through carbon taxes, which I thought was an interesting way as you partially fund it through that. To align with their environmentalist values would also, oh, here it is, carbon tax. Okay, so these are some ideas that keep coming up. Again, I think that the underlying model has a little bit of bias here. It would be interesting to see if there is a future version of GPT that is not already pre-trained to be kind of on board with some of these ideas. Because one thing that doesn't that has come up is like if you have someone who is just adamantly opposed to it, it doesn't say like this person will never agree to this under any circumstances. It works really hard to try and find something that they might agree with. So anyways, this is all saved out into the UBI folder as a YAML document. So it basically just saves the conversation as a whole. I think it even includes the system message because the system message includes the Includes the the the persona and the first one it was hilarious It was a radically intolerant feminist who is a Scientologist which is just like wow This was this was really interesting as it tried to figure out how to appease a very dogmatic Person, so anyways, this is a work in progress I He's a very dogmatic person. So anyways, this is a work in progress. I don't know where it's going exactly, but the idea is that maybe you could use it for policy research. Maybe you could use it for... It actually came... It was precip... I've been thinking about it for a long time, but I had some inspiration after talking to the Gato community about the democratic inputs to AI, because the idea of using a chatbot to extract information from a person, from a real person, is one thing. But then I was like, you know, the model already has a tremendous amount of information, so why don't we just bootstrap it and ask the model to kind of think through this. So this is essentially a tree of thought, but each branch of the tree is a different persona, and then each of those branches has three sub branches where I ask it those three questions like, you know, what do you think this person will think about UBI? What kind of fiscal policy do you think would resonate? And then finally, given the persona and their disposition, can you creatively conjure up a policy that has a high chance of reaching consensus with this person? So it's, you disposition, can you creatively conjure up a policy that has a high chance of reaching consensus with this person? So it's, you know, basically you can create an arbitrary number of branches, and then as those branches span out and you get all the leaves, you gather the leaves together and see what fits. Okay, anyways, so you're up to date on that project, so let's dive back into the Gaia Initiative, the global AI agencies. So I've been watching the news and I realized that the number of things that are piling up that make me feel good, and I know that there's a lot of people out there that are skeptical of anything to do with government or corporations, and for those people I empathize with you. Growing up I was more like that, where I was super skeptical of all trappings of power, and certainly my friends were very like disestablishmentarianism and anarcho-libertarian whatever, but none of them ever did anything with it. So this is the world we live in. We live in a world with corporations and governments and stuff and yes all power needs to be scrutinized. Healthy skepticism is absolutely fine. That is part of the democratic process. That being said if you're dogmatically against all forms of power, well I mean wish in one hand and you know you know what to do with the other one. See which one fills up first. So anyways, I have been keeping track of all this stuff because I see the currents and the trends and it is actually very, very encouraging to me. So I've got it all in chronological order. So first was the Future of Life Institute published their open letter, you know, signed by everyone including Elon Musk and yada yada yada. What I didn't realize was that it actually came with a policy paper. And so this policy paper, it's only 14 pages and it has seven policy recommendations. So this came out in, let's see, April 12th. I think I might have that wrong, the pause, the big pause. So the paper was published March 22nd. The policy recommendations came out a few days later, a couple weeks later. So what I did was I took all that and then I made a very brief summary of the whole thing right here. So you can click on the link and see it, but it's a few basic things. Mandate robust third-party auditing, regulate organizations' access to computational power, establish capable AI agencies at the national level, establish liability for AI-caused harm, introduce measures to prevent and track AI model leaks, expand AI technical safety research and develop standards for identifying and managing AI generated content. Okay, sure, whatever. It's all pretty boilerplate in the grand scheme of things. But so that came out March, April. March 29th, the UK did this jobby, which I haven't had a chance to summarize yet, but basically the idea is a pro-innovation AI regulatory framework, etc. Again, you see how long this thing is. That's why it takes a little bit of doing to summarize with GPT API calls. So anyways, they call for a regulatory sandbox, which so does the EUA, good grief, EUAI Act also calls for regulatory sandboxes. So if you don't know, a regulatory sandbox is basically you create a safe space where you can experiment with AI that is a little bit more permissive. And this is very often the case. So for instance, one of the most familiar ones is if you're doing medical research, for instance, you're allowed to use substances that are otherwise illegal. You just have to go through approval processes. It's not quite the same, but the idea is that like, people have been able to experiment with THC and LSD and psilocybin, even though it's still a Schedule II drug or whatever in the United States. You just have to, you have to be approved to do so. Likewise, if you are an approved entity, the idea of a regulatory sandbox is that you can still do whatever science you need to do as long as you do so safely. But also one thing about these pro-innovation things is, and this is a common theme that I actually noticed, which is why I was inspired to do this. So the UK and the United States have all focused on protecting innovation and accelerating innovation in fact. So then in early May the UN Secretary General Antonio Guterres said that he's amenable to the idea of the IAEA for AI, which also OpenAI, I forgot to add that, but OpenAI basically published a blog calling for the same thing. Then a few days later, the United States Senate hearing on AI, this was the one with Sam Altman and Christina Montgomery and Gary Marcus. This was almost a three-hour talk, and I took the transcript of that and I summarized it here. So the high-level summary basically just says here's the key points that they discussed and then I break each one of those down further. So it takes you 20 minutes to read this instead of three hours. It's pretty straightforward. There was a lot of back and forth, a lot of questions. I watched pretty much the entire hearing, but clearly the United States government was listening. And I wonder if this whole thing was just an orchestrated series of events or not. But anyways, a month later the EU AI Act was proposed. I don't think it's been adopted or ratified or anything. Someone explained in the comments that there's still quite a process to go through. They've got to get feedback. But then more recently, in just the last couple days, the United States House of Representatives by Representative Ted Lieu and a few others introduced a bipartisan commission. Basically it's an AI commission. I summarized it here. It's pretty, or no, sorry, I didn't summarize it here. I copied the text here because their PDF was garbage. Seriously, like, this is the United States. You can pay someone who knows how to make a PDF. Good Lord. So anyways, it's relatively straightforward. Mostly, this is just saying, like, let's appoint a panel to come up with policy recommendations. It's not really, they're not going to do anything. Basically it's going to produce three reports and so this is going to recommend what the United States Congress does for AI. Okay great. You know, Congressional Commission, they're interested in getting more information, which means that they're gonna solicit experts. So one thing that I thought was most interesting was that was the panel is that they want to have members of the Commission shall have a demonstrated background in at least one of the following, computer science or AI specifically, civil society including constitutional rights, civil liberties, ethics, and the creative community, industry and workforce, and then government including national security. So when you get these kinds of people in a room together, it's not just engineers and not just data scientists. This is going to be people that are in political science, civil rights, civil liberties, industry insiders, and then finally national security experts. So this is going to be a pretty comprehensive set of recommendations, and I'm actually pretty happy to see that Ted Lieu is leading that. And Ted Lieu is, where is he? Is he the Los Angeles County? So it's not surprising that California bro is going to be figuring that out. Okay, and then finally, most recently was just a couple days ago, Senator Chuck Schumer announced the SAFE framework at the CSIS, which is really interesting. And I don't know if this has been ratified yet or anything. I haven't been able to find the actual text of the idea, but there is a one pager out there somewhere that summarizes it very succinctly. But I took the transcript from this and I summarized the talk here. So basically it comes down to four major components. Security, which basically talks about national security above all else, but also corporate security and privacy of citizens. Accountability, which talks about how do you, it's actually pretty similar to the EU thing where, oh, I forgot to mention this, for the EU AI Act, the primary thing that the EU AI Act does is it bans outright social credit systems and surveillance like basically Big Brother, bans Big Brother stuff, and so this is what the Security and Accountability does. An interesting part of this was the foundations aspect of the framework. So basically, one of the key things of Chuck Schumer's framework is to protect the foundations of democracy. So I was talking with my wife about this, and she suspects that this was a direct reaction to the January 6th attempted insurrection at the US Capitol. When people are breaking into, and keep in mind that many members of Congress were directly in danger. And so we suspect, we being my wife and I, we suspect that this is actually basically the Congress, you know, House of Representatives and Senators, you know, they didn't take social media seriously. And then, you know, they didn't take social media seriously. And then, you know, Facebook happened with Cambridge Analytica. I don't think it's controversial to say that Facebook and other social media companies directly contributed to the widespread abuses of misinformation, but also just coordination of violence. It's that simple. And so they learned their lesson by not taking social media seriously and now they're taking artificial intelligence very seriously. So on a cynical note, this is basically the establishment wanting to protect the establishment and the status quo. That is a pretty cynical take. That doesn't mean that it's the only thing because I actually listened to all of Chuck Schumer's talk and he had a very clear like words matter, he had a very clear-eyed understanding of what's coming. He even talked about the possibility of jobs dislocation. He likened it to globalization and offshoring because he said like yes globalization and offshoring did actually help the economy because it, you know, allowed us to lower the prices of goods and services, but at the same time millions of Americans lost their job. And so the implication there was that the United States government did not do a good enough job to protect Americans while we were rabidly offshoring in the 90s and 2000s. And then finally explainability. Some people commented that Chuck Schumer doesn't really seem to understand how AI works because you can't just, it's not a database that you can like say, oh, this is where it got the data from. That being said, I think that these commissions will figure out, you know, that you, while you can't look at the model and infer what was in it, you can look at the training data. So what I suspect is that there's going to be very soon open source standards on training data. So basically in order to be a licensed and approved and publicly available model, the underpinning training data will have to be publicly available or at least inspected. He did talk about innovation first as well so this is a common theme that's emerging at least in Britain and America. The EU is less concerned about innovation, they're more concerned about fundamental civil rights and foundational human rights, which is good, like I would actually like that, but as an individual nation, they are highly, highly focused on focusing on innovation first, and then safety, rights, accountability, and stuff. So it's basically, here's the roadmap of how to innovate safely and quickly. And the idea is there are geopolitical competitions happening. Vladimir Putin said, what, I think it was 2021, the nation that solves artificial intelligence will own, you know, the next century. And it's probably going to be a lot longer than that. Russia, unfortunately for them, does not have the economy or the, they have brain drain, so they're not going to be a participant in artificial intelligence. It's basically going to come down to America versus China versus the EU, but the EU is more ideologically aligned with America and vice versa. So it'll basically come down to East versus West, which is basically the same idea of World War II and the Cold War, which was Western ideology versus Eastern ideology. So this is what the geopolitical conflict is shaping up to be for the next century. Yay! Repeat of the 20th century. Let's hope that it's not as bloody. And I say that flippantly, but I am dead serious because the stakes are very, very high here, which is why I call this the Gaia Initiative, because Gaia is Greek for Earth or Mother Earth. And also Gaia was the goddess of monsters too. So on the topic of Malak and Shoggoth and all those other things, I think that Gaia is a really appropriate name. So anyways, this is out here. It's just under github.com slash Dave shop slash Gaia initiative. I will update this as interesting news comes out. I might forget about it for a while. I tend to do that, but it's up there and I find all this news comes out. I might forget about it for a while, I tend to do that, but it's up there and I find all this news very encouraging. So, thanks for watching, I hope you got a lot out of it. Cheers.", "chunks": [{"timestamp": [0.0, 5.68], "text": " Hello everybody, David Shapiro here with a update."}, {"timestamp": [5.68, 9.12], "text": " So we're going to cover two things today real quick."}, {"timestamp": [9.12, 15.84], "text": " The big thing is I mentioned in a previous video we need Gaia, a global AI agency, and"}, {"timestamp": [15.84, 17.12], "text": " we're working towards that."}, {"timestamp": [17.12, 24.06], "text": " And so I created a public repository of news and summaries, basically where I'm collecting"}, {"timestamp": [24.06, 25.72], "text": " evidence and news that is very"}, {"timestamp": [25.72, 29.32], "text": " encouraging because it's all moving in the right direction."}, {"timestamp": [29.32, 35.48], "text": " We've got everything from the Future of Life Institute open letter to pause giant models,"}, {"timestamp": [35.48, 40.84], "text": " news out of the UK, the EU, which yes, I know the UK left the EU."}, {"timestamp": [40.84, 47.84], "text": " I made a mistake of forgetting about Brexit in a previous video. The UN Secretary"}, {"timestamp": [47.84, 54.72], "text": " General talking about, yes, he's amenable to the idea of an international AI watchdog."}, {"timestamp": [54.72, 68.4], "text": " The United States Senate, their hearing on AI, the EU AI Act, the US House of Representatives and Senate having now basically matched actions with words."}, {"timestamp": [68.4, 75.4], "text": " So after the hearing, both the US House of Representatives and the Senate have introduced"}, {"timestamp": [75.4, 80.0], "text": " legislation or commissions or policies."}, {"timestamp": [80.0, 83.44], "text": " So we'll go over all those in much greater detail in just a moment."}, {"timestamp": [83.44, 87.2], "text": " But before we dive into that, I've been working on this thing."}, {"timestamp": [87.2, 92.64], "text": " I had this idea for a long time, and it's basically we can use large language models"}, {"timestamp": [92.64, 96.32], "text": " like GPT because they are trained on so much text data."}, {"timestamp": [96.32, 99.24], "text": " They're trained on data from around the globe."}, {"timestamp": [99.24, 106.92], "text": " Granted, it is primarily English, so there is definitely some's definitely some bias cultural bias in there however that"}, {"timestamp": [106.92, 112.94], "text": " being said it has read so much about the world that it knows more about religion politics"}, {"timestamp": [112.94, 121.74], "text": " psychology culture history than any one person so as far as having the ability to take perspectives"}, {"timestamp": [121.74, 128.4], "text": " it's actually pretty good and so rather than you know walk you through the code I'll just show you what I've got working so"}, {"timestamp": [128.4, 134.6], "text": " far so basically what I have it do is actually first I need to make sure well that's fine."}, {"timestamp": [135.48, 145.6], "text": " So basically what I what I have it I have it do what it does anyways is I have it synthesize a persona."}, {"timestamp": [145.88, 157.8], "text": " And so this persona is a whole bunch of random stuff like variables that it can pick to basically create a synthetic person."}, {"timestamp": [167.28, 168.0], "text": " in the manipulation way, but it has geographic origins, ethnicities, cultures, languages,"}, {"timestamp": [174.56, 180.4], "text": " political dispositions, different factors about the person, such as their physical health, their mental health, other habits, preferences, that sort of thing. And so basically what it does"}, {"timestamp": [180.4, 185.96], "text": " is to create a persona, is it'll grab one of one one of these variables"}, {"timestamp": [185.96, 189.12], "text": " or one option from each set of variables"}, {"timestamp": [189.12, 192.96], "text": " and then create a profile or a dossier"}, {"timestamp": [192.96, 196.44], "text": " in order to like take the perspective of that"}, {"timestamp": [196.44, 199.0], "text": " person and then it will talk through on a particular"}, {"timestamp": [199.0, 203.12], "text": " issue and I picked UBI because I've been on a"}, {"timestamp": [203.12, 206.34], "text": " economics and UBI tick lately."}, {"timestamp": [206.34, 210.74], "text": " And so I wanted to basically come up with a way"}, {"timestamp": [210.74, 215.74], "text": " of automatically understanding what the concerns"}, {"timestamp": [215.82, 218.54], "text": " that everyone is going to have could be,"}, {"timestamp": [218.54, 222.7], "text": " but not just elucidate or articulate the problems"}, {"timestamp": [222.7, 225.2], "text": " that they will have or the concerns that they will have or you know the"}, {"timestamp": [225.2, 230.4], "text": " concerns that they'll have over a policy like UBI, but how do we actually arrive"}, {"timestamp": [230.4, 236.32], "text": " at consensus? And consensus is not necessarily, so a lot of people have"}, {"timestamp": [236.32, 240.48], "text": " misconception about consensus. Consensus doesn't mean unanimous agreement."}, {"timestamp": [240.48, 249.36], "text": " Consensus means that it gets to a point that is good enough that people will kind of stop fighting it. It's about compromise. And so anytime"}, {"timestamp": [249.36, 255.2], "text": " that there's been any kind of contentious policy or legislation, even"}, {"timestamp": [255.2, 259.14], "text": " including the United States Constitution, nobody was happy with it because they"}, {"timestamp": [259.14, 264.0], "text": " had to come to consensus in order to get something that everyone would tolerate,"}, {"timestamp": [264.0, 265.14], "text": " everyone would accept."}, {"timestamp": [265.14, 270.22], "text": " So it wasn't perfect to anyone's mind, but it was something that they would all accept."}, {"timestamp": [270.22, 275.72], "text": " And so the idea is, okay, let's take this random profile of a person so that we can"}, {"timestamp": [275.72, 281.96], "text": " get a global representation of all perspectives, regardless of how small they are."}, {"timestamp": [281.96, 291.04], "text": " Because the thing is, when you look at some of these things like atheist, Islam, Christianity, Buddhist, right, some of these are over-represented"}, {"timestamp": [291.04, 294.52], "text": " in some areas and some of them are under-represented. Same thing for"}, {"timestamp": [294.52, 299.56], "text": " political leanings. I even include libertarians and anarchists and statists"}, {"timestamp": [299.56, 303.8], "text": " and communists and reactionaries and populists and nationalists and fascists. I"}, {"timestamp": [303.8, 305.16], "text": " don't know if fascism is in here."}, {"timestamp": [305.16, 311.72], "text": " Fascism isn't in here. So fascist perspectives don't get represented, but nationalists do,"}, {"timestamp": [311.72, 317.64], "text": " so close enough. Authoritarians get represented. So the idea is that we can get a very well-rounded"}, {"timestamp": [317.64, 326.76], "text": " representation of all human perspectives, more or less. There's obviously gonna be some flaws with this because it is the first edition, first example,"}, {"timestamp": [326.76, 331.56], "text": " but the idea is that you can get a very, very diverse"}, {"timestamp": [331.56, 334.88], "text": " set of perspectives on a particular issue."}, {"timestamp": [334.88, 337.52], "text": " And then, once you get those perspectives,"}, {"timestamp": [337.52, 339.2], "text": " you can then work through and figure out,"}, {"timestamp": [339.2, 342.34], "text": " okay, what kind of policy is this person"}, {"timestamp": [342.34, 343.88], "text": " most likely to accept?"}, {"timestamp": [344.88, 346.96], "text": " And so, by then generating a whole"}, {"timestamp": [346.96, 348.8], "text": " bunch of potential policies"}, {"timestamp": [349.1, 351.0], "text": " you can say OK well let's look at"}, {"timestamp": [351.16, 353.02], "text": " let's look at the commonality between all"}, {"timestamp": [353.02, 354.52], "text": " of these and let's get really creative."}, {"timestamp": [354.56, 355.24], "text": " So let me just go ahead"}, {"timestamp": [355.24, 356.52], "text": " and show you how this works."}, {"timestamp": [357.28, 359.04], "text": " All right. So the first thing it does is"}, {"timestamp": [359.04, 360.92], "text": " it grabs a random persona"}, {"timestamp": [360.92, 362.7], "text": " so you see where it's like you know heavy social"}, {"timestamp": [362.7, 364.4], "text": " media user there West Asian"}, {"timestamp": [368.2, 373.2], "text": " cultural background is West Asian their geographic origin is from North Africa. So imagine a West Asian family in North Africa. They're a"}, {"timestamp": [373.2, 377.76], "text": " wealthy family, they're heavy social media user, so on and so forth. Okay, so I"}, {"timestamp": [377.76, 384.88], "text": " ask what would this person think about UBI? And because ChatGPT is so heavily"}, {"timestamp": [384.88, 385.24], "text": " trained to be a helpful assistant, I can't, I couldn And because ChatGPT is so heavily trained"}, {"timestamp": [385.24, 386.88], "text": " to be a helpful assistant,"}, {"timestamp": [386.88, 390.2], "text": " I couldn't get ChatGPT to take that perspective,"}, {"timestamp": [390.2, 391.44], "text": " but what I could do is say,"}, {"timestamp": [391.44, 394.24], "text": " advocate zealously on behalf of this person,"}, {"timestamp": [394.24, 396.44], "text": " and that got really good results."}, {"timestamp": [396.44, 399.32], "text": " So let's see, as an advocate for this persona,"}, {"timestamp": [399.32, 402.0], "text": " I would say that they might have mixed feelings about UBI."}, {"timestamp": [402.0, 406.24], "text": " On one hand, they are wealthy and underemployed, which might lead"}, {"timestamp": [406.24, 417.2], "text": " them to see UBI as unnecessary for themselves and potentially harmful to their financial status if"}, {"timestamp": [417.2, 421.28], "text": " it results in higher taxes. They also might be concerned about the potential for UBI to"}, {"timestamp": [421.28, 428.88], "text": " discourage work and productivity, given their own success and wealth-oriented aspirations. On the other hand, their experience with financial stress and their social"}, {"timestamp": [428.88, 434.48], "text": " concerns might make them sympathetic to the idea of UBI as a means of reducing poverty and"}, {"timestamp": [434.48, 438.8], "text": " inequality. However, their nationalist political affiliation might make them more inclined to"}, {"timestamp": [438.8, 443.68], "text": " support policies that prioritize the needs and interests of their own country and its citizens,"}, {"timestamp": [443.68, 449.52], "text": " which could include skepticism towards UBI if they perceive it as benefiting outsiders as a form of globalist policy."}, {"timestamp": [449.52, 456.56], "text": " So you see it has a very nuanced way of saying, okay, this person has lots of different beliefs and it's pretty complex."}, {"timestamp": [458.4, 468.16], "text": " Let's see. Okay, so given their wealth-oriented aspirations, nationalist political affiliation, and their experience with financial stress, they might resonate with a fiscal policy or UBI implementation"}, {"timestamp": [468.16, 472.58], "text": " that is designed to stimulate economic growth and productivity, while also addressing social"}, {"timestamp": [472.58, 474.66], "text": " inequality within their own country."}, {"timestamp": [474.66, 478.32], "text": " For instance, they might support a UBI program that is funded through progressive taxation"}, {"timestamp": [478.32, 481.24], "text": " where the wealthy pay a higher percentage of their income taxes."}, {"timestamp": [481.24, 484.12], "text": " This would align with their social concerns and their belief in the importance of addressing"}, {"timestamp": [484.12, 488.36], "text": " inequality. However, they would likely want assurances that this would not unduly burden them or"}, {"timestamp": [488.36, 490.76], "text": " negatively impact their own financial status."}, {"timestamp": [490.76, 495.36], "text": " They might also resonate with a UBI program that includes work incentives or requirements"}, {"timestamp": [495.36, 498.6], "text": " to address their concerns about discouraging work and productivity."}, {"timestamp": [498.6, 502.76], "text": " For instance, they might support a UBI that is conditional on recipients engaging in some"}, {"timestamp": [502.76, 506.24], "text": " kind of work, education or community service."}, {"timestamp": [506.24, 511.2], "text": " So this is a theme that keeps emerging because I've run this experiment a few times."}, {"timestamp": [511.2, 515.78], "text": " I don't know if that's the underlying training of chat GPT or if it's just this is the most"}, {"timestamp": [515.78, 522.08], "text": " logical way forward where basically either you have a requirement or an incentive or"}, {"timestamp": [522.08, 525.68], "text": " reward so basically like you get everyone gets a baseline"}, {"timestamp": [525.68, 531.7], "text": " UBI but if you volunteer you get more UBI right it's like a kind of adjusting"}, {"timestamp": [531.7, 536.78], "text": " your tax returns here in America. Okay so finally given their nationalist policy"}, {"timestamp": [536.78, 540.88], "text": " they want to UBI that prioritizes the needs and interests of their own"}, {"timestamp": [540.88, 545.44], "text": " country's citizens. So this could be something like a tax break"}, {"timestamp": [545.44, 549.68], "text": " if you buy local or any number of ways."}, {"timestamp": [549.68, 553.8], "text": " So then I ask it to say, all right,"}, {"timestamp": [553.8, 557.64], "text": " come up with a policy that this person might like."}, {"timestamp": [557.64, 561.28], "text": " And so in this case, it said the National Prosperity Dividend,"}, {"timestamp": [561.28, 563.96], "text": " which that sounds rather authoritarian,"}, {"timestamp": [563.96, 565.76], "text": " but OK, we'll go with it."}, {"timestamp": [565.76, 573.12], "text": " So the NPD, which that's also the acronym for narcissistic personality disorder."}, {"timestamp": [573.12, 575.32], "text": " Oh boy."}, {"timestamp": [575.32, 578.6], "text": " Maybe let's workshop that before we go live with it."}, {"timestamp": [578.6, 583.52], "text": " Anyways, so the NPD is a form of universal basic income that is designed to stimulate"}, {"timestamp": [583.52, 587.24], "text": " economic growth, reduce social inequality, and prioritize the needs and interests."}, {"timestamp": [587.24, 589.32], "text": " Okay, so you get that."}, {"timestamp": [589.32, 594.16], "text": " So it's predicated on their engaging in some form of work, education, or community service,"}, {"timestamp": [594.16, 597.92], "text": " part-time work, vocational training, higher ed, so on and so forth."}, {"timestamp": [597.92, 602.84], "text": " You know, actually like that particular thing, because this is a recurring theme, I'm not"}, {"timestamp": [602.84, 609.36], "text": " certain that that's actually a bad idea where like you incentivize people to continue to better themselves even if it's a small carrot."}, {"timestamp": [610.08, 616.88], "text": " Like you know, hey if you're in if you're if you're going to higher education even if you know"}, {"timestamp": [616.88, 621.68], "text": " you're the college degree you're getting might not ever do anything you get an extra $500 a month"}, {"timestamp": [621.68, 625.0], "text": " you will at least be a better informed citizen and a better civic"}, {"timestamp": [625.0, 626.0], "text": " participant."}, {"timestamp": [626.0, 627.0], "text": " Who knows?"}, {"timestamp": [627.0, 628.0], "text": " I don't know."}, {"timestamp": [628.0, 630.32], "text": " Incentivize the behavior you want to see."}, {"timestamp": [630.32, 631.32], "text": " Oh, here we go."}, {"timestamp": [631.32, 634.4], "text": " The NPD would also include a patriotic bonus."}, {"timestamp": [634.4, 636.76], "text": " Yikes."}, {"timestamp": [636.76, 640.8], "text": " An additional payment for those who contribute significantly to the country's economy, culture,"}, {"timestamp": [640.8, 641.8], "text": " or society."}, {"timestamp": [641.8, 642.8], "text": " Okay."}, {"timestamp": [642.8, 645.68], "text": " I wouldn't call it a patriotic bonus."}, {"timestamp": [645.68, 649.8], "text": " That's a little totalitarian, but I get the idea."}, {"timestamp": [649.8, 653.24], "text": " So this would include entrepreneurs, artists, scientists, and community leaders."}, {"timestamp": [653.24, 658.74], "text": " So actually I think Ireland already has something like this where basically if you are a professional"}, {"timestamp": [658.74, 663.56], "text": " artist or author or whatever, a creative type, you get a stipend."}, {"timestamp": [663.56, 667.28], "text": " I don't know what they call it in Ireland but there is precedent for this being a thing"}, {"timestamp": [667.28, 673.08], "text": " so like if you were if you're a content creator or cultural commentator or whatever you could"}, {"timestamp": [673.08, 676.92], "text": " get a little bit an additional stipend."}, {"timestamp": [676.92, 682.6], "text": " So all right so there you have it and then if we run it again so we do a clear screen"}, {"timestamp": [682.6, 688.48], "text": " if we run it again let's see we get a young adult who's wealthy from Eastern Europe, whose"}, {"timestamp": [688.48, 691.36], "text": " culture is indigenous South American."}, {"timestamp": [691.36, 692.36], "text": " Interesting."}, {"timestamp": [692.36, 693.84], "text": " They like gaming."}, {"timestamp": [693.84, 694.84], "text": " They speak Spanish."}, {"timestamp": [694.84, 698.36], "text": " That makes sense if they're from South America."}, {"timestamp": [698.36, 706.72], "text": " They do not care about the community and they are a very fragile person. They're an angry, fragile person who's"}, {"timestamp": [706.72, 712.52], "text": " who is educated. They've been very experienced. They had a good childhood."}, {"timestamp": [712.52, 716.52], "text": " Sorry, they've had a good life experience. They're presently single."}, {"timestamp": [716.52, 722.48], "text": " They're a progressive atheist. Yeah, this actually sounds... oh, and they're"}, {"timestamp": [722.48, 726.04], "text": " worried about their career interesting okay so let's"}, {"timestamp": [726.04, 730.64], "text": " see I'm not gonna read the whole thing to you like I did the first one you get"}, {"timestamp": [730.64, 736.2], "text": " the idea but so you see how it takes into account like the last one they were"}, {"timestamp": [736.2, 740.16], "text": " nationalist and blah blah blah and this one is progressive given their moderate"}, {"timestamp": [740.16, 743.36], "text": " intolerance they might prefer UBI that includes some form of means testing"}, {"timestamp": [743.36, 748.64], "text": " means testing keeps come up keeps coming up as well. Let's see, skeptical about"}, {"timestamp": [748.64, 753.68], "text": " whether everyone deserves UBI. Ouch. There's some people on Reddit that this"}, {"timestamp": [753.68, 757.96], "text": " sounds like, and that's not to trash people on Reddit. I actually learned a"}, {"timestamp": [757.96, 764.4], "text": " lot from some people on Reddit. But yeah, so UBI to reduce overconsumption and"}, {"timestamp": [764.4, 765.92], "text": " promote more sustainable lifestyles."}, {"timestamp": [765.92, 773.4], "text": " Yeah, so this actually keeps coming up as well where for some people means testing sustainability."}, {"timestamp": [773.4, 779.32], "text": " So basically like you might get an additional UBI bonus if you live sustainably or you know"}, {"timestamp": [779.32, 780.42], "text": " whatever."}, {"timestamp": [780.42, 783.2], "text": " So basically like discourage overconsumption."}, {"timestamp": [783.2, 787.06], "text": " That's a trend that keeps coming up. So okay, the progressive environmental"}, {"timestamp": [787.06, 790.56], "text": " You you UBI the Pui be the PB"}, {"timestamp": [791.46, 796.42], "text": " Would be funded primary through a progressive tax system where the wealthiest individuals and okay. Yeah, blah blah blah"}, {"timestamp": [796.94, 798.18], "text": " I"}, {"timestamp": [798.18, 800.7], "text": " Haven't seen too much in terms of funding"}, {"timestamp": [801.26, 804.34], "text": " One of them did say fund it through carbon taxes"}, {"timestamp": [806.96, 809.92], "text": " of funding, one of them did say fund it through carbon taxes, which I thought was an interesting way as you partially fund it through that."}, {"timestamp": [809.92, 814.52], "text": " To align with their environmentalist values would also, oh, here it is, carbon tax."}, {"timestamp": [814.52, 817.44], "text": " Okay, so these are some ideas that keep coming up."}, {"timestamp": [817.44, 822.08], "text": " Again, I think that the underlying model has a little bit of bias here."}, {"timestamp": [822.08, 825.44], "text": " It would be interesting to see if there is a future version of"}, {"timestamp": [825.44, 832.08], "text": " GPT that is not already pre-trained to be kind of on board with some of these ideas."}, {"timestamp": [832.8, 837.68], "text": " Because one thing that doesn't that has come up is like if you have someone who is just adamantly"}, {"timestamp": [837.68, 843.2], "text": " opposed to it, it doesn't say like this person will never agree to this under any circumstances."}, {"timestamp": [843.2, 848.52], "text": " It works really hard to try and find something that they might agree with. So anyways, this is all"}, {"timestamp": [848.52, 855.52], "text": " saved out into the UBI folder as a YAML document. So it"}, {"timestamp": [855.52, 860.8], "text": " basically just saves the conversation as a whole. I think"}, {"timestamp": [860.8, 865.16], "text": " it even includes the system message because the system message"}, {"timestamp": [866.68, 870.38], "text": " includes the Includes the the the persona and the first one it was hilarious"}, {"timestamp": [870.38, 875.36], "text": " It was a radically intolerant feminist who is a Scientologist which is just like wow"}, {"timestamp": [876.16, 881.06], "text": " This was this was really interesting as it tried to figure out how to appease a very dogmatic"}, {"timestamp": [881.64, 884.88], "text": " Person, so anyways, this is a work in progress"}, {"timestamp": [888.16, 892.5], "text": " I He's a very dogmatic person. So anyways, this is a work in progress. I don't know where it's going exactly, but the idea is that maybe you could use it for"}, {"timestamp": [892.5, 893.76], "text": " policy research."}, {"timestamp": [893.76, 895.88], "text": " Maybe you could use it for..."}, {"timestamp": [895.88, 897.04], "text": " It actually came..."}, {"timestamp": [897.04, 898.04], "text": " It was precip..."}, {"timestamp": [898.04, 902.0], "text": " I've been thinking about it for a long time, but I had some inspiration after talking to"}, {"timestamp": [902.0, 905.4], "text": " the Gato community about the democratic inputs"}, {"timestamp": [905.4, 911.56], "text": " to AI, because the idea of using a chatbot to extract information from a person, from"}, {"timestamp": [911.56, 913.66], "text": " a real person, is one thing."}, {"timestamp": [913.66, 916.96], "text": " But then I was like, you know, the model already has a tremendous amount of information, so"}, {"timestamp": [916.96, 921.8], "text": " why don't we just bootstrap it and ask the model to kind of think through this."}, {"timestamp": [921.8, 925.46], "text": " So this is essentially a tree of thought, but each"}, {"timestamp": [925.46, 929.64], "text": " branch of the tree is a different persona, and then each of those branches"}, {"timestamp": [929.64, 934.72], "text": " has three sub branches where I ask it those three questions like, you know, what"}, {"timestamp": [934.72, 937.88], "text": " do you think this person will think about UBI? What kind of fiscal policy do"}, {"timestamp": [937.88, 940.8], "text": " you think would resonate? And then finally, given the persona and their"}, {"timestamp": [940.8, 944.6], "text": " disposition, can you creatively conjure up a policy that has a high chance of"}, {"timestamp": [944.6, 945.52], "text": " reaching consensus with this person? So it's, you disposition, can you creatively conjure up a policy that has a high chance of reaching consensus"}, {"timestamp": [945.52, 946.52], "text": " with this person?"}, {"timestamp": [946.52, 948.14], "text": " So it's, you know, basically you can create"}, {"timestamp": [948.14, 949.8], "text": " an arbitrary number of branches,"}, {"timestamp": [949.8, 952.92], "text": " and then as those branches span out"}, {"timestamp": [952.92, 954.88], "text": " and you get all the leaves, you gather the leaves together"}, {"timestamp": [954.88, 956.2], "text": " and see what fits."}, {"timestamp": [956.2, 959.96], "text": " Okay, anyways, so you're up to date on that project,"}, {"timestamp": [959.96, 962.68], "text": " so let's dive back into the Gaia Initiative,"}, {"timestamp": [962.68, 964.96], "text": " the global AI agencies."}, {"timestamp": [964.96, 966.72], "text": " So I've been watching the"}, {"timestamp": [966.72, 972.88], "text": " news and I realized that the number of things that are piling up that make me feel good,"}, {"timestamp": [972.88, 978.08], "text": " and I know that there's a lot of people out there that are skeptical of anything to do with"}, {"timestamp": [978.08, 988.32], "text": " government or corporations, and for those people I empathize with you. Growing up I was more like that, where I was super skeptical of all"}, {"timestamp": [990.16, 991.76], "text": " trappings of power,"}, {"timestamp": [991.76, 997.48], "text": " and certainly my friends were very like disestablishmentarianism and anarcho-libertarian whatever,"}, {"timestamp": [998.24, 1003.84], "text": " but none of them ever did anything with it. So this is the world we live in. We live in a world with"}, {"timestamp": [1004.16, 1008.96], "text": " corporations and governments and stuff and yes all power needs to be"}, {"timestamp": [1008.96, 1014.04], "text": " scrutinized. Healthy skepticism is absolutely fine. That is part of the"}, {"timestamp": [1014.04, 1018.92], "text": " democratic process. That being said if you're dogmatically against all forms of"}, {"timestamp": [1018.92, 1022.12], "text": " power, well I mean wish in one hand and you know you know what to do with the"}, {"timestamp": [1022.12, 1030.48], "text": " other one. See which one fills up first. So anyways, I have been keeping track of all this stuff because I see the currents and"}, {"timestamp": [1030.48, 1034.14], "text": " the trends and it is actually very, very encouraging to me."}, {"timestamp": [1034.14, 1037.02], "text": " So I've got it all in chronological order."}, {"timestamp": [1037.02, 1043.02], "text": " So first was the Future of Life Institute published their open letter, you know, signed"}, {"timestamp": [1043.02, 1046.96], "text": " by everyone including Elon Musk and yada yada yada."}, {"timestamp": [1046.96, 1050.82], "text": " What I didn't realize was that it actually came with a policy paper."}, {"timestamp": [1050.82, 1058.0], "text": " And so this policy paper, it's only 14 pages and it has seven policy recommendations."}, {"timestamp": [1058.0, 1063.84], "text": " So this came out in, let's see, April 12th."}, {"timestamp": [1063.84, 1070.36], "text": " I think I might have that wrong, the pause, the big pause."}, {"timestamp": [1070.36, 1073.56], "text": " So the paper was published March 22nd."}, {"timestamp": [1073.56, 1078.08], "text": " The policy recommendations came out a few days later, a couple weeks later."}, {"timestamp": [1078.08, 1083.68], "text": " So what I did was I took all that and then I made a very brief summary of the whole thing"}, {"timestamp": [1083.68, 1087.0], "text": " right here. So you can click on the link and see it,"}, {"timestamp": [1087.0, 1089.04], "text": " but it's a few basic things."}, {"timestamp": [1089.04, 1091.0], "text": " Mandate robust third-party auditing,"}, {"timestamp": [1091.0, 1094.06], "text": " regulate organizations' access to computational power,"}, {"timestamp": [1095.12, 1098.16], "text": " establish capable AI agencies at the national level,"}, {"timestamp": [1098.16, 1101.2], "text": " establish liability for AI-caused harm,"}, {"timestamp": [1101.2, 1104.32], "text": " introduce measures to prevent and track AI model leaks,"}, {"timestamp": [1104.32, 1105.72], "text": " expand AI technical safety"}, {"timestamp": [1105.72, 1110.64], "text": " research and develop standards for identifying and managing AI generated content."}, {"timestamp": [1110.64, 1111.64], "text": " Okay, sure, whatever."}, {"timestamp": [1111.64, 1115.12], "text": " It's all pretty boilerplate in the grand scheme of things."}, {"timestamp": [1115.12, 1118.2], "text": " But so that came out March, April."}, {"timestamp": [1118.2, 1127.64], "text": " March 29th, the UK did this jobby, which I haven't had a chance to summarize yet, but basically the idea is"}, {"timestamp": [1127.64, 1132.88], "text": " a pro-innovation AI regulatory framework, etc."}, {"timestamp": [1132.88, 1135.28], "text": " Again, you see how long this thing is."}, {"timestamp": [1135.28, 1147.74], "text": " That's why it takes a little bit of doing to summarize with GPT API calls. So anyways, they call for a regulatory sandbox,"}, {"timestamp": [1147.74, 1151.62], "text": " which so does the EUA, good grief,"}, {"timestamp": [1151.62, 1156.02], "text": " EUAI Act also calls for regulatory sandboxes."}, {"timestamp": [1156.02, 1158.94], "text": " So if you don't know, a regulatory sandbox"}, {"timestamp": [1158.94, 1160.82], "text": " is basically you create a safe space"}, {"timestamp": [1160.82, 1162.74], "text": " where you can experiment with AI"}, {"timestamp": [1168.24, 1169.12], "text": " that is a little bit more permissive."}, {"timestamp": [1175.04, 1179.84], "text": " And this is very often the case. So for instance, one of the most familiar ones is if you're doing medical research, for instance, you're allowed to use substances that are otherwise illegal."}, {"timestamp": [1181.36, 1186.88], "text": " You just have to go through approval processes. It's not quite the same, but the idea is that like,"}, {"timestamp": [1186.88, 1189.72], "text": " people have been able to experiment with THC and LSD"}, {"timestamp": [1189.72, 1192.92], "text": " and psilocybin, even though it's still a Schedule II drug"}, {"timestamp": [1192.92, 1195.78], "text": " or whatever in the United States."}, {"timestamp": [1195.78, 1198.84], "text": " You just have to, you have to be approved to do so."}, {"timestamp": [1198.84, 1201.88], "text": " Likewise, if you are an approved entity,"}, {"timestamp": [1201.88, 1205.68], "text": " the idea of a regulatory sandbox is that you can still do whatever"}, {"timestamp": [1205.68, 1208.56], "text": " science you need to do as long as you do so safely."}, {"timestamp": [1208.56, 1212.84], "text": " But also one thing about these pro-innovation things is, and this is a common theme that"}, {"timestamp": [1212.84, 1216.16], "text": " I actually noticed, which is why I was inspired to do this."}, {"timestamp": [1216.16, 1224.04], "text": " So the UK and the United States have all focused on protecting innovation and accelerating"}, {"timestamp": [1224.04, 1227.8], "text": " innovation in fact. So then"}, {"timestamp": [1227.8, 1234.34], "text": " in early May the UN Secretary General Antonio Guterres said that he's"}, {"timestamp": [1234.34, 1240.48], "text": " amenable to the idea of the IAEA for AI, which also OpenAI, I forgot to add that,"}, {"timestamp": [1240.48, 1245.04], "text": " but OpenAI basically published a blog calling for the same thing."}, {"timestamp": [1245.04, 1252.92], "text": " Then a few days later, the United States Senate hearing on AI, this was the one with Sam Altman"}, {"timestamp": [1252.92, 1256.14], "text": " and Christina Montgomery and Gary Marcus."}, {"timestamp": [1256.14, 1261.56], "text": " This was almost a three-hour talk, and I took the transcript of that and I summarized it"}, {"timestamp": [1261.56, 1262.56], "text": " here."}, {"timestamp": [1262.56, 1265.46], "text": " So the high-level summary basically just says"}, {"timestamp": [1265.46, 1269.2], "text": " here's the key points that they discussed and then I break each one of"}, {"timestamp": [1269.2, 1274.4], "text": " those down further. So it takes you 20 minutes to read this instead of"}, {"timestamp": [1274.4, 1280.84], "text": " three hours. It's pretty straightforward. There was a lot of back"}, {"timestamp": [1280.84, 1284.72], "text": " and forth, a lot of questions. I watched pretty much the entire hearing, but"}, {"timestamp": [1284.72, 1287.36], "text": " clearly the United States government was listening."}, {"timestamp": [1288.24, 1294.0], "text": " And I wonder if this whole thing was just an orchestrated series of events or not."}, {"timestamp": [1295.2, 1301.2], "text": " But anyways, a month later the EU AI Act was proposed. I don't think it's been adopted or"}, {"timestamp": [1301.2, 1307.56], "text": " ratified or anything. Someone explained in the comments that there's still quite a process to go through."}, {"timestamp": [1307.56, 1309.74], "text": " They've got to get feedback."}, {"timestamp": [1309.74, 1316.08], "text": " But then more recently, in just the last couple days, the United States House of Representatives"}, {"timestamp": [1316.08, 1324.4], "text": " by Representative Ted Lieu and a few others introduced a bipartisan commission."}, {"timestamp": [1324.4, 1325.42], "text": " Basically it's an AI commission."}, {"timestamp": [1325.42, 1326.26], "text": " I summarized it here."}, {"timestamp": [1326.26, 1328.84], "text": " It's pretty, or no, sorry, I didn't summarize it here."}, {"timestamp": [1328.84, 1332.84], "text": " I copied the text here because their PDF was garbage."}, {"timestamp": [1332.84, 1335.48], "text": " Seriously, like, this is the United States."}, {"timestamp": [1335.48, 1338.12], "text": " You can pay someone who knows how to make a PDF."}, {"timestamp": [1338.12, 1339.14], "text": " Good Lord."}, {"timestamp": [1339.14, 1342.5], "text": " So anyways, it's relatively straightforward."}, {"timestamp": [1342.5, 1344.2], "text": " Mostly, this is just saying, like,"}, {"timestamp": [1344.2, 1349.76], "text": " let's appoint a panel to come up with policy recommendations. It's not really, they're"}, {"timestamp": [1349.76, 1353.32], "text": " not going to do anything. Basically it's going to produce three"}, {"timestamp": [1353.32, 1358.08], "text": " reports and so this is going to recommend what the United States"}, {"timestamp": [1358.08, 1366.56], "text": " Congress does for AI. Okay great. You know, Congressional Commission, they're interested in getting more information,"}, {"timestamp": [1367.52, 1372.78], "text": " which means that they're gonna solicit experts. So one thing that I thought was most interesting was that was the panel"}, {"timestamp": [1373.36, 1375.96], "text": " is that they want to have"}, {"timestamp": [1376.64, 1382.32], "text": " members of the Commission shall have a demonstrated background in at least one of the following, computer science or"}, {"timestamp": [1382.84, 1385.58], "text": " AI specifically, civil society"}, {"timestamp": [1385.58, 1389.6], "text": " including constitutional rights, civil liberties, ethics, and the creative"}, {"timestamp": [1389.6, 1393.64], "text": " community, industry and workforce, and then government including national"}, {"timestamp": [1393.64, 1398.6], "text": " security. So when you get these kinds of people in a room together, it's not just"}, {"timestamp": [1398.6, 1402.4], "text": " engineers and not just data scientists. This is going to be people that are in"}, {"timestamp": [1402.4, 1405.18], "text": " political science, civil rights, civil"}, {"timestamp": [1405.18, 1410.44], "text": " liberties, industry insiders, and then finally national security experts."}, {"timestamp": [1410.44, 1414.02], "text": " So this is going to be a pretty comprehensive set of recommendations, and I'm actually pretty"}, {"timestamp": [1414.02, 1417.66], "text": " happy to see that Ted Lieu is leading that."}, {"timestamp": [1417.66, 1419.3], "text": " And Ted Lieu is, where is he?"}, {"timestamp": [1419.3, 1421.92], "text": " Is he the Los Angeles County?"}, {"timestamp": [1421.92, 1426.36], "text": " So it's not surprising that California bro is going to be figuring that out."}, {"timestamp": [1426.36, 1432.56], "text": " Okay, and then finally, most recently was just a couple days ago, Senator Chuck Schumer"}, {"timestamp": [1432.56, 1439.7], "text": " announced the SAFE framework at the CSIS, which is really interesting."}, {"timestamp": [1439.7, 1442.16], "text": " And I don't know if this has been ratified yet or anything."}, {"timestamp": [1442.16, 1449.28], "text": " I haven't been able to find the actual text of the idea, but there is a one pager out there somewhere"}, {"timestamp": [1449.28, 1454.12], "text": " that summarizes it very succinctly. But I took the transcript from this"}, {"timestamp": [1454.12, 1461.88], "text": " and I summarized the talk here. So basically it comes down to four"}, {"timestamp": [1461.88, 1468.12], "text": " major components. Security, which basically talks about national security"}, {"timestamp": [1468.12, 1472.22], "text": " above all else, but also corporate security"}, {"timestamp": [1472.22, 1474.8], "text": " and privacy of citizens."}, {"timestamp": [1474.8, 1477.76], "text": " Accountability, which talks about how do you,"}, {"timestamp": [1479.44, 1482.6], "text": " it's actually pretty similar to the EU thing where,"}, {"timestamp": [1482.6, 1484.88], "text": " oh, I forgot to mention this, for the EU AI Act,"}, {"timestamp": [1484.88, 1489.12], "text": " the primary thing that the EU AI Act does is it bans outright"}, {"timestamp": [1489.12, 1495.36], "text": " social credit systems and surveillance like basically Big Brother,"}, {"timestamp": [1495.36, 1499.74], "text": " bans Big Brother stuff, and so this is what the Security and Accountability"}, {"timestamp": [1499.74, 1505.56], "text": " does. An interesting part of this was the foundations aspect of the framework."}, {"timestamp": [1505.56, 1512.24], "text": " So basically, one of the key things of Chuck Schumer's framework is to protect the foundations"}, {"timestamp": [1512.24, 1513.84], "text": " of democracy."}, {"timestamp": [1513.84, 1518.7], "text": " So I was talking with my wife about this, and she suspects that this was a direct reaction"}, {"timestamp": [1518.7, 1524.36], "text": " to the January 6th attempted insurrection at the US Capitol."}, {"timestamp": [1524.36, 1526.16], "text": " When people are breaking into,"}, {"timestamp": [1526.16, 1528.78], "text": " and keep in mind that many members of Congress"}, {"timestamp": [1528.78, 1530.68], "text": " were directly in danger."}, {"timestamp": [1530.68, 1534.52], "text": " And so we suspect, we being my wife and I,"}, {"timestamp": [1534.52, 1537.64], "text": " we suspect that this is actually basically"}, {"timestamp": [1537.64, 1540.32], "text": " the Congress, you know, House of Representatives"}, {"timestamp": [1540.32, 1542.96], "text": " and Senators, you know, they didn't take"}, {"timestamp": [1542.96, 1545.52], "text": " social media seriously. And then, you know, they didn't take social media seriously."}, {"timestamp": [1545.52, 1549.36], "text": " And then, you know, Facebook happened with Cambridge Analytica."}, {"timestamp": [1549.36, 1555.24], "text": " I don't think it's controversial to say that Facebook and other social media companies"}, {"timestamp": [1555.24, 1562.08], "text": " directly contributed to the widespread abuses of misinformation, but also just coordination"}, {"timestamp": [1562.08, 1563.14], "text": " of violence."}, {"timestamp": [1563.14, 1564.56], "text": " It's that simple."}, {"timestamp": [1564.56, 1566.08], "text": " And so they learned"}, {"timestamp": [1566.08, 1569.52], "text": " their lesson by not taking social media seriously and now they're taking"}, {"timestamp": [1569.52, 1574.32], "text": " artificial intelligence very seriously. So on a cynical note, this is basically"}, {"timestamp": [1574.32, 1579.92], "text": " the establishment wanting to protect the establishment and the status quo. That is"}, {"timestamp": [1579.92, 1583.56], "text": " a pretty cynical take. That doesn't mean that it's the only thing because I"}, {"timestamp": [1583.56, 1587.0], "text": " actually listened to all of Chuck Schumer's talk and he had a very clear"}, {"timestamp": [1587.0, 1590.84], "text": " like words matter, he had a very clear-eyed understanding of what's"}, {"timestamp": [1590.84, 1595.92], "text": " coming. He even talked about the possibility of jobs dislocation. He"}, {"timestamp": [1595.92, 1599.92], "text": " likened it to globalization and offshoring because he said like yes"}, {"timestamp": [1599.92, 1606.8], "text": " globalization and offshoring did actually help the economy because it, you know, allowed us to lower"}, {"timestamp": [1606.8, 1611.2], "text": " the prices of goods and services, but at the same time millions of Americans lost their job."}, {"timestamp": [1612.0, 1616.72], "text": " And so the implication there was that the United States government did not do a good enough job to"}, {"timestamp": [1616.72, 1626.56], "text": " protect Americans while we were rabidly offshoring in the 90s and 2000s. And then finally explainability."}, {"timestamp": [1626.56, 1628.12], "text": " Some people commented that Chuck Schumer"}, {"timestamp": [1628.12, 1630.76], "text": " doesn't really seem to understand how AI works"}, {"timestamp": [1630.76, 1633.02], "text": " because you can't just, it's not a database"}, {"timestamp": [1633.02, 1633.86], "text": " that you can like say,"}, {"timestamp": [1633.86, 1635.84], "text": " oh, this is where it got the data from."}, {"timestamp": [1635.84, 1638.06], "text": " That being said, I think that these commissions"}, {"timestamp": [1638.06, 1641.08], "text": " will figure out, you know, that you,"}, {"timestamp": [1641.08, 1644.92], "text": " while you can't look at the model"}, {"timestamp": [1644.92, 1647.36], "text": " and infer what was in it, you can look at the training data."}, {"timestamp": [1647.36, 1652.96], "text": " So what I suspect is that there's going to be very soon open source standards on training data. So"}, {"timestamp": [1652.96, 1658.32], "text": " basically in order to be a licensed and approved and publicly available model, the underpinning"}, {"timestamp": [1658.32, 1666.2], "text": " training data will have to be publicly available or at least inspected. He did talk about innovation first as well so"}, {"timestamp": [1666.2, 1670.56], "text": " this is a common theme that's emerging at least in Britain and America. The EU"}, {"timestamp": [1670.56, 1675.64], "text": " is less concerned about innovation, they're more concerned about fundamental"}, {"timestamp": [1675.64, 1680.16], "text": " civil rights and foundational human rights, which is good, like I would"}, {"timestamp": [1680.16, 1690.2], "text": " actually like that, but as an individual nation, they are highly, highly focused on focusing on innovation first,"}, {"timestamp": [1690.2, 1692.6], "text": " and then safety, rights, accountability, and stuff."}, {"timestamp": [1692.6, 1694.48], "text": " So it's basically, here's the roadmap"}, {"timestamp": [1694.48, 1697.88], "text": " of how to innovate safely and quickly."}, {"timestamp": [1697.88, 1701.2], "text": " And the idea is there are geopolitical competitions"}, {"timestamp": [1701.2, 1702.28], "text": " happening."}, {"timestamp": [1702.28, 1709.5], "text": " Vladimir Putin said, what, I think it was 2021, the nation that solves artificial intelligence will own, you know, the next century."}, {"timestamp": [1709.5, 1725.36], "text": " And it's probably going to be a lot longer than that. Russia, unfortunately for them, does not have the economy or the, they have brain drain, so they're not going to be a participant in artificial intelligence. It's basically going to come down to America versus China versus the EU,"}, {"timestamp": [1726.4, 1732.96], "text": " but the EU is more ideologically aligned with America and vice versa. So it'll basically come"}, {"timestamp": [1732.96, 1739.84], "text": " down to East versus West, which is basically the same idea of World War II and the Cold War, which"}, {"timestamp": [1739.84, 1749.44], "text": " was Western ideology versus Eastern ideology. So this is what the geopolitical conflict is shaping up to be for the next century. Yay! Repeat of the 20th"}, {"timestamp": [1749.44, 1753.68], "text": " century. Let's hope that it's not as bloody. And I say that flippantly, but I"}, {"timestamp": [1753.68, 1758.84], "text": " am dead serious because the stakes are very, very high here, which is why I call"}, {"timestamp": [1758.84, 1763.16], "text": " this the Gaia Initiative, because Gaia is Greek for Earth or Mother Earth. And"}, {"timestamp": [1763.16, 1765.36], "text": " also Gaia was the goddess of monsters too."}, {"timestamp": [1765.36, 1768.56], "text": " So on the topic of Malak and Shoggoth"}, {"timestamp": [1768.56, 1769.44], "text": " and all those other things,"}, {"timestamp": [1769.44, 1771.88], "text": " I think that Gaia is a really appropriate name."}, {"timestamp": [1771.88, 1773.42], "text": " So anyways, this is out here."}, {"timestamp": [1773.42, 1776.28], "text": " It's just under github.com slash Dave shop"}, {"timestamp": [1776.28, 1777.48], "text": " slash Gaia initiative."}, {"timestamp": [1779.26, 1782.6], "text": " I will update this as interesting news comes out."}, {"timestamp": [1782.6, 1783.94], "text": " I might forget about it for a while."}, {"timestamp": [1783.94, 1785.36], "text": " I tend to do that, but it's up there and I find all this news comes out. I might forget about it for a while, I tend to do that,"}, {"timestamp": [1789.76, 1792.64], "text": " but it's up there and I find all this news very encouraging. So, thanks for watching, I hope you got a lot out of it. Cheers."}]}