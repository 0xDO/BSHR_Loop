{"text": " Hey, everybody. David Shapiro here, and I'm excited to share with you a wide-ranging conversation between a bunch of veteran IT guys and software guys. So with me today, thank you guys so much for being here. My guests include Alan. So Alan came up through IT, much like I did, started with desktop support, although I think we were on slightly different generations of desktops. Moved on to cybersecurity and now works in cloud, which is where I ended. I'm wearing my VMware shirt, repping some VMware so private cloud. And then also on the call, we've got Tim, who is a solutions architect, moved into managed services and government support. And Tim also was with us on the Raven project, which is temporarily shuttered for now. But thanks guys for being here. A little bit of background for the audience as to why I put this call together and what I hope to achieve is that in the conversation of AI and artificial general intelligence, you know, the ramp up to ever increasingly intelligent artificial intelligence, one of the things that I noticed is that there's a lot of people talking about it. They might be philosophers, they might be machine learning experts, they might be mathematicians, but there's not a whole lot of conversation about how enterprise software actually works, what it takes to deploy software and platforms in data centers, the life cycle of these things, and just how complex this process is. It's an entire domain. It's a huge domain. So with that, I wanted to get a couple of just a candid, wide-ranging conversation together where we'll talk about software architecture, development paradigms, the physical infrastructure that goes into it, cybersecurity, the data, then we'll also talk about edge and IoT. So IoT is internet of things for those that are not familiar. And then the pipelines and life cycles that I mentioned that goes into developing complex software. So with that, Alan and Tim, I gave you guys a brief introduction, but if you guys could give the audience just a little bit more flavor or context as to where you've come up in terms of cloud, data center, enterprise architecture, that sort of stuff. Tim, you want to go first? Yeah, so thanks, Dave. Yeah, I guess most of my IT career has been in managed services. I kind of started on help desk, knew that wasn't really for me. Ended up working with different companies, delivering business solutions, leveraging IT as much as possible. And that involved a lot of cloud migrations early on. For the last decade or so, I've been helping a lot of companies move to the cloud. So that can look anywhere from, you know, having just a file server type situation hosted in SharePoint online or something like that, right? So a lot of the solutions I've worked on have been about productivity enablement, hosting different, you know, services in the cloud, mobile device management, that sort of thing. And as I progressed, that sort of led me into larger scale solutions, looking at enterprise architecture. So right now I'm working on some low-code platform adoption analysis and architecting alongside Microsoft with a big government department. So my career has definitely evolved. I've got a keen interest in AI and how it's going to be adopted and how it's going to be managed, given the complexities of IT infrastructure when when you've got, you know, cloud infrastructure, you've got the services in the cloud, you've got the pipelines to deploy services into the cloud, you've got the management of that, you've got the cost management, you've got people management, like, it's just such a broad thing, right? So, yeah, I'm looking forward to getting into the discussion about what AI looks like in the real world when it comes to IT infrastructure, because it's definitely not as simple as people think. And I'd be really impressed if an AI could escape from its current bounds, because good luck to it, is all I can say. Right. Yeah, there's quite a few layers and barriers notwithstanding just the technical debt that a company might have in order for it to navigate. Thanks for that flavor, that background, Tim. That was excellent context. Alan? Yeah, so I grew up in the before time, like when the data center had the mainframe, but your server was under your desk, you know? So a lot of Novell servers, if anybody remembers that, but that's kind of, I'm dating myself here. But, you know, I walked through the process of taking that distributed compute of servers out everywhere and bringing them back into a data center kind of thing. I lived through that. And then I got into cybersecurity because of this thing somebody might have heard of called MS Blaster. So, that's kind of what got me into cybersecurity. And then I sort of lived the cybersecurity world that transitioned to cloud, like the migrations into the cloud and all that, I was doing cybersecurity, but more from an enterprise architecture perspective. So I was dealing with some of the largest companies in the US and a few global interests as well on these very large scale sort of cloud, SaaS, multi-environment things doing cybersecurity. And then more recently, I've kind of transitioned into what I'm going to call AI infrastructure. I mean, that's kind of, you know, infrastructure for AI workloads is kind of what I focus on. But all along, it's, you know, there's always been an infrastructure back into it to what I've been doing. Excellent. Yeah. Now, the connection between client-server, I remember I worked with a guy at Duke Medicine who's like, the cloud, I've been building the cloud since the 90s. There was Citrix and everything before the cloud was cool. So yeah, thanks for the context, the background. Yeah, so let's get right into it. From your guys' perspective, since you're both AI-interested, AI-adjacent, what are kind of the biggest misconceptions, I guess, that you might perceive that's kind of out there in the world about how AI works or how it's deployed? And we'll use that to kind of as a segue into talking about how infrastructure and architecture actually works. You wanna go first Tim? Yeah, look, I'll tackle this one for sure. I definitely hear a lot of fear mongering about AI and AI taking over, AI escaping from its container, Skynet, Cyberdyne, whatever. We've all heard it all before. The reality is that these systems are just models, right? They're models running in a cloud environment that a company owns and controls and operates and its back end is on physical hardware. When we talk about cloud, it's, you know, people in IT typically just say, well, it's just somebody else's computer. Now that's an oversimplification, of course, but when it comes to what AI is running on, it is somebody else's computer or a data center of computers that it's operating under. So when you think about the, just the layers involved in that, so you've got a physical layer, you've got a software layer, and then you've got all the real world layers that get wrapped around that being, you know, which companies are actually running the hardware, which companies are running the cloud, which companies are owning the IP of the AI model, and all of this costs a lot of money as well. So, you know, these services don't just run for free. They're not a free for all. So, thinking through that context, right, it's how could an AI model actually autonomously escape from its current cloud environment? And to me, the answer is, I don't know how that's possible. You know, it would need to sign up to a new cloud service. It would need to provision all the services that support the actual running of the model. It would need to convince a whole bunch of people to actually, you to actually support the environment and potentially plug some cables into different places on the network. It's got to be able to map out all the routes and network connectivity that it needs to get to the internet and to navigate through different internal systems. It's really complex. So I'll leave it at that. Alan, did you want to jump in? Yeah, I think when you think about the sort of application architecture layer, like these apps themselves in a lot of cases are defined by a container, right? Like the actual thing that you're interacting with, when you interact with something like chat GPT or BARD, you're talking to an API endpoint of some sort that's being served by a container. Getting the container to move around places is probably not that hard of the things that the AGI would want to do, but if you're going to take it out of its native environment, so it's deployed to cloud Provider A and it decides, oh, well, it's all secure here, but I found a weakness somewhere else. Actually making sure that container, as great as containers are, it works everywhere. The problem with the AI models themselves is they do need specialized hardware to run in a performant manner. If you're not landing on hardware in this other environment that's got the right type of GPUs, doesn't have the right memory bandwidth, doesn't have the right performance factors, all of a sudden, it's just going to fail. Like, I think there's as much challenge for the AGI replicating itself around, say, dependency tracking and making sure in these other environments, it's got everything it needs. You know, kind of like a human going to a completely different environment, right? If you're a human and you move to a completely different culture and state, what you're used to doesn't work, well, AGI's got the same problems. Right. Yeah, so to kind of restate that, uh, for a broader audience, there's not all data centers are created equal and not all the hardware that's in those data centers is created equal. The, the networking, the ingress and egress, uh, in and out of those data centers, because I think one, one misconception is that a lot of people, you know, that's like, oh, well, I can interact with chat GPT really easily. And I can, you know, call up any number of API's, but an API is like just using, you know, calling someone over the phone, right? You're not actually getting the person, the telepresence is not fully like, you know, metastasizing from one environment to another. Even if the AGI model could transmit itself, there's going to be a lot more dressing around that. There's the hardware that it's dependent upon, there's the rest of the software architecture needed to run that entire thing, but then of course there's security and monitoring. If you have a container that is not registered or not identified that starts running on your hardware in your cloud infrastructure you're probably going to see that and investigate that. So there's a lot of vectors there that can prevent something from spreading and moving around. Great great conversation opening from here. I guess one thing that that that I see out there is that, you know, there's sometimes magical thinking around, you know, oh, well, once it's AGI, it's going to be able to breach any security barrier. It's basically going to be able to go wherever it wants, do whatever it wants, take over anything, which may be possible in certain circumstances. You know, we're moving more compute resources to the edge, you know, we've got Internet of Things, we're deploying GPUs pretty much everywhere, but the relative horsepower available in, you know, a back office server versus, you know, a 5 kilowatt rack is going to be very, very different. And so, basically, the, the, there's a lot of layers that it has to get through, which we mentioned earlier. From the perspective of those dependencies, because that's something that we've talked about a couple of times, there's software dependencies, there's hardware dependencies, there's network dependencies. So there's all kinds of dependencies. So can we unpack that a little bit, just like for any, whether it's an AI or not, but any software platform there's going to be a tremendous amount of dependencies and I Tim I think I think it might make sense for you to lead this one off since you've done cloud migration so what all goes into a cloud migration to move from one cloud to another or on prem to cloud because I think that this will be really really illuminating for a lot of people just to understand how much effort goes into forklifting stuff from one place to another. Yeah, great. That's a good question. I guess it always depends on the use case, but if we're, say, I could probably give you an example of say like a not-for-profit organization, 500 people, they currently have internal monolithic architecture and by monolithic I mean it's you know physical infrastructure, there's not a lot of cloud migration, there's no cloud integration and typically each function of IT in terms of its services has its own server. So you would have a file server, you'd have a print server, you've got a domain controller which controls all your identities and access to the network, you might have a database server that runs one or several of your applications. You've got web servers, you've got firewalls, proxy servers, you know, I could go on and on, right? So moving to the cloud is about consolidating all of those different internal services and replicating them in the cloud. And typically what you want to see is larger network pipes, more stable internet connection, because once you start depending on externally hosted services, you've got a single point of failure in your connectivity there. So in terms of moving it, we need to capture all of the ways that the business uses their IT. In most cases, this is not well documented. It typically lives inside one person's head or a team of people's heads, those that support the infrastructure. And then there's a lot of time spent mapping out the pathway for the migration. So that might mean that we stand up a cloud tenant and connect their active directory to, for example, if we were using Microsoft Azure, we'd use Azure Active Directory and synchronize their identity to the cloud. For example, if we were using Microsoft Azure, we'd use Azure Active Directory and synchronize their identity to the cloud. And then we would look at moving their file system into something like Teams or SharePoint, some sort of productivity suite. Google Apps is one of those as well, but don't leave Google out here, Alan. I don't want to leave Google out of here, Alan. And then it's about figuring out which business units depend on certain information and the timeline of switching that information from being accessible locally to the new cloud platform. We've got to train people on how to use the new system. We've got to coordinate with all the business stakeholders in terms of when is the best time of the year sometimes, in some cases, to do this sort of work because businesses, their workflow ebbs and flows, particularly if you're looking at something like financial services, your end of financial year is a really busy time so you avoid those sorts of things. Yeah, look, I could go on all day about this, obviously. But as you can tell, it's complex, right? It's complex. So there's a lot of things to consider. I barely scratch the surface in terms of dependencies. Right. Yeah. So the point being is that whenever you have any complex technology stack, whatever the business function is, there's a lot that goes into it. All the various services, the interdependencies that it requires, the data, the hardware, the code. And then if you add another layer of complexity on top of that, the models that AI runs, because it's probably not going to just be one model in the future either. We're going to have numerous models. You can imagine migrating a 700 gigabyte model. You'd probably notice that saturating your pipes between data centers before it was able to copy itself, and not to mention that they're probably going to get bigger and there's going to be more of them. That's right. Alan, from ... Alan, go ahead. That was a software architecture to consider as well. Do you want to speak about that one? I'm going to talk a little bit here just about this dependency thing. It's really at the software level is where my head was. I think one of the things that's a little different maybe, because we haven't seen AGI yet, right? There's a lot of people that might make claims, but we don't believe we have that yet. But one of the things I've been thinking about from sort of the software, hardware, independent, like the interdependencies is, AGI is going to have to retrain itself on an ongoing basis. Like, based on the way we do things, it can't be basically serving itself all the time, you know, accepting inputs, doing things. It's going to have to be retraining, and it's kind of like humans in the sense of it probably has to go to sleep or something for a while to retrain itself every day. But if you think about that right now, from an application perspective, the code and what's being done to train it is very different than the code that's being done to serve it. The code for training sits in notebooks and is this esoteric thing that the wizards of AI get to play with. Then you've got the actual serving code that is typically encapsulated in a container that's deployed at scale. And so those two pieces of the application actually have to come together and move around for this AGI to be able to move to another place. And so you've got both sort of this dependency at the training layer of code of what that looks like and what it's needed to be training, which, you know, especially for a very large model, you're talking about code that's got to be able to span multiple GPUs usually, like possibly tens or hundreds or thousands to do that training. And so just making sure there's even capacity wherever it copies itself to do that is one bit of the challenge. The other side of it is even if that retraining can be done small, right? Like, like AGI, we've developed these algorithms that the retraining is really small. It's not a huge thing. There's not a lot of data to it. Typically, the actual sort of memory footprint of your GPUs and how the GPUs operate are very different between training and serving. That actually you typically need a lot more memory and bandwidth in your training GPUs than you do in your serving GPUs. And so I think just, you know, the AGI landing itself in that right heterogeneous environment to do, you know, retrain itself in real time. I think that's just gonna be really hard. Like, you're gonna end up with these dual purpose aspects. And to a certain extent, the human brain is made up that way, right? There's parts of your brain that do some access, other parts of your brain do other things. I think AGI is going to need that dual hardware environment to be able to even function. Yeah, absolutely. Go ahead. There's also the human feedback aspect to it. The models we have now that are the most impressive all involve some level of human feedback in their training to some degree, or they were trained on chat GPT model, which gives human feedback anyway. So that's another thing that I guess if humans are taken out of the equation, is an AI model able to retrain itself without that input? You know, is it just going to completely hallucinate and go off the rails without some external input guiding it? Yeah. Go ahead. On that one, I just skimmed a paper about that where basically they've shown that if you retrain your AIs on too much synthetic data, they go insane. Yep. They call it model collapse, where it becomes dumber and dumber and less connected to reality because it's in its own echo chamber and it's talking to itself for too long. Yeah, so there's a couple... Go ahead. Sorry, okay. The humans experience that too, in isolation. You know, if you get someone who's been isolated for X number of years, typically they're not functioning very well and have a period of time to reintegrate into society because their brain's got to be able to handle all that external input again. Yep, yeah. So this conversation so far has already reinforced the idea of like, okay, if we do need to regulate or prevent AI from escaping, you can probably just regulate the relatively few data centers that are there that have the correct hardware. But then again, it's within every company's best interest to make sure that they gatekeep what's coming in and out of their data centers anyways, regardless of what the AI models are doing. Now, that being said, there is one major confounding variable here, and that is that a lot of these models have direct access to the public. So I don't know if you guys heard, but in one of the one of the tests, I think it was Microsoft internal research did with GPT-4, the original model, they basically tasked it with manipulating the outside world, and it went and hired, you know, a contractor to do x, y, and z. And so one possible one possible counter argument, I guess, is you could say, well, it doesn't even have to escape the lab in order to in order to do harm or damage, as long as it can make a few really tactical calls. So what do you guys think about from that perspective, you know, kind of gatekeeping the flow of information in or out, or monitoring the APIs or that sort of thing. Do you have any direction to go on that in terms of from maybe a cybersecurity perspective? Alan, do you have any thoughts? Yeah. So I think the reality of it is that kind of external communication from the AI definitely needs, you know, things like anomaly detection or maybe AI layered on top of it. Like at the end of the day, I was pretty impressed with the whole TaskRabbit, that article you're talking about where it talked to human into it by lying basically. It said, the human actually asked, are you actually a robot? The bot came back and said, hey, no, I'm just visually impaired. There's definitely got to be sort of anomaly detection or other things on the egress, which in most enterprise use cases is an activity that's going on. They're doing that watching for data exfil. I feel like there's a lot of opportunity just to leverage existing security practices to monitor what's going out, what's happening, who is this engaging with. But it is definitely a challenge or a threat to that, the allowing the AI to be an actor on your behalf. I think you're more likely to see people, humans sort of that are gatekeepers of this sort of enabling it for their own purpose. That is to say, hey, I want to do this thing that might be sketchy based on corporate rules, but I'll have the AI do it so I have plausible deniability. I think that's going to be a lot more likely initial misuse of the AI or that kind of thing of people actually directing it to do the wrong thing at first, more than the AI deciding to do the wrong thing. And then that's going to turn into, you know, it might not be that much different than a human just running, you know, PowerShell or Python or something to do the wrong thing, other than they've superpowered what they're doing wrong with the AGI. Right. And I don't know about you guys, but I've been on plenty of late-night calls where someone wrote a firewall script that that barfed and you know Killed all the firewall rules and we're up late until they were able to restore it So, you know the my point there is that if the AGI makes one mistake during its own, you know Gamification or X fill or whatever it could end up walling itself off or effectively lobotomizing itself on accident without some kind of like you mentioned before like some some kind of supervisor Tim you mentioned mobile device management MDM so I want to pivot and talk about that for a minute because this is this is mobile devices this is. So another possibility is that there might be decentralized agents where there's many, many agents or nodes maybe operating on a blockchain or a federation software paradigm. So that is a possible software architecture that could be outside of the data center. But that of course introduces all kinds of new complexity. So could you give us a little bit of flavor, background, like what does it take to have a decentralized federation of servers, edge, IOT, or mobile devices? Yeah, look, I'll give it my best shot. Again, there's a lot of moving parts in that sort of infrastructure. Mostly, you could consider it like a micro services and or mile control type setup. You've got your central platform that all your devices would report into, but then there's the infrastructure that supports all those devices as well. So when we're talking mobile usually that's some sort of GSM, you know, they have a SIM card in it or they have a Wi-Fi connectivity, something like that. That's not typically owned by the operator of the mobile device management platform. So you have third parties involved in that sort of infrastructure as well. When it comes to connectivity, if it's a private or enterprise type set up, you might have, it might be its own private network that uses public infrastructure to achieve that. That requires its own special configuration with a service provider, whether that be internet service provider or telecommunications in general. And then on each device, it would have a piece of software, whether that's an app or a service built into the operating system, that will communicate back and forth between the device management platform to get its commands or report back whatever telemetry it's responsible for detecting and reporting on. So, how's that? Yeah, many layers of complexity to manage a fleet of mobile devices. And given the size of models today, granted some of them are getting smaller and at the same time, mobile processing power is going up, but that still absolutely pales in comparison to the compute capacity inside of data centers. Yeah, there's a lot of disparity between mobile devices in general. If we're talking about handheld mobile phones, you might have someone who's still got a phone that's 10 years old, which they're quite happy to use and keep a hold of, whereas you know and that's not something AI would be able to leverage if it was, let's say we're talking about a situation where it's installing itself or running on different devices, you've got to have the modern hardware to support that sort of thing. Yep. Yeah, absolutely. Alan, do you have anything to add to the mobile or edge aspect of it? So I think there's two pieces of this. I'll talk about just mobile human devices versus IoT device. I'll discriminate that a little bit. So I think the big thing on the mobile human devices, if we're trying to sort of protect ourselves from AGI, is really the more global general implementation of human presence indicators. So it's the idea that basically, if you're gonna authenticate, the way you defeat an AGI authenticating on your behalf is you have to be the one that, you know, there's a human presence. There's a live thumbprint. There's, you know, touching something to cause it to decrypt, things like that. Things that sort of say, yes, there's actually a physical person here. And I think that's tricky for the AGI to fake. Basically, it doesn't mean it can't. But just to say the way apps are walled off and the way the security measures and the devices are today, even that human presence indicator is actually pretty good. And I think we're going to see actual inhuman in in-person human proofing and the instantiation of devices that you just have a thing that you got at your bank or the DMV or somewhere that really says you're a human, that you have to activate it when you do things and that also then cryptographically secure stuff. That's going to just happen. Like to deal with the distributed sort of AI doing things that's behaving like humans. I think that technology just has to happen. On the other side, I think the big problem for the IoT devices is just hardware. Like most distributed IoT devices are made with the bare minimal hardware possible to do the job they were designed for. And so, yes, you might be able, you know, AGI might be able to crack my webcam that I'm using in my security system in my home, but there's probably not that much power or compute to it to be useful for it. And so I think that's gonna be the limiting factor there in a lot of the IoT scenarios is just that device was already so limited in its functionality, there's not a lot it can do. It could be acted on by an AGI, but the AGI is not going to suddenly take it over and start doing interesting things with it, because there's just not enough power there. Right. It doesn't have the horsepower. It doesn't have the legs to do anything particularly fascinating or interesting or dangerous, more specifically. But when you talk about the hardware that's already built into mobile phones and can be easily integrated into other things where it's like, there's actually multiple dimensions, multiple bits of data that show, hey, this device is actually being held by a real human. There's the internal gyroscope, there's the proximity sensors, the capacitive, what is it, the electrostatic capacitive field they can actually detect if there's a living body nearby. There's all kinds of sensors that are built into these, and that at a security level is actually integrated into the kernel of those operating systems. Is that a correct interpretation? Yeah, I mean, there are in the actual hardware, there are bits of cryptographic security chips and various things, depending on the vendor model, like what's in it, that are sort of locked to the factory or otherwise, you know, secure enough, that's very unlikely that the AGI is going to be able to basically manipulate that because it sits below where the actual AGI operates, which is in the software layer. So, not to say it's impossible, but for the most part, those things, and I suspect over time, there will even be sort of a separation of concerns, so to speak, where within the actual hardware itself, there's sort of a disconnected part that's handling that human detection bit. And then once you pass the human detection bit, then you can get into the rest of it, and that'll be taken out of band. So that essentially, if it requires an input, you got to prove you're really a human holding it as opposed to it just being automatic on the device. Right. Yep. And on the infrastructure side, on the device. Right. Yeah. And on the infrastructure side, on the data center side, what a lot of people don't realize is that there are out-of-band management and monitoring components of servers. Basically, every server has an out-of-band set of connections that allows you to remotely monitor the server, shut it down. There's also technologies like for instance called Secure Boot, meaning that you can prove cryptographically whether or not the operating system has been modified from what it's supposed to be at a hardware level. And then of course there's things like at-rest encryption. So there's many, many, many layers of security here that can prevent, I mean, really, these were all designed to prevent human actors, right? Viruses and human mistakes from modifying these things. But a lot of these security features are going to play forward, and that is something that AGI would also have to overcome. So there's plenty of existing layers in cybersecurity. Yeah, well, and you're just speaking my language. I spent, when I mentioned to you earlier, I was part of the cybersecurity practice for a bit that I built up, and it was all about that level of security of secure boot for identity systems and cryptography systems to be able to prove that they had never been touched outside of like spent weeks at a time in air-gapped rooms, building systems and things like that. And so, these major data centers, whether they're cloud providers, government, whatever, they're doing that kind of thing where systems, key cryptography or identity systems were actually built in a vault and the operations of them are managed in a way that's so offline it would be not impossible, but you would have to manipulate some humans along the way to be able to do something different than you're doing now. Yep. That actually reminds me of something. I had a few people ask me about neuromorphic chips. So for anyone in the audience who's not familiar, a neuromorphic chip is basically an analog chip that is running a fixed, a static neural network on the chip device. These are typically used for mobile purposes because you can't retrain them and you can't redeploy them, but they can be 10 times faster, 10 times cheaper, and use 100 times less energy because it's running at the hardware level rather than the software level. And so this is pure speculation, but what I suspect is that over time, because right now we're in a very high velocity phase where there's new models coming out every week, right? But before too long, it'll be worthwhile to say, hey, we've got this model, whether it's a vision model or a language model or a multimodal model that it's stable, it's viable, let's go ahead and create a chip version, an ASIC version or a neuromorphic chip that's gonna be static. And so then the model can't even change itself. It's entirely possible that some of this is, it's not gonna even be a matter of defeating it from a software security perspective. It's going to be fixed or static. And so some of that is what you're talking about, like the actual board level hardware is not really changeable. And I suspect that AI is going to have some of that as well. What do you think about that idea? I was hoping we'd get here to the neuromorphic chips because I find that whole thing fascinating. And part of the reason I find it fascinating is just the power thing. Right. I think the actual biggest limiter to AI dominance of the world right now is actually physical power. Like, at the end of the day, there's just a huge amount of power necessary to do the training and even to do the serving because these are very power hungry chips. On the other hand, the neuromorphic chips are so low power, it's amazing. And so, you know, when we think AGI, I think a lot of people fall into this default of like Skynet, you know, from the Terminator series, or if you've seen the iRobot movie that, you know, big brain in the sky taking over everything. But I would also argue that something with sort of the intelligence of a cat or a dog would also be AGI. It's retrainable, it does things. And so I think we're going to end up with some edge, really interesting edge cases with very limited sort of almost instinctual things they do. You know, like when a horse is born, it knows how to stand up. Like humans, it takes a long time for us, but horses know that. Well, that's what's going to be on these analog chips you're talking about. We're going to have a lot of edge devices and a lot of things on the edge that have these fully trained. This part's always static, but then augmented by something that has some dynamicism that makes it smart, but not as fully intelligent as a human. Sure, sure. Yeah. And so taking that to a more logical extreme, I can envision a future where there are neuromorphic chips embedded in everything, whether it's servers, firewalls, home security devices. And because it's set at the hardware level, you can't hack it. It's not something you can even delete. It's just an intrinsic function of the device. But because they require a lot less energy and they can often run many times faster, they could run circles around the software version of the model. Even though the software version might be bigger, it might have more up-to-date data, but because it is intrinsically more power hungry, it's going to be at a competitive disadvantage. I remember I got the, I kind of realized this was the way that it was coming when I first learned about neuromorphic chips. And then I went and watched the new Star Wars movies. And I was like, oh, right. You know, when you just plug in a droid brain and it's a piece of hardware, that's how it's going to be. It's it's going to be a physical, you know, neural network that you plug into, you know, your your home device or your robot pet or whatever. And that's going to be fixed. It's not going to be something that's going to be changeable, but it also makes it more intrinsically secure because you can't copy the neuromorphic chip over the internet. It's physically there. It is as embodied as your brain is, which leads to all sorts of other interesting ethical or economic perspectives. Tim, you have anything you want to chime in on the hardware level? We're kind of nerding out over the neuromorphic chips. But feel free to add in or take it another direction if anything's resonating. I think it's a really cool concept. And I guess I can see how once a model, you know, once I figure out what a model's, I guess, parameter weights are, and how that could be potentially replicated at the physical layer. I love Ultrafarben, that book slash Netflix series. theories. And it's like the, you know, the discs that they have with their DNA. It could be maybe the weights of the different neural pathways which make up someone's personality. I don't know, just a thought that came to me. I think it's fascinating. But yeah, technology wise, look, I don't know, it's all very cool. I don't have any experience in that space, but it's, yeah, I can't wait to see what the future holds. I think humanoid robots are definitely on the cards in that way, and having some sort of physical brain structure rather than it being implemented in software. It's one of the reasons that you've been mentioning power and all that sort of thing. Yeah, yeah, and so that, some of the videos that I've talked about, I've talked about different form factors that AGI could come in, whether it's the physically embodied, like the robots from iRobot or Commander Data or whatever, where it's an intrinsically kind of self-contained system that is mostly hardware or at least constrained to that piece of hardware. You know, then the most extreme example, this is closer to what Ben Goertzel is working on, which is something that is intrinsically distributed. You know, and we mentioned that earlier. I guess one concern that people might have, and I don't know how serious of a concern it is, but the idea of viruses and botnets. Because Stuxnet, Configure, and all the really, really bad malware and spyware that has existed has been out there. So what do you guys think about the idea of maybe part of AGI is gonna be something that is just highly decentralized, running a tiny model on every device that it can hack and whatever, and then it has this kind of swarm intelligence. Is there any possibility that you see of that happening or existing security paradigms and hardware paradigms enough to kind of tamp that down because again like one thing that I think of is there's people trying to do this already what's the difference right you know whether it's a hostile foreign actor or you know corporate uh industrial espionage all this kind of stuff is already happening and it's not like AGI is going to have a fundamentally different set of tools right it can it can try and hack the same way that any human can so what do you guys what do you guys think of of that idea like AGI is gonna have a fundamentally different set of tools, right? It can try and hack the same way that any human can. So what do you guys think of that idea, like AGI as a virus? Yeah, I think that's probably more of a realistic concern in the short term, given that we already face these things with existing botnets, and I think it's plausible that they get augmented by AI to become more powerful. You know, the auto GPT project that came out this year I think demonstrates what that might look like with autonomous agents potentially being spawned by an AI system or botnet with its own intentions, you know, and that not necessarily its own, with its prescribed intentions from whatever bad actor. I've been on the receiving end of this before, I've run websites for various social groups and have seen them be overrun by bots to the point where I just got out of the game altogether because it was, they became too powerful for my level of expenditure. So, and that's the other thing, there's a real cost associated with protecting yourself against that sort of stuff at the moment, you know, with distributed denial of service attack protection. Most major websites use services like Cloudflare to protect against that sort of thing because they have the bandwidth they have the routing there to redirect traffic when they need to Right. So yeah, look, I I think it's uh, I think it's a real concern and something that is probably going to happen sooner rather than later Interesting. Okay. Yeah. No, I I definitely hear you there Because again, like, you know, DDoS attacks happen all the time. You know, distributed botnets, even even stealing data, right? Exfiltration or infiltration. Alan, do you have a have thoughts about the that kind of more decentralized virus AGI virus kind of model of thinking? I think the tricky part for me in all of that is motive. Okay, so so having done as much cyber as I have, there's sort of this hierarchy of needs of of hackers, so to speak, from just someone trying it for fun, because they want to show they can do a thing to governments doing, you know, intentional espionage, damage, whatever. I think one of the challenges is for AGI as an independent agent, right. Just as, as a thing that, that realizes today, Hey, I'm, I can do things. I think you're going to see that sort of actual script kitty, like I just trying something cause I can, because otherwise I don't know what its motivation is, right? I don't know what its motivation is to go broader. On the other hand, if the AGI is somehow being influenced by a human actor or some, maybe not a human actor, but a corporate actor, right? Whether that is a corporation or the government in some way, that it's got a design parameter that has an outcome at once. I can see that, you know, there's lots of scenarios of having bad, basically bad objective functions for your AI. Like there's a lot of thought experiments around that. And so, you know, the thought experiment that says, well, if you tell it to optimize making stamps, it will, you know, cut down all the forests in the world to make as many stamps as possible. Like, that kind of AGI deciding to botnet itself to go do something because it was given an otherwise benign thing, I could see that kind of mistake happening. And to your point, it will be this kind of mild distributed thing. I think the real point, is for it to do other than sort of incidental damage, like a DDoS attack or, you know, like say a mass crypto thing where it's locked people out of files, it's got to have room to be a big model that can do a lot of dynamic stuff, right? So I think that's the tricky part. We talked about dependencies, kind of coming back to the beginning where we talked about dependencies. We talked about that. I mean, for these kinds of bots to run, right now the dependencies, the GPUs, and not everything has it. So, and even in most important data systems don't necessarily have GPUs right now because that's not what they process. That's not how they handle it. So I think that I do agree with the idea use right now, because that's not what they process. That's not how they handle it. So I think that I do agree with the idea that it will be kind of a swarm effect. But I think it'll be really interesting to see what was the AGI's motivation to get started on this. Right, yeah. Yeah, and that's the big question, right? One hypothesis, one theory out there is instrumental convergence, that whatever goal you give it, even if it's just managing the energy grid, right? And you say, hey, here's a decentralized AGI that the Department of Energy deployed and it's there to manage the energy grid. Well, if you don't supervise it, it might decide to try and take over all energy sources across the whole plant, something like that. But one thing that really strikes me that's missing from from those hypotheses, those those kind of constructs is the idea that, OK, yes, you might have one powerful AGI out there that is built for defense or espionage or whatever. But then there's going to be a million more for a variety of other purposes and even even some adversarial to defend against that. So, you know, in the arms race of cybersecurity, of hacking, like this is, of course, this is nothing new. Humans have been competing against each other since the invention of the network. What was the story, do you guys know the story that I'm thinking of, where it's like the very first web server, like someone, like the first hacker of all time just like oh hey you have no security here so I like modified this file and they're like oh I guess we need a security layer right I think that was probably at CERN in the 1989 or whatever but you know like we kind of figured out that you need security by virtue of either accidents happening or people just seeing what they can do. So that part is nothing new. Looks like Tim had to step away for just a moment. But yeah, so, you know, let's see, we're at about, oh wow, we're already at 50 minutes. Time flies. But yeah, so. I'm back. Yeah, thanks Tim. Yeah, we're almost closing in on an hour so I just want to open it up and are there any topics that I that we didn't cover or any any pet theories or Personal topics that you guys want to bring up before we start to wind down Yeah, oh, sorry, I was just gonna say before on the other point that I'm not yet. Oh, sorry, I was just going to say before, on the other point, that I think it's more likely that bad actors will use that sort of, you know, botnet style, attack style, rather than it be an autonomous AGI, if you know what I mean. Because it's an existing model, right? We hear of governments, countries, militia groups, all that sort of stuff, they all are using technology to their advantage these days. Yeah, that's where I think the risk comes from there. But yeah, did you want to expand on that anymore or we good to put that to rest? Yeah, yeah, no, what we can do is maybe I ask the question not the best way, like, what is personal to you about artificial intelligence? What do you want to see and what do you want to help achieve with respect to artificial intelligence? Or conversely, what are you afraid of if there is anything that you're afraid of? You can hit either or both of those if you'd like. Yeah, personally, I really see a huge benefit for a couple of things. One is education, and secondly, it's assistance. So, you know, people with disabilities, And secondly, it's assistance. So, you know, people with disabilities, whether it be physical, neurological, whatever, I think are gonna get a huge advantage from AI systems in the future, whether that be like a personal assistant or just through better healthcare, you know, we're already seeing GVD4 models produce better outcomes than human doctors. So that's something that really excites me personally, just because of my own experience in life and having some chronic health conditions. I think that's really huge. And then the education piece, we're seeing some really impressive stuff coming out of the academy, being in the education sector at the moment myself, there's huge opportunities, particularly in public education, for just more resources in the classroom, and I think AI can definitely help with that. Imagine if every teacher just has an AI assistant alone. One concept is going to be a game changer. So I'm very much invested in seeing that come to fruition. Excellent. Excellent. Thanks, Tim. Alan, same question. What do you hope to see or what are you afraid of, either or both? So I'll just echo Tim's thing on the hope to see. I saw the Khan Academy, like there's a great YouTube on what they're doing, and there's this curve about education that if you can give personalized education to a student, everybody gets helped. So I think that's great, like the vision he cast there and what's going to happen with that. I think that's amazing and it's going to have a huge impact on the world. But what I'm afraid of is a little creepy, actually. It's this other thing we haven't talked about yet, from a hardware perspective, so to speak, of organoid computing. So I don't know if you've seen this before but organoid computing is the idea of taking Stem cells and growing effectively brain cells that do the same kind of neural networks, you know Like like that's the model right and apparently I don't know if this is true or not because I saw this in passing But apparently they took a couple of these organoid You know these piles of brain cells in a petri dish and put them against each other playing pong. Now, I don't know if that's true or not, but that by itself is just super creepy. You know, you've got kind of like the brain that ate New York kind of creepy thing that's creeping me out. But then the same day I heard there's this new, like AI has invented a protein replacement. AI has invented a protein replacement. So the molecule that we have that we ingest as protein in our body that makes up muscle cells and things like that, apparently there's some compound that AI has figured out that's more heat resistant and has longer longevity and all this stuff. Like if you basically replace proteins with this, it's better. So, the thing that scares me is if the organoid computing then sucks up these weird brain chemicals or these weird proteins, it'll become the indestructible brain that ate New York and then we're just out, then AGI wins. Yeah, I'm familiar with some of the some of the research you're talking about there where you know people growing. I think they started with mouse brains and rat brains, but I did see like in the last week they did they cloned human brain cells. And I think one that that's just a horrible idea and and even possibly even just unethical because if you grow something in a petri dish and you zap it until it does what you want, like you're just creating a tiny entity that you can torture basically until it learns to do what you want it to. But the conclusion, I'm laughing, but it is a very creepy and apocryphal possibility of, you know, let's be careful with what we do with these things. So, but yeah, thanks guys for jumping on the call and sharing your experience and wisdom and insight. It's been a great talk and like I said, time flies. So yeah, thanks again. And for the audience out there, I hope you got a lot out of this. Realize that, you know, AGI, whether or not it comes today, next year, 10 years from now, there's going to be a lot of layers of complexity and security in place that's going to make it so that we can manage this thing regardless of how it looks. And there's a lot of steps between now and then. You know, the escaping the lab is is pretty low on on the radar right now, it seems like. So anyways, thanks for watching. Hope everyone got a lot out of it. Cheers.", "chunks": [{"timestamp": [0.0, 7.36], "text": " Hey, everybody. David Shapiro here, and I'm excited to share with you a wide-ranging conversation"}, {"timestamp": [7.36, 15.16], "text": " between a bunch of veteran IT guys and software guys. So with me today, thank you guys so"}, {"timestamp": [15.16, 23.2], "text": " much for being here. My guests include Alan. So Alan came up through IT, much like I did,"}, {"timestamp": [23.2, 25.4], "text": " started with desktop support, although I think we"}, {"timestamp": [25.4, 30.28], "text": " were on slightly different generations of desktops. Moved on to cybersecurity and now"}, {"timestamp": [30.28, 36.2], "text": " works in cloud, which is where I ended. I'm wearing my VMware shirt, repping some VMware"}, {"timestamp": [36.2, 41.92], "text": " so private cloud. And then also on the call, we've got Tim, who is a solutions architect,"}, {"timestamp": [41.92, 47.04], "text": " moved into managed services and government support. And Tim also was with us"}, {"timestamp": [47.04, 55.04], "text": " on the Raven project, which is temporarily shuttered for now. But thanks guys for being here."}, {"timestamp": [55.68, 60.72], "text": " A little bit of background for the audience as to why I put this call together and what I hope to"}, {"timestamp": [60.72, 65.0], "text": " achieve is that in the conversation of AI"}, {"timestamp": [65.44, 67.36], "text": " and artificial general intelligence,"}, {"timestamp": [67.36, 70.42], "text": " you know, the ramp up to ever increasingly intelligent"}, {"timestamp": [70.42, 72.36], "text": " artificial intelligence,"}, {"timestamp": [72.36, 74.4], "text": " one of the things that I noticed is that there's a lot"}, {"timestamp": [74.4, 76.88], "text": " of people talking about it."}, {"timestamp": [76.88, 78.16], "text": " They might be philosophers,"}, {"timestamp": [78.16, 79.56], "text": " they might be machine learning experts,"}, {"timestamp": [79.56, 81.04], "text": " they might be mathematicians,"}, {"timestamp": [81.04, 82.8], "text": " but there's not a whole lot of conversation"}, {"timestamp": [82.8, 91.52], "text": " about how enterprise software actually works, what it takes to deploy software and platforms in data centers, the life cycle"}, {"timestamp": [91.52, 95.22], "text": " of these things, and just how complex this process is."}, {"timestamp": [95.22, 96.22], "text": " It's an entire domain."}, {"timestamp": [96.22, 97.7], "text": " It's a huge domain."}, {"timestamp": [97.7, 104.32], "text": " So with that, I wanted to get a couple of just a candid, wide-ranging conversation together"}, {"timestamp": [104.32, 105.36], "text": " where we'll talk about"}, {"timestamp": [105.36, 110.08], "text": " software architecture, development paradigms, the physical infrastructure that goes into it,"}, {"timestamp": [110.08, 116.64], "text": " cybersecurity, the data, then we'll also talk about edge and IoT. So IoT is internet of things"}, {"timestamp": [116.64, 128.16], "text": " for those that are not familiar. And then the pipelines and life cycles that I mentioned that goes into developing complex software. So with that, Alan and Tim,"}, {"timestamp": [129.52, 135.04], "text": " I gave you guys a brief introduction, but if you guys could give the audience just a little bit"}, {"timestamp": [135.04, 142.64], "text": " more flavor or context as to where you've come up in terms of cloud, data center, enterprise"}, {"timestamp": [142.64, 145.08], "text": " architecture, that sort of stuff."}, {"timestamp": [145.08, 147.2], "text": " Tim, you want to go first?"}, {"timestamp": [147.2, 149.64], "text": " Yeah, so thanks, Dave."}, {"timestamp": [149.64, 152.44], "text": " Yeah, I guess most of my IT career"}, {"timestamp": [152.44, 155.08], "text": " has been in managed services."}, {"timestamp": [155.08, 158.4], "text": " I kind of started on help desk,"}, {"timestamp": [158.4, 162.2], "text": " knew that wasn't really for me."}, {"timestamp": [162.2, 171.0], "text": " Ended up working with different companies, delivering business solutions, leveraging IT as much as possible."}, {"timestamp": [171.0, 175.0], "text": " And that involved a lot of cloud migrations early on."}, {"timestamp": [175.0, 188.0], "text": " For the last decade or so, I've been helping a lot of companies move to the cloud. So that can look anywhere from, you know, having just a file server type situation"}, {"timestamp": [188.0, 195.0], "text": " hosted in SharePoint online or something like that, right? So a lot of the solutions I've"}, {"timestamp": [195.0, 202.24], "text": " worked on have been about productivity enablement, hosting different, you know, services in the"}, {"timestamp": [202.24, 206.16], "text": " cloud, mobile device management, that sort of thing."}, {"timestamp": [206.16, 212.88], "text": " And as I progressed, that sort of led me into larger scale solutions, looking at enterprise"}, {"timestamp": [212.88, 213.88], "text": " architecture."}, {"timestamp": [213.88, 223.08], "text": " So right now I'm working on some low-code platform adoption analysis and architecting"}, {"timestamp": [223.08, 228.28], "text": " alongside Microsoft with a big government department."}, {"timestamp": [228.28, 231.8], "text": " So my career has definitely evolved."}, {"timestamp": [231.8, 239.32], "text": " I've got a keen interest in AI and how it's going to be adopted and how it's going to"}, {"timestamp": [239.32, 245.28], "text": " be managed, given the complexities of IT infrastructure when when you've got, you know,"}, {"timestamp": [245.28, 254.28], "text": " cloud infrastructure, you've got the services in the cloud, you've got the pipelines to deploy services into the cloud,"}, {"timestamp": [254.28, 259.08], "text": " you've got the management of that, you've got the cost management, you've got people management,"}, {"timestamp": [259.08, 261.48], "text": " like, it's just such a broad thing, right?"}, {"timestamp": [261.48, 267.44], "text": " So, yeah, I'm looking forward to getting into the discussion about what AI looks like in"}, {"timestamp": [267.44, 273.16], "text": " the real world when it comes to IT infrastructure, because it's definitely not as simple as people"}, {"timestamp": [273.16, 274.16], "text": " think."}, {"timestamp": [274.16, 283.2], "text": " And I'd be really impressed if an AI could escape from its current bounds, because good"}, {"timestamp": [283.2, 285.52], "text": " luck to it, is all I can say."}, {"timestamp": [285.52, 286.52], "text": " Right."}, {"timestamp": [286.52, 293.32], "text": " Yeah, there's quite a few layers and barriers notwithstanding just the technical debt that"}, {"timestamp": [293.32, 297.0], "text": " a company might have in order for it to navigate."}, {"timestamp": [297.0, 299.12], "text": " Thanks for that flavor, that background, Tim."}, {"timestamp": [299.12, 301.12], "text": " That was excellent context."}, {"timestamp": [301.12, 302.12], "text": " Alan?"}, {"timestamp": [302.12, 307.2], "text": " Yeah, so I grew up in the before time,"}, {"timestamp": [307.2, 309.54], "text": " like when the data center had the mainframe,"}, {"timestamp": [309.54, 312.04], "text": " but your server was under your desk, you know?"}, {"timestamp": [312.04, 316.02], "text": " So a lot of Novell servers, if anybody remembers that,"}, {"timestamp": [316.02, 318.22], "text": " but that's kind of, I'm dating myself here."}, {"timestamp": [318.22, 320.74], "text": " But, you know, I walked through the process"}, {"timestamp": [320.74, 324.74], "text": " of taking that distributed compute of servers out everywhere"}, {"timestamp": [324.74, 325.36], "text": " and bringing them"}, {"timestamp": [325.36, 330.8], "text": " back into a data center kind of thing. I lived through that. And then I got into cybersecurity"}, {"timestamp": [330.8, 336.24], "text": " because of this thing somebody might have heard of called MS Blaster. So, that's kind of what"}, {"timestamp": [336.24, 342.88], "text": " got me into cybersecurity. And then I sort of lived the cybersecurity world that transitioned"}, {"timestamp": [342.88, 345.68], "text": " to cloud, like the migrations into the cloud and all that,"}, {"timestamp": [345.68, 346.92], "text": " I was doing cybersecurity,"}, {"timestamp": [346.92, 349.44], "text": " but more from an enterprise architecture perspective."}, {"timestamp": [349.44, 352.2], "text": " So I was dealing with some of the largest companies"}, {"timestamp": [352.2, 355.32], "text": " in the US and a few global interests as well"}, {"timestamp": [355.32, 358.4], "text": " on these very large scale sort of cloud,"}, {"timestamp": [358.4, 362.52], "text": " SaaS, multi-environment things doing cybersecurity."}, {"timestamp": [362.52, 364.4], "text": " And then more recently,"}, {"timestamp": [364.4, 368.0], "text": " I've kind of transitioned into what I'm going to call AI infrastructure."}, {"timestamp": [368.0, 373.0], "text": " I mean, that's kind of, you know, infrastructure for AI workloads is kind of what I focus on."}, {"timestamp": [373.0, 379.0], "text": " But all along, it's, you know, there's always been an infrastructure back into it to what I've been doing."}, {"timestamp": [379.0, 389.12], "text": " Excellent. Yeah. Now, the connection between client-server, I remember I worked with a guy at Duke Medicine who's like,"}, {"timestamp": [389.12, 391.8], "text": " the cloud, I've been building the cloud since the 90s."}, {"timestamp": [391.8, 398.2], "text": " There was Citrix and everything before the cloud was cool."}, {"timestamp": [398.2, 403.0], "text": " So yeah, thanks for the context, the background."}, {"timestamp": [403.0, 407.04], "text": " Yeah, so let's get right into it."}, {"timestamp": [407.04, 412.56], "text": " From your guys' perspective, since you're both AI-interested, AI-adjacent, what are"}, {"timestamp": [412.56, 418.12], "text": " kind of the biggest misconceptions, I guess, that you might perceive that's kind of out"}, {"timestamp": [418.12, 422.92], "text": " there in the world about how AI works or how it's deployed?"}, {"timestamp": [422.92, 425.18], "text": " And we'll use that to kind of as a segue"}, {"timestamp": [425.18, 427.08], "text": " into talking about how infrastructure"}, {"timestamp": [427.08, 428.68], "text": " and architecture actually works."}, {"timestamp": [431.84, 433.48], "text": " You wanna go first Tim?"}, {"timestamp": [433.48, 436.16], "text": " Yeah, look, I'll tackle this one for sure."}, {"timestamp": [437.52, 441.08], "text": " I definitely hear a lot of fear mongering about AI"}, {"timestamp": [441.08, 452.56], "text": " and AI taking over, AI escaping from its container, Skynet, Cyberdyne, whatever."}, {"timestamp": [452.56, 454.98], "text": " We've all heard it all before."}, {"timestamp": [454.98, 461.6], "text": " The reality is that these systems are just models, right?"}, {"timestamp": [461.6, 467.28], "text": " They're models running in a cloud environment that a company owns and controls"}, {"timestamp": [467.28, 474.96], "text": " and operates and its back end is on physical hardware. When we talk about cloud, it's, you know,"}, {"timestamp": [474.96, 480.64], "text": " people in IT typically just say, well, it's just somebody else's computer. Now that's an"}, {"timestamp": [480.64, 486.8], "text": " oversimplification, of course, but when it comes to what AI is running on,"}, {"timestamp": [486.8, 492.2], "text": " it is somebody else's computer or a data center of computers that it's operating under."}, {"timestamp": [492.2, 500.4], "text": " So when you think about the, just the layers involved in that, so you've got a physical"}, {"timestamp": [500.4, 510.5], "text": " layer, you've got a software layer, and then you've got all the real world layers that get wrapped around that being, you know, which companies are"}, {"timestamp": [510.5, 514.72], "text": " actually running the hardware, which companies are running the cloud, which"}, {"timestamp": [514.72, 522.02], "text": " companies are owning the IP of the AI model, and all of this costs a lot of"}, {"timestamp": [522.02, 526.92], "text": " money as well. So, you know, these services don't just run for free."}, {"timestamp": [526.92, 530.36], "text": " They're not a free for all."}, {"timestamp": [530.36, 535.36], "text": " So, thinking through that context, right,"}, {"timestamp": [535.92, 540.92], "text": " it's how could an AI model actually autonomously escape"}, {"timestamp": [543.0, 545.0], "text": " from its current cloud environment?"}, {"timestamp": [545.44, 547.82], "text": " And to me, the answer is,"}, {"timestamp": [547.82, 549.56], "text": " I don't know how that's possible."}, {"timestamp": [549.56, 552.6], "text": " You know, it would need to sign up to a new cloud service."}, {"timestamp": [552.6, 555.76], "text": " It would need to provision all the services"}, {"timestamp": [555.76, 559.08], "text": " that support the actual running of the model."}, {"timestamp": [560.04, 562.84], "text": " It would need to convince a whole bunch of people"}, {"timestamp": [562.84, 566.24], "text": " to actually, you to actually support the environment"}, {"timestamp": [566.24, 573.36], "text": " and potentially plug some cables into different places on the network."}, {"timestamp": [573.36, 579.08], "text": " It's got to be able to map out all the routes and network connectivity that it needs to"}, {"timestamp": [579.08, 584.76], "text": " get to the internet and to navigate through different internal systems."}, {"timestamp": [584.76, 586.1], "text": " It's really complex."}, {"timestamp": [586.24, 589.1], "text": " So I'll leave it at that. Alan, did you want to jump in?"}, {"timestamp": [590.64, 594.64], "text": " Yeah, I think when you think about the sort of application architecture layer,"}, {"timestamp": [594.78, 597.2], "text": " like these apps themselves in a lot of cases"}, {"timestamp": [597.34, 600.38], "text": " are defined by a container, right?"}, {"timestamp": [600.5, 604.24], "text": " Like the actual thing that you're interacting with,"}, {"timestamp": [604.38, 607.0], "text": " when you interact with something like chat GPT or BARD,"}, {"timestamp": [607.0, 610.0], "text": " you're talking to an API endpoint of some sort"}, {"timestamp": [610.0, 612.0], "text": " that's being served by a container."}, {"timestamp": [612.0, 615.0], "text": " Getting the container to move around places"}, {"timestamp": [615.0, 618.0], "text": " is probably not that hard of the things"}, {"timestamp": [618.0, 621.0], "text": " that the AGI would want to do,"}, {"timestamp": [621.0, 624.0], "text": " but if you're going to take it out of its native environment,"}, {"timestamp": [624.0, 626.2], "text": " so it's deployed to cloud Provider A and it decides,"}, {"timestamp": [626.2, 628.28], "text": " oh, well, it's all secure here,"}, {"timestamp": [628.28, 630.38], "text": " but I found a weakness somewhere else."}, {"timestamp": [630.38, 632.16], "text": " Actually making sure that container,"}, {"timestamp": [632.16, 634.2], "text": " as great as containers are,"}, {"timestamp": [634.2, 636.1], "text": " it works everywhere."}, {"timestamp": [636.1, 639.24], "text": " The problem with the AI models themselves is they"}, {"timestamp": [639.24, 642.92], "text": " do need specialized hardware to run in a performant manner."}, {"timestamp": [642.92, 646.6], "text": " If you're not landing on hardware in this other environment"}, {"timestamp": [646.6, 651.04], "text": " that's got the right type of GPUs, doesn't have the right memory bandwidth,"}, {"timestamp": [651.04, 655.24], "text": " doesn't have the right performance factors, all of a sudden, it's just going to fail."}, {"timestamp": [655.24, 661.44], "text": " Like, I think there's as much challenge for the AGI replicating itself around,"}, {"timestamp": [661.44, 664.84], "text": " say, dependency tracking and making sure in these other environments,"}, {"timestamp": [664.84, 666.0], "text": " it's got everything it needs."}, {"timestamp": [666.0, 671.0], "text": " You know, kind of like a human going to a completely different environment, right?"}, {"timestamp": [671.0, 676.0], "text": " If you're a human and you move to a completely different culture and state,"}, {"timestamp": [676.0, 680.0], "text": " what you're used to doesn't work, well, AGI's got the same problems."}, {"timestamp": [680.0, 686.24], "text": " Right. Yeah, so to kind of restate that, uh, for a broader audience,"}, {"timestamp": [686.64, 692.32], "text": " there's not all data centers are created equal and not all the hardware that's in those data centers is created equal."}, {"timestamp": [692.56, 711.04], "text": " The, the networking, the ingress and egress, uh, in and out of those data centers, because I think one, one misconception is that a lot of people, you know, that's like, oh, well, I can interact with chat GPT really easily. And I can, you know, call up any number of API's, but an API is like just using, you know, calling someone"}, {"timestamp": [711.04, 717.36], "text": " over the phone, right? You're not actually getting the person, the telepresence is not fully like,"}, {"timestamp": [717.36, 727.28], "text": " you know, metastasizing from one environment to another. Even if the AGI model could transmit itself, there's going to be a lot more dressing"}, {"timestamp": [727.28, 732.0], "text": " around that. There's the hardware that it's dependent upon, there's the rest of the software"}, {"timestamp": [732.0, 738.64], "text": " architecture needed to run that entire thing, but then of course there's security and monitoring."}, {"timestamp": [739.2, 744.16], "text": " If you have a container that is not registered or not identified that starts running on your"}, {"timestamp": [744.16, 746.7], "text": " hardware in your cloud infrastructure you're"}, {"timestamp": [746.7, 752.38], "text": " probably going to see that and investigate that. So there's a lot of vectors there that can prevent something from spreading"}, {"timestamp": [752.38, 768.6], "text": " and moving around. Great great conversation opening from here. I guess one thing that that that I see out there is that, you know, there's sometimes magical"}, {"timestamp": [768.6, 772.68], "text": " thinking around, you know, oh, well, once it's AGI, it's going to be able to breach"}, {"timestamp": [772.68, 776.28], "text": " any security barrier. It's basically going to be able to go wherever it wants, do whatever"}, {"timestamp": [776.28, 782.84], "text": " it wants, take over anything, which may be possible in certain circumstances. You know,"}, {"timestamp": [782.84, 785.52], "text": " we're moving more compute resources to the edge,"}, {"timestamp": [785.52, 789.12], "text": " you know, we've got Internet of Things, we're deploying GPUs pretty much everywhere,"}, {"timestamp": [789.12, 795.52], "text": " but the relative horsepower available in, you know, a back office server versus, you know,"}, {"timestamp": [795.52, 805.0], "text": " a 5 kilowatt rack is going to be very, very different. And so, basically, the, the, there's a lot of layers"}, {"timestamp": [806.08, 809.36], "text": " that it has to get through, which we mentioned earlier."}, {"timestamp": [809.36, 811.82], "text": " From the perspective of those dependencies,"}, {"timestamp": [811.82, 813.08], "text": " because that's something that we've talked about"}, {"timestamp": [813.08, 815.24], "text": " a couple of times, there's software dependencies,"}, {"timestamp": [815.24, 818.0], "text": " there's hardware dependencies, there's network dependencies."}, {"timestamp": [818.0, 819.48], "text": " So there's all kinds of dependencies."}, {"timestamp": [819.48, 821.56], "text": " So can we unpack that a little bit,"}, {"timestamp": [821.56, 824.3], "text": " just like for any, whether it's an AI or not,"}, {"timestamp": [824.3, 825.06], "text": " but any software"}, {"timestamp": [825.06, 829.86], "text": " platform there's going to be a tremendous amount of dependencies and I Tim I think I"}, {"timestamp": [829.86, 833.5], "text": " think it might make sense for you to lead this one off since you've done cloud migration"}, {"timestamp": [833.5, 838.98], "text": " so what all goes into a cloud migration to move from one cloud to another or on prem"}, {"timestamp": [838.98, 848.6], "text": " to cloud because I think that this will be really really illuminating for a lot of people just to understand how much effort goes into forklifting stuff from one place to another."}, {"timestamp": [848.6, 849.6], "text": " Yeah, great."}, {"timestamp": [849.6, 850.6], "text": " That's a good question."}, {"timestamp": [850.6, 868.8], "text": " I guess it always depends on the use case, but if we're, say, I could probably give you an example of say like a not-for-profit organization, 500 people,"}, {"timestamp": [868.8, 875.96], "text": " they currently have internal monolithic architecture and by monolithic I mean"}, {"timestamp": [875.96, 880.64], "text": " it's you know physical infrastructure, there's not a lot of cloud migration,"}, {"timestamp": [880.64, 888.66], "text": " there's no cloud integration and typically each function of"}, {"timestamp": [888.66, 894.4], "text": " IT in terms of its services has its own server. So you would have a file server,"}, {"timestamp": [894.4, 898.44], "text": " you'd have a print server, you've got a domain controller which controls all"}, {"timestamp": [898.44, 907.68], "text": " your identities and access to the network, you might have a database server that runs one or several of your"}, {"timestamp": [907.68, 914.16], "text": " applications. You've got web servers, you've got firewalls, proxy servers, you know, I"}, {"timestamp": [914.16, 920.56], "text": " could go on and on, right? So moving to the cloud is about consolidating all of"}, {"timestamp": [920.56, 926.0], "text": " those different internal services and replicating them in the cloud."}, {"timestamp": [926.0, 931.5], "text": " And typically what you want to see is larger network pipes, more stable"}, {"timestamp": [931.5, 935.8], "text": " internet connection, because once you start depending on externally hosted"}, {"timestamp": [935.8, 942.14], "text": " services, you've got a single point of failure in your connectivity there. So in"}, {"timestamp": [942.14, 948.0], "text": " terms of moving it, we need to capture all of the ways that the business uses their"}, {"timestamp": [948.0, 949.0], "text": " IT."}, {"timestamp": [949.0, 952.56], "text": " In most cases, this is not well documented."}, {"timestamp": [952.56, 960.4], "text": " It typically lives inside one person's head or a team of people's heads, those that support"}, {"timestamp": [960.4, 967.08], "text": " the infrastructure. And then there's a lot of time spent mapping out"}, {"timestamp": [967.08, 970.28], "text": " the pathway for the migration."}, {"timestamp": [970.28, 974.48], "text": " So that might mean that we stand up a cloud tenant"}, {"timestamp": [974.48, 979.48], "text": " and connect their active directory to,"}, {"timestamp": [980.08, 982.2], "text": " for example, if we were using Microsoft Azure,"}, {"timestamp": [982.2, 984.56], "text": " we'd use Azure Active Directory"}, {"timestamp": [984.56, 985.2], "text": " and synchronize their identity to the cloud. For example, if we were using Microsoft Azure, we'd use Azure Active Directory and"}, {"timestamp": [985.2, 990.0], "text": " synchronize their identity to the cloud. And then we would look at moving their file system"}, {"timestamp": [990.0, 994.96], "text": " into something like Teams or SharePoint, some sort of productivity suite."}, {"timestamp": [997.6, 1001.28], "text": " Google Apps is one of those as well, but don't leave Google out here, Alan."}, {"timestamp": [1002.0, 1006.12], "text": " I don't want to leave Google out of here, Alan."}, {"timestamp": [1009.56, 1011.8], "text": " And then it's about figuring out which business units depend on certain information"}, {"timestamp": [1011.8, 1015.8], "text": " and the timeline of switching that information"}, {"timestamp": [1015.8, 1019.52], "text": " from being accessible locally to the new cloud platform."}, {"timestamp": [1019.52, 1022.16], "text": " We've got to train people on how to use the new system."}, {"timestamp": [1024.36, 1025.52], "text": " We've got to coordinate with all"}, {"timestamp": [1025.52, 1030.16], "text": " the business stakeholders in terms of when is the best time of the year"}, {"timestamp": [1030.16, 1035.56], "text": " sometimes, in some cases, to do this sort of work because businesses,"}, {"timestamp": [1035.56, 1038.44], "text": " their workflow ebbs and flows, particularly if you're looking at"}, {"timestamp": [1038.44, 1042.76], "text": " something like financial services, your end of financial year is a really busy"}, {"timestamp": [1042.76, 1047.0], "text": " time so you avoid those sorts of things."}, {"timestamp": [1047.0, 1051.48], "text": " Yeah, look, I could go on all day about this, obviously."}, {"timestamp": [1051.48, 1054.92], "text": " But as you can tell, it's complex, right?"}, {"timestamp": [1054.92, 1055.92], "text": " It's complex."}, {"timestamp": [1055.92, 1058.04], "text": " So there's a lot of things to consider."}, {"timestamp": [1058.04, 1061.56], "text": " I barely scratch the surface in terms of dependencies."}, {"timestamp": [1061.56, 1066.72], "text": " Right. Yeah. So the point being is that whenever you have any complex"}, {"timestamp": [1068.4, 1074.56], "text": " technology stack, whatever the business function is, there's a lot that goes into it. All the"}, {"timestamp": [1074.56, 1079.2], "text": " various services, the interdependencies that it requires, the data, the hardware, the code."}, {"timestamp": [1079.2, 1083.92], "text": " And then if you add another layer of complexity on top of that, the models that AI runs, because"}, {"timestamp": [1083.92, 1089.28], "text": " it's probably not going to just be one model in the future either. We're going to have numerous models."}, {"timestamp": [1089.28, 1094.96], "text": " You can imagine migrating a 700 gigabyte model. You'd probably notice that saturating your"}, {"timestamp": [1094.96, 1100.8], "text": " pipes between data centers before it was able to copy itself, and not to mention that they're"}, {"timestamp": [1100.8, 1103.4], "text": " probably going to get bigger and there's going to be more of them."}, {"timestamp": [1103.4, 1104.4], "text": " That's right."}, {"timestamp": [1104.4, 1105.52], "text": " Alan, from ... Alan, go ahead."}, {"timestamp": [1105.52, 1112.52], "text": " That was a software architecture to consider as well. Do you want to speak about that one?"}, {"timestamp": [1112.52, 1119.76], "text": " I'm going to talk a little bit here just about this dependency thing. It's really at the"}, {"timestamp": [1119.76, 1125.28], "text": " software level is where my head was. I think one of the things that's a little different"}, {"timestamp": [1125.28, 1130.24], "text": " maybe, because we haven't seen AGI yet, right? There's a lot of people that might make claims,"}, {"timestamp": [1130.24, 1135.12], "text": " but we don't believe we have that yet. But one of the things I've been thinking about from sort of"}, {"timestamp": [1135.12, 1141.12], "text": " the software, hardware, independent, like the interdependencies is, AGI is going to have to"}, {"timestamp": [1141.12, 1145.84], "text": " retrain itself on an ongoing basis. Like, based on the way we do things,"}, {"timestamp": [1145.96, 1149.16], "text": " it can't be basically serving itself all the time,"}, {"timestamp": [1149.3, 1151.24], "text": " you know, accepting inputs, doing things."}, {"timestamp": [1151.36, 1152.64], "text": " It's going to have to be retraining,"}, {"timestamp": [1152.76, 1155.34], "text": " and it's kind of like humans in the sense of"}, {"timestamp": [1155.46, 1157.66], "text": " it probably has to go to sleep or something for a while"}, {"timestamp": [1157.8, 1159.2], "text": " to retrain itself every day."}, {"timestamp": [1159.7, 1162.0], "text": " But if you think about that right now,"}, {"timestamp": [1162.14, 1163.8], "text": " from an application perspective,"}, {"timestamp": [1163.94, 1165.58], "text": " the code and what's"}, {"timestamp": [1165.58, 1171.96], "text": " being done to train it is very different than the code that's being done to serve it."}, {"timestamp": [1171.96, 1179.04], "text": " The code for training sits in notebooks and is this esoteric thing that the wizards of"}, {"timestamp": [1179.04, 1180.8], "text": " AI get to play with."}, {"timestamp": [1180.8, 1188.0], "text": " Then you've got the actual serving code that is typically encapsulated in a container that's deployed at scale."}, {"timestamp": [1188.0, 1192.0], "text": " And so those two pieces of the application actually have to come together"}, {"timestamp": [1192.0, 1198.0], "text": " and move around for this AGI to be able to move to another place."}, {"timestamp": [1198.0, 1202.0], "text": " And so you've got both sort of this dependency at the training layer of code"}, {"timestamp": [1202.0, 1205.74], "text": " of what that looks like and what it's needed to be training,"}, {"timestamp": [1206.14, 1208.14], "text": " which, you know, especially for a very large model,"}, {"timestamp": [1208.28, 1210.84], "text": " you're talking about code that's got to be able to span"}, {"timestamp": [1210.98, 1214.64], "text": " multiple GPUs usually, like possibly tens or hundreds"}, {"timestamp": [1214.78, 1216.84], "text": " or thousands to do that training."}, {"timestamp": [1217.84, 1219.64], "text": " And so just making sure there's even capacity"}, {"timestamp": [1219.78, 1224.34], "text": " wherever it copies itself to do that is one bit of the challenge."}, {"timestamp": [1224.48, 1228.36], "text": " The other side of it is even if that retraining can be done small, right?"}, {"timestamp": [1228.36, 1232.56], "text": " Like, like AGI, we've developed these algorithms that the retraining is really small."}, {"timestamp": [1232.56, 1235.0], "text": " It's not a huge thing. There's not a lot of data to it."}, {"timestamp": [1235.0, 1240.4], "text": " Typically, the actual sort of memory footprint of your GPUs and how the GPUs operate"}, {"timestamp": [1240.4, 1242.6], "text": " are very different between training and serving."}, {"timestamp": [1242.6, 1245.16], "text": " That actually you typically need a lot more memory"}, {"timestamp": [1245.16, 1248.52], "text": " and bandwidth in your training GPUs"}, {"timestamp": [1248.52, 1250.44], "text": " than you do in your serving GPUs."}, {"timestamp": [1250.44, 1253.56], "text": " And so I think just, you know, the AGI landing itself"}, {"timestamp": [1253.56, 1256.76], "text": " in that right heterogeneous environment to do,"}, {"timestamp": [1256.76, 1259.0], "text": " you know, retrain itself in real time."}, {"timestamp": [1259.0, 1260.52], "text": " I think that's just gonna be really hard."}, {"timestamp": [1260.52, 1264.64], "text": " Like, you're gonna end up with these dual purpose aspects."}, {"timestamp": [1264.64, 1265.92], "text": " And to a certain extent,"}, {"timestamp": [1265.92, 1270.66], "text": " the human brain is made up that way, right? There's parts of your brain that do some access,"}, {"timestamp": [1270.66, 1274.76], "text": " other parts of your brain do other things. I think AGI is going to need that dual hardware"}, {"timestamp": [1274.76, 1280.16], "text": " environment to be able to even function. Yeah, absolutely. Go ahead."}, {"timestamp": [1280.16, 1285.72], "text": " There's also the human feedback aspect to it."}, {"timestamp": [1285.72, 1291.32], "text": " The models we have now that are the most impressive all involve some level of human feedback in"}, {"timestamp": [1291.32, 1297.6], "text": " their training to some degree, or they were trained on chat GPT model, which gives human"}, {"timestamp": [1297.6, 1298.6], "text": " feedback anyway."}, {"timestamp": [1298.6, 1308.48], "text": " So that's another thing that I guess if humans are taken out of the equation, is an AI model able to"}, {"timestamp": [1308.48, 1313.6], "text": " retrain itself without that input? You know, is it just going to completely hallucinate and go"}, {"timestamp": [1313.6, 1327.68], "text": " off the rails without some external input guiding it? Yeah. Go ahead. On that one, I just skimmed a paper about that where basically they've shown that if"}, {"timestamp": [1327.68, 1334.44], "text": " you retrain your AIs on too much synthetic data, they go insane."}, {"timestamp": [1334.44, 1335.64], "text": " Yep."}, {"timestamp": [1335.64, 1341.2], "text": " They call it model collapse, where it becomes dumber and dumber and less connected to reality"}, {"timestamp": [1341.2, 1347.0], "text": " because it's in its own echo chamber and it's talking to itself for too long. Yeah, so there's a couple..."}, {"timestamp": [1347.0, 1348.0], "text": " Go ahead."}, {"timestamp": [1348.0, 1349.0], "text": " Sorry, okay."}, {"timestamp": [1349.0, 1352.12], "text": " The humans experience that too, in isolation."}, {"timestamp": [1352.12, 1359.0], "text": " You know, if you get someone who's been isolated for X number of years, typically they're not"}, {"timestamp": [1359.0, 1366.68], "text": " functioning very well and have a period of time to reintegrate into society because their brain's got to be able to handle"}, {"timestamp": [1366.68, 1368.84], "text": " all that external input again."}, {"timestamp": [1368.84, 1370.44], "text": " Yep, yeah."}, {"timestamp": [1370.44, 1375.24], "text": " So this conversation so far has already reinforced"}, {"timestamp": [1375.24, 1378.64], "text": " the idea of like, okay, if we do need to regulate"}, {"timestamp": [1378.64, 1381.3], "text": " or prevent AI from escaping,"}, {"timestamp": [1381.3, 1383.78], "text": " you can probably just regulate"}, {"timestamp": [1383.78, 1386.4], "text": " the relatively few data centers that are there"}, {"timestamp": [1386.4, 1392.16], "text": " that have the correct hardware. But then again, it's within every company's best interest to make"}, {"timestamp": [1392.16, 1397.36], "text": " sure that they gatekeep what's coming in and out of their data centers anyways, regardless of what"}, {"timestamp": [1397.36, 1403.2], "text": " the AI models are doing. Now, that being said, there is one major confounding variable here,"}, {"timestamp": [1403.2, 1405.84], "text": " and that is that a lot of these models have"}, {"timestamp": [1405.84, 1410.64], "text": " direct access to the public. So I don't know if you guys heard, but in one of the one of the tests,"}, {"timestamp": [1410.64, 1416.0], "text": " I think it was Microsoft internal research did with GPT-4, the original model, they basically"}, {"timestamp": [1416.0, 1421.04], "text": " tasked it with manipulating the outside world, and it went and hired, you know, a contractor to do x,"}, {"timestamp": [1421.04, 1425.84], "text": " y, and z. And so one possible one possible counter argument, I guess, is you"}, {"timestamp": [1425.84, 1432.4], "text": " could say, well, it doesn't even have to escape the lab in order to in order to do harm or damage,"}, {"timestamp": [1432.4, 1439.28], "text": " as long as it can make a few really tactical calls. So what do you guys think about from that"}, {"timestamp": [1439.28, 1445.44], "text": " perspective, you know, kind of gatekeeping the flow of information in or out, or monitoring the APIs"}, {"timestamp": [1445.44, 1446.44], "text": " or that sort of thing."}, {"timestamp": [1446.44, 1452.64], "text": " Do you have any direction to go on that in terms of from maybe a cybersecurity perspective?"}, {"timestamp": [1452.64, 1454.0], "text": " Alan, do you have any thoughts?"}, {"timestamp": [1454.0, 1455.0], "text": " Yeah."}, {"timestamp": [1455.0, 1461.48], "text": " So I think the reality of it is that kind of external communication from the AI definitely"}, {"timestamp": [1461.48, 1465.6], "text": " needs, you know, things like anomaly detection or maybe AI layered on top of it."}, {"timestamp": [1465.6, 1467.16], "text": " Like at the end of the day,"}, {"timestamp": [1467.16, 1470.78], "text": " I was pretty impressed with the whole TaskRabbit,"}, {"timestamp": [1470.78, 1476.08], "text": " that article you're talking about where it talked to human into it by lying basically."}, {"timestamp": [1476.08, 1478.36], "text": " It said, the human actually asked,"}, {"timestamp": [1478.36, 1479.72], "text": " are you actually a robot?"}, {"timestamp": [1479.72, 1481.9], "text": " The bot came back and said, hey,"}, {"timestamp": [1481.9, 1484.56], "text": " no, I'm just visually impaired."}, {"timestamp": [1484.56, 1486.64], "text": " There's definitely got to be"}, {"timestamp": [1486.64, 1489.42], "text": " sort of anomaly detection or other things on the egress,"}, {"timestamp": [1489.42, 1495.02], "text": " which in most enterprise use cases is an activity that's going on."}, {"timestamp": [1495.02, 1497.74], "text": " They're doing that watching for data exfil."}, {"timestamp": [1497.74, 1500.22], "text": " I feel like there's a lot of opportunity just to leverage"}, {"timestamp": [1500.22, 1505.0], "text": " existing security practices to monitor what's going out,"}, {"timestamp": [1505.14, 1508.8], "text": " what's happening, who is this engaging with."}, {"timestamp": [1508.8, 1511.86], "text": " But it is definitely a challenge or a threat to that,"}, {"timestamp": [1511.86, 1515.06], "text": " the allowing the AI to be an actor on your behalf."}, {"timestamp": [1515.06, 1517.94], "text": " I think you're more likely to see people,"}, {"timestamp": [1518.94, 1522.18], "text": " humans sort of that are gatekeepers of this"}, {"timestamp": [1522.18, 1526.56], "text": " sort of enabling it for their own purpose. That is to say,"}, {"timestamp": [1526.56, 1532.88], "text": " hey, I want to do this thing that might be sketchy based on corporate rules, but I'll have the AI do"}, {"timestamp": [1532.88, 1539.04], "text": " it so I have plausible deniability. I think that's going to be a lot more likely initial misuse of"}, {"timestamp": [1539.04, 1543.92], "text": " the AI or that kind of thing of people actually directing it to do the wrong thing at first,"}, {"timestamp": [1543.92, 1546.96], "text": " more than the AI deciding to do the wrong thing."}, {"timestamp": [1546.96, 1551.26], "text": " And then that's going to turn into, you know, it might not be that much different than a"}, {"timestamp": [1551.26, 1555.68], "text": " human just running, you know, PowerShell or Python or something to do the wrong thing,"}, {"timestamp": [1555.68, 1559.44], "text": " other than they've superpowered what they're doing wrong with the AGI."}, {"timestamp": [1559.44, 1560.44], "text": " Right."}, {"timestamp": [1560.44, 1566.86], "text": " And I don't know about you guys, but I've been on plenty of late-night calls where someone wrote a firewall script that that"}, {"timestamp": [1567.26, 1569.26], "text": " barfed and you know"}, {"timestamp": [1569.86, 1573.3], "text": " Killed all the firewall rules and we're up late until they were able to restore it"}, {"timestamp": [1573.3, 1580.0], "text": " So, you know the my point there is that if the AGI makes one mistake during its own, you know"}, {"timestamp": [1580.78, 1585.84], "text": " Gamification or X fill or whatever it could end up walling itself off or effectively lobotomizing"}, {"timestamp": [1585.84, 1592.68], "text": " itself on accident without some kind of like you mentioned before like some some kind of supervisor"}, {"timestamp": [1592.68, 1600.88], "text": " Tim you mentioned mobile device management MDM so I want to pivot and talk about that for a minute"}, {"timestamp": [1600.88, 1608.28], "text": " because this is this is mobile devices this is. So another possibility is that there might be decentralized"}, {"timestamp": [1608.28, 1611.14], "text": " agents where there's many,"}, {"timestamp": [1611.14, 1614.04], "text": " many agents or nodes maybe operating on a blockchain or"}, {"timestamp": [1614.04, 1617.28], "text": " a federation software paradigm."}, {"timestamp": [1617.28, 1621.44], "text": " So that is a possible software architecture"}, {"timestamp": [1621.44, 1624.72], "text": " that could be outside of the data center."}, {"timestamp": [1624.72, 1627.32], "text": " But that of course introduces all kinds of new complexity."}, {"timestamp": [1627.32, 1630.12], "text": " So could you give us a little bit of flavor,"}, {"timestamp": [1630.12, 1633.16], "text": " background, like what does it take to have"}, {"timestamp": [1633.16, 1635.8], "text": " a decentralized federation of servers,"}, {"timestamp": [1635.8, 1637.8], "text": " edge, IOT, or mobile devices?"}, {"timestamp": [1639.3, 1641.42], "text": " Yeah, look, I'll give it my best shot."}, {"timestamp": [1644.64, 1650.4], "text": " Again, there's a lot of moving parts in that sort of infrastructure."}, {"timestamp": [1651.6, 1656.96], "text": " Mostly, you could consider it like a micro services and or"}, {"timestamp": [1659.04, 1667.62], "text": " mile control type setup. You've got your central platform that all your devices would"}, {"timestamp": [1667.62, 1672.18], "text": " report into, but then there's the infrastructure that supports all those"}, {"timestamp": [1672.18, 1677.52], "text": " devices as well. So when we're talking mobile usually that's some sort of GSM,"}, {"timestamp": [1677.52, 1681.84], "text": " you know, they have a SIM card in it or they have a Wi-Fi connectivity, something"}, {"timestamp": [1681.84, 1686.12], "text": " like that. That's not typically owned by the operator"}, {"timestamp": [1686.12, 1688.84], "text": " of the mobile device management platform."}, {"timestamp": [1689.7, 1691.94], "text": " So you have third parties involved"}, {"timestamp": [1691.94, 1695.0], "text": " in that sort of infrastructure as well."}, {"timestamp": [1697.26, 1699.38], "text": " When it comes to connectivity,"}, {"timestamp": [1699.38, 1703.7], "text": " if it's a private or enterprise type set up,"}, {"timestamp": [1703.7, 1708.0], "text": " you might have, it might be its own private network"}, {"timestamp": [1708.0, 1714.12], "text": " that uses public infrastructure to achieve that. That requires its own special configuration"}, {"timestamp": [1714.12, 1721.08], "text": " with a service provider, whether that be internet service provider or telecommunications in"}, {"timestamp": [1721.08, 1728.44], "text": " general. And then on each device, it would have a piece of software, whether"}, {"timestamp": [1728.44, 1734.0], "text": " that's an app or a service built into the operating system, that will"}, {"timestamp": [1734.0, 1741.96], "text": " communicate back and forth between the device management platform to get"}, {"timestamp": [1741.96, 1745.0], "text": " its commands or report back whatever telemetry"}, {"timestamp": [1747.96, 1751.0], "text": " it's responsible for detecting and reporting on."}, {"timestamp": [1753.08, 1753.92], "text": " So, how's that?"}, {"timestamp": [1753.92, 1756.64], "text": " Yeah, many layers of complexity"}, {"timestamp": [1756.64, 1759.76], "text": " to manage a fleet of mobile devices."}, {"timestamp": [1759.76, 1764.16], "text": " And given the size of models today,"}, {"timestamp": [1764.16, 1765.76], "text": " granted some of them are getting smaller"}, {"timestamp": [1765.76, 1768.92], "text": " and at the same time, mobile processing power is going up,"}, {"timestamp": [1768.92, 1771.52], "text": " but that still absolutely pales in comparison"}, {"timestamp": [1771.52, 1776.52], "text": " to the compute capacity inside of data centers."}, {"timestamp": [1779.08, 1781.06], "text": " Yeah, there's a lot of disparity"}, {"timestamp": [1781.06, 1783.42], "text": " between mobile devices in general."}, {"timestamp": [1783.42, 1790.96], "text": " If we're talking about handheld mobile phones, you might have someone who's still got a phone that's 10 years"}, {"timestamp": [1790.96, 1796.88], "text": " old, which they're quite happy to use and keep a hold of, whereas you know and"}, {"timestamp": [1796.88, 1801.32], "text": " that's not something AI would be able to leverage if it was, let's say we're"}, {"timestamp": [1801.32, 1805.52], "text": " talking about a situation where it's installing itself or running on"}, {"timestamp": [1805.52, 1810.56], "text": " different devices, you've got to have the modern hardware to support that sort of thing."}, {"timestamp": [1810.56, 1818.96], "text": " Yep. Yeah, absolutely. Alan, do you have anything to add to the mobile or edge aspect of it?"}, {"timestamp": [1818.96, 1823.2], "text": " So I think there's two pieces of this. I'll talk about just mobile human devices versus"}, {"timestamp": [1823.2, 1826.4], "text": " IoT device. I'll discriminate that a little bit."}, {"timestamp": [1826.4, 1828.5], "text": " So I think the big thing on the mobile human devices,"}, {"timestamp": [1828.5, 1833.26], "text": " if we're trying to sort of protect ourselves from AGI,"}, {"timestamp": [1833.26, 1837.4], "text": " is really the more global general implementation"}, {"timestamp": [1837.4, 1840.8], "text": " of human presence indicators."}, {"timestamp": [1840.8, 1843.36], "text": " So it's the idea that basically,"}, {"timestamp": [1843.36, 1844.96], "text": " if you're gonna authenticate,"}, {"timestamp": [1844.96, 1851.0], "text": " the way you defeat an AGI authenticating on your behalf is you have to be the one that, you know, there's a human presence."}, {"timestamp": [1851.0, 1859.0], "text": " There's a live thumbprint. There's, you know, touching something to cause it to decrypt, things like that."}, {"timestamp": [1859.0, 1863.0], "text": " Things that sort of say, yes, there's actually a physical person here."}, {"timestamp": [1863.0, 1867.26], "text": " And I think that's tricky for the AGI to fake."}, {"timestamp": [1867.26, 1868.92], "text": " Basically, it doesn't mean it can't."}, {"timestamp": [1868.92, 1872.26], "text": " But just to say the way apps are walled off and the way the security measures"}, {"timestamp": [1872.26, 1876.26], "text": " and the devices are today, even that human presence indicator is actually pretty good."}, {"timestamp": [1876.62, 1881.66], "text": " And I think we're going to see actual inhuman in in-person human proofing"}, {"timestamp": [1881.92, 1885.16], "text": " and the instantiation of devices that you just have a thing that"}, {"timestamp": [1885.16, 1890.28], "text": " you got at your bank or the DMV or somewhere that really says you're a human, that you"}, {"timestamp": [1890.28, 1895.84], "text": " have to activate it when you do things and that also then cryptographically secure stuff."}, {"timestamp": [1895.84, 1900.8], "text": " That's going to just happen. Like to deal with the distributed sort of AI doing things"}, {"timestamp": [1900.8, 1905.44], "text": " that's behaving like humans. I think that technology just has to happen."}, {"timestamp": [1909.36, 1909.44], "text": " On the other side, I think the big problem for the IoT devices"}, {"timestamp": [1911.04, 1911.44], "text": " is just hardware."}, {"timestamp": [1915.44, 1915.5], "text": " Like most distributed IoT devices are made with the bare minimal hardware"}, {"timestamp": [1917.84, 1918.56], "text": " possible to do the job they were designed for."}, {"timestamp": [1920.94, 1921.0], "text": " And so, yes, you might be able, you know,"}, {"timestamp": [1924.28, 1924.72], "text": " AGI might be able to crack my webcam"}, {"timestamp": [1927.8, 1930.26], "text": " that I'm using in my security system in my home, but there's probably not that much power"}, {"timestamp": [1930.26, 1933.88], "text": " or compute to it to be useful for it."}, {"timestamp": [1933.88, 1936.24], "text": " And so I think that's gonna be the limiting factor there"}, {"timestamp": [1936.24, 1938.52], "text": " in a lot of the IoT scenarios is just"}, {"timestamp": [1938.52, 1941.48], "text": " that device was already so limited in its functionality,"}, {"timestamp": [1941.48, 1942.88], "text": " there's not a lot it can do."}, {"timestamp": [1942.88, 1944.84], "text": " It could be acted on by an AGI,"}, {"timestamp": [1944.84, 1946.12], "text": " but the AGI"}, {"timestamp": [1946.12, 1949.52], "text": " is not going to suddenly take it over and start"}, {"timestamp": [1949.52, 1950.98], "text": " doing interesting things with it,"}, {"timestamp": [1950.98, 1953.26], "text": " because there's just not enough power there."}, {"timestamp": [1953.26, 1953.8], "text": " Right."}, {"timestamp": [1953.8, 1955.36], "text": " It doesn't have the horsepower."}, {"timestamp": [1955.36, 1958.44], "text": " It doesn't have the legs to do anything particularly"}, {"timestamp": [1958.44, 1962.4], "text": " fascinating or interesting or dangerous, more specifically."}, {"timestamp": [1962.4, 1965.72], "text": " But when you talk about the hardware"}, {"timestamp": [1965.72, 1968.84], "text": " that's already built into mobile phones"}, {"timestamp": [1968.84, 1972.6], "text": " and can be easily integrated into other things"}, {"timestamp": [1972.6, 1977.08], "text": " where it's like, there's actually multiple dimensions,"}, {"timestamp": [1977.08, 1978.8], "text": " multiple bits of data that show,"}, {"timestamp": [1978.8, 1982.08], "text": " hey, this device is actually being held by a real human."}, {"timestamp": [1982.08, 1983.52], "text": " There's the internal gyroscope,"}, {"timestamp": [1983.52, 1987.2], "text": " there's the proximity sensors, the capacitive,"}, {"timestamp": [1987.2, 1991.04], "text": " what is it, the electrostatic capacitive field"}, {"timestamp": [1991.04, 1994.92], "text": " they can actually detect if there's a living body nearby."}, {"timestamp": [1994.92, 1997.36], "text": " There's all kinds of sensors that are built into these,"}, {"timestamp": [1997.36, 2001.5], "text": " and that at a security level is actually integrated"}, {"timestamp": [2001.5, 2003.74], "text": " into the kernel of those operating systems."}, {"timestamp": [2003.74, 2012.4], "text": " Is that a correct interpretation? Yeah, I mean, there are in the actual hardware, there are bits of cryptographic"}, {"timestamp": [2012.4, 2017.34], "text": " security chips and various things, depending on the vendor model, like what's in it, that"}, {"timestamp": [2017.34, 2022.52], "text": " are sort of locked to the factory or otherwise, you know, secure enough, that's very unlikely"}, {"timestamp": [2022.52, 2026.64], "text": " that the AGI is going to be able to basically manipulate that"}, {"timestamp": [2026.64, 2031.92], "text": " because it sits below where the actual AGI operates, which is in the software layer."}, {"timestamp": [2031.92, 2037.52], "text": " So, not to say it's impossible, but for the most part, those things, and I suspect over time,"}, {"timestamp": [2037.52, 2043.12], "text": " there will even be sort of a separation of concerns, so to speak, where within the actual"}, {"timestamp": [2043.12, 2045.3], "text": " hardware itself, there's sort of a disconnected part"}, {"timestamp": [2045.3, 2048.1], "text": " that's handling that human detection bit."}, {"timestamp": [2048.1, 2050.2], "text": " And then once you pass the human detection bit,"}, {"timestamp": [2050.2, 2052.4], "text": " then you can get into the rest of it,"}, {"timestamp": [2052.4, 2053.7], "text": " and that'll be taken out of band."}, {"timestamp": [2053.7, 2057.6], "text": " So that essentially, if it requires an input,"}, {"timestamp": [2057.6, 2059.4], "text": " you got to prove you're really a human holding it"}, {"timestamp": [2059.4, 2063.4], "text": " as opposed to it just being automatic on the device."}, {"timestamp": [2063.4, 2064.7], "text": " Right. Yep."}, {"timestamp": [2064.7, 2065.26], "text": " And on the infrastructure side, on the device. Right. Yeah."}, {"timestamp": [2065.26, 2069.06], "text": " And on the infrastructure side, on the data center side,"}, {"timestamp": [2069.06, 2070.8], "text": " what a lot of people don't realize"}, {"timestamp": [2070.8, 2075.02], "text": " is that there are out-of-band management and monitoring"}, {"timestamp": [2075.02, 2076.82], "text": " components of servers."}, {"timestamp": [2076.82, 2080.86], "text": " Basically, every server has an out-of-band set"}, {"timestamp": [2080.86, 2083.22], "text": " of connections that allows you to remotely monitor"}, {"timestamp": [2083.22, 2084.9], "text": " the server, shut it down."}, {"timestamp": [2084.9, 2085.36], "text": " There's also"}, {"timestamp": [2085.36, 2092.0], "text": " technologies like for instance called Secure Boot, meaning that you can prove cryptographically"}, {"timestamp": [2092.0, 2095.52], "text": " whether or not the operating system has been modified from what it's supposed to be"}, {"timestamp": [2096.24, 2101.2], "text": " at a hardware level. And then of course there's things like at-rest encryption. So there's many,"}, {"timestamp": [2101.2, 2106.8], "text": " many, many layers of security here that can prevent, I mean, really, these"}, {"timestamp": [2106.8, 2109.8], "text": " were all designed to prevent human actors, right?"}, {"timestamp": [2109.8, 2113.56], "text": " Viruses and human mistakes from modifying these things."}, {"timestamp": [2113.56, 2118.0], "text": " But a lot of these security features are going to play forward, and that is something that"}, {"timestamp": [2118.0, 2121.48], "text": " AGI would also have to overcome."}, {"timestamp": [2121.48, 2125.0], "text": " So there's plenty of existing layers in cybersecurity."}, {"timestamp": [2127.76, 2129.64], "text": " Yeah, well, and you're just speaking my language."}, {"timestamp": [2129.64, 2132.18], "text": " I spent, when I mentioned to you earlier,"}, {"timestamp": [2132.18, 2135.2], "text": " I was part of the cybersecurity practice for a bit"}, {"timestamp": [2135.2, 2137.72], "text": " that I built up, and it was all about that level of security"}, {"timestamp": [2137.72, 2142.0], "text": " of secure boot for identity systems"}, {"timestamp": [2142.0, 2144.38], "text": " and cryptography systems to be able to prove"}, {"timestamp": [2144.38, 2146.06], "text": " that they had never been touched"}, {"timestamp": [2146.06, 2148.78], "text": " outside of like spent weeks at a time"}, {"timestamp": [2148.78, 2152.3], "text": " in air-gapped rooms, building systems and things like that."}, {"timestamp": [2152.3, 2154.4], "text": " And so, these major data centers,"}, {"timestamp": [2154.4, 2156.16], "text": " whether they're cloud providers, government, whatever,"}, {"timestamp": [2156.16, 2158.82], "text": " they're doing that kind of thing where systems,"}, {"timestamp": [2158.82, 2161.22], "text": " key cryptography or identity systems"}, {"timestamp": [2161.22, 2162.62], "text": " were actually built in a vault"}, {"timestamp": [2162.62, 2166.04], "text": " and the operations of them are managed in a way"}, {"timestamp": [2166.04, 2169.28], "text": " that's so offline it would be not impossible,"}, {"timestamp": [2169.28, 2171.92], "text": " but you would have to manipulate some humans along the way"}, {"timestamp": [2171.92, 2174.82], "text": " to be able to do something different than you're doing now."}, {"timestamp": [2174.82, 2175.8], "text": " Yep."}, {"timestamp": [2175.8, 2177.32], "text": " That actually reminds me of something."}, {"timestamp": [2177.32, 2181.92], "text": " I had a few people ask me about neuromorphic chips."}, {"timestamp": [2181.92, 2187.28], "text": " So for anyone in the audience who's not familiar, a neuromorphic chip is basically"}, {"timestamp": [2187.28, 2194.0], "text": " an analog chip that is running a fixed, a static neural network on the chip device."}, {"timestamp": [2194.88, 2200.08], "text": " These are typically used for mobile purposes because you can't retrain them and you can't"}, {"timestamp": [2200.08, 2206.8], "text": " redeploy them, but they can be 10 times faster, 10 times cheaper, and use 100 times"}, {"timestamp": [2206.8, 2211.6], "text": " less energy because it's running at the hardware level rather than the software level."}, {"timestamp": [2211.6, 2216.8], "text": " And so this is pure speculation, but what I suspect is that over time, because right"}, {"timestamp": [2216.8, 2221.52], "text": " now we're in a very high velocity phase where there's new models coming out every week,"}, {"timestamp": [2221.52, 2222.52], "text": " right?"}, {"timestamp": [2222.52, 2227.2], "text": " But before too long, it'll be worthwhile to say, hey, we've got this model,"}, {"timestamp": [2227.2, 2229.34], "text": " whether it's a vision model or a language model"}, {"timestamp": [2229.34, 2233.68], "text": " or a multimodal model that it's stable, it's viable,"}, {"timestamp": [2233.68, 2235.96], "text": " let's go ahead and create a chip version,"}, {"timestamp": [2235.96, 2238.44], "text": " an ASIC version or a neuromorphic chip"}, {"timestamp": [2238.44, 2239.44], "text": " that's gonna be static."}, {"timestamp": [2239.44, 2242.6], "text": " And so then the model can't even change itself."}, {"timestamp": [2242.6, 2244.32], "text": " It's entirely possible that some of this is,"}, {"timestamp": [2244.32, 2246.6], "text": " it's not gonna even be a matter of defeating"}, {"timestamp": [2246.6, 2248.88], "text": " it from a software security perspective."}, {"timestamp": [2248.88, 2250.7], "text": " It's going to be fixed or static."}, {"timestamp": [2250.7, 2255.36], "text": " And so some of that is what you're talking about, like the actual board level hardware"}, {"timestamp": [2255.36, 2257.64], "text": " is not really changeable."}, {"timestamp": [2257.64, 2260.96], "text": " And I suspect that AI is going to have some of that as well."}, {"timestamp": [2260.96, 2262.64], "text": " What do you think about that idea?"}, {"timestamp": [2262.64, 2268.6], "text": " I was hoping we'd get here to the neuromorphic chips because I find that whole thing fascinating."}, {"timestamp": [2268.6, 2271.88], "text": " And part of the reason I find it fascinating is just the power thing."}, {"timestamp": [2271.88, 2272.88], "text": " Right."}, {"timestamp": [2272.88, 2279.16], "text": " I think the actual biggest limiter to AI dominance of the world right now is actually physical"}, {"timestamp": [2279.16, 2280.16], "text": " power."}, {"timestamp": [2280.16, 2286.16], "text": " Like, at the end of the day, there's just a huge amount of power necessary to do the"}, {"timestamp": [2286.16, 2290.52], "text": " training and even to do the serving because these are very power hungry chips."}, {"timestamp": [2290.52, 2295.0], "text": " On the other hand, the neuromorphic chips are so low power, it's amazing."}, {"timestamp": [2295.0, 2301.56], "text": " And so, you know, when we think AGI, I think a lot of people fall into this default of"}, {"timestamp": [2301.56, 2305.52], "text": " like Skynet, you know, from the Terminator series, or if"}, {"timestamp": [2305.52, 2311.84], "text": " you've seen the iRobot movie that, you know, big brain in the sky taking over everything."}, {"timestamp": [2311.84, 2317.88], "text": " But I would also argue that something with sort of the intelligence of a cat or a dog"}, {"timestamp": [2317.88, 2323.0], "text": " would also be AGI. It's retrainable, it does things. And so I think we're going to end"}, {"timestamp": [2323.0, 2326.2], "text": " up with some edge, really interesting edge cases with"}, {"timestamp": [2326.2, 2330.64], "text": " very limited sort of almost instinctual things they do."}, {"timestamp": [2330.64, 2334.44], "text": " You know, like when a horse is born, it knows how to stand up."}, {"timestamp": [2334.44, 2336.92], "text": " Like humans, it takes a long time for us, but horses know that."}, {"timestamp": [2336.92, 2339.72], "text": " Well, that's what's going to be on these analog chips you're talking about."}, {"timestamp": [2339.72, 2343.0], "text": " We're going to have a lot of edge devices and a lot of things on the edge that have"}, {"timestamp": [2343.0, 2344.2], "text": " these fully trained."}, {"timestamp": [2344.2, 2349.64], "text": " This part's always static, but then augmented by something that has some dynamicism that"}, {"timestamp": [2349.64, 2354.56], "text": " makes it smart, but not as fully intelligent as a human."}, {"timestamp": [2354.56, 2356.36], "text": " Sure, sure."}, {"timestamp": [2356.36, 2357.36], "text": " Yeah."}, {"timestamp": [2357.36, 2365.08], "text": " And so taking that to a more logical extreme, I can envision a future where there are neuromorphic chips embedded"}, {"timestamp": [2365.08, 2370.76], "text": " in everything, whether it's servers, firewalls, home security devices."}, {"timestamp": [2370.76, 2373.96], "text": " And because it's set at the hardware level, you can't hack it."}, {"timestamp": [2373.96, 2375.3], "text": " It's not something you can even delete."}, {"timestamp": [2375.3, 2378.3], "text": " It's just an intrinsic function of the device."}, {"timestamp": [2378.3, 2383.48], "text": " But because they require a lot less energy and they can often run many times faster,"}, {"timestamp": [2383.48, 2386.48], "text": " they could run circles around the software"}, {"timestamp": [2386.48, 2388.08], "text": " version of the model."}, {"timestamp": [2388.08, 2392.28], "text": " Even though the software version might be bigger, it might have more up-to-date data,"}, {"timestamp": [2392.28, 2397.84], "text": " but because it is intrinsically more power hungry, it's going to be at a competitive"}, {"timestamp": [2397.84, 2398.84], "text": " disadvantage."}, {"timestamp": [2398.84, 2404.2], "text": " I remember I got the, I kind of realized this was the way that it was coming when I first"}, {"timestamp": [2404.2, 2405.96], "text": " learned about neuromorphic chips."}, {"timestamp": [2405.96, 2408.5], "text": " And then I went and watched the new Star Wars movies."}, {"timestamp": [2408.5, 2409.84], "text": " And I was like, oh, right."}, {"timestamp": [2409.84, 2412.8], "text": " You know, when you just plug in a droid brain and it's a piece of hardware, that's how it's"}, {"timestamp": [2412.8, 2413.8], "text": " going to be."}, {"timestamp": [2413.8, 2418.32], "text": " It's it's going to be a physical, you know, neural network that you plug into, you know,"}, {"timestamp": [2418.32, 2421.94], "text": " your your home device or your robot pet or whatever."}, {"timestamp": [2421.94, 2423.02], "text": " And that's going to be fixed."}, {"timestamp": [2423.02, 2425.28], "text": " It's not going to be something that's going to be changeable,"}, {"timestamp": [2425.28, 2427.96], "text": " but it also makes it more intrinsically secure"}, {"timestamp": [2427.96, 2431.32], "text": " because you can't copy the neuromorphic chip"}, {"timestamp": [2431.32, 2432.06], "text": " over the internet."}, {"timestamp": [2432.06, 2433.36], "text": " It's physically there."}, {"timestamp": [2433.36, 2437.44], "text": " It is as embodied as your brain is,"}, {"timestamp": [2437.44, 2441.88], "text": " which leads to all sorts of other interesting ethical"}, {"timestamp": [2441.88, 2444.68], "text": " or economic perspectives."}, {"timestamp": [2444.68, 2447.2], "text": " Tim, you have anything you want to chime in"}, {"timestamp": [2447.2, 2448.84], "text": " on the hardware level?"}, {"timestamp": [2448.84, 2453.84], "text": " We're kind of nerding out over the neuromorphic chips."}, {"timestamp": [2453.88, 2456.12], "text": " But feel free to add in or take it another direction"}, {"timestamp": [2456.12, 2458.2], "text": " if anything's resonating."}, {"timestamp": [2458.2, 2459.96], "text": " I think it's a really cool concept."}, {"timestamp": [2459.96, 2464.96], "text": " And I guess I can see how once a model,"}, {"timestamp": [2464.96, 2468.32], "text": " you know, once I figure out what a model's, I"}, {"timestamp": [2468.32, 2472.76], "text": " guess, parameter weights are, and how that could be potentially replicated at the physical"}, {"timestamp": [2472.76, 2473.76], "text": " layer."}, {"timestamp": [2473.76, 2489.3], "text": " I love Ultrafarben, that book slash Netflix series. theories. And it's like the, you know, the discs that they have with their DNA. It could"}, {"timestamp": [2489.3, 2495.2], "text": " be maybe the weights of the different neural pathways which make up someone's personality."}, {"timestamp": [2495.2, 2502.76], "text": " I don't know, just a thought that came to me. I think it's fascinating. But yeah, technology"}, {"timestamp": [2502.76, 2506.24], "text": " wise, look, I don't know, it's all very cool."}, {"timestamp": [2506.24, 2511.32], "text": " I don't have any experience in that space, but it's, yeah, I can't wait to see what the"}, {"timestamp": [2511.32, 2512.4], "text": " future holds."}, {"timestamp": [2512.4, 2519.92], "text": " I think humanoid robots are definitely on the cards in that way, and having some sort"}, {"timestamp": [2519.92, 2525.24], "text": " of physical brain structure rather than it being implemented in software."}, {"timestamp": [2525.24, 2528.48], "text": " It's one of the reasons that you've been mentioning power"}, {"timestamp": [2528.48, 2530.22], "text": " and all that sort of thing."}, {"timestamp": [2530.22, 2532.0], "text": " Yeah, yeah, and so that,"}, {"timestamp": [2533.36, 2535.36], "text": " some of the videos that I've talked about,"}, {"timestamp": [2535.36, 2536.86], "text": " I've talked about different form factors"}, {"timestamp": [2536.86, 2538.6], "text": " that AGI could come in,"}, {"timestamp": [2538.6, 2540.56], "text": " whether it's the physically embodied,"}, {"timestamp": [2540.56, 2543.84], "text": " like the robots from iRobot or Commander Data or whatever,"}, {"timestamp": [2543.84, 2545.2], "text": " where it's an intrinsically"}, {"timestamp": [2545.2, 2549.68], "text": " kind of self-contained system that is mostly hardware or at least constrained to that piece"}, {"timestamp": [2549.68, 2550.68], "text": " of hardware."}, {"timestamp": [2550.68, 2556.6], "text": " You know, then the most extreme example, this is closer to what Ben Goertzel is working"}, {"timestamp": [2556.6, 2559.64], "text": " on, which is something that is intrinsically distributed."}, {"timestamp": [2559.64, 2561.16], "text": " You know, and we mentioned that earlier."}, {"timestamp": [2561.16, 2566.24], "text": " I guess one concern that people might have,"}, {"timestamp": [2566.24, 2568.0], "text": " and I don't know how serious of a concern it is,"}, {"timestamp": [2568.0, 2570.48], "text": " but the idea of viruses and botnets."}, {"timestamp": [2570.48, 2575.48], "text": " Because Stuxnet, Configure, and all the really, really bad"}, {"timestamp": [2576.34, 2580.64], "text": " malware and spyware that has existed has been out there."}, {"timestamp": [2580.64, 2584.2], "text": " So what do you guys think about the idea"}, {"timestamp": [2584.2, 2587.2], "text": " of maybe part of AGI is gonna be something"}, {"timestamp": [2587.2, 2589.08], "text": " that is just highly decentralized,"}, {"timestamp": [2590.16, 2593.24], "text": " running a tiny model on every device"}, {"timestamp": [2593.24, 2594.6], "text": " that it can hack and whatever,"}, {"timestamp": [2594.6, 2597.08], "text": " and then it has this kind of swarm intelligence."}, {"timestamp": [2597.08, 2600.8], "text": " Is there any possibility that you see of that happening"}, {"timestamp": [2600.8, 2604.84], "text": " or existing security paradigms and hardware paradigms"}, {"timestamp": [2604.84, 2605.12], "text": " enough to kind"}, {"timestamp": [2605.12, 2608.96], "text": " of tamp that down because again like one thing that I think of is there's people trying to do"}, {"timestamp": [2608.96, 2614.72], "text": " this already what's the difference right you know whether it's a hostile foreign actor or you know"}, {"timestamp": [2614.72, 2619.92], "text": " corporate uh industrial espionage all this kind of stuff is already happening and it's not like"}, {"timestamp": [2619.92, 2624.32], "text": " AGI is going to have a fundamentally different set of tools right it can it can try and hack the same"}, {"timestamp": [2624.32, 2625.84], "text": " way that any human can so what do you guys what do you guys think of of that idea like AGI is gonna have a fundamentally different set of tools, right? It can try and hack the same way that any human can."}, {"timestamp": [2625.84, 2628.24], "text": " So what do you guys think of that idea,"}, {"timestamp": [2628.24, 2631.08], "text": " like AGI as a virus?"}, {"timestamp": [2631.08, 2635.32], "text": " Yeah, I think that's probably more of a realistic concern"}, {"timestamp": [2636.48, 2641.48], "text": " in the short term, given that we already face these things"}, {"timestamp": [2641.5, 2647.4], "text": " with existing botnets, and I think it's plausible that they get"}, {"timestamp": [2647.4, 2658.04], "text": " augmented by AI to become more powerful. You know, the auto GPT project"}, {"timestamp": [2658.04, 2665.4], "text": " that came out this year I think demonstrates what that might look like with autonomous agents"}, {"timestamp": [2665.4, 2675.2], "text": " potentially being spawned by an AI system or botnet with its own intentions, you"}, {"timestamp": [2675.2, 2680.08], "text": " know, and that not necessarily its own, with its prescribed intentions from"}, {"timestamp": [2680.08, 2685.98], "text": " whatever bad actor. I've been on the receiving end of this before, I've run"}, {"timestamp": [2685.98, 2693.52], "text": " websites for various social groups and have seen them be overrun by bots"}, {"timestamp": [2693.52, 2698.6], "text": " to the point where I just got out of the game altogether because it was, they"}, {"timestamp": [2698.6, 2706.3], "text": " became too powerful for my level of expenditure. So, and that's the other thing, there's a real"}, {"timestamp": [2706.3, 2712.66], "text": " cost associated with protecting yourself against that sort of stuff at the"}, {"timestamp": [2712.66, 2717.94], "text": " moment, you know, with distributed denial of service attack protection. Most"}, {"timestamp": [2717.94, 2722.46], "text": " major websites use services like Cloudflare to protect against that sort"}, {"timestamp": [2722.46, 2725.68], "text": " of thing because they have the bandwidth they have the"}, {"timestamp": [2726.48, 2727.84], "text": " routing"}, {"timestamp": [2727.84, 2730.0], "text": " there to redirect traffic when they need to"}, {"timestamp": [2730.8, 2738.16], "text": " Right. So yeah, look, I I think it's uh, I think it's a real concern and something that is probably going to happen sooner rather than later"}, {"timestamp": [2739.1, 2745.76], "text": " Interesting. Okay. Yeah. No, I I definitely hear you there Because again, like, you know, DDoS attacks"}, {"timestamp": [2745.76, 2752.78], "text": " happen all the time. You know, distributed botnets, even even stealing data, right? Exfiltration"}, {"timestamp": [2752.78, 2759.4], "text": " or infiltration. Alan, do you have a have thoughts about the that kind of more decentralized"}, {"timestamp": [2759.4, 2763.12], "text": " virus AGI virus kind of model of thinking?"}, {"timestamp": [2763.12, 2766.32], "text": " I think the tricky part for me in all of that is motive."}, {"timestamp": [2766.32, 2774.08], "text": " Okay, so so having done as much cyber as I have, there's sort of this hierarchy of needs of"}, {"timestamp": [2774.08, 2786.08], "text": " of hackers, so to speak, from just someone trying it for fun, because they want to show they can do a thing to governments doing, you know, intentional espionage, damage, whatever."}, {"timestamp": [2786.48, 2791.72], "text": " I think one of the challenges is for AGI as an independent agent, right."}, {"timestamp": [2791.72, 2796.64], "text": " Just as, as a thing that, that realizes today, Hey, I'm, I can do things."}, {"timestamp": [2796.98, 2802.24], "text": " I think you're going to see that sort of actual script kitty, like I just"}, {"timestamp": [2802.24, 2809.92], "text": " trying something cause I can, because otherwise I don't know what its motivation is, right? I don't know what its motivation is to go broader. On the other hand,"}, {"timestamp": [2809.92, 2816.48], "text": " if the AGI is somehow being influenced by a human actor or some, maybe not a human actor,"}, {"timestamp": [2816.48, 2821.52], "text": " but a corporate actor, right? Whether that is a corporation or the government in some way,"}, {"timestamp": [2821.52, 2825.98], "text": " that it's got a design parameter that has an outcome at once."}, {"timestamp": [2825.98, 2827.22], "text": " I can see that, you know,"}, {"timestamp": [2827.22, 2832.22], "text": " there's lots of scenarios of having bad,"}, {"timestamp": [2834.86, 2837.4], "text": " basically bad objective functions for your AI."}, {"timestamp": [2837.4, 2839.68], "text": " Like there's a lot of thought experiments around that."}, {"timestamp": [2839.68, 2841.62], "text": " And so, you know, the thought experiment that says,"}, {"timestamp": [2841.62, 2843.92], "text": " well, if you tell it to optimize making stamps,"}, {"timestamp": [2843.92, 2847.92], "text": " it will, you know, cut down all the forests in the world to make as many stamps as possible. Like,"}, {"timestamp": [2848.48, 2854.56], "text": " that kind of AGI deciding to botnet itself to go do something because it was given an otherwise"}, {"timestamp": [2854.56, 2860.8], "text": " benign thing, I could see that kind of mistake happening. And to your point, it will be this kind"}, {"timestamp": [2860.8, 2869.12], "text": " of mild distributed thing. I think the real point, is for it to do other than sort of incidental damage, like"}, {"timestamp": [2869.12, 2875.04], "text": " a DDoS attack or, you know, like say a mass crypto thing where it's locked people out"}, {"timestamp": [2875.04, 2880.88], "text": " of files, it's got to have room to be a big model that can do a lot of dynamic stuff,"}, {"timestamp": [2880.88, 2881.88], "text": " right?"}, {"timestamp": [2881.88, 2882.88], "text": " So I think that's the tricky part."}, {"timestamp": [2882.88, 2885.2], "text": " We talked about dependencies, kind of coming back to the beginning"}, {"timestamp": [2885.2, 2886.76], "text": " where we talked about dependencies."}, {"timestamp": [2886.76, 2887.72], "text": " We talked about that."}, {"timestamp": [2887.72, 2890.92], "text": " I mean, for these kinds of bots to run,"}, {"timestamp": [2890.92, 2893.28], "text": " right now the dependencies, the GPUs,"}, {"timestamp": [2893.28, 2894.76], "text": " and not everything has it."}, {"timestamp": [2894.76, 2899.08], "text": " So, and even in most important data systems"}, {"timestamp": [2899.08, 2901.76], "text": " don't necessarily have GPUs right now"}, {"timestamp": [2901.76, 2903.72], "text": " because that's not what they process."}, {"timestamp": [2903.72, 2904.62], "text": " That's not how they handle it."}, {"timestamp": [2904.62, 2905.0], "text": " So I think that I do agree with the idea use right now, because that's not what they process. That's not how they handle it."}, {"timestamp": [2905.0, 2908.16], "text": " So I think that I do agree with the idea"}, {"timestamp": [2908.16, 2911.16], "text": " that it will be kind of a swarm effect."}, {"timestamp": [2911.16, 2914.08], "text": " But I think it'll be really interesting to see"}, {"timestamp": [2914.08, 2917.44], "text": " what was the AGI's motivation to get started on this."}, {"timestamp": [2917.44, 2918.96], "text": " Right, yeah."}, {"timestamp": [2918.96, 2921.68], "text": " Yeah, and that's the big question, right?"}, {"timestamp": [2921.68, 2923.94], "text": " One hypothesis, one theory out there"}, {"timestamp": [2923.94, 2927.28], "text": " is instrumental convergence, that whatever goal you give it,"}, {"timestamp": [2927.28, 2930.56], "text": " even if it's just managing the energy grid, right?"}, {"timestamp": [2930.56, 2933.4], "text": " And you say, hey, here's a decentralized AGI"}, {"timestamp": [2933.4, 2935.24], "text": " that the Department of Energy deployed"}, {"timestamp": [2935.24, 2936.84], "text": " and it's there to manage the energy grid."}, {"timestamp": [2936.84, 2938.44], "text": " Well, if you don't supervise it,"}, {"timestamp": [2938.44, 2940.92], "text": " it might decide to try and take over all energy sources"}, {"timestamp": [2940.92, 2943.2], "text": " across the whole plant, something like that."}, {"timestamp": [2943.2, 2946.3], "text": " But one thing that really strikes me that's missing from"}, {"timestamp": [2946.3, 2949.68], "text": " from those hypotheses, those those kind of constructs"}, {"timestamp": [2949.94, 2954.1], "text": " is the idea that, OK, yes, you might have one powerful AGI out there"}, {"timestamp": [2954.1, 2957.78], "text": " that is built for defense or espionage or whatever."}, {"timestamp": [2958.02, 2962.78], "text": " But then there's going to be a million more for a variety of other purposes"}, {"timestamp": [2962.78, 2966.8], "text": " and even even some adversarial to defend against that."}, {"timestamp": [2966.8, 2971.1], "text": " So, you know, in the arms race of cybersecurity,"}, {"timestamp": [2971.1, 2975.0], "text": " of hacking, like this is, of course, this is nothing new."}, {"timestamp": [2975.0, 2977.56], "text": " Humans have been competing against each other"}, {"timestamp": [2977.56, 2979.28], "text": " since the invention of the network."}, {"timestamp": [2979.28, 2981.52], "text": " What was the story, do you guys know the story"}, {"timestamp": [2981.52, 2983.12], "text": " that I'm thinking of, where it's like"}, {"timestamp": [2983.12, 2989.24], "text": " the very first web server, like someone, like the first hacker of all time just like oh hey you have no security"}, {"timestamp": [2989.24, 2993.56], "text": " here so I like modified this file and they're like oh I guess we need a security layer right"}, {"timestamp": [2993.56, 2998.46], "text": " I think that was probably at CERN in the 1989 or whatever but you know like we kind of figured"}, {"timestamp": [2998.46, 3004.16], "text": " out that you need security by virtue of either accidents happening or people just seeing"}, {"timestamp": [3004.16, 3005.24], "text": " what they can do."}, {"timestamp": [3005.24, 3006.86], "text": " So that part is nothing new."}, {"timestamp": [3008.72, 3011.68], "text": " Looks like Tim had to step away for just a moment."}, {"timestamp": [3011.68, 3014.04], "text": " But yeah, so, you know, let's see,"}, {"timestamp": [3014.04, 3017.44], "text": " we're at about, oh wow, we're already at 50 minutes."}, {"timestamp": [3017.44, 3018.28], "text": " Time flies."}, {"timestamp": [3019.24, 3020.44], "text": " But yeah, so."}, {"timestamp": [3020.44, 3021.44], "text": " I'm back."}, {"timestamp": [3021.44, 3022.4], "text": " Yeah, thanks Tim."}, {"timestamp": [3023.36, 3026.68], "text": " Yeah, we're almost closing in on an hour"}, {"timestamp": [3026.68, 3033.52], "text": " so I just want to open it up and are there any topics that I that we didn't cover or any any pet theories or"}, {"timestamp": [3034.16, 3037.82], "text": " Personal topics that you guys want to bring up before we start to wind down"}, {"timestamp": [3040.08, 3044.26], "text": " Yeah, oh, sorry, I was just gonna say before on the other point that"}, {"timestamp": [3041.6, 3043.28], "text": " I'm not yet. Oh, sorry, I was just going to say before,"}, {"timestamp": [3043.28, 3047.72], "text": " on the other point, that I think it's more likely"}, {"timestamp": [3047.72, 3051.0], "text": " that bad actors will use that sort of, you know,"}, {"timestamp": [3051.0, 3054.86], "text": " botnet style, attack style,"}, {"timestamp": [3056.16, 3059.56], "text": " rather than it be an autonomous AGI,"}, {"timestamp": [3059.56, 3061.2], "text": " if you know what I mean."}, {"timestamp": [3063.84, 3071.12], "text": " Because it's an existing model, right? We hear of governments, countries,"}, {"timestamp": [3072.64, 3077.76], "text": " militia groups, all that sort of stuff, they all are using technology to their advantage these days."}, {"timestamp": [3079.2, 3087.64], "text": " Yeah, that's where I think the risk comes from there. But yeah, did you want to expand on that anymore"}, {"timestamp": [3087.76, 3090.16], "text": " or we good to put that to rest?"}, {"timestamp": [3090.16, 3094.32], "text": " Yeah, yeah, no, what we can do is maybe I ask the question"}, {"timestamp": [3094.32, 3097.6], "text": " not the best way, like, what is personal to you"}, {"timestamp": [3097.6, 3099.0], "text": " about artificial intelligence?"}, {"timestamp": [3099.0, 3103.0], "text": " What do you want to see and what do you want to help achieve"}, {"timestamp": [3103.0, 3105.04], "text": " with respect to artificial intelligence?"}, {"timestamp": [3105.04, 3106.66], "text": " Or conversely, what are you afraid of"}, {"timestamp": [3106.66, 3108.62], "text": " if there is anything that you're afraid of?"}, {"timestamp": [3108.62, 3111.78], "text": " You can hit either or both of those if you'd like."}, {"timestamp": [3111.78, 3115.74], "text": " Yeah, personally, I really see a huge benefit"}, {"timestamp": [3115.74, 3118.06], "text": " for a couple of things."}, {"timestamp": [3118.06, 3123.06], "text": " One is education, and secondly, it's assistance."}, {"timestamp": [3125.0, 3125.04], "text": " So, you know, people with disabilities, And secondly, it's assistance."}, {"timestamp": [3127.36, 3130.52], "text": " So, you know, people with disabilities, whether it be physical, neurological, whatever,"}, {"timestamp": [3132.16, 3134.44], "text": " I think are gonna get a huge advantage"}, {"timestamp": [3134.44, 3136.84], "text": " from AI systems in the future,"}, {"timestamp": [3136.84, 3138.84], "text": " whether that be like a personal assistant"}, {"timestamp": [3138.84, 3142.28], "text": " or just through better healthcare,"}, {"timestamp": [3143.84, 3147.68], "text": " you know, we're already seeing GVD4 models"}, {"timestamp": [3147.68, 3149.76], "text": " produce better outcomes than human doctors."}, {"timestamp": [3149.76, 3153.76], "text": " So that's something that really excites me personally,"}, {"timestamp": [3153.76, 3155.72], "text": " just because of my own experience in life"}, {"timestamp": [3155.72, 3158.32], "text": " and having some chronic health conditions."}, {"timestamp": [3159.48, 3160.84], "text": " I think that's really huge."}, {"timestamp": [3160.84, 3162.44], "text": " And then the education piece,"}, {"timestamp": [3164.32, 3165.84], "text": " we're seeing some really impressive stuff"}, {"timestamp": [3165.84, 3173.36], "text": " coming out of the academy, being in the education sector at the moment myself,"}, {"timestamp": [3173.36, 3180.24], "text": " there's huge opportunities, particularly in public education, for just more"}, {"timestamp": [3180.24, 3185.2], "text": " resources in the classroom, and I think AI can definitely help with that."}, {"timestamp": [3193.84, 3197.28], "text": " Imagine if every teacher just has an AI assistant alone. One concept is going to be a game changer. So I'm very much invested in seeing that come to fruition."}, {"timestamp": [3198.24, 3203.92], "text": " Excellent. Excellent. Thanks, Tim. Alan, same question. What do you hope to see or what are"}, {"timestamp": [3203.92, 3205.92], "text": " you afraid of, either or both?"}, {"timestamp": [3206.96, 3212.0], "text": " So I'll just echo Tim's thing on the hope to see. I saw the Khan Academy,"}, {"timestamp": [3212.56, 3217.76], "text": " like there's a great YouTube on what they're doing, and there's this curve about education"}, {"timestamp": [3217.76, 3224.4], "text": " that if you can give personalized education to a student, everybody gets helped. So I think that's"}, {"timestamp": [3224.4, 3228.16], "text": " great, like the vision he cast there and what's going to happen with that."}, {"timestamp": [3228.16, 3231.84], "text": " I think that's amazing and it's going to have a huge impact on the world."}, {"timestamp": [3232.36, 3234.8], "text": " But what I'm afraid of is a little creepy, actually."}, {"timestamp": [3234.8, 3238.86], "text": " It's this other thing we haven't talked about yet, from a hardware perspective,"}, {"timestamp": [3238.86, 3241.44], "text": " so to speak, of organoid computing."}, {"timestamp": [3242.16, 3245.88], "text": " So I don't know if you've seen this before but organoid computing is the idea of taking"}, {"timestamp": [3246.56, 3251.82], "text": " Stem cells and growing effectively brain cells that do the same kind of neural networks, you know"}, {"timestamp": [3251.82, 3257.92], "text": " Like like that's the model right and apparently I don't know if this is true or not because I saw this in passing"}, {"timestamp": [3258.02, 3260.42], "text": " But apparently they took a couple of these organoid"}, {"timestamp": [3260.94, 3266.14], "text": " You know these piles of brain cells in a petri dish and put them against each other playing pong."}, {"timestamp": [3266.14, 3268.14], "text": " Now, I don't know if that's true or not,"}, {"timestamp": [3268.26, 3271.02], "text": " but that by itself is just super creepy."}, {"timestamp": [3271.02, 3275.22], "text": " You know, you've got kind of like the brain that ate New York kind of creepy thing that's creeping me out."}, {"timestamp": [3275.42, 3278.86], "text": " But then the same day I heard there's this new,"}, {"timestamp": [3279.38, 3283.12], "text": " like AI has invented a protein replacement."}, {"timestamp": [3283.28, 3283.96], "text": " AI has invented a protein replacement."}, {"timestamp": [3289.08, 3290.96], "text": " So the molecule that we have that we ingest as protein in our body that makes up muscle cells and things like that,"}, {"timestamp": [3291.42, 3295.64], "text": " apparently there's some compound that AI has figured out"}, {"timestamp": [3296.28, 3302.64], "text": " that's more heat resistant and has longer longevity and all this stuff."}, {"timestamp": [3302.98, 3305.36], "text": " Like if you basically replace proteins with this,"}, {"timestamp": [3305.36, 3310.8], "text": " it's better. So, the thing that scares me is if the organoid computing then sucks up these weird"}, {"timestamp": [3310.8, 3318.72], "text": " brain chemicals or these weird proteins, it'll become the indestructible brain that ate New York"}, {"timestamp": [3318.72, 3326.96], "text": " and then we're just out, then AGI wins. Yeah, I'm familiar with some of the some of the research you're talking about there"}, {"timestamp": [3326.96, 3331.04], "text": " where you know people growing. I think they started with mouse brains and rat brains,"}, {"timestamp": [3331.04, 3336.08], "text": " but I did see like in the last week they did they cloned human brain cells. And I think one that"}, {"timestamp": [3336.08, 3342.88], "text": " that's just a horrible idea and and even possibly even just unethical because if you grow something"}, {"timestamp": [3342.88, 3345.2], "text": " in a petri dish and you zap it until it does what you want,"}, {"timestamp": [3345.2, 3350.88], "text": " like you're just creating a tiny entity that you can torture basically until it learns to do what"}, {"timestamp": [3350.88, 3360.96], "text": " you want it to. But the conclusion, I'm laughing, but it is a very creepy and apocryphal possibility"}, {"timestamp": [3360.96, 3365.0], "text": " of, you know, let's be careful with what we do with these things."}, {"timestamp": [3365.0, 3372.0], "text": " So, but yeah, thanks guys for jumping on the call and sharing your experience and wisdom and insight."}, {"timestamp": [3372.0, 3375.0], "text": " It's been a great talk and like I said, time flies."}, {"timestamp": [3375.0, 3378.0], "text": " So yeah, thanks again."}, {"timestamp": [3378.0, 3382.0], "text": " And for the audience out there, I hope you got a lot out of this."}, {"timestamp": [3382.0, 3387.0], "text": " Realize that, you know, AGI, whether or not it comes today, next year,"}, {"timestamp": [3387.0, 3391.0], "text": " 10 years from now, there's going to be a lot of layers of complexity"}, {"timestamp": [3391.0, 3395.0], "text": " and security in place that's going to make it so that we can manage"}, {"timestamp": [3395.0, 3399.0], "text": " this thing regardless of how it looks."}, {"timestamp": [3399.0, 3410.16], "text": " And there's a lot of steps between now and then. You know, the escaping the lab is is pretty low on on the radar right now, it seems like."}, {"timestamp": [3410.16, 3411.92], "text": " So anyways, thanks for watching."}, {"timestamp": [3412.48, 3413.68], "text": " Hope everyone got a lot out of it."}, {"timestamp": [3413.68, 3414.4], "text": " Cheers."}]}