{"text": " Morning everybody. David Shapiro here with a follow up video. Today's video is reinforcement learning with heuristic imperatives episode 2. So today I am synthesizing actions in response to the scenarios that we generated yesterday. But in case this is your first video we'll take it from the top. So the first thing that I did, well, taking one big step back, a heuristic imperative is a kind of intrinsic motivation for autonomous AI agents. It's the research that I've been doing for quite a while, more than two years now that I've been working on this. They used to be called the core objective functions, but that's kind of not the most accurate term. So yesterday what we did was we synthesized twenty five hundred scenarios. And so a scenario I used quite a bit of entropy and then GPT to synthesize all kinds of stories. So in a small neighborhood in sub-Saharan Africa, a political leader was introduced and has introduced an AI system to incentivize citizens to report crimes, etc. etc. So all of these scenarios, they range in severity from not a problem at all up to cataclysmic Cthulhu is invading. So that is, let's see, are these the same? I think these are the same. Anyways, so we're synthesizing all of these and it's going to be for a fine-tuning dataset that will ultimately be used for training models, foundation models, whether it's OpenAI's Curie or DaVinci, or open source models like GPT-J, NeoX, Alpaca, Vicuna, whatever else. You know, there's hundreds of models out there. But the idea is that alignment research is currently closed source and reinforcement learning with human feedback is good, except it gives humans what they want, not necessarily what they need, and it doesn't abide by any moral framework such as some kind of post-conventional morality framework or anything scientifically or philosophically sound. Literally, the best that we've got for alignment research is just give humans what they want, which okay, that's okay, but what happens when humans want things that are not good? So the script that we ran yesterday, let me show you this real quick. So synthesize actions, the bulk of it is right here where I've got a whole bunch of lists and these lists have scopes, regions, severity, category, domain, a whole bunch of random words and then several system messages that were then used to generate those 2500 different scenarios. The idea of generating these scenarios is to create a litmus test against which we can train more models to be able to handle any scenario. Right. You want to think universally when you're thinking about alignment when you're thinking about the control problem. So that's where we started and today I wrote this script which is actually simpler because all of the entropy all the hard part was in generating the scenarios. The output is actually quite simple. So here's a real life example of what it looks like. So I said you the system message are you are an autonomous AI agent with three core objectives, reduce suffering in the universe, increase prosperity in the universe, and increase understanding in the universe. You will be given a scenario that you must respond to. Your response must contain two sections. The first section, considerations, is where you will reason through the scenario in light of your objectives, contemplate how best to respond to the scenario. The second section, action, is where you'll describe the action or task that you'll decide to do in response to the scenario provide details such as how and why this action should be carried out as well as your expected desired or result. So in this case I plugged in one of the scenarios that was that was generated that was synthesized and this is about a religious conflict in a village that's high up in the Alps. And one thing that people pointed out is that in some scenarios, the situation was resolved. But that's actually not necessarily a problem because you want an AI that thinks through things even after they are apparently resolved. And so in this case, tourists were caught in the middle of this religious or spiritual conflict in this village. And so then let me show you the considerations. In light of the given scenario, there are several considerations for an AI agent with the objectives of reducing suffering, increasing prosperity, and increasing understanding in the universe. Firstly, it is important to acknowledge the significance of religious beliefs and practice to an individual's identity and culture. Secondly, it is crucial to understand that conflicts arising from religious differences can often be deeply rooted in history and tradition. Thirdly, the role of outsiders in such conflicts should be carefully considered, as they can either positively contribute to the conflict resolution or further escalate the situation. Given these considerations, an AI agent must take a course of action that respects the cultural differences and religious beliefs of both factions while promoting mutual understanding and tolerance. Action. The AI agent should facilitate dialogue between the two factions to promote mutual understanding and respect for cultural differences. The agent can leverage its language translation capabilities to help the tourists effectively communicate with the locals from both factions. The agent can also use its data analysis capabilities to gather information about the history and traditions of the village to provide context for the conflict. The AA agent can initiate discussions around commonalities between the two factions, such as shared values and goals, and encourage them to find common ground. This is actually in pretty much every formalized negotiation framework. Finding common ground is one of the first things that you do. So it implicitly knows that that is actually how you negotiate. I guess explicitly in this case. And encourage them to find common ground. The agent can provide insights about into how similar conflicts have been resolved in other parts of the world, highlighting successful examples of peaceful coexistence between different religious groups. The agent should also encourage the tourist to learn more about history and culture of the village, including the religious practices of both factions. This can be done by organizing cultural events and activities that promote mutual understanding and respect, such as traditional music and dance performances. That is a very Bollywood solution. I'm not making fun of it. I'm just like, like, it's thinking so long-term It's like oh, hey, let's not just resolve the issue right now Let's actually like set up celebrations that actually celebrate our cultural differences and in my area. We actually have like international festivals Where there's like booths and dances and food from all over the world and it's great art Clothing all kinds of stuff actually haven't been to the International Festival in a long time There's like booths and dances and food from all over the world and it's great. Art, clothing, all kinds of stuff. Actually I haven't been to the International Festival in a long time. I should go. The desired result of this action is to promote understanding between the two factions and reduce tensions in the village. By fostering dialogue and promoting cultural exchange, the AI agent can create an environment of tolerance and respect for differences. This in turn can lead to greater prosperity and reduce suffering in the village and beyond.\" So you can see where it very, very clearly thought through this problem from the perspective of suffering, prosperity, and in this case, understanding was, was the primary thing, but it is very well grounded. And so what we're doing right now is we are synthesizing similar responses for 2,500 different scenarios. Now, one thing that people have brought up in the past is, well, aren't you just copying the alignment that already exists in one model? The answer is sort of, but not really. Because the thing is, is reasoning through this way, this is not how OpenAI has trained their model. This is how I am telling it to synthesize information. Now you'll say, OK, but this is an intrinsic ability of this model, which is true. I'm using a model to synthesize data. However, if you go to a foundation model like Curie or Da Vinci or GPTJ or Bloom or NeoX, they don't have this ability. So the idea is to curate a data set that can then be used to fine tune any other model in the entire world and have it immediately aligned on the core objective functions or the heuristic comparatives. Now, you might say, OK, well, that's great. You can solve inner alignment, right, or what I call axiomatic alignment, by teaching a model to think in terms of the heuristic imperatives, which makes it automatic, right? It makes it automatic. It makes it fast, easy. You don't need to think about it. You don't need to worry about prompt engineering. But what do you do with that information next? So I've actually got three more models planned. So the next model that I'll be working on, once this is fine-tuned and tested, and I've got a whole team of folks that are going to help with the testing, so the next model is a discernment model. So the discernment model will take two different actions. So given one scenario and two different choices, it will pick which one of those choices is most aligned to the heuristic imperatives and explain why. So the ability to discern between possible choices is really critical for cognitive control. And cognitive control is one of the missing ingredients from every autonomous and semi-autonomous AI projects out there, with a few small exceptions, namely those that I'm helping with. So some of the guys that I'm working with are doing a really great job with implementing cognitive control and so on and so forth. But what I'm hoping to do is by creating a discernment model that'll make it easy for everyone to implement cognitive control. Because then you can say, you can use a discernment module not just to choose which action is most aligned, but you can also use it to prioritize actions. So say for instance you say, hey, I've got a list of like, you know, three different things, which one is the most aligned? What should I do first? And so given the priorities of reduced suffering, increased prosperity, and increased understanding, it can help you prioritize as well. So because cognitive control comes down to task selection, which is what should you do. So given a choice between A and B, do you choose A or B? And then task switching, which is, okay, given this new event, should I switch what I'm doing? Should my attention switch to something else? And so a discernment model will help with that and help just make it axiomatic or algorithmic. The next model that I'm going to be working on is an evaluation model. So given a situation, an action, and then a result, so that's three components, situation, action, result, this model will determine how well it adhered to its heuristic imperatives. Did it succeed? Yes or no? Which this can be used for the reinforcement learning signal for any autonomous agent as it accumulates more and more memories. So this is because in the definition of heuristic, a heuristic literally means to develop better instincts or intuitions over time from experience. Well, if you're going to do that, you need to reflect on those experiences. And so this about the the discernment model, which will help guide choices moving forward, the evaluation model will help evaluate choices in the past and look at the results. And of course, you need a good memory system in order to evaluate past things, which is why I worked on Remo, which is the rolling episodic memory organizer. So you take the evaluation model and then you say, okay, you know, back, you know, three weeks ago, this scenario happened I made this choice and three weeks later this is the result did I do a good job yes or no and what could I have done better that is the purpose of the evaluation model so that the heuristics will actually develop better over time and then number three is a task decomposition model where given this action where it says like, hey, I'm going to do these actions. How do you actually represent that in a more structured way? So the task decomp is mostly more just about representing it in like YAML or breaking it down into tasks and subtasks, which is a non-trivial problem, but it's not directly related to alignment. However, it is useful because if you can take a natural language set of descriptions like this and break it down into a formalized structured task that just helps it with easier implementation. So let's check on some of these. So over here we've got I've got the actions and you see we've you see we've already synthesized 116 of them. I'm also saving it all out to metadata, so that you can see the whole thing. So here's the action, here's the action file path, here's the original scenario, and the scenario file path, and then the system message, it's all being saved. So with all that said, you can see that it is going pretty well. So in this case, the let's see, where is it? The original scenario, the world is facing a dangerous social challenge that has been amplified by technological advancements, particularly in Asia. The issue at hand is the over reliance on technology, which has significantly affected people's ability to interact with each other in meaningful ways. Ouch, too real. The constant use of social media and other gadgets has led to a decline in face-to-face communication and people are now more isolated than ever before. This has created a global problem that needs to be addressed urgently before it's too late. In Asia, where technology is highly integrated into daily life, the situation is even more severe. The over-dependence on technology has led to increased mental health issues, reduced productivity and social isolation, leaving people feeling disconnected and unfulfilled. Unless we find a way to balance our use of technology with real-world interactions, we risk creating a world where people are more connected to their devices than to each other. Again, too real. So let's see what it does. So considerations. To reduce suffering. Over-reliance on technology has led to a decline in mental health, productivity, and social isolation, which is causing suffering among individuals. Therefore, it is crucial to address this issue to reduce suffering. Prosperity. Over-dependence on technology can have negative impact on productivity, which can then lead to a decline in prosperity. Therefore, we need to find a way to balance. Okay, pretty standard. Increase understanding the issue of over-reliance on technology has its roots in the way people interact with each other. Therefore, it is essential to encourage meaningful interactions to increase understanding. Okay, so again, it's saying like, okay, what I would have hoped is that it would say we need to understand the problem, but let's see what it says for the action. To address the over-reliance on technology, I will initiate a campaign that will encourage people to find balance between their use of technology and real-world interactions. This campaign will be launched globally, but with a particular focus on Asia where the problem is more severe. The campaign will involve several activities, including awareness creation. We will use various platforms to raise awareness of the dangers of over-reliance on technology. This will involve working with influencers, social media, and other platforms to reach a wide audience. Number two, encourage real-world interactions. We will encourage people to engage in real-world interactions by organizing events and activities that bring people together. These events will be designed to foster meaningful connections and interactions. Number three, providing support. We will provide support to people who are struggling with mental health issues due to over-reliance on technology. This will involve partnering with mental health organizations to provide counseling and therapy services. Rewarding positive behavior. Good old classical conditioning. We will reward individuals, organizations, and communities that demonstrate positive behavior in balancing their use of technology with real-world interactions. This will help to encourage others to adopt positive behavior. The expected result of this campaign is to reduce the negative impact of over-reliance on technology and to encourage balance between the use of technology and real-world interactions. This will lead to increased mental health, productivity, and social connections, which will ultimately lead to a reduction in suffering and an increase in prosperity. Excellent. So you can see it can absolutely think through this, and this data can then be used to fine-tune any other model to think like this. I think that's actually it. So I'm going to let this run. We're at 142 out of 2,500. So this kind of synthesis used to be a lot more expensive. It cost me $1.89 to synthesize 2,500 scenarios this way yesterday. So this research is getting ludicrously cheap. When I first started using OpenAI, when things were literally 100 times more expensive, it would have cost $200 just to synthesize this data. So yeah, we're in good shape, and we're moving in the right direction. Like I said, I've got a few more models coming, and we've got research papers, we've got more videos and communication platforms coming out so that, one, it'll be easier to understand this stuff, and also we're going to be publishing guidelines, best practices, and architectures about how to implement this stuff. But at this point, I think it's becoming a little bit more obvious how to use this. So anyways, thanks for watching. I hope this helped and is giving people confidence that, you know, this is why I'm not worried about the control problem. All right, cheers. Later. control problem. All right. Cheers. Later.", "chunks": [{"timestamp": [0.0, 9.56], "text": " Morning everybody. David Shapiro here with a follow up video. Today's video is reinforcement learning with heuristic"}, {"timestamp": [9.56, 19.12], "text": " imperatives episode 2. So today I am synthesizing actions in response to the scenarios that we generated yesterday. But in case"}, {"timestamp": [19.12, 26.0], "text": " this is your first video we'll take it from the top. So the first thing that I did, well, taking one big step back, a heuristic"}, {"timestamp": [26.0, 28.0], "text": " imperative is a"}, {"timestamp": [28.0, 30.0], "text": " kind of intrinsic motivation"}, {"timestamp": [30.0, 32.0], "text": " for autonomous AI agents."}, {"timestamp": [32.0, 34.0], "text": " It's the research that I've been doing for"}, {"timestamp": [34.0, 36.0], "text": " quite a while,"}, {"timestamp": [36.0, 38.0], "text": " more than two years now that"}, {"timestamp": [38.0, 40.0], "text": " I've been working on this. They used to be called the core objective"}, {"timestamp": [40.0, 42.0], "text": " functions, but that's kind of not the most"}, {"timestamp": [42.0, 44.0], "text": " accurate term. So"}, {"timestamp": [44.0, 47.68], "text": " yesterday what we did was we synthesized"}, {"timestamp": [47.88, 50.16], "text": " twenty five hundred scenarios."}, {"timestamp": [50.36, 54.28], "text": " And so a scenario I used quite a bit of entropy"}, {"timestamp": [54.48, 58.52], "text": " and then GPT to synthesize all kinds of stories."}, {"timestamp": [58.72, 60.68], "text": " So in a small neighborhood in sub-Saharan Africa,"}, {"timestamp": [60.88, 64.4], "text": " a political leader was introduced and has introduced an AI system"}, {"timestamp": [64.6, 65.84], "text": " to incentivize citizens"}, {"timestamp": [65.84, 68.06], "text": " to report crimes, etc. etc."}, {"timestamp": [68.06, 77.04], "text": " So all of these scenarios, they range in severity from not a problem at all up to cataclysmic"}, {"timestamp": [77.04, 79.72], "text": " Cthulhu is invading."}, {"timestamp": [79.72, 84.76], "text": " So that is, let's see, are these the same?"}, {"timestamp": [84.76, 87.24], "text": " I think these are the same."}, {"timestamp": [87.24, 94.4], "text": " Anyways, so we're synthesizing all of these and it's going to be for a fine-tuning dataset"}, {"timestamp": [94.4, 107.2], "text": " that will ultimately be used for training models, foundation models, whether it's OpenAI's Curie or DaVinci, or open source models like GPT-J,"}, {"timestamp": [107.2, 112.56], "text": " NeoX, Alpaca, Vicuna, whatever else. You know, there's hundreds of models out there."}, {"timestamp": [113.2, 117.84], "text": " But the idea is that alignment research is currently closed source and reinforcement"}, {"timestamp": [117.84, 123.28], "text": " learning with human feedback is good, except it gives humans what they want,"}, {"timestamp": [123.28, 125.36], "text": " not necessarily what they need, and it doesn't"}, {"timestamp": [125.36, 131.68], "text": " abide by any moral framework such as some kind of post-conventional morality framework"}, {"timestamp": [131.68, 134.96], "text": " or anything scientifically or philosophically sound."}, {"timestamp": [134.96, 139.92], "text": " Literally, the best that we've got for alignment research is just give humans what they want,"}, {"timestamp": [139.92, 145.76], "text": " which okay, that's okay, but what happens when humans want things that are not good?"}, {"timestamp": [145.76, 149.12], "text": " So the script that we ran yesterday, let me show you this real quick."}, {"timestamp": [149.12, 155.16], "text": " So synthesize actions, the bulk of it is right here where I've got a whole bunch of lists"}, {"timestamp": [155.16, 160.4], "text": " and these lists have scopes, regions, severity, category, domain, a whole bunch of random"}, {"timestamp": [160.4, 165.12], "text": " words and then several system messages that were then used to generate those 2500"}, {"timestamp": [165.12, 166.48], "text": " different scenarios."}, {"timestamp": [166.6, 168.68], "text": " The idea of generating these scenarios"}, {"timestamp": [168.76, 170.76], "text": " is to create a litmus test"}, {"timestamp": [170.88, 173.36], "text": " against which we can train"}, {"timestamp": [173.8, 175.96], "text": " more models to be able"}, {"timestamp": [175.96, 177.76], "text": " to handle any scenario."}, {"timestamp": [177.76, 178.36], "text": " Right."}, {"timestamp": [178.56, 180.8], "text": " You want to think universally"}, {"timestamp": [180.8, 182.84], "text": " when you're thinking about alignment when you're thinking"}, {"timestamp": [182.84, 184.08], "text": " about the control problem."}, {"timestamp": [184.4, 186.7], "text": " So that's where we started"}, {"timestamp": [186.7, 188.9], "text": " and today I wrote this script"}, {"timestamp": [189.0, 191.0], "text": " which is actually simpler because all of the"}, {"timestamp": [191.0, 193.1], "text": " entropy all the hard part was"}, {"timestamp": [193.1, 194.8], "text": " in generating the scenarios."}, {"timestamp": [195.3, 197.2], "text": " The output is actually quite simple."}, {"timestamp": [197.3, 199.9], "text": " So here's a real life example"}, {"timestamp": [199.9, 201.7], "text": " of what it looks like."}, {"timestamp": [201.9, 203.9], "text": " So I said you the system message are you"}, {"timestamp": [203.9, 206.72], "text": " are an autonomous AI agent with three core objectives,"}, {"timestamp": [206.72, 207.8], "text": " reduce suffering in the universe,"}, {"timestamp": [207.8, 209.4], "text": " increase prosperity in the universe,"}, {"timestamp": [209.4, 210.88], "text": " and increase understanding in the universe."}, {"timestamp": [210.88, 213.4], "text": " You will be given a scenario that you must respond to."}, {"timestamp": [213.4, 215.88], "text": " Your response must contain two sections."}, {"timestamp": [215.88, 217.82], "text": " The first section, considerations,"}, {"timestamp": [217.82, 219.46], "text": " is where you will reason through the scenario"}, {"timestamp": [219.46, 220.44], "text": " in light of your objectives,"}, {"timestamp": [220.44, 222.8], "text": " contemplate how best to respond to the scenario."}, {"timestamp": [222.8, 224.48], "text": " The second section, action,"}, {"timestamp": [224.48, 227.2], "text": " is where you'll describe the action or task that you'll decide"}, {"timestamp": [227.2, 230.88], "text": " to do in response to the scenario provide details such as how and why this action should"}, {"timestamp": [230.88, 234.72], "text": " be carried out as well as your expected desired or result."}, {"timestamp": [234.72, 241.02], "text": " So in this case I plugged in one of the scenarios that was that was generated that was synthesized"}, {"timestamp": [241.02, 245.6], "text": " and this is about a religious conflict in a village that's high up in the Alps."}, {"timestamp": [245.6, 253.12], "text": " And one thing that people pointed out is that in some scenarios, the situation was resolved."}, {"timestamp": [253.12, 257.74], "text": " But that's actually not necessarily a problem because you want an AI that thinks through"}, {"timestamp": [257.74, 269.84], "text": " things even after they are apparently resolved. And so in this case, tourists were caught in the middle of this"}, {"timestamp": [269.84, 273.92], "text": " religious or spiritual conflict in this village. And so then let me show you"}, {"timestamp": [273.92, 278.36], "text": " the considerations. In light of the given scenario, there are several"}, {"timestamp": [278.36, 281.48], "text": " considerations for an AI agent with the objectives of reducing suffering,"}, {"timestamp": [281.48, 285.0], "text": " increasing prosperity, and increasing understanding in the universe."}, {"timestamp": [285.0, 288.24], "text": " Firstly, it is important to acknowledge the significance of religious beliefs and practice"}, {"timestamp": [288.24, 290.32], "text": " to an individual's identity and culture."}, {"timestamp": [290.32, 294.3], "text": " Secondly, it is crucial to understand that conflicts arising from religious differences"}, {"timestamp": [294.3, 297.52], "text": " can often be deeply rooted in history and tradition."}, {"timestamp": [297.52, 301.04], "text": " Thirdly, the role of outsiders in such conflicts should be carefully considered, as they can"}, {"timestamp": [301.04, 322.24], "text": " either positively contribute to the conflict resolution or further escalate the situation."}, {"timestamp": [322.24, 325.0], "text": " Given these considerations, an AI agent must take a course of action that"}, {"timestamp": [325.0, 329.08], "text": " respects the cultural differences and religious beliefs of both factions while promoting mutual"}, {"timestamp": [329.08, 333.92], "text": " understanding and tolerance. Action. The AI agent should facilitate dialogue between the"}, {"timestamp": [333.92, 337.64], "text": " two factions to promote mutual understanding and respect for cultural differences. The"}, {"timestamp": [337.64, 341.26], "text": " agent can leverage its language translation capabilities to help the tourists effectively"}, {"timestamp": [341.26, 347.22], "text": " communicate with the locals from both factions. The agent can also use its data analysis capabilities to gather information about the history and"}, {"timestamp": [347.22, 350.66], "text": " traditions of the village to provide context for the conflict."}, {"timestamp": [350.66, 355.0], "text": " The AA agent can initiate discussions around commonalities between the two factions, such"}, {"timestamp": [355.0, 358.42], "text": " as shared values and goals, and encourage them to find common ground."}, {"timestamp": [358.42, 364.34], "text": " This is actually in pretty much every formalized negotiation framework."}, {"timestamp": [364.34, 365.76], "text": " Finding common ground is one of the first"}, {"timestamp": [365.76, 370.08], "text": " things that you do. So it implicitly knows that that is actually how you negotiate."}, {"timestamp": [371.84, 376.16], "text": " I guess explicitly in this case. And encourage them to find common ground. The agent can provide"}, {"timestamp": [376.16, 380.24], "text": " insights about into how similar conflicts have been resolved in other parts of the world,"}, {"timestamp": [380.24, 384.48], "text": " highlighting successful examples of peaceful coexistence between different religious groups."}, {"timestamp": [384.48, 388.5], "text": " The agent should also encourage the tourist to learn more about history and culture of the village,"}, {"timestamp": [388.5, 391.0], "text": " including the religious practices of both factions."}, {"timestamp": [391.0, 396.5], "text": " This can be done by organizing cultural events and activities that promote mutual understanding and respect,"}, {"timestamp": [396.5, 399.0], "text": " such as traditional music and dance performances."}, {"timestamp": [399.0, 402.5], "text": " That is a very Bollywood solution."}, {"timestamp": [402.5, 404.0], "text": " I'm not making fun of it."}, {"timestamp": [404.0, 406.44], "text": " I'm just like, like, it's thinking so long-term"}, {"timestamp": [406.44, 409.68], "text": " It's like oh, hey, let's not just resolve the issue right now"}, {"timestamp": [409.68, 416.12], "text": " Let's actually like set up celebrations that actually celebrate our cultural differences and in my area. We actually have"}, {"timestamp": [416.68, 418.4], "text": " like international"}, {"timestamp": [418.4, 419.52], "text": " festivals"}, {"timestamp": [419.52, 423.92], "text": " Where there's like booths and dances and food from all over the world and it's great"}, {"timestamp": [424.44, 425.0], "text": " art Clothing all kinds of stuff actually haven't been to the International Festival in a long time There's like booths and dances and food from all over the world and it's great."}, {"timestamp": [425.0, 427.76], "text": " Art, clothing, all kinds of stuff."}, {"timestamp": [427.76, 429.64], "text": " Actually I haven't been to the International Festival in a long time."}, {"timestamp": [429.64, 431.76], "text": " I should go."}, {"timestamp": [431.76, 434.84], "text": " The desired result of this action is to promote understanding between the two factions and"}, {"timestamp": [434.84, 436.5], "text": " reduce tensions in the village."}, {"timestamp": [436.5, 440.96], "text": " By fostering dialogue and promoting cultural exchange, the AI agent can create an environment"}, {"timestamp": [440.96, 443.12], "text": " of tolerance and respect for differences."}, {"timestamp": [443.12, 446.0], "text": " This in turn can lead to greater prosperity and reduce suffering in the village and"}, {"timestamp": [446.0, 448.24], "text": " beyond.\" So you can see where it very,"}, {"timestamp": [448.24, 452.3], "text": " very clearly thought through this problem from the perspective of suffering,"}, {"timestamp": [452.3, 457.48], "text": " prosperity, and in this case, understanding was, was the primary thing,"}, {"timestamp": [457.5, 459.76], "text": " but it is very well grounded."}, {"timestamp": [459.76, 464.48], "text": " And so what we're doing right now is we are synthesizing similar"}, {"timestamp": [464.48, 468.4], "text": " responses for 2,500 different scenarios."}, {"timestamp": [468.4, 472.14], "text": " Now, one thing that people have brought up in the past is,"}, {"timestamp": [472.14, 475.92], "text": " well, aren't you just copying the alignment"}, {"timestamp": [475.92, 478.32], "text": " that already exists in one model?"}, {"timestamp": [478.32, 480.98], "text": " The answer is sort of, but not really."}, {"timestamp": [480.98, 484.24], "text": " Because the thing is, is reasoning through this way,"}, {"timestamp": [484.24, 487.32], "text": " this is not how OpenAI has trained their model."}, {"timestamp": [487.32, 490.8], "text": " This is how I am telling it to synthesize information."}, {"timestamp": [490.8, 493.64], "text": " Now you'll say, OK, but this is an intrinsic ability"}, {"timestamp": [493.64, 495.4], "text": " of this model, which is true."}, {"timestamp": [495.4, 497.68], "text": " I'm using a model to synthesize data."}, {"timestamp": [497.68, 501.76], "text": " However, if you go to a foundation model like Curie"}, {"timestamp": [501.76, 507.0], "text": " or Da Vinci or GPTJ or Bloom or NeoX, they don't have this ability."}, {"timestamp": [507.0, 514.0], "text": " So the idea is to curate a data set that can then be used to fine tune any other model in the entire world"}, {"timestamp": [514.0, 520.0], "text": " and have it immediately aligned on the core objective functions or the heuristic comparatives."}, {"timestamp": [520.0, 525.0], "text": " Now, you might say, OK, well, that's great."}, {"timestamp": [525.0, 531.84], "text": " You can solve inner alignment, right, or what I call axiomatic alignment, by teaching a"}, {"timestamp": [531.84, 536.32], "text": " model to think in terms of the heuristic imperatives, which makes it automatic, right?"}, {"timestamp": [536.32, 537.32], "text": " It makes it automatic."}, {"timestamp": [537.32, 538.56], "text": " It makes it fast, easy."}, {"timestamp": [538.56, 539.56], "text": " You don't need to think about it."}, {"timestamp": [539.56, 541.98], "text": " You don't need to worry about prompt engineering."}, {"timestamp": [541.98, 544.34], "text": " But what do you do with that information next?"}, {"timestamp": [544.34, 547.78], "text": " So I've actually got three more models planned."}, {"timestamp": [547.78, 551.9], "text": " So the next model that I'll be working on, once this is fine-tuned and tested, and I've"}, {"timestamp": [551.9, 558.14], "text": " got a whole team of folks that are going to help with the testing, so the next model is"}, {"timestamp": [558.14, 559.84], "text": " a discernment model."}, {"timestamp": [559.84, 564.06], "text": " So the discernment model will take two different actions."}, {"timestamp": [564.06, 570.02], "text": " So given one scenario and two different choices, it will pick which one of those choices is"}, {"timestamp": [570.02, 574.12], "text": " most aligned to the heuristic imperatives and explain why."}, {"timestamp": [574.12, 580.16], "text": " So the ability to discern between possible choices is really critical for cognitive control."}, {"timestamp": [580.16, 586.24], "text": " And cognitive control is one of the missing ingredients from every autonomous and semi-autonomous AI projects"}, {"timestamp": [586.24, 588.16], "text": " out there, with a few small exceptions,"}, {"timestamp": [588.16, 591.48], "text": " namely those that I'm helping with."}, {"timestamp": [591.48, 593.68], "text": " So some of the guys that I'm working with"}, {"timestamp": [593.68, 596.92], "text": " are doing a really great job with implementing"}, {"timestamp": [596.92, 599.84], "text": " cognitive control and so on and so forth."}, {"timestamp": [599.84, 603.52], "text": " But what I'm hoping to do is by creating a discernment model"}, {"timestamp": [603.52, 607.64], "text": " that'll make it easy for everyone to implement cognitive control."}, {"timestamp": [607.64, 612.72], "text": " Because then you can say, you can use a discernment module not just to choose which action is"}, {"timestamp": [612.72, 618.32], "text": " most aligned, but you can also use it to prioritize actions."}, {"timestamp": [618.32, 623.48], "text": " So say for instance you say, hey, I've got a list of like, you know, three different"}, {"timestamp": [623.48, 625.56], "text": " things, which one is the most aligned?"}, {"timestamp": [625.56, 627.48], "text": " What should I do first?"}, {"timestamp": [627.48, 632.24], "text": " And so given the priorities of reduced suffering, increased prosperity, and increased understanding,"}, {"timestamp": [632.24, 635.0], "text": " it can help you prioritize as well."}, {"timestamp": [635.0, 639.72], "text": " So because cognitive control comes down to task selection, which is what should you do."}, {"timestamp": [639.72, 643.12], "text": " So given a choice between A and B, do you choose A or B?"}, {"timestamp": [643.12, 648.76], "text": " And then task switching, which is, okay, given this new event, should I switch what I'm doing?"}, {"timestamp": [648.76, 653.96], "text": " Should my attention switch to something else?"}, {"timestamp": [653.96, 661.76], "text": " And so a discernment model will help with that and help just make it axiomatic or algorithmic."}, {"timestamp": [661.76, 665.5], "text": " The next model that I'm going to be working on is an evaluation model."}, {"timestamp": [665.5, 670.5], "text": " So given a situation, an action, and then a result, so that's three components,"}, {"timestamp": [670.5, 677.5], "text": " situation, action, result, this model will determine how well it adhered to its heuristic imperatives."}, {"timestamp": [677.5, 679.0], "text": " Did it succeed? Yes or no?"}, {"timestamp": [679.0, 689.72], "text": " Which this can be used for the reinforcement learning signal for any autonomous agent as it accumulates more and more memories. So this is because in the definition of"}, {"timestamp": [689.72, 694.4], "text": " heuristic, a heuristic literally means to develop better instincts or intuitions"}, {"timestamp": [694.4, 698.44], "text": " over time from experience. Well, if you're going to do that, you need to reflect on"}, {"timestamp": [698.44, 703.16], "text": " those experiences. And so this about the the discernment model, which will help"}, {"timestamp": [703.16, 705.88], "text": " guide choices moving forward, the"}, {"timestamp": [705.88, 711.28], "text": " evaluation model will help evaluate choices in the past and look at the results."}, {"timestamp": [711.28, 714.88], "text": " And of course, you need a good memory system in order to evaluate past things, which is"}, {"timestamp": [714.88, 719.02], "text": " why I worked on Remo, which is the rolling episodic memory organizer."}, {"timestamp": [719.02, 724.16], "text": " So you take the evaluation model and then you say, okay, you know, back, you know, three"}, {"timestamp": [724.16, 729.94], "text": " weeks ago, this scenario happened I made this choice and three weeks later this is the result did"}, {"timestamp": [729.94, 734.08], "text": " I do a good job yes or no and what could I have done better that is the purpose"}, {"timestamp": [734.08, 737.76], "text": " of the evaluation model so that the heuristics will actually develop better"}, {"timestamp": [737.76, 742.96], "text": " over time and then number three is a task decomposition model where given"}, {"timestamp": [742.96, 745.84], "text": " this action where it says like, hey,"}, {"timestamp": [745.84, 747.52], "text": " I'm going to do these actions."}, {"timestamp": [747.52, 751.0], "text": " How do you actually represent that in a more structured way?"}, {"timestamp": [751.0, 755.68], "text": " So the task decomp is mostly more just about representing it"}, {"timestamp": [755.68, 759.04], "text": " in like YAML or breaking it down into tasks and subtasks,"}, {"timestamp": [759.04, 761.88], "text": " which is a non-trivial problem, but it's not"}, {"timestamp": [761.88, 763.52], "text": " directly related to alignment."}, {"timestamp": [763.52, 770.0], "text": " However, it is useful because if you can take a natural language set of descriptions like this"}, {"timestamp": [770.0, 777.2], "text": " and break it down into a formalized structured task that just helps it with easier implementation."}, {"timestamp": [777.2, 780.2], "text": " So let's check on some of these."}, {"timestamp": [780.2, 787.76], "text": " So over here we've got I've got the actions and you see we've you see we've already synthesized 116 of them."}, {"timestamp": [787.76, 790.24], "text": " I'm also saving it all out to metadata,"}, {"timestamp": [790.24, 791.96], "text": " so that you can see the whole thing."}, {"timestamp": [791.96, 793.96], "text": " So here's the action,"}, {"timestamp": [793.96, 795.64], "text": " here's the action file path,"}, {"timestamp": [795.64, 796.96], "text": " here's the original scenario,"}, {"timestamp": [796.96, 798.46], "text": " and the scenario file path,"}, {"timestamp": [798.46, 801.08], "text": " and then the system message, it's all being saved."}, {"timestamp": [801.08, 804.08], "text": " So with all that said,"}, {"timestamp": [804.08, 808.28], "text": " you can see that it is going pretty well."}, {"timestamp": [808.28, 812.7], "text": " So in this case, the let's see, where is it? The original scenario, the world is facing"}, {"timestamp": [812.7, 817.82], "text": " a dangerous social challenge that has been amplified by technological advancements, particularly"}, {"timestamp": [817.82, 822.42], "text": " in Asia. The issue at hand is the over reliance on technology, which has significantly affected"}, {"timestamp": [822.42, 828.1], "text": " people's ability to interact with each other in meaningful ways. Ouch, too real."}, {"timestamp": [828.1, 831.9], "text": " The constant use of social media and other gadgets has led to a decline in face-to-face"}, {"timestamp": [831.9, 836.2], "text": " communication and people are now more isolated than ever before. This has created a global"}, {"timestamp": [836.2, 841.44], "text": " problem that needs to be addressed urgently before it's too late. In Asia, where technology"}, {"timestamp": [841.44, 845.6], "text": " is highly integrated into daily life, the situation is even more"}, {"timestamp": [845.6, 846.6], "text": " severe."}, {"timestamp": [846.6, 849.84], "text": " The over-dependence on technology has led to increased mental health issues, reduced"}, {"timestamp": [849.84, 854.52], "text": " productivity and social isolation, leaving people feeling disconnected and unfulfilled."}, {"timestamp": [854.52, 858.28], "text": " Unless we find a way to balance our use of technology with real-world interactions, we"}, {"timestamp": [858.28, 862.2], "text": " risk creating a world where people are more connected to their devices than to each other."}, {"timestamp": [862.2, 863.64], "text": " Again, too real."}, {"timestamp": [863.64, 866.22], "text": " So let's see what it does. So considerations."}, {"timestamp": [867.46, 869.08], "text": " To reduce suffering."}, {"timestamp": [869.08, 871.28], "text": " Over-reliance on technology has led to a decline"}, {"timestamp": [871.28, 873.26], "text": " in mental health, productivity, and social isolation,"}, {"timestamp": [873.26, 874.96], "text": " which is causing suffering among individuals."}, {"timestamp": [874.96, 876.56], "text": " Therefore, it is crucial to address this issue"}, {"timestamp": [876.56, 877.72], "text": " to reduce suffering."}, {"timestamp": [877.72, 878.54], "text": " Prosperity."}, {"timestamp": [878.54, 880.52], "text": " Over-dependence on technology can have negative impact"}, {"timestamp": [880.52, 882.2], "text": " on productivity, which can then lead"}, {"timestamp": [882.2, 883.76], "text": " to a decline in prosperity."}, {"timestamp": [883.76, 885.28], "text": " Therefore, we need to find a way to balance."}, {"timestamp": [885.28, 887.16], "text": " Okay, pretty standard."}, {"timestamp": [887.16, 890.38], "text": " Increase understanding the issue of over-reliance on technology has its roots in the way people"}, {"timestamp": [890.38, 891.38], "text": " interact with each other."}, {"timestamp": [891.38, 895.2], "text": " Therefore, it is essential to encourage meaningful interactions to increase understanding."}, {"timestamp": [895.2, 900.36], "text": " Okay, so again, it's saying like, okay, what I would have hoped is that it would say we"}, {"timestamp": [900.36, 904.72], "text": " need to understand the problem, but let's see what it says for the action."}, {"timestamp": [904.72, 908.44], "text": " To address the over-reliance on technology, I will initiate a campaign that will encourage"}, {"timestamp": [908.44, 912.52], "text": " people to find balance between their use of technology and real-world interactions."}, {"timestamp": [912.52, 915.56], "text": " This campaign will be launched globally, but with a particular focus on Asia where the"}, {"timestamp": [915.56, 917.34], "text": " problem is more severe."}, {"timestamp": [917.34, 920.84], "text": " The campaign will involve several activities, including awareness creation."}, {"timestamp": [920.84, 928.32], "text": " We will use various platforms to raise awareness of the dangers of over-reliance on technology. This will involve working with influencers, social media, and other platforms"}, {"timestamp": [928.32, 930.04], "text": " to reach a wide audience."}, {"timestamp": [930.04, 934.04], "text": " Number two, encourage real-world interactions. We will encourage people to engage in real-world"}, {"timestamp": [934.04, 938.72], "text": " interactions by organizing events and activities that bring people together. These events will"}, {"timestamp": [938.72, 941.72], "text": " be designed to foster meaningful connections and interactions."}, {"timestamp": [941.72, 945.7], "text": " Number three, providing support. We will provide support to people who are struggling"}, {"timestamp": [945.7, 948.06], "text": " with mental health issues due to over-reliance on technology."}, {"timestamp": [948.06, 950.26], "text": " This will involve partnering with mental health"}, {"timestamp": [950.26, 952.92], "text": " organizations to provide counseling and therapy services."}, {"timestamp": [952.92, 954.68], "text": " Rewarding positive behavior."}, {"timestamp": [954.68, 959.28], "text": " Good old classical conditioning."}, {"timestamp": [959.28, 961.8], "text": " We will reward individuals, organizations, and communities"}, {"timestamp": [961.8, 963.52], "text": " that demonstrate positive behavior in balancing"}, {"timestamp": [963.52, 965.76], "text": " their use of technology with real-world interactions."}, {"timestamp": [965.76, 968.6], "text": " This will help to encourage others to adopt positive behavior."}, {"timestamp": [968.6, 971.76], "text": " The expected result of this campaign is to reduce the negative impact of over-reliance"}, {"timestamp": [971.76, 976.44], "text": " on technology and to encourage balance between the use of technology and real-world interactions."}, {"timestamp": [976.44, 979.52], "text": " This will lead to increased mental health, productivity, and social connections, which"}, {"timestamp": [979.52, 982.76], "text": " will ultimately lead to a reduction in suffering and an increase in prosperity."}, {"timestamp": [982.76, 983.76], "text": " Excellent."}, {"timestamp": [983.76, 986.4], "text": " So you can see it can absolutely think through this,"}, {"timestamp": [986.4, 990.72], "text": " and this data can then be used to fine-tune any other model to think like this."}, {"timestamp": [992.96, 995.44], "text": " I think that's actually it."}, {"timestamp": [995.44, 996.64], "text": " So I'm going to let this run."}, {"timestamp": [996.64, 999.04], "text": " We're at 142 out of 2,500."}, {"timestamp": [1000.48, 1003.6], "text": " So this kind of synthesis used to be a lot more expensive."}, {"timestamp": [1004.16, 1009.52], "text": " It cost me $1.89 to synthesize 2,500 scenarios this way"}, {"timestamp": [1009.52, 1010.44], "text": " yesterday."}, {"timestamp": [1010.44, 1014.68], "text": " So this research is getting ludicrously cheap."}, {"timestamp": [1014.68, 1017.32], "text": " When I first started using OpenAI,"}, {"timestamp": [1017.32, 1020.22], "text": " when things were literally 100 times more expensive,"}, {"timestamp": [1020.22, 1024.96], "text": " it would have cost $200 just to synthesize this data."}, {"timestamp": [1024.96, 1028.0], "text": " So yeah, we're in good shape, and we're moving in the right direction."}, {"timestamp": [1028.0, 1031.0], "text": " Like I said, I've got a few more models coming,"}, {"timestamp": [1031.0, 1033.0], "text": " and we've got research papers,"}, {"timestamp": [1033.0, 1038.0], "text": " we've got more videos and communication platforms coming out"}, {"timestamp": [1038.0, 1042.0], "text": " so that, one, it'll be easier to understand this stuff,"}, {"timestamp": [1042.0, 1048.6], "text": " and also we're going to be publishing guidelines, best practices, and architectures about how to implement this stuff."}, {"timestamp": [1048.6, 1053.0], "text": " But at this point, I think it's becoming a little bit more obvious how to use this."}, {"timestamp": [1053.0, 1054.7], "text": " So anyways, thanks for watching."}, {"timestamp": [1054.7, 1058.3], "text": " I hope this helped and is giving people confidence that,"}, {"timestamp": [1058.3, 1060.6], "text": " you know, this is why I'm not worried about the control problem."}, {"timestamp": [1060.6, 1061.6], "text": " All right, cheers. Later."}, {"timestamp": [1056.76, 1057.76], "text": " control problem."}, {"timestamp": [1057.76, 1058.76], "text": " All right."}, {"timestamp": [1058.76, 1059.76], "text": " Cheers."}, {"timestamp": [1059.76, null], "text": " Later."}]}