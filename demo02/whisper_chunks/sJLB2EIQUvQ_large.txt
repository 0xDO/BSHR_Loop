{"text": " One question that I get a lot is, Dave, you have made literally hundreds of videos and, you know, you've written a few books, but the books are out of date and I want to use a chat bot to talk with you or, you know, otherwise use all your material. And so if you saw this video yesterday, Matt Wolf produced this video where he basically made a Mr. Beast chat bot by downloading, I think it was like 11 or 12 transcripts which is a really phenomenal idea. But also I've been talking about MemGPT and other ways of basically organizing arbitrarily large data sets. So I went to one of my old repos where I had my YouTube chapter generator. So if you've seen some of my older videos, I generated this thing where it would just download and download the transcript from a video and make a set of YouTube chapters. This is done automatically. There's other services that do this now. Even YouTube will sometimes generate chapters for you. So this project is kind of, you know, whatever. But if you wanna see how it's done, this is how it's done. And this was back with GPT-3. So with GPT-4, it's probably infinitely easier. But in the service of doing this, I wrote a script that literally it's just called download all transcripts. And all it does is it goes to my channel and you can you can change it so that it will go to any channel. You just change the channel ID here. And it will download literally every transcript. So here you can see that I have 270 plus transcripts from all of my videos. This is obviously a potentially highly valuable corpus of training data. Now one thing is that I think people are coming to terms with the fact that fine tuning is not useful for knowledge representation. We're now in the age of retrieval augmented generation and basically MemGPT is just a retrieval system. It's not a particularly sophisticated memory system. And one thing that I want to address is like yes I can be very highly critical of scientific papers I'm notoriously difficult to impress. I'm sorry if this frustrates some people. Another thing that I wanted to address is that some members of the audience are more scientifically minded and some members of the audience are more engineering and coding minded where they just want practical results. So sometimes I'll be talking about things from a more scientific lens and sometimes I'll be talking from a more pragmatic lens. So my criticism of MemGPT is more from the pragmatic lens. And yes, I am aware that there are A-B testing and all sorts of more scientifically rigorous things that I can do. And I apologize again if that frustrates you. Anyways, moving on. So basically we've got this huge corpus of valuable data here. So if you wanna understand how MindMind works and all that stuff you can download these transcripts it's all free and do whatever you want with it. Just don't you know do anything creepy. Not that anyone would. I don't think. Anyways. So now yesterday I created a video about latent space activation. So a few recent concepts that I've been working on, I made another video talking about sparse priming representations. So if you haven't seen that, a sparse priming representation is a way of activating certain aspects of a large language model without having the full bulk of it. And so this banks on the fact that large language models are associative, just like human memory is. However, large language models have read literally hundreds of lifetimes worth of text. So you only need to remind them of a few key facts or features or assertions about stuff, even things that are outside of its training distribution, and it can then adopt and use new concepts. You can teach it new terms You can teach it new events all sorts of stuff using sparse priming representations And you can compress relatively large things. I actually took My systems thinking book that I'm working on and gave it to Claude and I asked Claude to create a sparse priming Representation of my systems thinking book and it was able to compress it down to about a page and then unpack most of it. Now, this is basically a form of semantic compression, or you might say, from a mathematical perspective, it's like a semantic PCA, principal component analysis. But anyways, the idea here is that it is a form of lossy verbal compression. But because LLMs have the ability to confabulate, which means that they can infer or impute or kind of guess, sparse priming representations are super useful. And then yesterday I talked about latent space activation. So latent space activation is kind of the broader concept of what's going on behind the scenes inside of the model. And then also yesterday I mentioned something that I was working on, which is what I call the Basher Loop, or BSHR. So BSHR is the point of today's video, and this stands for Brainstorm, Search, Hypothesize, and Refine. So I married a librarian, so this basically constitutes dinner conversation for us, but in the field of information and library science People have information needs. This is why you go to Google. This is why you go to Wikipedia or even you search reddit or YouTube Now there are tools out there like perplexity like the chatbot that Matt Wolf built But there's one's a few things missing from all of these tools and that is information literacy and information foraging strategies. So I am here to teach you about that and we are also here to introduce the Bashor Loop repo which is brand new. But basically, the ultimate goal here is to create a Bashor Loop search tool chatbot that will allow you to search literally all of my videos. So there's a lot of steps to do. We're not going to finish it today, but I wanted to take this time to one, introduce the repo, introduce the concepts and show you the work that I've already done. So when you first get to the repo, it's just Dave Schapp slash BSHR loop or basher loop as I, as I say it out loud. So the basherloop, welcome to the repo. It allows you to search for arbitrarily large information domains. This is what it means. The overview. So the overview of the loop. First, brainstorm. It accepts a query from the user. It brainstorms a list of questions, which I showed you yesterday, and I'll show you the prompt that I used to do it today in just a little bit. Then you use search functionality, whether it's APIs or vector database or whatever. The queries that you start with are then basically just piped to whatever your information tap is. Or if you have multiple information taps, you can use that. Then hypothesize, so you take the information that is retrieved from your data source, whether it is Wikipedia or a vector database or just a general internet search, and then you have the LLM read all of it and form a hypothesis based on that information. This hypothesis is an answer to the potential question. It says, okay, based on everything that you're seeing, this is the answer. And if you want to try this, this is basically what Perplexity does, but it does it as a single step where it just searches and summarizes. It doesn't really form a hypothesis, nor does it actually write good queries, which is my chief complaint and why I canceled my Perplexity subscription. And then finally, refine. So this is refine or recurse or whatever, but the idea is you don't just do one information search. Think about the last time that you had a really challenging problem. What do you do? You do a Google search, you open a bunch of tabs, you read a few things, you read a few more things, and then you learn about the space, and then you go write a better information query. You write a better search query. So this is the loop. This is why it is a loop, is because finding and using the correct information is not a single-step process. When you go to the library, whether it's the University Library or the local city library, what do you do? You go, you talk to a librarian, they ask you a bunch of questions about what you're trying to achieve, and then you you know, you go look at a book and you take some notes and it's like, okay cool I liked this book, but now that you're informed you go from a naive query to an informed query. Real quick, Dave here with a request. So you've probably noticed that I'm cranking out videos and I'm really getting my content dialed into what is adding the most value to you guys. And so I'm really doubling down on subscriber growth and just really serving the community. Now, the reason that I've been able to increase the quality of my videos and the frequency is because I've stepped away from consulting. More than half my income came from consulting, so I'm really kind of hurting for cash right now. However, I have been largely supported by a grassroots movement, so my request is hop on over to my Patreon page and sign up. The lowest tier is $5 a month, and that gets you access to Discord, which I'll show you in just a moment, but I also have a premium Discord tier, which gives you access to some private channels, some live streams, and QA sessions, and that sort of thing. So if you could, help me out, and you'll get access to this community. And it's a great community. We've got almost 600 people right now, and we talk about all kinds of stuff, not just AI. We talk about the future of humanity. We have artistic interests. We talk about economics. We talk about the future of humanity, we have artistic interests, we talk about economics, we talk about existential coping, post-labor economics, all of the above. And then finally, I also have some premium channels for the high-tier subscribers. So, thanks for watching, and yeah, thank you. You go from a naive query to an informed query. So, this is where I'll go down, and I'm not going to read all of these to you verbatim, but I'm just pointing out that this information is here in the repo so that you can get familiar because I'm assuming that most of you are not familiar with library and information science, so here's some critical things that I can teach you so that you can make informed queries. So first of all, what we're talking about is information foraging. Information foraging is when you go into an unknown or incomplete information domain where you have an information need, but you don't necessarily even know what questions to ask. So you have to go in search of information by basically starting out guessing. Information literacy is one of the primary things that I complain about, both with these tools and humans in general. So information literacy is basically understanding how to engage with sources of information in order to find correct information or validate the information that you have. And this is something that I talked about yesterday and will also show you in just a moment where the way that I build information literacy into this tool is by telling the LLM during the brainstorm phase to generate counterfactual questions. Basically it's trying to prove itself wrong and it's trying to find all sides of any given information problem which will result in a better recall. Recall is a very specific term from library science where basically are you getting all of the information that is relevant, that is salient to your query. So next up is satisficing. So satisficing is a portmanteau of sufficing and satisfying. So when you satisfy an information query the idea is that you have found you have gotten to the level of good enough. It's not perfect, it's not complete, but you have the information that you eminently need and you're ready to move on. So, one example that you can use for satisficing is when you're looking for a restaurant to go to. You might have in your mind the perfect restaurant, but the perfect restaurant might not be available, it might be too far, it might just not even exist. And so what you do is you look for something that is good enough. And so the idea is that within information foraging, within search, you need to satisfy from time to time. Which means that the information, the exact information that you need, might not be available. A definitive answer to your question might not even be possible. If you watch the video that I made yesterday, one of the things that I asked was what is the exact coastline of Britain? And the answer that it gave me was, well, that's really hard to determine, but here's how you could go about it. And so the answer to the information query that I had, the information need, was not a definitive answer, but rather, this is how you approach that information problem. So in that case, what it needed to do was outside of the scope of information foraging. Information needs, so I've referred to this before, but basically all problems are a form of information need. So an information need is I have some sort of problem, solution, query, whatever, and I need information in order to be able to tackle this. Whether you're a CEO making strategic decisions about AI, whether you're a broke college student whose car is making funny noises, whether you're in a relationship and you want to know how do I navigate this fight that we just had, literally everything you do in life has information needs. And this is why libraries are super underrated, as well as librarians. But of course I am biased because I married a librarian. Now, this is a term that I invented, at least as far as I know that I invented. So there's what's called a naive query. So a naive query is something that everyone does, where you go to Google and you don't even know the right questions to ask. So you just kind of guess. You just launch your best guess out into the ether and then Google gives you back some stuff that it, you know, Google has a lot of really good algorithms so it can kind of infer what you're actually looking for. And the reason that it can do this is because lots of other people before you have launched those naive queries and Google tracks where they ultimately end up. And it says, okay, based on what you're looking for, based on what you've put in, I'm predicting that this is actually the page that you're looking for. So you launch a naive query because you don't know what you don't know. Once you know a little bit more, then you can write an informed query. Because let's say, for for instance you start with you know the one of the questions that I asked yesterday which was who were the important senators during the peak of Roman power right you might not know that there is a thing called Pax Romana. So part of the part of what you would find during that query is you know the Pax Romana or as someone pointed out in the comments Rome was a a kingdom first, then a republic, then an empire. So it depends on how you define like, you know, empire versus Senate, you know, how do you define the peak of Roman power? And so you can then integrate all of those bits of information to ask better questions like, you know, was Rome more powerful as a republic? Was Rome more powerful as an empire? Now, of course, large language models already know most of these things, which is why the Basher loop can actually work in a vacuum for things, particularly historical information, that have been discussed to death. But, as other people pointed out in the comments, there's lots of data out there that is just not in the training distribution, like your personal data, like my YouTube transcripts, like corporate data. So once you have your naive query, you know a little bit more, then you can dial into an information scent, which is like, okay, here are some clues to what I'm actually looking for, and then you can write an informed query. And then I already mentioned precision versus recall, I'm not going to read that one to you. And then finally, there's some use cases. So I've kind of alluded to all these. You could apply the basher loop to the business data lake, to an internet search, to a university library system, or a personal archive in the case of my transcripts. So, I've got all the transcripts saved here. You can go through them all. There's obviously quite a few. Yeah, so there's that. And then finally, or not finally, but next is contributing. So I've got there's there's three ways that you can contribute or participate and the order is listed so please make sure you check the contributing file before jumping in. First is join the discussions. This is where everyone should start. Don't just jump in immediately submitting issues and pull requests. If they don't follow the guidelines here, they'll be closed and rejected. But yeah, so check out the contributing.markdown file. If you're not familiar with this, the discussions tab is up here, so you can jump in. There's no discussions yet because I just created the repo. There's issues here. Again, no issues have been created, and there's no pull requests yet either. All right. So, then I've created demo01. So this one will be, before we get all the way into, you know, building our own local repository, our own local database on my YouTube transcripts, first we're just going to use an existing information source, specifically Wikipedia. I've got the project defined here. I showed a very naive initial test yesterday. I've got the code copied here. It doesn't work yet, so don't... Lower your expectations. We are still very early in the process. But what I did want to show you was that demo 01 is here. It's got its own readme. And I also... the work that I did do is that I already wrote the system prompts. So let me... let's go through these one at a time. So this is the system prompt for 01, the brainstorming one. Now what I had yesterday was just this bit. So you're a search query generator, yada yada. Basically, it generates a list of questions in a JSON object that can be used to do Google searches or Wikipedia searches or whatever. And so this is the first part of the process that will be used to generate the brainstorm step of the basher loop. So brainstorm, a list of questions, but then what I added was refined queries. This integrates that idea of whatever information you give the chat GPT API, if you don't give it any previous queries, it'll be like, okay, whatever. But if you do, it will integrate it. If these materials are present, you are to generate informed queries, more specific search queries that aim to zero in on the correct information domain. Do not duplicate previously asked questions. Use the notes and other information to write better questions, basically. So this one prompt will be part of the basher loop. So whether it's the first time you're running it or subsequent times, it will generate recursively better search queries. So that's the first bit. So I wrote that and then going back to system 02. So the second part is hypothesize. Obviously the search part, that's to be handled by an API or ChromaDB or whatever. So you don't need a system prompt for that Basically, the search part, that's to be handled by an API or ChromaDB or whatever. So you don't need a system prompt for that because basically that's an algorithmic thing that is just a script. So the next step that is handled by the LLM is the hypothesis generator. So like the brainstorming, the query generator, you're an information needs hypothesis generator. You'll be given a main information need or user query as well as a variety of materials, such as search results, previous hypotheses, and notes. Whatever information you receive, your output should be a revised, refined, or an improved hypothesis. In this case, the hypothesis is a comprehensive answer to the user question, etc, etc, etc. Basically, I'm just giving an instructions that whatever I give you, generate a hypothesis that answers the user query as comprehensively as possible I tell it not to worry about citations because we'll hold that out as metadata And so that's a problem that we need to work out okay, and then finally the satisficing check so I'm guessing that this is probably the first time that most of you have heard about satisficing So here's the instruction that I wrote in order to produce this, and I'll explain why. But the very short answer is I'm going to give you a bunch of information, and then you judge, you being the LLM, GPT, you judge whether or not the information need has been satisfied. And then I tell it, like, you're to make this judgment by virtue of several factors, amount and quality of searches, specificity and comprehensiveness of the hypothesis, and the notes about the information domain and foraging if present. So basically we can include notes from the search part to say, hey we've exhausted all the search, like we're not finding anything else. And you can see that we've run 30 queries and this is the best information we've got. So several things to keep in mind, the user's information need might not be answerable. So in the case of asking what is the exact coastline of Britain, you might want to see a specific number or it might be partially answerable, which is like, it's generally estimated to be about, I think it was like 12,000 kilometers or something like that. Or given the information available for the problem. Basically, some things are outside of the scope of information needs. For instance, if you need to actually do something in the physical world, right? So like, you might go to the library and say like, I need to file my taxes. And it's like, well, I'm'm a librarian I can't file your taxes but I can give you all the information that you will need to be able to file your taxes. So tool use and acting upon the world is outside of the scope of the Basher loop but the idea is if the information is available we will give you all the information that we can get we will basically act like a librarian and be your information concierge to get you the information that you need that you can then go take and give to another AI or a chatbot or a robot or your best friend or do it yourself or whatever. Anyways, finally, the output format is a JSON object. So there's two things that I put in the JSON object. One is feedback, which is basically it unpacking what its perception is. And the reason that I do this first is because as language models kind of talk through things, it'll be able to triangulate and make a judgment or a decision a little bit better. Because as you might have seen on AI Explains videos, if you have a language model just output an answer, like if you give it a whole list of stuff and then just ask it to say true or false, it's going to be kind of random. But as I demonstrated in yesterday's video with sequential reasoning, large language models, because you get more latent space activation with sequential activation, this is also a form of sequential activation, wherein it talks through the evidence that you've presented and then it will make a better judgment as to whether or not the user information need has been satisfied. That's the TLDR of all of this and I think that brings us to the conclusion for today. So, that's where we're at. This is where we're starting. I'm probably going to be working on this for a little bit. This project isn't going to live too terribly long. It's probably going to be a three or four part series. We'll see. But yeah, so thanks for tuning in. I hope you got a lot out of this. Like, subscribe, etc, etc. You know the drill. Cheers. you", "chunks": [{"timestamp": [0.0, 6.32], "text": " One question that I get a lot is, Dave, you have made literally hundreds of videos and,"}, {"timestamp": [6.32, 11.04], "text": " you know, you've written a few books, but the books are out of date and I want to use a chat"}, {"timestamp": [11.04, 18.0], "text": " bot to talk with you or, you know, otherwise use all your material. And so if you saw this video"}, {"timestamp": [18.0, 23.92], "text": " yesterday, Matt Wolf produced this video where he basically made a Mr. Beast chat bot by downloading,"}, {"timestamp": [23.92, 26.32], "text": " I think it was like 11 or 12"}, {"timestamp": [26.32, 29.2], "text": " transcripts which is a really phenomenal idea."}, {"timestamp": [29.2, 35.0], "text": " But also I've been talking about MemGPT and other ways of basically organizing arbitrarily"}, {"timestamp": [35.0, 36.8], "text": " large data sets."}, {"timestamp": [36.8, 42.5], "text": " So I went to one of my old repos where I had my YouTube chapter generator."}, {"timestamp": [42.5, 46.0], "text": " So if you've seen some of my older videos,"}, {"timestamp": [46.0, 49.32], "text": " I generated this thing where it would just download"}, {"timestamp": [49.32, 52.18], "text": " and download the transcript from a video"}, {"timestamp": [52.18, 54.9], "text": " and make a set of YouTube chapters."}, {"timestamp": [54.9, 56.04], "text": " This is done automatically."}, {"timestamp": [56.04, 57.62], "text": " There's other services that do this now."}, {"timestamp": [57.62, 60.62], "text": " Even YouTube will sometimes generate chapters for you."}, {"timestamp": [60.62, 63.62], "text": " So this project is kind of, you know, whatever."}, {"timestamp": [63.62, 65.72], "text": " But if you wanna see how it's done, this is how it's done."}, {"timestamp": [65.72, 67.92], "text": " And this was back with GPT-3."}, {"timestamp": [67.92, 70.88], "text": " So with GPT-4, it's probably infinitely easier."}, {"timestamp": [70.88, 75.76], "text": " But in the service of doing this, I wrote a script that literally it's just called download"}, {"timestamp": [75.76, 77.48], "text": " all transcripts."}, {"timestamp": [77.48, 81.72], "text": " And all it does is it goes to my channel and you can you can change it so that it will"}, {"timestamp": [81.72, 82.72], "text": " go to any channel."}, {"timestamp": [82.72, 85.12], "text": " You just change the channel ID here."}, {"timestamp": [85.12, 88.32], "text": " And it will download literally every transcript."}, {"timestamp": [88.32, 95.08], "text": " So here you can see that I have 270 plus transcripts from all of my videos."}, {"timestamp": [95.08, 100.04], "text": " This is obviously a potentially highly valuable corpus of training data."}, {"timestamp": [100.04, 103.94], "text": " Now one thing is that I think people are coming to terms with the fact that fine tuning is"}, {"timestamp": [103.94, 107.6], "text": " not useful for knowledge representation."}, {"timestamp": [107.6, 113.16], "text": " We're now in the age of retrieval augmented generation and basically MemGPT is just a"}, {"timestamp": [113.16, 114.72], "text": " retrieval system."}, {"timestamp": [114.72, 117.72], "text": " It's not a particularly sophisticated memory system."}, {"timestamp": [117.72, 122.0], "text": " And one thing that I want to address is like yes I can be very highly critical of scientific"}, {"timestamp": [122.0, 124.52], "text": " papers I'm notoriously difficult to impress."}, {"timestamp": [124.52, 128.04], "text": " I'm sorry if this frustrates some people. Another thing that I wanted to address"}, {"timestamp": [128.04, 132.32], "text": " is that some members of the audience are more scientifically minded and some"}, {"timestamp": [132.32, 136.04], "text": " members of the audience are more engineering and coding minded where they"}, {"timestamp": [136.04, 140.36], "text": " just want practical results. So sometimes I'll be talking about things from a more"}, {"timestamp": [140.36, 148.52], "text": " scientific lens and sometimes I'll be talking from a more pragmatic lens. So my criticism of MemGPT is more from the pragmatic lens."}, {"timestamp": [148.52, 152.12], "text": " And yes, I am aware that there are A-B testing"}, {"timestamp": [152.12, 154.4], "text": " and all sorts of more scientifically rigorous things"}, {"timestamp": [154.4, 155.4], "text": " that I can do."}, {"timestamp": [155.4, 157.2], "text": " And I apologize again if that frustrates you."}, {"timestamp": [157.2, 158.28], "text": " Anyways, moving on."}, {"timestamp": [159.24, 162.58], "text": " So basically we've got this huge corpus"}, {"timestamp": [162.58, 163.88], "text": " of valuable data here."}, {"timestamp": [163.88, 167.76], "text": " So if you wanna understand how MindMind works and all that stuff you can download these"}, {"timestamp": [167.76, 172.48], "text": " transcripts it's all free and do whatever you want with it."}, {"timestamp": [172.48, 175.24], "text": " Just don't you know do anything creepy."}, {"timestamp": [175.24, 176.4], "text": " Not that anyone would."}, {"timestamp": [176.4, 177.4], "text": " I don't think."}, {"timestamp": [177.4, 178.4], "text": " Anyways."}, {"timestamp": [178.4, 184.68], "text": " So now yesterday I created a video about latent space activation."}, {"timestamp": [184.68, 187.66], "text": " So a few recent concepts that I've been working on,"}, {"timestamp": [187.66, 189.78], "text": " I made another video talking about"}, {"timestamp": [189.78, 191.94], "text": " sparse priming representations."}, {"timestamp": [191.94, 192.86], "text": " So if you haven't seen that,"}, {"timestamp": [192.86, 197.06], "text": " a sparse priming representation is a way of activating"}, {"timestamp": [197.06, 199.76], "text": " certain aspects of a large language model"}, {"timestamp": [199.76, 201.94], "text": " without having the full bulk of it."}, {"timestamp": [201.94, 206.24], "text": " And so this banks on the fact that large language models are associative,"}, {"timestamp": [206.24, 211.44], "text": " just like human memory is. However, large language models have read literally hundreds of lifetimes"}, {"timestamp": [211.44, 216.88], "text": " worth of text. So you only need to remind them of a few key facts or features or assertions"}, {"timestamp": [216.88, 222.24], "text": " about stuff, even things that are outside of its training distribution, and it can then adopt and"}, {"timestamp": [222.24, 225.06], "text": " use new concepts. You can teach it new terms"}, {"timestamp": [225.06, 229.98], "text": " You can teach it new events all sorts of stuff using sparse priming representations"}, {"timestamp": [229.98, 233.76], "text": " And you can compress relatively large things. I actually took"}, {"timestamp": [234.28, 240.52], "text": " My systems thinking book that I'm working on and gave it to Claude and I asked Claude to create a sparse priming"}, {"timestamp": [240.82, 245.4], "text": " Representation of my systems thinking book and it was able to compress it down to about a page"}, {"timestamp": [245.4, 247.62], "text": " and then unpack most of it."}, {"timestamp": [247.62, 250.5], "text": " Now, this is basically a form of semantic compression,"}, {"timestamp": [250.5, 253.38], "text": " or you might say, from a mathematical perspective,"}, {"timestamp": [253.38, 258.26], "text": " it's like a semantic PCA, principal component analysis."}, {"timestamp": [258.26, 261.66], "text": " But anyways, the idea here is that it is a form"}, {"timestamp": [261.66, 263.98], "text": " of lossy verbal compression."}, {"timestamp": [263.98, 268.0], "text": " But because LLMs have the ability to confabulate, which means that they can"}, {"timestamp": [268.0, 272.0], "text": " infer or impute or kind of guess, sparse priming"}, {"timestamp": [272.0, 276.0], "text": " representations are super useful. And then yesterday I talked about latent"}, {"timestamp": [276.0, 280.0], "text": " space activation. So latent space activation is kind of the broader concept of what's"}, {"timestamp": [280.0, 284.0], "text": " going on behind the scenes inside of the model. And then"}, {"timestamp": [284.0, 286.94], "text": " also yesterday I mentioned something"}, {"timestamp": [286.94, 289.0], "text": " that I was working on, which is what I call"}, {"timestamp": [289.0, 290.68], "text": " the Basher Loop, or BSHR."}, {"timestamp": [290.68, 293.84], "text": " So BSHR is the point of today's video,"}, {"timestamp": [293.84, 296.76], "text": " and this stands for Brainstorm, Search,"}, {"timestamp": [296.76, 299.04], "text": " Hypothesize, and Refine."}, {"timestamp": [299.04, 302.96], "text": " So I married a librarian, so this basically constitutes"}, {"timestamp": [302.96, 307.92], "text": " dinner conversation for us, but in the field of information and library science"}, {"timestamp": [309.0, 315.16], "text": " People have information needs. This is why you go to Google. This is why you go to Wikipedia or even you search reddit or YouTube"}, {"timestamp": [315.92, 321.4], "text": " Now there are tools out there like perplexity like the chatbot that Matt Wolf built"}, {"timestamp": [322.92, 325.56], "text": " But there's one's a few things"}, {"timestamp": [325.56, 327.4], "text": " missing from all of these tools and that is"}, {"timestamp": [327.4, 330.68], "text": " information literacy and information foraging strategies."}, {"timestamp": [330.68, 333.44], "text": " So I am here to teach you about that and we are also here"}, {"timestamp": [333.44, 338.3], "text": " to introduce the Bashor Loop repo which is brand new."}, {"timestamp": [338.3, 341.52], "text": " But basically, the ultimate goal here is to create"}, {"timestamp": [341.52, 347.4], "text": " a Bashor Loop search tool chatbot that will allow you to search literally"}, {"timestamp": [347.4, 349.62], "text": " all of my videos."}, {"timestamp": [349.62, 351.12], "text": " So there's a lot of steps to do."}, {"timestamp": [351.12, 355.16], "text": " We're not going to finish it today, but I wanted to take this time to one, introduce"}, {"timestamp": [355.16, 359.4], "text": " the repo, introduce the concepts and show you the work that I've already done."}, {"timestamp": [359.4, 364.56], "text": " So when you first get to the repo, it's just Dave Schapp slash BSHR loop or basher loop"}, {"timestamp": [364.56, 367.24], "text": " as I, as I say it out loud."}, {"timestamp": [367.24, 372.24], "text": " So the basherloop, welcome to the repo."}, {"timestamp": [372.52, 373.8], "text": " It allows you to search for"}, {"timestamp": [373.8, 376.3], "text": " arbitrarily large information domains."}, {"timestamp": [376.3, 377.34], "text": " This is what it means."}, {"timestamp": [377.34, 378.18], "text": " The overview."}, {"timestamp": [378.18, 379.36], "text": " So the overview of the loop."}, {"timestamp": [379.36, 381.0], "text": " First, brainstorm."}, {"timestamp": [381.0, 382.64], "text": " It accepts a query from the user."}, {"timestamp": [382.64, 386.0], "text": " It brainstorms a list of questions,"}, {"timestamp": [386.0, 391.0], "text": " which I showed you yesterday, and I'll show you the prompt that I used to do it today in just a little bit."}, {"timestamp": [391.0, 397.0], "text": " Then you use search functionality, whether it's APIs or vector database or whatever."}, {"timestamp": [397.0, 403.0], "text": " The queries that you start with are then basically just piped to whatever your information tap is."}, {"timestamp": [403.0, 405.18], "text": " Or if you have multiple information taps,"}, {"timestamp": [405.18, 406.56], "text": " you can use that."}, {"timestamp": [406.56, 410.42], "text": " Then hypothesize, so you take the information"}, {"timestamp": [410.42, 412.66], "text": " that is retrieved from your data source,"}, {"timestamp": [412.66, 415.64], "text": " whether it is Wikipedia or a vector database"}, {"timestamp": [415.64, 418.06], "text": " or just a general internet search,"}, {"timestamp": [418.06, 420.8], "text": " and then you have the LLM read all of it"}, {"timestamp": [420.8, 424.7], "text": " and form a hypothesis based on that information."}, {"timestamp": [424.7, 428.8], "text": " This hypothesis is an answer to the potential question."}, {"timestamp": [428.8, 432.16], "text": " It says, okay, based on everything that you're seeing, this is the answer."}, {"timestamp": [432.16, 436.92], "text": " And if you want to try this, this is basically what Perplexity does, but it does it as a"}, {"timestamp": [436.92, 439.88], "text": " single step where it just searches and summarizes."}, {"timestamp": [439.88, 446.2], "text": " It doesn't really form a hypothesis, nor does it actually write good queries, which is my chief complaint"}, {"timestamp": [446.2, 448.68], "text": " and why I canceled my Perplexity subscription."}, {"timestamp": [450.08, 451.52], "text": " And then finally, refine."}, {"timestamp": [451.52, 455.1], "text": " So this is refine or recurse or whatever,"}, {"timestamp": [455.1, 458.52], "text": " but the idea is you don't just do one information search."}, {"timestamp": [458.52, 460.54], "text": " Think about the last time"}, {"timestamp": [460.54, 462.66], "text": " that you had a really challenging problem."}, {"timestamp": [462.66, 463.5], "text": " What do you do?"}, {"timestamp": [463.5, 467.24], "text": " You do a Google search, you open a bunch of tabs, you read a few things, you read a"}, {"timestamp": [467.24, 470.48], "text": " few more things, and then you learn about the space, and then you go write a better"}, {"timestamp": [470.48, 474.88], "text": " information query. You write a better search query. So this is the loop. This is"}, {"timestamp": [474.88, 479.44], "text": " why it is a loop, is because finding and using the correct information is not a"}, {"timestamp": [479.44, 483.52], "text": " single-step process. When you go to the library, whether it's the University"}, {"timestamp": [483.52, 488.12], "text": " Library or the local city library, what do you do? You go, you talk to a librarian, they"}, {"timestamp": [488.12, 492.36], "text": " ask you a bunch of questions about what you're trying to achieve, and then you"}, {"timestamp": [492.36, 496.0], "text": " you know, you go look at a book and you take some notes and it's like, okay cool"}, {"timestamp": [496.0, 501.04], "text": " I liked this book, but now that you're informed you go from a naive query to an"}, {"timestamp": [501.04, 508.2], "text": " informed query. Real quick, Dave here with a request. So you've probably noticed that I'm cranking out videos"}, {"timestamp": [508.2, 510.36], "text": " and I'm really getting my content dialed into"}, {"timestamp": [510.36, 513.14], "text": " what is adding the most value to you guys."}, {"timestamp": [513.14, 516.12], "text": " And so I'm really doubling down on subscriber growth"}, {"timestamp": [516.12, 517.78], "text": " and just really serving the community."}, {"timestamp": [517.78, 520.8], "text": " Now, the reason that I've been able to increase"}, {"timestamp": [520.8, 522.76], "text": " the quality of my videos and the frequency"}, {"timestamp": [522.76, 525.36], "text": " is because I've stepped away from consulting."}, {"timestamp": [525.36, 527.74], "text": " More than half my income came from consulting,"}, {"timestamp": [527.74, 530.72], "text": " so I'm really kind of hurting for cash right now."}, {"timestamp": [530.72, 532.7], "text": " However, I have been largely supported"}, {"timestamp": [532.7, 533.88], "text": " by a grassroots movement,"}, {"timestamp": [533.88, 537.84], "text": " so my request is hop on over to my Patreon page and sign up."}, {"timestamp": [537.84, 540.24], "text": " The lowest tier is $5 a month,"}, {"timestamp": [540.24, 542.12], "text": " and that gets you access to Discord,"}, {"timestamp": [542.12, 543.56], "text": " which I'll show you in just a moment,"}, {"timestamp": [543.56, 547.52], "text": " but I also have a premium Discord tier, which gives you access to some private channels,"}, {"timestamp": [547.52, 551.36], "text": " some live streams, and QA sessions, and that sort of thing."}, {"timestamp": [551.36, 555.2], "text": " So if you could, help me out, and you'll get access to this community."}, {"timestamp": [555.76, 558.64], "text": " And it's a great community. We've got almost 600 people right now,"}, {"timestamp": [558.64, 561.36], "text": " and we talk about all kinds of stuff, not just AI."}, {"timestamp": [561.36, 564.96], "text": " We talk about the future of humanity. We have artistic interests."}, {"timestamp": [564.96, 565.2], "text": " We talk about economics. We talk about the future of humanity, we have artistic interests, we"}, {"timestamp": [565.2, 570.16], "text": " talk about economics, we talk about existential coping, post-labor economics, all of the above."}, {"timestamp": [570.16, 575.64], "text": " And then finally, I also have some premium channels for the high-tier subscribers. So,"}, {"timestamp": [575.64, 578.04], "text": " thanks for watching, and yeah, thank you."}, {"timestamp": [578.04, 583.52], "text": " You go from a naive query to an informed query. So, this is where I'll go down, and I'm not"}, {"timestamp": [583.52, 587.16], "text": " going to read all of these to you verbatim, but I'm just pointing out that this information"}, {"timestamp": [587.16, 590.44], "text": " is here in the repo so that you can get familiar because I'm assuming that most"}, {"timestamp": [590.44, 593.4], "text": " of you are not familiar with library and information science, so here's some"}, {"timestamp": [593.4, 597.36], "text": " critical things that I can teach you so that you can make informed queries. So"}, {"timestamp": [597.36, 601.16], "text": " first of all, what we're talking about is information foraging. Information"}, {"timestamp": [601.16, 605.0], "text": " foraging is when you go into an unknown or incomplete information domain"}, {"timestamp": [605.0, 610.0], "text": " where you have an information need, but you don't necessarily even know what questions to ask."}, {"timestamp": [610.0, 615.0], "text": " So you have to go in search of information by basically starting out guessing."}, {"timestamp": [615.0, 619.0], "text": " Information literacy is one of the primary things that I complain about,"}, {"timestamp": [619.0, 622.0], "text": " both with these tools and humans in general."}, {"timestamp": [622.0, 626.04], "text": " So information literacy is basically understanding"}, {"timestamp": [626.04, 628.84], "text": " how to engage with sources of information"}, {"timestamp": [628.84, 631.44], "text": " in order to find correct information"}, {"timestamp": [631.44, 633.68], "text": " or validate the information that you have."}, {"timestamp": [633.68, 635.56], "text": " And this is something that I talked about yesterday"}, {"timestamp": [635.56, 637.72], "text": " and will also show you in just a moment"}, {"timestamp": [637.72, 640.64], "text": " where the way that I build information literacy"}, {"timestamp": [640.64, 643.6], "text": " into this tool is by telling the LLM"}, {"timestamp": [643.6, 645.6], "text": " during the brainstorm phase to generate"}, {"timestamp": [645.6, 647.8], "text": " counterfactual questions."}, {"timestamp": [647.8, 651.76], "text": " Basically it's trying to prove itself wrong and it's trying to find all sides of any given"}, {"timestamp": [651.76, 657.84], "text": " information problem which will result in a better recall."}, {"timestamp": [657.84, 662.04], "text": " Recall is a very specific term from library science where basically are you getting all"}, {"timestamp": [662.04, 669.88], "text": " of the information that is relevant, that is salient to your query. So next up is satisficing. So satisficing is a"}, {"timestamp": [669.88, 676.96], "text": " portmanteau of sufficing and satisfying. So when you satisfy an information query"}, {"timestamp": [676.96, 681.52], "text": " the idea is that you have found you have gotten to the level of good enough. It's"}, {"timestamp": [681.52, 690.24], "text": " not perfect, it's not complete, but you have the information that you eminently need and you're ready to move on. So, one example that you can use"}, {"timestamp": [690.24, 695.76], "text": " for satisficing is when you're looking for a restaurant to go to. You might have in your"}, {"timestamp": [695.76, 699.52], "text": " mind the perfect restaurant, but the perfect restaurant might not be available, it might"}, {"timestamp": [699.52, 703.92], "text": " be too far, it might just not even exist. And so what you do is you look for something"}, {"timestamp": [703.92, 711.36], "text": " that is good enough. And so the idea is that within information foraging, within search, you need to satisfy from time to time."}, {"timestamp": [711.76, 716.52], "text": " Which means that the information, the exact information that you need, might not be available."}, {"timestamp": [716.88, 721.76], "text": " A definitive answer to your question might not even be possible. If you watch the video that I made yesterday,"}, {"timestamp": [722.08, 726.4], "text": " one of the things that I asked was what is the exact coastline of Britain?"}, {"timestamp": [726.4, 731.6], "text": " And the answer that it gave me was, well, that's really hard to determine,"}, {"timestamp": [731.6, 733.4], "text": " but here's how you could go about it."}, {"timestamp": [733.4, 737.6], "text": " And so the answer to the information query that I had, the information need,"}, {"timestamp": [737.6, 743.1], "text": " was not a definitive answer, but rather, this is how you approach that information problem."}, {"timestamp": [743.1, 749.0], "text": " So in that case, what it needed to do was outside of the scope of information foraging."}, {"timestamp": [749.0, 753.4], "text": " Information needs, so I've referred to this before, but basically all problems"}, {"timestamp": [753.4, 758.12], "text": " are a form of information need. So an information need is I have some sort of"}, {"timestamp": [758.12, 764.0], "text": " problem, solution, query, whatever, and I need information in order to be able to"}, {"timestamp": [764.0, 765.6], "text": " tackle this. Whether you're"}, {"timestamp": [765.6, 772.44], "text": " a CEO making strategic decisions about AI, whether you're a broke college student whose"}, {"timestamp": [772.44, 777.3], "text": " car is making funny noises, whether you're in a relationship and you want to know how"}, {"timestamp": [777.3, 782.86], "text": " do I navigate this fight that we just had, literally everything you do in life has information"}, {"timestamp": [782.86, 786.16], "text": " needs. And this is why libraries are super underrated,"}, {"timestamp": [786.16, 790.16], "text": " as well as librarians. But of course I am biased because I married a librarian."}, {"timestamp": [790.8, 797.44], "text": " Now, this is a term that I invented, at least as far as I know that I invented. So there's what's"}, {"timestamp": [797.44, 803.28], "text": " called a naive query. So a naive query is something that everyone does, where you go to Google and you"}, {"timestamp": [803.28, 810.56], "text": " don't even know the right questions to ask. So you just kind of guess. You just launch your best guess out into the ether and then Google"}, {"timestamp": [810.56, 814.96], "text": " gives you back some stuff that it, you know, Google has a lot of really good algorithms so it"}, {"timestamp": [814.96, 820.56], "text": " can kind of infer what you're actually looking for. And the reason that it can do this is because"}, {"timestamp": [820.56, 825.84], "text": " lots of other people before you have launched those naive queries and"}, {"timestamp": [825.84, 827.76], "text": " Google tracks where they ultimately end up."}, {"timestamp": [827.76, 832.24], "text": " And it says, okay, based on what you're looking for, based on what you've put in, I'm predicting"}, {"timestamp": [832.24, 835.1], "text": " that this is actually the page that you're looking for."}, {"timestamp": [835.1, 839.16], "text": " So you launch a naive query because you don't know what you don't know."}, {"timestamp": [839.16, 842.54], "text": " Once you know a little bit more, then you can write an informed query."}, {"timestamp": [842.54, 845.44], "text": " Because let's say, for for instance you start with you know"}, {"timestamp": [845.44, 851.12], "text": " the one of the questions that I asked yesterday which was who were the important senators during"}, {"timestamp": [851.12, 858.16], "text": " the peak of Roman power right you might not know that there is a thing called Pax Romana. So part"}, {"timestamp": [858.16, 863.36], "text": " of the part of what you would find during that query is you know the Pax Romana or as someone"}, {"timestamp": [863.36, 866.8], "text": " pointed out in the comments Rome was a a kingdom first, then a republic,"}, {"timestamp": [867.12, 872.46], "text": " then an empire. So it depends on how you define like, you know, empire versus Senate,"}, {"timestamp": [872.46, 875.78], "text": " you know, how do you define the peak of Roman power?"}, {"timestamp": [875.78, 881.74], "text": " And so you can then integrate all of those bits of information to ask better questions like,"}, {"timestamp": [882.26, 885.76], "text": " you know, was Rome more powerful as a republic?"}, {"timestamp": [885.76, 888.12], "text": " Was Rome more powerful as an empire?"}, {"timestamp": [888.12, 889.4], "text": " Now, of course, large language models"}, {"timestamp": [889.4, 891.32], "text": " already know most of these things,"}, {"timestamp": [891.32, 894.2], "text": " which is why the Basher loop can actually work in a vacuum"}, {"timestamp": [894.2, 896.98], "text": " for things, particularly historical information,"}, {"timestamp": [896.98, 898.6], "text": " that have been discussed to death."}, {"timestamp": [898.6, 901.24], "text": " But, as other people pointed out in the comments,"}, {"timestamp": [901.24, 902.6], "text": " there's lots of data out there"}, {"timestamp": [902.6, 904.88], "text": " that is just not in the training distribution,"}, {"timestamp": [904.88, 907.48], "text": " like your personal data, like my YouTube transcripts,"}, {"timestamp": [907.48, 908.74], "text": " like corporate data."}, {"timestamp": [910.1, 912.54], "text": " So once you have your naive query,"}, {"timestamp": [912.54, 914.88], "text": " you know a little bit more,"}, {"timestamp": [914.88, 917.4], "text": " then you can dial into an information scent,"}, {"timestamp": [917.4, 920.04], "text": " which is like, okay, here are some clues"}, {"timestamp": [920.04, 921.84], "text": " to what I'm actually looking for,"}, {"timestamp": [921.84, 923.96], "text": " and then you can write an informed query."}, {"timestamp": [923.96, 928.0], "text": " And then I already mentioned precision versus recall, I'm not going to read that one to you."}, {"timestamp": [928.0, 932.0], "text": " And then finally, there's some use cases. So I've kind of alluded"}, {"timestamp": [932.0, 936.0], "text": " to all these. You could apply the basher loop to the business data lake,"}, {"timestamp": [936.0, 940.0], "text": " to an internet search, to a university library system, or a personal archive"}, {"timestamp": [940.0, 944.0], "text": " in the case of my transcripts. So, I've got all the transcripts"}, {"timestamp": [944.0, 949.28], "text": " saved here. You can go through them all. There's obviously quite a few. Yeah, so there's"}, {"timestamp": [949.28, 955.64], "text": " that. And then finally, or not finally, but next is contributing. So I've got"}, {"timestamp": [955.64, 959.86], "text": " there's there's three ways that you can contribute or participate and the order"}, {"timestamp": [959.86, 970.08], "text": " is listed so please make sure you check the contributing file before jumping in. First is join the discussions. This is where everyone should start. Don't just"}, {"timestamp": [970.08, 975.08], "text": " jump in immediately submitting issues and pull requests. If they don't"}, {"timestamp": [975.08, 979.28], "text": " follow the guidelines here, they'll be closed and rejected. But yeah, so check"}, {"timestamp": [979.28, 983.04], "text": " out the contributing.markdown file. If you're not familiar with this, the"}, {"timestamp": [983.04, 985.0], "text": " discussions tab is up here, so you can jump in."}, {"timestamp": [985.0, 987.0], "text": " There's no discussions yet because I just created the repo."}, {"timestamp": [987.0, 993.0], "text": " There's issues here. Again, no issues have been created, and there's no pull requests yet either."}, {"timestamp": [993.0, 998.0], "text": " All right. So, then I've created demo01."}, {"timestamp": [998.0, 1006.36], "text": " So this one will be, before we get all the way into, you know, building our own local repository, our own local database"}, {"timestamp": [1006.36, 1011.68], "text": " on my YouTube transcripts, first we're just going to use an existing information source,"}, {"timestamp": [1011.68, 1013.88], "text": " specifically Wikipedia."}, {"timestamp": [1013.88, 1017.16], "text": " I've got the project defined here."}, {"timestamp": [1017.16, 1020.92], "text": " I showed a very naive initial test yesterday."}, {"timestamp": [1020.92, 1022.76], "text": " I've got the code copied here."}, {"timestamp": [1022.76, 1029.12], "text": " It doesn't work yet, so don't... Lower your expectations. We are still very early in the process. But what I did want to show you"}, {"timestamp": [1029.12, 1035.68], "text": " was that demo 01 is here. It's got its own readme. And I also... the work that I did do is that I"}, {"timestamp": [1035.68, 1040.64], "text": " already wrote the system prompts. So let me... let's go through these one at a time. So this is"}, {"timestamp": [1040.64, 1047.12], "text": " the system prompt for 01, the brainstorming one. Now what I had yesterday was just this bit."}, {"timestamp": [1047.12, 1049.52], "text": " So you're a search query generator, yada yada."}, {"timestamp": [1049.52, 1055.04], "text": " Basically, it generates a list of questions in a JSON object that can be used to"}, {"timestamp": [1055.04, 1057.6], "text": " do Google searches or Wikipedia searches or whatever."}, {"timestamp": [1058.4, 1063.28], "text": " And so this is the first part of the process that will be used to generate"}, {"timestamp": [1064.08, 1066.6], "text": " the brainstorm step of the basher loop."}, {"timestamp": [1066.6, 1073.56], "text": " So brainstorm, a list of questions, but then what I added was refined queries."}, {"timestamp": [1073.56, 1080.48], "text": " This integrates that idea of whatever information you give the chat GPT API, if you don't give"}, {"timestamp": [1080.48, 1083.6], "text": " it any previous queries, it'll be like, okay, whatever."}, {"timestamp": [1083.6, 1085.84], "text": " But if you do, it will integrate it."}, {"timestamp": [1085.84, 1089.72], "text": " If these materials are present, you are to generate informed queries, more specific search"}, {"timestamp": [1089.72, 1092.88], "text": " queries that aim to zero in on the correct information domain."}, {"timestamp": [1092.88, 1095.18], "text": " Do not duplicate previously asked questions."}, {"timestamp": [1095.18, 1098.54], "text": " Use the notes and other information to write better questions, basically."}, {"timestamp": [1098.54, 1102.2], "text": " So this one prompt will be part of the basher loop."}, {"timestamp": [1102.2, 1105.48], "text": " So whether it's the first time you're running it or subsequent times,"}, {"timestamp": [1105.48, 1109.76], "text": " it will generate recursively better search queries."}, {"timestamp": [1110.68, 1112.48], "text": " So that's the first bit."}, {"timestamp": [1112.48, 1117.48], "text": " So I wrote that and then going back to system 02."}, {"timestamp": [1117.64, 1119.58], "text": " So the second part is hypothesize."}, {"timestamp": [1119.58, 1121.32], "text": " Obviously the search part,"}, {"timestamp": [1121.32, 1124.96], "text": " that's to be handled by an API or ChromaDB or whatever."}, {"timestamp": [1124.96, 1125.08], "text": " So you don't need a system prompt for that Basically, the search part, that's to be handled by an API or ChromaDB or whatever."}, {"timestamp": [1125.08, 1130.44], "text": " So you don't need a system prompt for that because basically that's an algorithmic thing"}, {"timestamp": [1130.44, 1132.6], "text": " that is just a script."}, {"timestamp": [1132.6, 1137.64], "text": " So the next step that is handled by the LLM is the hypothesis generator."}, {"timestamp": [1137.64, 1143.64], "text": " So like the brainstorming, the query generator, you're an information needs hypothesis generator."}, {"timestamp": [1143.64, 1146.84], "text": " You'll be given a main information need or user query as well as a variety of"}, {"timestamp": [1146.84, 1150.8], "text": " materials, such as search results, previous hypotheses, and notes. Whatever"}, {"timestamp": [1150.8, 1153.52], "text": " information you receive, your output should be a revised, refined, or an"}, {"timestamp": [1153.52, 1157.6], "text": " improved hypothesis. In this case, the hypothesis is a comprehensive answer to"}, {"timestamp": [1157.6, 1161.36], "text": " the user question, etc, etc, etc. Basically, I'm just giving an instructions that"}, {"timestamp": [1161.36, 1167.5], "text": " whatever I give you, generate a hypothesis that answers the user query as comprehensively as possible"}, {"timestamp": [1167.5, 1171.44], "text": " I tell it not to worry about citations because we'll hold that out as metadata"}, {"timestamp": [1172.04, 1175.36], "text": " And so that's a problem that we need to work out"}, {"timestamp": [1176.56, 1179.58], "text": " okay, and then finally the satisficing check so"}, {"timestamp": [1180.52, 1184.74], "text": " I'm guessing that this is probably the first time that most of you have heard about satisficing"}, {"timestamp": [1185.0, 1190.0], "text": " So here's the instruction that I wrote in order to produce this, and I'll explain why."}, {"timestamp": [1190.0, 1195.0], "text": " But the very short answer is I'm going to give you a bunch of information, and then you judge,"}, {"timestamp": [1195.0, 1201.0], "text": " you being the LLM, GPT, you judge whether or not the information need has been satisfied."}, {"timestamp": [1201.0, 1208.16], "text": " And then I tell it, like, you're to make this judgment by virtue of several factors, amount and quality of searches, specificity"}, {"timestamp": [1208.16, 1211.84], "text": " and comprehensiveness of the hypothesis, and the notes about the information"}, {"timestamp": [1211.84, 1216.08], "text": " domain and foraging if present. So basically we can include notes from the"}, {"timestamp": [1216.08, 1221.32], "text": " search part to say, hey we've exhausted all the search, like we're not finding"}, {"timestamp": [1221.32, 1228.04], "text": " anything else. And you can see that we've run 30 queries and this is the best information we've got."}, {"timestamp": [1228.04, 1232.7], "text": " So several things to keep in mind, the user's information need might not be answerable."}, {"timestamp": [1232.7, 1238.34], "text": " So in the case of asking what is the exact coastline of Britain, you might want to see"}, {"timestamp": [1238.34, 1243.16], "text": " a specific number or it might be partially answerable, which is like, it's generally"}, {"timestamp": [1243.16, 1246.96], "text": " estimated to be about, I think it was like 12,000 kilometers or something like that."}, {"timestamp": [1248.72, 1251.52], "text": " Or given the information available for the problem."}, {"timestamp": [1252.08, 1255.68], "text": " Basically, some things are outside of the scope of information needs."}, {"timestamp": [1255.68, 1261.2], "text": " For instance, if you need to actually do something in the physical world, right?"}, {"timestamp": [1261.2, 1264.72], "text": " So like, you might go to the library and say like, I need to file my taxes."}, {"timestamp": [1264.72, 1268.46], "text": " And it's like, well, I'm'm a librarian I can't file your taxes but I can give"}, {"timestamp": [1268.46, 1271.94], "text": " you all the information that you will need to be able to file your taxes. So"}, {"timestamp": [1271.94, 1276.22], "text": " tool use and acting upon the world is outside of the scope of the Basher loop"}, {"timestamp": [1276.22, 1280.58], "text": " but the idea is if the information is available we will give you all the"}, {"timestamp": [1280.58, 1284.62], "text": " information that we can get we will basically act like a librarian and be"}, {"timestamp": [1284.62, 1288.08], "text": " your information concierge to get you the information that you need that you can then"}, {"timestamp": [1288.08, 1293.48], "text": " go take and give to another AI or a chatbot or a robot or your best friend or do it yourself"}, {"timestamp": [1293.48, 1294.88], "text": " or whatever."}, {"timestamp": [1294.88, 1300.88], "text": " Anyways, finally, the output format is a JSON object. So there's two things that I put in"}, {"timestamp": [1300.88, 1311.12], "text": " the JSON object. One is feedback, which is basically it unpacking what its perception is. And the reason that I do this first is because as language models kind of talk"}, {"timestamp": [1311.12, 1316.16], "text": " through things, it'll be able to triangulate and make a judgment or a decision a little bit better."}, {"timestamp": [1316.16, 1321.84], "text": " Because as you might have seen on AI Explains videos, if you have a language model just output"}, {"timestamp": [1321.84, 1329.78], "text": " an answer, like if you give it a whole list of stuff and then just ask it to say true or false, it's going to be kind of random."}, {"timestamp": [1329.78, 1335.6], "text": " But as I demonstrated in yesterday's video with sequential reasoning, large language"}, {"timestamp": [1335.6, 1340.32], "text": " models, because you get more latent space activation with sequential activation, this"}, {"timestamp": [1340.32, 1346.24], "text": " is also a form of sequential activation, wherein it talks through the evidence that you've presented"}, {"timestamp": [1346.24, 1352.08], "text": " and then it will make a better judgment as to whether or not the user information need has been satisfied."}, {"timestamp": [1352.08, 1357.52], "text": " That's the TLDR of all of this and I think that brings us to the conclusion for today."}, {"timestamp": [1357.52, 1361.36], "text": " So, that's where we're at. This is where we're starting."}, {"timestamp": [1361.36, 1365.88], "text": " I'm probably going to be working on this for a little bit."}, {"timestamp": [1365.88, 1368.66], "text": " This project isn't going to live too terribly long."}, {"timestamp": [1368.66, 1371.48], "text": " It's probably going to be a three or four part series."}, {"timestamp": [1371.48, 1372.48], "text": " We'll see."}, {"timestamp": [1372.48, 1374.12], "text": " But yeah, so thanks for tuning in."}, {"timestamp": [1374.12, 1375.6], "text": " I hope you got a lot out of this."}, {"timestamp": [1375.6, 1377.26], "text": " Like, subscribe, etc, etc."}, {"timestamp": [1377.26, 1378.26], "text": " You know the drill."}, {"timestamp": [1378.26, 1378.76], "text": " Cheers."}, {"timestamp": [1381.01, 1383.01], "text": " you"}]}