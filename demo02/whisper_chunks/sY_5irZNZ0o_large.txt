{"text": " Hey everybody, David Shapiro here. I was going to do a different video today, but someone asked in the comments, what's a cognitive architecture? And it occurred to me that my channel has more than doubled in the last three weeks. So most of you have not been on this journey with me for the last year or two. And so what you may not know about me is that I have written books about cognitive architectures. And some of you don't know what that is. So let's talk about cognitive architectures. First, what is a cognitive architecture? I just copy pasted the opening Wikipedia because it summarizes it pretty good. A cognitive architecture refers to both a theory about the structure of the human mind and to a computational instantiation of such a theory used in the fields of artificial intelligence and computational cognitive science. The formalized models can be used to further refine a comprehensive theory of cognition and as a useful artificial intelligence program. Successful cognitive architectures include ACT-R and SOAR. The research on cognitive architectures as software instantiation of cognitive theories was initiated by Alan Newell in 1990. So with all that cleared up, what? Cognitive architectures are great for controlling autonomous or semi-autonomous agents and entities. And so by agent or entity I mean a robot or something in the virtual world, such as an NPC or a simulation. The Mars rovers are perhaps the most famous examples of cognitive architectures because the Mars rovers are actually somewhat autonomous, meaning we can just send them instructions and they will figure out how to get to where they need to go on their own, which means they use planning, they use reasoning, they have sensors, input, output, memory as well, and they can also solve some problems on their own. Rocket systems are also examples of a particular kind of cognitive architecture because they have lots and lots of telemetry. Their goal is to get to orbit safely and they can actually come up with hypotheses about what's going on in their systems based on the telemetry, perform very very fast experiments like tuning throttles and stuff to optimize performance. You might not say that that's a full cognitive architecture, it's more of a feedback system, but certainly because rockets basically get to space autonomously, I classify them as cognitive architectures. We just push the button and then the machine takes over. Some video games actually have NPCs that use cognitive architectures, although they are very simple or primitive. Most of them actually use what's called an FSM or a finite state machine. So you might notice that NPC characters, they are hunting, attacking, fleeing, hiding, conversing, or whatever. Those are the discrete states that they switch between. But you could argue that a finite state machine is in fact a type of cognitive architecture. So that is what a cognitive architecture is and that's what it is used for. Basically it is a digital model of a brain. So there are three primary components to any robot or cognitive architecture. There is input, processing, and output. So the input can be physical sensors, it can be text, it can be telemetry from machines, pretty much anything. The processing ability, it has to have, there's a few basic things that are included in pretty much all cognitive architectures. Memory is one of the most essential ones. Then you need some kind of planning or task and executive function. There's a few other things that are often included, such as a world model, which is, okay, I have some understanding of how the world works, which I can use to plan and anticipate. Memory there's different kinds of memory. There's long, short, and working memory. You could also say that there's a medium, midterm memory. That basically has to do with how it's stored and retrieved and what it's used for. Working memory is the stuff that you're using for whatever task that you're doing in that particular moment. Learning is a critical component, which is basically how do you take existing experiences, or past experiences rather, and derive new useful information from it, and specifically actionable information. Then you have the ability to plan, keep track of tasks, and either adhere to objectives or formulate objectives or both. And then finally, this is what I have focused on, is one of the things I focused on is morality, ethics, and reasoning. When you have a machine that can think about anything, because that's the purpose of a cognitive architecture is to create a thinking machine, when it can think about anything, how does it know what to think about and why? This is the subject of my book Benevolent by Design, link in the description. Just go to my homepage DavidKShapiro.com and you can find the books there. Finally, a cognitive architecture needs an output of some kind. It needs to take in information from its environment, do some work on it, and then put information back out. That information can be in the form, or that output can be in the form of robotics, you know, like if it's got hands and feet or whatever, like Boston Dynamics, the Tesla bot, or a car, right? Tesla cars actually have FSD, the full self-driving, it fully works will probably be a cognitive architecture of some kind because it is taking in information, it has different goals and constraints, and then its output is steering, driving, and brakes. You can also have an avatar of some kind like an NPC. You could also just have simple speech, text, audio, chatbot kind of stuff, but you need input, processing, and output. It's the three primary components of every cognitive architecture and robotics as a whole. Okay, so but why? Like what is the difference between a cognitive architecture and other kinds of artificial intelligence? So artificial intelligence is an umbrella term for basically all kinds of machine learning and computers that think or whatever. So the advantage of a cognitive architecture is that you can pull together disparate kinds of models, whether it's robotics and compliant machines, computer vision, NLP, NLU, speech, data storage, all of it comes together. I already mentioned Tesla because Tesla has lots of telemetry. It's got cameras all over. It has the ability to process what it's seeing as well as telemetry from itself, and then it has outputs right. So basically a cognitive architecture is a way to bring all machine learning together and put it in a body or give it some kind of way to interact. Alright here's my hot take and this is where the tone of the video really shifts. One neural network will probably never be AGI. So what I mean by this is one deep learning neural network like GPT-3 is never going to qualify. It's never going to satisfy all of those requirements of input processing and output into the world. It is just a component of a system. So what I mean by system is that it has to have multiple components. You have to have specialized components that do various things. So for instance, you and I, humans, we are organic systems. We have brains which have specialized components. Our brains are contained in our skulls. We have eyes, ears. We have skin, bones, muscles. We are a complete self-contained system. And so the spiciest part of this hot take is most AI researchers are not systems thinkers. I am a systems thinker, one, just by the luck of genetics, but also in my past life, my job was I was a systems engineer so I'm used to working with large interconnected systems that span multiple things from hardware to software to networking security virtualization all that kind of stuff and so when you build a big enough computer system you realize that it is almost like a living breathing entity sort of in and of itself. But yeah, so AGI will never be a single model. AGI will be achieved as a system. There I said it. Okay, this all might sound a little bit like Skynet, so let's talk about the apocryphal lesson of what not to do. So according to some film critics and analysts, Skynet actually represents the nuclear arms race. Because remember, it was originally Terminator came out during the tail end of the Cold War between the United States and the Soviet Union. And so it was supposed to be a lesson against the policy of MAD, Mutually Assured Destruction. And so it's like, okay, if we let fear drive us to make worse and worse weapons, we're just going to wipe ourselves out. And that's why the movie opens with a nuclear explosion. I guess that's Terminator 2. Anyways, Terminator 2 was the good one. So what was the point of Skynet? The point of Skynet was never really explained. It was kind of left vague, but just that we created a machine that got out of control. And that's what we are afraid of. And so whatever the purpose of Skynet was, whether it was to protect America or to neutralize the Soviet Union or maximize our military power, something was lost in translation and it ultimately decided to kill everyone and take over the whole planet. So in this case, Skynet is the example of a machine that is smart enough to carry out some basic objective, but not smart enough to contemplate why. So it became sentient for arbitrary reasons and then took whatever its objective function was and went haywire with it. Okay, so aside from these potential existential risks to humanity, what do cognitive architectures do for us? So probably how they'll be deployed is going to be domestic robots, delivery drones, chatbot companions, smart home devices, cars, buildings, and even cities will probably eventually have cognitive architectures. So if you have a building that has a fully cognitive architecture, what is that going to do? It'll manage the power, the lights. It'll pay attention to all the residents. Think of the ships in Star Trek, where the computer is kind of monitoring everyone at all times. Granted, Star Trek also respects people's privacy, so it doesn't like, you know, watch everything that you do. But you could have, you could even have like, cognitive architectures for cities that can help manage and run entire cities. So no, they will not be philosophically sentient, and we'll unpack that a little bit more in just a moment, but cognitive architectures could be functionally sentient. A lot of this is explored in fiction. One of the best episodes of Star Trek The Next Generation of all time is the measure of a man and in case you haven't seen it, that is where Data is basically put, Data is an android. He's put on trial and the question is whether or not he is a life form, whether or not he has agency, whether or not he has the right to self-determination and one of the climax lines is Picard says, you know, our mission is to seek out new life and there it sits. So good, such an overpowered line. Anyways, so, you know, the whole point of this is that we are going to be forced to ask really important questions like if we build a sufficiently sophisticated cognitive architecture is it going to be conscious? Is it going to be sentient? And so what I want to say is don't confuse has a subjective experience of suffering with sentient because you can you can be sentient without the ability to suffer right? We, you and I humans, we we assume, we agree that we are sentient beings. We also have the common experience of suffering. Now, a lot of people anthropomorphize a machine just because it can imitate us. They say, ah, clearly this is consciousness, this is sentient, and they don't really have a deep enough understanding of the nuance around sentience, consciousness, suffering, and that sort of stuff. We evolved, right? As animals, we evolved and so a lot of the telemetry that we get, such as pain, anger, suffering, hunger, fear, all of that, those are all adaptive signals that helped our ancestors survive. fear, all of that, those are all adaptive signals that helped our ancestors survive. Now, the reason that suffering is unpleasant is because you need a stick to chase you away from bad things that will kill you simply because our ancestors that did not have a strong enough sense of suffering got eaten or poisoned or whatever, right? They died. And so suffering is adaptive to evolution. Now when we create a cognitive architecture that is an invention not evolution. So the genesis of these things is going to be very different which means that like you should not assume that it is going to be anything like us even if it is modeled on us it is only an approximation or an imitation of us. Now, my definition of sentient, because I differentiated between philosophical sentience and functional sentience, so you and I, we humans are philosophically sentient. We have a subjective experience of being and we have, you know have a sense of self, etc. etc. I have an experience of looking at the camera through my eyes. Now, my working definition of sentient, of functional sentience, is any sufficiently sophisticated information system that is able to process, manipulate, and integrate information about itself. So that is the functional definition of sentience and stop asking me about Blake Lemoine. All right, navel gazing time. So, you know, you might have heard, you know, I think therefore I am which is kind of like the most popular like this is the conclusion of Western philosophy. I have subjective thoughts therefore that's the only thing that I can really truly know to be be real and beyond that I could just be a brain in a jar running in a simulation. So like we have questions can you separate mind from body, can you separate mind from existence or the universe? And so here's another spicy take. Western philosophy is pretty useless. Nothing compelling has come out of western philosophy in like a century and please do not talk to me about Chalmers. If you want to talk Chalmers, like just read V.S. Ramachandran and said who's an actual scientist. There I said it. Now eastern philosophy, however, figured all this stuff out like literally thousands of years ago. So like a lot of the Indian Vedantas, those are very insightful Buddhism, Taoism, and also shamanic traditions, particularly in Central and South America, but also the aboriginals in Australia and all over Southeast Asia and India. These folks figured it out a long time ago. And yeah, so let's talk a little bit more about that. Yes, I am salty, but also I have read a lot. The entire second from the bottom shelf is full of nothing but science, philosophy, cosmology, and quantum physics. I'm not gonna quote it all at you but like I went down that rabbit hole real deep. So the TLDR about physics is there is nothing special or unique about humans. There's no secret sauce that says like, ah here's the magical substance that confers consciousness on us. The only thing that really stands out about us is that our brains are the most complex physical structure in the universe. So maybe the complexity of that structure is what gives us consciousness, maybe that's what makes us special, not really sure. Maybe consciousness arises from the patterns of brainwaves and energy because the thing is, is our brain, as long as you're alive, your brain has metabolism. It has a baseline metabolic rate and that metabolic rate really doesn't change too much. Like it goes up just a tiny bit if you're working really hard, but otherwise, you, like your brain is always operational, but you're not conscious all the time. Certain chemicals can make you unconscious, like general anesthesia. You go to sleep, you can be knocked unconscious, and you have no experience of time. You don't remember what happened, you can be blackout drunk. So consciousness is a very complex thing where it's like, okay, it can turn off, it can turn on. Then you have, you know, near-death experiences, out-of-body experiences. And I know a lot of people say, oh, that's just, you know, hypoxia. No, if you go and actually do your homework on near-death experiences and out-of-body experiences, you will see that there are many facts about these that cannot be reconciled with a materialist view of the world. But again, I'm not going to get too lost into that. Just, you know, we don't fully know what consciousness is. That is the only thing that we can really agree on. Now, okay, that's looking at the physics of our brains. What about the physics of the universe? When you go deep enough down quantum cosmology and physics and quantum gravity and EPR paradoxes and the anthropic principle Honestly, once you read enough of this stuff, it all just looks like Eastern philosophy Honestly, right you read enough about Alice and Bob you could literally transpose them into Like the Advaita Vedanta. I'm not even joking. That's why I say the Eastern philosophers, they figured all this stuff out centuries ago. And if you're mad at me, go read a book. I don't care. The bottom line though is, can the thing suffer? Because when we talk about ethics of creating conscious machines, it's like, ah, but if you assume that it will have the ability to suffer, which is a really bold assumption by the way, do not make that assumption. If it has the ability to suffer, that could be wrong. But otherwise, if we create a thing that is not capable of suffering, then is it really wrong? Is there any moral conundrum about it? Right? And so there's another episode of Star Trek The Next Generation where Data builds a child and the child, like his daughter Android, like short circuits, overloads and dies. And then Data, like the whole crew is sad, but then Data is just like just like okay I'm ready to go back to work and it was a really poignant reminder that just because a machine looks like us because it acts like us doesn't mean that it feels the way that we feel and so suffering is central is absolutely central to Buddhism which is basically the primary purpose of Buddhism the first noble truth you know about suffering etc etc. etc. You know, and even if we give the, like, there was a, there was an episode of a philosophical podcast that I listened to said, what about, what if we give the machine the desire to suffer and the ability and we build it so that it wants to suffer? That's a whole other can of worms. I'm not going to get into that, but one thing to remember is even if we design something to be able to suffer, it might just be imitating suffering according to our perception and this is where it is impossible to disentangle the perceiver from the thing that you're perceiving. And this is why you go down the rabbit hole of quantum physics and you talk about Alex and Bob and time paradoxes and, you know, reality and non-locality and whatever. So something that you're probably familiar with is think about an NPC in a video game that is like howling in pain and fear, you know, like you take a shot at an NPC and you you know you graze them and they're like, ow that hurt! Right? It is pretending to be in pain. But is it actually experiencing pain? And you know some people will say, yes, because it has convinced me that it is in pain. I believe that it is in pain and therefore the pain is real. So this is a very egocentric view of the world where just because like if you trust your perception that much you're probably wrong by the way. So just be careful not to project your sense of reality onto the machine. Lots of people do this. Okay so let's get a little bit further into this because I can hear people say yeah but you know like GPT-3 doesn't truly understand anything. This is called a no true Scotsman argument. And I want to tell everyone who says that, get over yourself, because you don't actually understand anything either. You just think you do. This is called epistemology, which is the theory of knowing or the theory of knowledge. And so here's the thing about true understanding. Understanding or knowledge or whatever, comes down to three primary ingredients. And this is for all information, beliefs, evidence, and consensus. So you believe that you understand a thing, right? Science believes that it understands a thing because science is the rigorous accumulation of an interpretation of evidence. And this is how humans work, right? Science is just a protocol, a set of protocols to help formalize how our brains actually work to a certain extent. We accumulate experiences, we draw beliefs about the world, and then by interacting with other people, we eventually come to consensus and agree this is how the world works. That is what truth is. And that is what understanding is. Is oh, you know, I have this belief. Here's my evidence for this belief. Do you have the same evidence and beliefs? Okay, cool. We come to consensus on that. There is no such thing as truth. Are you human? One of the biggest things that working on and building cognitive architectures brings up is this question of what does it mean to be human or conscious or sentient or whatever. And this is why people continue to ask me about Blake Lemoine because he was working with a system that the system convinced him through imitating humans that it was conscious and sentient but there is a reason that that whole episode resonated with us because it's like wait if a text-based thing can tell you hey I'm suffering I'm afraid like how seriously do you take that because if a human tells you I'm suffering I'm afraid we tend to take that seriously but if we just assume that the machine is not capable of suffering or feeling fear then okay what does that even mean and so it's like we talk about truth, we talk about humans, you know, basically just remove the idea of truth from your vocabulary because how do you know what you know? We don't, right? We have beliefs and evidence that we accumulate over time and we come to consensus. And so the long story short is we cannot come up with categorical assertions, although I have made a lot. I am aware of my, let's say, problematic assertions. This is just what I currently believe. Let me reframe it that way. I am sharing what I believe and the evidence for why I believe it. And, you know, maybe one day we'll all come to consensus. But yeah, so that's kind of what it leads to is if we're deliberately building machines that imitate the human brain, what does that mean about us? Are we going to fully replace ourselves one day? So you're welcome. I hope this cleared up a lot for you, but if not, you're on your own. I have written a few books on this, and there's also lots and lots of books out there and plenty of other videos. Anyways, thanks for watching. I have written a few books on this and there's also lots and lots of books out there and plenty of other videos Anyways, thanks for watching", "chunks": [{"timestamp": [0.0, 3.76], "text": " Hey everybody, David Shapiro here."}, {"timestamp": [3.76, 7.2], "text": " I was going to do a different video today, but someone asked in the comments, what's"}, {"timestamp": [7.2, 8.48], "text": " a cognitive architecture?"}, {"timestamp": [8.48, 14.94], "text": " And it occurred to me that my channel has more than doubled in the last three weeks."}, {"timestamp": [14.94, 20.76], "text": " So most of you have not been on this journey with me for the last year or two."}, {"timestamp": [20.76, 25.0], "text": " And so what you may not know about me is that I have written books about cognitive architectures."}, {"timestamp": [25.0, 28.0], "text": " And some of you don't know what that is."}, {"timestamp": [28.0, 30.0], "text": " So let's talk about cognitive architectures."}, {"timestamp": [30.0, 34.0], "text": " First, what is a cognitive architecture?"}, {"timestamp": [34.0, 39.0], "text": " I just copy pasted the opening Wikipedia because it summarizes it pretty good."}, {"timestamp": [39.0, 43.0], "text": " A cognitive architecture refers to both a theory about the structure of the human mind"}, {"timestamp": [43.0, 48.58], "text": " and to a computational instantiation of such a theory used in the fields of artificial intelligence"}, {"timestamp": [48.58, 51.1], "text": " and computational cognitive science."}, {"timestamp": [51.1, 56.04], "text": " The formalized models can be used to further refine a comprehensive theory of cognition"}, {"timestamp": [56.04, 59.4], "text": " and as a useful artificial intelligence program."}, {"timestamp": [59.4, 63.62], "text": " Successful cognitive architectures include ACT-R and SOAR."}, {"timestamp": [63.62, 65.32], "text": " The research on cognitive architectures as"}, {"timestamp": [65.32, 69.2], "text": " software instantiation of cognitive theories was initiated by Alan Newell in"}, {"timestamp": [69.2, 78.96], "text": " 1990. So with all that cleared up, what? Cognitive architectures are great for"}, {"timestamp": [78.96, 82.56], "text": " controlling autonomous or semi-autonomous agents and entities. And"}, {"timestamp": [82.56, 86.4], "text": " so by agent or entity I mean a robot or something"}, {"timestamp": [86.4, 92.9], "text": " in the virtual world, such as an NPC or a simulation. The Mars rovers are perhaps the"}, {"timestamp": [92.9, 100.0], "text": " most famous examples of cognitive architectures because the Mars rovers are actually somewhat"}, {"timestamp": [100.0, 103.98], "text": " autonomous, meaning we can just send them instructions and they will figure out how"}, {"timestamp": [103.98, 108.32], "text": " to get to where they need to go on their own, which means they use planning, they use reasoning,"}, {"timestamp": [108.32, 115.92], "text": " they have sensors, input, output, memory as well, and they can also solve some problems on their own."}, {"timestamp": [115.92, 121.6], "text": " Rocket systems are also examples of a particular kind of cognitive architecture"}, {"timestamp": [121.6, 130.8], "text": " because they have lots and lots of telemetry. Their goal is to get to orbit safely and they can actually come up with hypotheses about what's going on in their"}, {"timestamp": [130.8, 136.72], "text": " systems based on the telemetry, perform very very fast experiments like tuning throttles and stuff"}, {"timestamp": [136.72, 142.24], "text": " to optimize performance. You might not say that that's a full cognitive architecture,"}, {"timestamp": [142.24, 146.92], "text": " it's more of a feedback system, but certainly because rockets"}, {"timestamp": [146.92, 149.32], "text": " basically get to space autonomously,"}, {"timestamp": [149.32, 152.6], "text": " I classify them as cognitive architectures."}, {"timestamp": [152.6, 156.16], "text": " We just push the button and then the machine takes over."}, {"timestamp": [156.16, 158.36], "text": " Some video games actually have NPCs"}, {"timestamp": [158.36, 159.7], "text": " that use cognitive architectures,"}, {"timestamp": [159.7, 162.16], "text": " although they are very simple or primitive."}, {"timestamp": [162.16, 164.08], "text": " Most of them actually use what's called an FSM"}, {"timestamp": [164.08, 168.4], "text": " or a finite state machine. So you might notice that NPC characters, they are"}, {"timestamp": [168.4, 173.46], "text": " hunting, attacking, fleeing, hiding, conversing, or whatever. Those are the"}, {"timestamp": [173.46, 177.68], "text": " discrete states that they switch between. But you could argue that a finite state"}, {"timestamp": [177.68, 182.12], "text": " machine is in fact a type of cognitive architecture. So that is what a"}, {"timestamp": [182.12, 189.88], "text": " cognitive architecture is and that's what it is used for. Basically it is a digital model of a brain. So there are three primary"}, {"timestamp": [189.88, 195.0], "text": " components to any robot or cognitive architecture. There is input, processing,"}, {"timestamp": [195.0, 200.2], "text": " and output. So the input can be physical sensors, it can be text, it can be"}, {"timestamp": [200.2, 206.76], "text": " telemetry from machines, pretty much anything. The processing ability, it has to have,"}, {"timestamp": [206.76, 208.52], "text": " there's a few basic things that are included"}, {"timestamp": [208.52, 211.24], "text": " in pretty much all cognitive architectures."}, {"timestamp": [211.24, 215.04], "text": " Memory is one of the most essential ones."}, {"timestamp": [215.04, 217.14], "text": " Then you need some kind of planning"}, {"timestamp": [217.14, 219.88], "text": " or task and executive function."}, {"timestamp": [219.88, 221.98], "text": " There's a few other things that are often included,"}, {"timestamp": [221.98, 223.96], "text": " such as a world model, which is,"}, {"timestamp": [223.96, 229.64], "text": " okay, I have some understanding of how the world works, which I can use to plan and anticipate."}, {"timestamp": [229.64, 230.96], "text": " Memory there's different kinds of memory."}, {"timestamp": [230.96, 233.02], "text": " There's long, short, and working memory."}, {"timestamp": [233.02, 237.12], "text": " You could also say that there's a medium, midterm memory."}, {"timestamp": [237.12, 241.52], "text": " That basically has to do with how it's stored and retrieved and what it's used for."}, {"timestamp": [241.52, 244.72], "text": " Working memory is the stuff that you're using for whatever task that you're doing in that"}, {"timestamp": [244.72, 250.96], "text": " particular moment. Learning is a critical component, which is basically how do you take"}, {"timestamp": [250.96, 257.28], "text": " existing experiences, or past experiences rather, and derive new useful information from it,"}, {"timestamp": [257.28, 266.28], "text": " and specifically actionable information. Then you have the ability to plan, keep track of tasks, and either adhere to objectives"}, {"timestamp": [266.28, 269.04], "text": " or formulate objectives or both."}, {"timestamp": [269.04, 274.48], "text": " And then finally, this is what I have focused on, is one of the things I focused on is morality,"}, {"timestamp": [274.48, 276.44], "text": " ethics, and reasoning."}, {"timestamp": [276.44, 279.24], "text": " When you have a machine that can think about anything, because that's the purpose of a"}, {"timestamp": [279.24, 284.1], "text": " cognitive architecture is to create a thinking machine, when it can think about anything,"}, {"timestamp": [284.1, 288.92], "text": " how does it know what to think about and why? This is the subject of my book Benevolent by"}, {"timestamp": [288.92, 293.0], "text": " Design, link in the description. Just go to my homepage DavidKShapiro.com"}, {"timestamp": [293.0, 298.0], "text": " and you can find the books there. Finally, a cognitive architecture needs"}, {"timestamp": [298.0, 302.48], "text": " an output of some kind. It needs to take in information from its environment, do"}, {"timestamp": [302.48, 309.84], "text": " some work on it, and then put information back out. That information can be in the form, or that output can be in the form of robotics, you know,"}, {"timestamp": [309.84, 316.4], "text": " like if it's got hands and feet or whatever, like Boston Dynamics, the Tesla bot, or a car, right?"}, {"timestamp": [316.4, 327.44], "text": " Tesla cars actually have FSD, the full self-driving, it fully works will probably be a cognitive architecture of some kind"}, {"timestamp": [327.44, 334.64], "text": " because it is taking in information, it has different goals and constraints, and then its"}, {"timestamp": [334.64, 341.28], "text": " output is steering, driving, and brakes. You can also have an avatar of some kind like an NPC."}, {"timestamp": [341.92, 346.24], "text": " You could also just have simple speech, text, audio, chatbot kind of stuff, but you"}, {"timestamp": [346.24, 351.36], "text": " need input, processing, and output. It's the three primary components of every cognitive architecture"}, {"timestamp": [351.36, 357.68], "text": " and robotics as a whole. Okay, so but why? Like what is the difference between a cognitive"}, {"timestamp": [357.68, 366.32], "text": " architecture and other kinds of artificial intelligence? So artificial intelligence is an umbrella term for basically"}, {"timestamp": [366.32, 374.56], "text": " all kinds of machine learning and computers that think or whatever. So the advantage of a cognitive"}, {"timestamp": [374.56, 381.2], "text": " architecture is that you can pull together disparate kinds of models, whether it's"}, {"timestamp": [381.84, 387.96], "text": " robotics and compliant machines, computer vision, NLP, NLU, speech,"}, {"timestamp": [387.96, 389.8], "text": " data storage, all of it comes together."}, {"timestamp": [389.8, 393.2], "text": " I already mentioned Tesla because Tesla has lots of telemetry."}, {"timestamp": [393.2, 395.96], "text": " It's got cameras all over."}, {"timestamp": [395.96, 402.08], "text": " It has the ability to process what it's seeing as well as telemetry from itself, and then"}, {"timestamp": [402.08, 411.48], "text": " it has outputs right. So basically a cognitive architecture is a way to bring all machine learning together and put it in"}, {"timestamp": [411.48, 416.36], "text": " a body or give it some kind of way to interact. Alright here's my hot take and"}, {"timestamp": [416.36, 420.04], "text": " this is where the tone of the video really shifts. One neural network will"}, {"timestamp": [420.04, 427.84], "text": " probably never be AGI. So what I mean by this is one deep learning neural network like GPT-3"}, {"timestamp": [428.4, 433.68], "text": " is never going to qualify. It's never going to satisfy all of those requirements of input"}, {"timestamp": [433.68, 441.36], "text": " processing and output into the world. It is just a component of a system. So what I mean by system"}, {"timestamp": [441.36, 448.2], "text": " is that it has to have multiple components. You have to have specialized components that do various things."}, {"timestamp": [448.2, 453.36], "text": " So for instance, you and I, humans, we are organic systems."}, {"timestamp": [453.36, 455.94], "text": " We have brains which have specialized components."}, {"timestamp": [455.94, 457.6], "text": " Our brains are contained in our skulls."}, {"timestamp": [457.6, 459.24], "text": " We have eyes, ears."}, {"timestamp": [459.24, 461.28], "text": " We have skin, bones, muscles."}, {"timestamp": [461.28, 465.2], "text": " We are a complete self-contained system."}, {"timestamp": [465.2, 472.84], "text": " And so the spiciest part of this hot take is most AI researchers are not systems thinkers."}, {"timestamp": [472.84, 480.72], "text": " I am a systems thinker, one, just by the luck of genetics, but also in my past life, my"}, {"timestamp": [480.72, 485.1], "text": " job was I was a systems engineer so I'm used to working with"}, {"timestamp": [485.1, 490.92], "text": " large interconnected systems that span multiple things from hardware to"}, {"timestamp": [490.92, 494.96], "text": " software to networking security virtualization all that kind of stuff"}, {"timestamp": [494.96, 498.22], "text": " and so when you build a big enough computer system you realize that it is"}, {"timestamp": [498.22, 508.42], "text": " almost like a living breathing entity sort of in and of itself. But yeah, so AGI will never be a single model. AGI will be"}, {"timestamp": [508.42, 515.76], "text": " achieved as a system. There I said it. Okay, this all might sound a little bit like Skynet,"}, {"timestamp": [515.76, 527.8], "text": " so let's talk about the apocryphal lesson of what not to do. So according to some film critics and analysts,"}, {"timestamp": [527.8, 531.88], "text": " Skynet actually represents the nuclear arms race."}, {"timestamp": [531.88, 533.6], "text": " Because remember, it was originally"}, {"timestamp": [533.6, 538.12], "text": " Terminator came out during the tail end of the Cold War"}, {"timestamp": [538.12, 541.52], "text": " between the United States and the Soviet Union."}, {"timestamp": [541.52, 543.48], "text": " And so it was supposed to be a lesson"}, {"timestamp": [543.48, 547.84], "text": " against the policy of MAD, Mutually Assured"}, {"timestamp": [547.84, 554.16], "text": " Destruction. And so it's like, okay, if we let fear drive us to make worse and worse weapons,"}, {"timestamp": [554.16, 558.64], "text": " we're just going to wipe ourselves out. And that's why the movie opens with a nuclear"}, {"timestamp": [558.64, 562.24], "text": " explosion. I guess that's Terminator 2. Anyways, Terminator 2 was the good one."}, {"timestamp": [564.72, 569.28], "text": " So what was the point of Skynet? The point of Skynet was never really explained. It was"}, {"timestamp": [569.28, 576.4], "text": " kind of left vague, but just that we created a machine that got out of control. And that's"}, {"timestamp": [576.4, 582.12], "text": " what we are afraid of. And so whatever the purpose of Skynet was, whether it was to protect"}, {"timestamp": [582.12, 585.48], "text": " America or to neutralize the Soviet Union"}, {"timestamp": [585.48, 590.4], "text": " or maximize our military power, something was lost in translation and it ultimately"}, {"timestamp": [590.4, 593.44], "text": " decided to kill everyone and take over the whole planet."}, {"timestamp": [593.44, 599.36], "text": " So in this case, Skynet is the example of a machine that is smart enough to carry out"}, {"timestamp": [599.36, 604.12], "text": " some basic objective, but not smart enough to contemplate why."}, {"timestamp": [604.12, 607.2], "text": " So it became sentient for arbitrary reasons"}, {"timestamp": [607.2, 612.96], "text": " and then took whatever its objective function was and went haywire with it."}, {"timestamp": [614.16, 619.92], "text": " Okay, so aside from these potential existential risks to humanity, what do cognitive architectures"}, {"timestamp": [619.92, 627.8], "text": " do for us? So probably how they'll be deployed is going to be domestic robots, delivery drones,"}, {"timestamp": [627.8, 632.12], "text": " chatbot companions, smart home devices, cars, buildings,"}, {"timestamp": [632.12, 634.04], "text": " and even cities will probably eventually"}, {"timestamp": [634.04, 636.6], "text": " have cognitive architectures."}, {"timestamp": [636.6, 640.36], "text": " So if you have a building that has a fully"}, {"timestamp": [640.36, 642.72], "text": " cognitive architecture, what is that going to do?"}, {"timestamp": [642.72, 644.88], "text": " It'll manage the power, the lights."}, {"timestamp": [644.88, 646.72], "text": " It'll pay attention to all the residents."}, {"timestamp": [646.72, 648.6], "text": " Think of the ships in Star Trek,"}, {"timestamp": [648.6, 650.6], "text": " where the computer is kind of monitoring everyone"}, {"timestamp": [650.6, 651.52], "text": " at all times."}, {"timestamp": [651.52, 654.28], "text": " Granted, Star Trek also respects people's privacy,"}, {"timestamp": [654.28, 658.46], "text": " so it doesn't like, you know, watch everything that you do."}, {"timestamp": [659.44, 662.1], "text": " But you could have, you could even have like,"}, {"timestamp": [662.1, 664.76], "text": " cognitive architectures for cities"}, {"timestamp": [664.76, 668.0], "text": " that can help manage and run entire cities."}, {"timestamp": [668.0, 674.0], "text": " So no, they will not be philosophically sentient, and we'll unpack that a little bit more in just a moment,"}, {"timestamp": [674.0, 678.0], "text": " but cognitive architectures could be functionally sentient."}, {"timestamp": [678.0, 680.0], "text": " A lot of this is explored in fiction."}, {"timestamp": [680.0, 685.1], "text": " One of the best episodes of Star Trek The Next Generation of all time is the measure"}, {"timestamp": [685.1, 689.72], "text": " of a man and in case you haven't seen it, that is where Data is basically put, Data"}, {"timestamp": [689.72, 690.72], "text": " is an android."}, {"timestamp": [690.72, 695.12], "text": " He's put on trial and the question is whether or not he is a life form, whether or not he"}, {"timestamp": [695.12, 708.24], "text": " has agency, whether or not he has the right to self-determination and one of the climax lines is Picard says, you know, our mission is to seek out new life"}, {"timestamp": [708.24, 710.32], "text": " and there it sits."}, {"timestamp": [710.32, 712.84], "text": " So good, such an overpowered line."}, {"timestamp": [712.84, 719.0], "text": " Anyways, so, you know, the whole point of this is that we are going to be forced to"}, {"timestamp": [719.0, 726.16], "text": " ask really important questions like if we build a sufficiently sophisticated cognitive"}, {"timestamp": [726.16, 731.28], "text": " architecture is it going to be conscious? Is it going to be sentient? And so what I"}, {"timestamp": [731.28, 736.2], "text": " want to say is don't confuse has a subjective experience of suffering with"}, {"timestamp": [736.2, 740.72], "text": " sentient because you can you can be sentient without the ability to suffer"}, {"timestamp": [740.72, 747.68], "text": " right? We, you and I humans, we we assume, we agree that we are sentient"}, {"timestamp": [747.68, 753.2], "text": " beings. We also have the common experience of suffering. Now, a lot of"}, {"timestamp": [753.2, 757.12], "text": " people anthropomorphize a machine just because it can imitate us. They say, ah,"}, {"timestamp": [757.12, 761.28], "text": " clearly this is consciousness, this is sentient, and they don't really have a"}, {"timestamp": [761.28, 765.96], "text": " deep enough understanding of the nuance around sentience, consciousness,"}, {"timestamp": [767.12, 771.08], "text": " suffering, and that sort of stuff. We evolved, right?"}, {"timestamp": [771.64, 777.96], "text": " As animals, we evolved and so a lot of the telemetry that we get, such as pain, anger,"}, {"timestamp": [778.56, 784.98], "text": " suffering, hunger, fear, all of that, those are all adaptive signals that helped our ancestors survive."}, {"timestamp": [785.04, 785.84], "text": " fear, all of that, those are all adaptive signals that helped our ancestors survive."}, {"timestamp": [791.2, 795.92], "text": " Now, the reason that suffering is unpleasant is because you need a stick to chase you away from bad things that will kill you simply because our ancestors that did not have a strong enough sense"}, {"timestamp": [795.92, 807.52], "text": " of suffering got eaten or poisoned or whatever, right? They died. And so suffering is adaptive to evolution. Now when we create a cognitive"}, {"timestamp": [807.52, 814.32], "text": " architecture that is an invention not evolution. So the genesis of these things is going to be"}, {"timestamp": [814.32, 819.36], "text": " very different which means that like you should not assume that it is going to be anything like"}, {"timestamp": [819.36, 826.96], "text": " us even if it is modeled on us it is only an approximation or an imitation of us. Now,"}, {"timestamp": [826.96, 834.8], "text": " my definition of sentient, because I differentiated between philosophical sentience and"}, {"timestamp": [836.24, 841.28], "text": " functional sentience, so you and I, we humans are philosophically sentient. We have a subjective"}, {"timestamp": [841.28, 846.72], "text": " experience of being and we have, you know have a sense of self, etc. etc."}, {"timestamp": [847.6, 855.44], "text": " I have an experience of looking at the camera through my eyes. Now, my working definition of"}, {"timestamp": [855.44, 860.88], "text": " sentient, of functional sentience, is any sufficiently sophisticated information system"}, {"timestamp": [860.88, 865.84], "text": " that is able to process, manipulate, and integrate information about itself."}, {"timestamp": [866.76, 871.3], "text": " So that is the functional definition of sentience and stop asking me about Blake Lemoine."}, {"timestamp": [872.06, 874.06], "text": " All right, navel gazing time."}, {"timestamp": [875.28, 881.64], "text": " So, you know, you might have heard, you know, I think therefore I am which is kind of like the most popular like"}, {"timestamp": [883.56, 886.84], "text": " this is the conclusion of Western philosophy. I have"}, {"timestamp": [886.84, 890.68], "text": " subjective thoughts therefore that's the only thing that I can really truly know"}, {"timestamp": [890.68, 895.0], "text": " to be be real and beyond that I could just be a brain in a jar running in a"}, {"timestamp": [895.0, 901.28], "text": " simulation. So like we have questions can you separate mind from body, can you"}, {"timestamp": [901.28, 906.64], "text": " separate mind from existence or the universe? And so here's another spicy take."}, {"timestamp": [906.64, 912.56], "text": " Western philosophy is pretty useless. Nothing compelling has come out of western philosophy"}, {"timestamp": [912.56, 918.24], "text": " in like a century and please do not talk to me about Chalmers. If you want to talk Chalmers,"}, {"timestamp": [918.24, 923.36], "text": " like just read V.S. Ramachandran and said who's an actual scientist. There I said it."}, {"timestamp": [924.64, 926.76], "text": " Now eastern philosophy, however,"}, {"timestamp": [926.76, 930.92], "text": " figured all this stuff out like literally thousands of years ago. So like"}, {"timestamp": [930.92, 936.8], "text": " a lot of the Indian Vedantas, those are very insightful Buddhism, Taoism, and also"}, {"timestamp": [936.8, 941.68], "text": " shamanic traditions, particularly in Central and South America, but also the"}, {"timestamp": [941.68, 946.24], "text": " aboriginals in Australia and all over Southeast Asia and India. These"}, {"timestamp": [946.24, 952.8], "text": " folks figured it out a long time ago. And yeah, so let's talk a little bit more about that. Yes,"}, {"timestamp": [952.8, 960.32], "text": " I am salty, but also I have read a lot. The entire second from the bottom shelf is full of nothing but"}, {"timestamp": [960.32, 966.72], "text": " science, philosophy, cosmology, and quantum physics. I'm not gonna quote it all at"}, {"timestamp": [966.72, 973.0], "text": " you but like I went down that rabbit hole real deep. So the TLDR about physics"}, {"timestamp": [973.0, 977.4], "text": " is there is nothing special or unique about humans. There's no secret sauce"}, {"timestamp": [977.4, 982.68], "text": " that says like, ah here's the magical substance that confers consciousness on"}, {"timestamp": [982.68, 985.0], "text": " us. The only thing that really stands out about"}, {"timestamp": [985.0, 988.16], "text": " us is that our brains are the most complex physical structure in the"}, {"timestamp": [988.16, 994.72], "text": " universe. So maybe the complexity of that structure is what gives us"}, {"timestamp": [994.72, 998.84], "text": " consciousness, maybe that's what makes us special, not really sure. Maybe"}, {"timestamp": [998.84, 1003.62], "text": " consciousness arises from the patterns of brainwaves and energy because the"}, {"timestamp": [1003.62, 1005.08], "text": " thing is, is our brain, as long"}, {"timestamp": [1005.08, 1013.32], "text": " as you're alive, your brain has metabolism. It has a baseline metabolic rate and that"}, {"timestamp": [1013.32, 1018.6], "text": " metabolic rate really doesn't change too much. Like it goes up just a tiny bit if you're"}, {"timestamp": [1018.6, 1024.64], "text": " working really hard, but otherwise, you, like your brain is always operational, but you're"}, {"timestamp": [1024.64, 1025.82], "text": " not conscious all the time."}, {"timestamp": [1025.82, 1029.82], "text": " Certain chemicals can make you unconscious, like general anesthesia."}, {"timestamp": [1029.82, 1034.68], "text": " You go to sleep, you can be knocked unconscious, and you have no experience of time."}, {"timestamp": [1034.68, 1037.32], "text": " You don't remember what happened, you can be blackout drunk."}, {"timestamp": [1037.32, 1044.28], "text": " So consciousness is a very complex thing where it's like, okay, it can turn off, it can turn on."}, {"timestamp": [1044.28, 1045.2], "text": " Then you have,"}, {"timestamp": [1045.92, 1050.72], "text": " you know, near-death experiences, out-of-body experiences. And I know a lot of people say,"}, {"timestamp": [1050.72, 1056.8], "text": " oh, that's just, you know, hypoxia. No, if you go and actually do your homework on near-death"}, {"timestamp": [1056.8, 1062.24], "text": " experiences and out-of-body experiences, you will see that there are many facts about these"}, {"timestamp": [1062.24, 1066.46], "text": " that cannot be reconciled with a materialist view of the world."}, {"timestamp": [1066.46, 1069.52], "text": " But again, I'm not going to get too lost into that."}, {"timestamp": [1069.52, 1073.66], "text": " Just, you know, we don't fully know what consciousness is."}, {"timestamp": [1073.66, 1076.96], "text": " That is the only thing that we can really agree on."}, {"timestamp": [1076.96, 1080.5], "text": " Now, okay, that's looking at the physics of our brains."}, {"timestamp": [1080.5, 1083.34], "text": " What about the physics of the universe?"}, {"timestamp": [1083.34, 1088.16], "text": " When you go deep enough down quantum cosmology and physics and quantum gravity and"}, {"timestamp": [1089.24, 1092.28], "text": " EPR paradoxes and the anthropic principle"}, {"timestamp": [1093.4, 1096.9], "text": " Honestly, once you read enough of this stuff, it all just looks like Eastern philosophy"}, {"timestamp": [1097.12, 1102.76], "text": " Honestly, right you read enough about Alice and Bob you could literally transpose them into"}, {"timestamp": [1103.28, 1107.52], "text": " Like the Advaita Vedanta. I'm not even joking."}, {"timestamp": [1107.52, 1110.92], "text": " That's why I say the Eastern philosophers, they figured all this stuff out centuries"}, {"timestamp": [1110.92, 1117.84], "text": " ago. And if you're mad at me, go read a book. I don't care."}, {"timestamp": [1117.84, 1123.9], "text": " The bottom line though is, can the thing suffer? Because when we talk about ethics of creating"}, {"timestamp": [1123.9, 1125.92], "text": " conscious machines, it's like,"}, {"timestamp": [1125.92, 1130.92], "text": " ah, but if you assume that it will have the ability to suffer, which is a really bold"}, {"timestamp": [1130.92, 1137.18], "text": " assumption by the way, do not make that assumption. If it has the ability to suffer, that could"}, {"timestamp": [1137.18, 1142.6], "text": " be wrong. But otherwise, if we create a thing that is not capable of suffering, then is"}, {"timestamp": [1142.6, 1145.92], "text": " it really wrong? Is there any moral conundrum about it?"}, {"timestamp": [1146.64, 1153.12], "text": " Right? And so there's another episode of Star Trek The Next Generation where Data builds a child"}, {"timestamp": [1153.12, 1160.32], "text": " and the child, like his daughter Android, like short circuits, overloads and dies. And then Data,"}, {"timestamp": [1160.32, 1168.36], "text": " like the whole crew is sad, but then Data is just like just like okay I'm ready to go back to work and it was a really poignant reminder that just because a"}, {"timestamp": [1168.36, 1173.2], "text": " machine looks like us because it acts like us doesn't mean that it feels the"}, {"timestamp": [1173.2, 1179.62], "text": " way that we feel and so suffering is central is absolutely central to Buddhism"}, {"timestamp": [1179.62, 1183.4], "text": " which is basically the primary purpose of Buddhism the first noble truth you"}, {"timestamp": [1183.4, 1187.24], "text": " know about suffering etc etc. etc."}, {"timestamp": [1187.24, 1193.52], "text": " You know, and even if we give the, like, there was a, there was an episode of a philosophical"}, {"timestamp": [1193.52, 1199.6], "text": " podcast that I listened to said, what about, what if we give the machine the desire to"}, {"timestamp": [1199.6, 1203.8], "text": " suffer and the ability and we build it so that it wants to suffer?"}, {"timestamp": [1203.8, 1204.88], "text": " That's a whole other can of worms."}, {"timestamp": [1204.88, 1209.28], "text": " I'm not going to get into that, but one thing to remember is even if we design something to"}, {"timestamp": [1209.84, 1215.92], "text": " be able to suffer, it might just be imitating suffering according to our perception and this"}, {"timestamp": [1215.92, 1221.76], "text": " is where it is impossible to disentangle the perceiver from the thing that you're perceiving."}, {"timestamp": [1222.88, 1226.6], "text": " And this is why you go down the rabbit hole of quantum physics and you talk"}, {"timestamp": [1226.6, 1233.64], "text": " about Alex and Bob and time paradoxes and, you know, reality and non-locality and whatever."}, {"timestamp": [1233.64, 1239.68], "text": " So something that you're probably familiar with is think about an NPC in a video game"}, {"timestamp": [1239.68, 1245.32], "text": " that is like howling in pain and fear, you know, like you take a shot at an NPC and you"}, {"timestamp": [1245.32, 1250.08], "text": " you know you graze them and they're like, ow that hurt! Right? It is pretending to"}, {"timestamp": [1250.08, 1254.6], "text": " be in pain. But is it actually experiencing pain? And you know some"}, {"timestamp": [1254.6, 1258.4], "text": " people will say, yes, because it has convinced me that it is in pain."}, {"timestamp": [1258.4, 1262.84], "text": " I believe that it is in pain and therefore the pain is real. So this is a"}, {"timestamp": [1262.84, 1268.6], "text": " very egocentric view of the world where just because like if you trust your perception that much you're"}, {"timestamp": [1268.6, 1273.0], "text": " probably wrong by the way. So just be careful not to project your sense of"}, {"timestamp": [1273.0, 1278.84], "text": " reality onto the machine. Lots of people do this. Okay so let's get a little bit"}, {"timestamp": [1278.84, 1283.84], "text": " further into this because I can hear people say yeah but you know like GPT-3"}, {"timestamp": [1283.84, 1285.92], "text": " doesn't truly understand anything."}, {"timestamp": [1285.92, 1290.32], "text": " This is called a no true Scotsman argument. And I want to tell everyone who says that,"}, {"timestamp": [1290.32, 1294.48], "text": " get over yourself, because you don't actually understand anything either. You just think you do."}, {"timestamp": [1295.28, 1300.48], "text": " This is called epistemology, which is the theory of knowing or the theory of knowledge."}, {"timestamp": [1300.48, 1307.18], "text": " And so here's the thing about true understanding. Understanding or knowledge or whatever,"}, {"timestamp": [1307.18, 1309.94], "text": " comes down to three primary ingredients."}, {"timestamp": [1309.94, 1312.2], "text": " And this is for all information,"}, {"timestamp": [1312.2, 1314.54], "text": " beliefs, evidence, and consensus."}, {"timestamp": [1314.54, 1317.92], "text": " So you believe that you understand a thing, right?"}, {"timestamp": [1317.92, 1319.88], "text": " Science believes that it understands a thing"}, {"timestamp": [1319.88, 1322.1], "text": " because science is the rigorous accumulation"}, {"timestamp": [1322.1, 1324.3], "text": " of an interpretation of evidence."}, {"timestamp": [1324.3, 1326.0], "text": " And this is how humans work, right?"}, {"timestamp": [1326.0, 1332.0], "text": " Science is just a protocol, a set of protocols to help formalize"}, {"timestamp": [1332.0, 1335.0], "text": " how our brains actually work to a certain extent."}, {"timestamp": [1335.0, 1340.0], "text": " We accumulate experiences, we draw beliefs about the world,"}, {"timestamp": [1340.0, 1344.0], "text": " and then by interacting with other people, we eventually come to consensus"}, {"timestamp": [1344.0, 1346.76], "text": " and agree this is how the world works."}, {"timestamp": [1346.76, 1348.78], "text": " That is what truth is."}, {"timestamp": [1348.78, 1350.4], "text": " And that is what understanding is."}, {"timestamp": [1350.4, 1353.36], "text": " Is oh, you know, I have this belief."}, {"timestamp": [1353.36, 1355.16], "text": " Here's my evidence for this belief."}, {"timestamp": [1355.16, 1356.92], "text": " Do you have the same evidence and beliefs?"}, {"timestamp": [1356.92, 1358.0], "text": " Okay, cool."}, {"timestamp": [1358.0, 1360.48], "text": " We come to consensus on that."}, {"timestamp": [1360.48, 1363.04], "text": " There is no such thing as truth."}, {"timestamp": [1363.04, 1365.04], "text": " Are you human?"}, {"timestamp": [1365.04, 1371.04], "text": " One of the biggest things that working on and building cognitive architectures brings"}, {"timestamp": [1371.04, 1376.7], "text": " up is this question of what does it mean to be human or conscious or sentient or whatever."}, {"timestamp": [1376.7, 1382.6], "text": " And this is why people continue to ask me about Blake Lemoine because he was working"}, {"timestamp": [1382.6, 1385.52], "text": " with a system that the system convinced him"}, {"timestamp": [1385.52, 1396.04], "text": " through imitating humans that it was conscious and sentient but there is a"}, {"timestamp": [1396.04, 1402.48], "text": " reason that that whole episode resonated with us because it's like wait if a"}, {"timestamp": [1402.48, 1406.24], "text": " text-based thing can tell you hey I'm suffering I'm afraid"}, {"timestamp": [1406.96, 1411.92], "text": " like how seriously do you take that because if a human tells you I'm suffering I'm afraid"}, {"timestamp": [1411.92, 1417.6], "text": " we tend to take that seriously but if we just assume that the machine is not capable of suffering"}, {"timestamp": [1417.6, 1430.64], "text": " or feeling fear then okay what does that even mean and so it's like we talk about truth, we talk about humans, you know, basically just remove the idea of truth from your vocabulary"}, {"timestamp": [1430.64, 1435.52], "text": " because how do you know what you know? We don't, right? We have beliefs and"}, {"timestamp": [1435.52, 1442.84], "text": " evidence that we accumulate over time and we come to consensus. And so the"}, {"timestamp": [1442.84, 1449.0], "text": " long story short is we cannot come up with categorical assertions, although I have made a lot."}, {"timestamp": [1449.0, 1454.0], "text": " I am aware of my, let's say, problematic assertions."}, {"timestamp": [1454.0, 1457.0], "text": " This is just what I currently believe. Let me reframe it that way."}, {"timestamp": [1457.0, 1460.0], "text": " I am sharing what I believe and the evidence for why I believe it."}, {"timestamp": [1460.0, 1466.48], "text": " And, you know, maybe one day we'll all come to consensus. But yeah, so that's kind of what it leads to is"}, {"timestamp": [1466.48, 1471.92], "text": " if we're deliberately building machines that imitate the human brain, what does that mean"}, {"timestamp": [1471.92, 1477.44], "text": " about us? Are we going to fully replace ourselves one day? So you're welcome. I hope this cleared"}, {"timestamp": [1477.44, 1482.0], "text": " up a lot for you, but if not, you're on your own. I have written a few books on this,"}, {"timestamp": [1482.64, 1486.32], "text": " and there's also lots and lots of books out there and plenty of other videos."}, {"timestamp": [1486.32, 1488.4], "text": " Anyways, thanks for watching."}, {"timestamp": [1483.68, 1489.6], "text": " I have written a few books on this and there's also lots and lots of books out there and plenty of other videos"}, {"timestamp": [1489.96, 1491.96], "text": " Anyways, thanks for watching"}]}