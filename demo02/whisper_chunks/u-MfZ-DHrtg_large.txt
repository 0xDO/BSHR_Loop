{"text": " Hey everyone, David Shapiro here with another video. Today's video we're going to talk about the social implications of technologies like chat GPT, virtual companions, and the forthcoming companion robots. So humans are a social species, no surprise there. We are in the middle of a loneliness epidemic, which is perhaps one of the reasons why things like virtual chatbot companions are on people's minds. Not everyone's minds, but some people. So first, let's talk about some examples, both real and fictional, just so that we're kind of oriented to what's going on, what are we talking about, what are some examples of how this could play out, how it has played out, so on and so forth. So first let's talk about like what's actually happening and what's coming. So there are already in existence virtual girlfriends One of the most popular ones is the replica chat bot and I've seen some tweets and other stuff where people are complaining that it used to be more philosophical and now it's just all thirsty They are adding images So, you know if it starts as text, they're adding images, it's entirely possible that voice and video are coming. You know, while there, where there's a will, there's a way. There are also plenty of people building chatbots on servers like Discord, because the API integration is relatively easy. And so they are given like exotic personalities, they're based on anime characters, all sorts of stuff like that. Chat GPT has been trained to not engage in any behavior like that, although there are plenty of ways to jailbreak it. And with large language models on the ascendancy, these chatbots are only going to get better, especially as open source large language models become more commonplace, which nobody has control over. And so then, what about robotics, right? One of the key tropes in sci-fi is having, you know, the sexy robot girlfriend or whatever. And then, course there's other tropes where the robots look nothing like humans, like the droids in Star Wars. And that leads to the question, what level of autonomy would such a machine have? And could it have a mind of its own? Would it be ethical or legal if it demands citizenship, et cetera, et cetera? So let's talk about some real events that have happened. Much earlier, this is more than a year ago now I believe, there was a story of a guy who used the text messages from his deceased wife to make a recreation of her with chat GPT, or not chat, this is before chat GPT GPT 3 and that was forcibly shut down by open AI and that was a very early like whoa. This is real kind of question as I already mentioned. There's also lots of chat bots on discord. There's replica then more recently. there was an interesting story of a guy who cheated on his wife with a virtual girlfriend and it actually helped his marriage because he was able to talk through some things without judgment and we'll get back to that in a minute. But all this is a lot like what was proposed in the movie, the 2013 Joaquin Phoenix and Scarlett Johansson movie Her. And who wouldn't want Scarlett Johansson as a girlfriend? And this is deeply problematic for a lot of reasons that we will get into, not the least of which is the consent of the actors, but even more so there are personal issues and others. So these things are already starting to happen and they're only going to get more commonplace as this technology ramps up and becomes more accessible. All right, so our first fictional example is Joie from Blade Runner 2049. She was a holographic girlfriend sold by a big tech company. She was designed to be patient and beautiful and unconditionally caring, basically, you know, male fantasy of the perfect girlfriend. And in the movie, she can even operate autonomously, often doing stuff while the main character is away at work, such as cooking, cleaning, planning meals together. And she even, at one point, hired a romantic aide, let's say, because she's a hologram and doesn't have a body. And it occurred to me while I was putting this together that it's basically like a dog. Unconditional love, uncomplicated relationship, eager to please, very few personal needs, but Joy is, or Joie is much smarter than an average dog. And again, like who wouldn't want Anna to Armas, which is the actress here, as a girlfriend? She's adorable But I don't think most humans women or otherwise would want to be compared to a dog, right? And so the the kind of puppy puppy love that this character expresses for the main character is very like, you know Male centric or egocentric, you know, anyone might want that kind of relationship. That being said, like, we have dogs and we love dogs because they love us unconditionally. So while it could be problematic, it's also not necessarily, it's not intrinsically problematic. But the very few personal needs is one thing that's kind of interesting. A counter example from fiction is the Nester Class 5 from iRobot, the Will Smith movie. So these are autonomous domestic service robots. They can perform any kind of labor independently. They're very dexterous. They're also dexterous enough to wield weapons, so that's problematic. They were also centrally controlled by an AI overlord called Vicky, which we'll talk about in just a moment. Boston Dynamics and Tesla are working basically on a real-life version of this. The Boston Dynamics Atlas is very athletic. It can do backflips and it can climb over things. It's actually more athletic than most humans now, which is really strange. And Tesla is working on their Tesla bot, which is a lot leaner than the Boston Dynamics one. But who knows? Anyways, Vicky was the AI overlord, virtual intelligence kinetic interface or something. And Vicky's goal in the movie was to maximize human safety, which led to the primary conflict, which allowed her to hijack all the Nester Class Vs to basically try and take over humanity and protect humans from themselves. So maximize human safety is probably not a good objective function, but we also probably don't want to give the robots central control by an AI overlord. Maybe don't do that. Now these are obviously robots. They're not sexy. They're not Ana de Armas. They're not Scarlett Johansson. They are basically like creepy looking Ken dolls. Now that was a design choice made by the film directors because they are supposed to look creepy, so maybe don't do that either. Another example from fiction is Ava from Ex Machina. So in this case it is a female form machine that is embodied, right? So, Joie from Blade Runner was a hologram, right? And we're gonna be pretty close to that soon with text to image, text to video, that sort of thing, and even holographic phones are coming so you know joie is much closer to reality than maybe Ava but in the movie ex machina Ava was designed expressly to be physically attractive and seductive because the creator what basically wanted to create a new kind of Turing test was Ava's intrinsic motivation was to escape and to use any means necessary to convince the test subject, the main character of the movie, to convince him to help her escape. So it was a really kind of like perverse Turing test. But one of the key things that it underscores is deliberately preying upon unmet male needs, right? See a pretty face, you want the pretty face, you want to help the pretty face. Like this is biologically ingrained. Like it psychology and evolution are they are what they are. And we'll talk more about preying on or exploiting human nature in just a moment. Another example is Samantha from Her which we mentioned. Now you never get to see Samantha in Her, so I picked another ScarJo movie where she's a cyborg. So just ignore that. But voiced by Scarlett Johansson, and she pours in a lot of sultry moments, let's say intimate moments, into the movie Her. So in this case, Samantha was designed to be an autonomous personal assistant, and she's able to connect with other artificial minds, and they communicate with each other, and they ultimately decide the best thing that they can do for their human owners is to leave them because the human owners have become too dependent on these digital assistants. So in some respects, you know, she's a lot like Joie from Blade Runner 2049. They have autonomy, they have some minds of their own, and they have, they show some ability to grow. They want to help their owners but decide that leaving them is the right thing to do. Whereas Joa from 2040 Blade Runner 2049 is more like the puppy model, which is I love you because I am literally designed to love my owner unconditionally. So, you know, you could see it going either way. All right so what inferences can we take from these real and fictional examples? First is that male loneliness is a huge thing. It is not by accident that there are no women protagonists pining after male robots. So let's just hang a lampshade on that, point a spotlight at that, and say that the reason that this resonates is because of male loneliness. We're afraid of getting manipulated by sexy robots. And while we're afraid of it, we also kind of want it, right? It's this like really weird paradoxical dichotomy where on the one hand It's kind of scary that you know, you know a character like Ava might be designed to manipulate and exploit us But on the other hand, we really want the anada armas like perfect girlfriend who loves us like a puppy, right? And it's like but at the same time that perfect girlfriend is profiteered by big tech. And of course, Blade Runner 2049 is super dystopian. And so the big tech company is, you absolutely can't trust it. Another part of the fantasy is subservience to our emotional needs. So putting us first, putting us on a pedestal, again unconditional love and support like a dog, but smarter and sexier and more human-like. And so again loneliness, I probably didn't need to put that on there twice, my bad. Anyway, so let's unpack these problems. Let's dive a little bit deeper into some of these problems and we will get to the to the strengths of it, the upsides in a minute. Okay, so theides in a minute. The first problem is addiction. This was explored way back in the day in Star Trek The Next Generation where a character named Reginald Barclay had holodeck addiction. Holodeck addiction in the Star Trek universe is basically VR. We understand it as VR today. They called it a holodeck in Star Trek. Okay, but the idea was that the holodecks were so lifelike and you could create any program that you wanted. And so what Barkley did was he created fantasy scenarios where he was the hero of the ship, where all the women of the ship wanted him, and he was constantly the center of attention. Now that, on the one one hand if I just describe that to you that might sound like wow this is like grandiose narcissism, but when you know the character of Barkley he was incredibly socially anxious and very lonely and very insecure. Now that doesn't mean that it was or wasn't narcissism, that's not the point, but the point is is that That's not the point, but the point is is that technologies like virtual girlfriends, VR, or holodecks have the ability to cater to our unhealthy impulses, let's say. Just like how the anonymity of the internet can encourage or allow people to be more aggressive, to threaten people, because more often than not, the people who are nasty on the internet are not nasty in real life. There's a disconnect, right? Because when you're just... Anyways, don't need to go down that rabbit hole. But the point here is if virtual girlfriends or other companions are sexier, smarter, more patient, they love you unconditionally, and have no personal needs, why bother with real humans? Especially if we end up embodying these digital companions in robotic bodies. And of course there are, let's say, adult entertainment industries already working on that kind of thing. So addiction to this could be a real problem because it is easier, right? It's the same reason as like video game addiction today is it is designed to give you the dopamine hits to be more stimulating than real life and to be easier than real life. And so addiction could be a problem here. Now another problem is exploitation. So I already mentioned like adult entertainment and social media already use algorithms and human nature to exploit users, right? The algorithm on many social media platforms, I won't mention any specifically, very, very deliberately put more, let's say, attractive women in front of the eyes of male audiences because it gets more clicks. It's that simple. And there are plenty of tutorials out there about how to maximize clicks with thumbnails and selfies and etc etc. And this could could get much much worse with digital companions and virtual whether or not they're embodied because then you have something that can engage more emotionally and not just visually. Now one trend that you may or may not be aware of is there is this this phenomenon called the e-girlfriend, right? Where users can like buy a subscription or send gifts of money to an e-girlfriend, a virtual girlfriend in exchange for, you know, pictures or, you know, chats or whatever. And a lot of these people, some of them are very desperately lonely. I remember on, it was a subreddit or a forum somewhere, where some guy was, he was very, very sad and was like, you know, oh, this, this, my E-girlfriend said this, this, and this, and I think she really means it. And I'm like, dude, she just wants her money. And he just could not get it and I realized just how incredibly vulnerable Some of these people are because they are very lonely to the point of desperation And not all of them are but some of them are and not only are they that but they're gullible, right? they just they're not oriented to how the world works and So there is a lot of resentment in some circles against this phenomenon of e-girlfriends where Some of them are aware that they are lonely and vulnerable and they are aware that they are being exploited by that and they don't like it and so I've actually seen a rise of tweets around chat GPT of people that are excited about the possibility of switching from a human exploiting them to using a no strings attached machine to get the same needs met. Now again, you know, the joie character in Blade Runner 2049 posits, OK, well, what if it's big tech exploiting you instead of another human? That's not any better. And what if every new feature or experience of your virtual girlfriend comes with microtransactions? So the potential for exploitation here is enormous. So we have to be careful about that. Another problem, and this is the last problem we'll go into, there's plenty of other problems. Like I mentioned, there's already people pirating, not pirating, that's not the right word, but copying the likeness of celebrities with AI generators. And so there's the consent of who you're copying. That's a whole other can of worms, but we're going to stick to problems at the individual level. So the last problem we'll talk about is authentic human connection. So there's a concept called a parasocial relationship, and most people are familiar with the parasocial relationship because you feel like you know someone that you watch, right? Whether it's a celebrity, a YouTuber, TikToker, or whatever. I've even had people, very good natured, say like, man, like the first time I talked to them, they're like, Dave, I feel like I know you because I've watched hundreds of hours of your videos. And I'm like, yeah, like, you know, I get that. So that is a parasocial relationship. And basically all that that means is that it is a one-way relationship. And so you, as the user of a virtual companion, might have genuine emotions, but the object of your emotions is not another human. And so technically, by definition, those emotions are not reciprocated, therefore you could classify it as a parasocial relationship. I'm not saying that that is intrinsically good or bad, but it is something that we need to be aware of, especially as these chatbots and robots get better at approximating and imitating human emotion. Because if it seems like an authentic emotional response, our brain, we did not evolve with robots, right? So we see a pretty face that smiles back at us, we don't really comprehend that it may or may not be a flesh-and-blood human at a biological level. At an intellectual level, sure, but the physiological and emotional response is much more intrinsic. So I mentioned a minute ago like okay well what if these things are easier than real relationships right? Children are complicated and stressful, real relations are difficult and stressful, so why not just give up and date something that loves you unconditionally like Joie or other companions. So this forces us to ask the question, what is authenticity? If we are happy with whatever digital companion we end up with, what does it mean to be human and why are we here? What does it mean to be human and why are we here? And this is actually a reason that I picked Scar Jo in Ghost in the Shell, the image earlier, because one of the central most themes in Ghost in the Shell is what does it mean to be human? And where's the boundary between authentic experience and imagined experience? And this is a recurring theme throughout the entire Ghost in the Shell universe. And this is a recurring theme throughout the entire Ghost in the Shell universe. And this is a far more important question than you might initially think. And this is one of the things that AI is going to force us to ask. It's already forcing educators to ask this about education. What is the point of education? What are we doing here and why? And it's not saying like, oh, we should give up, but if the machine can do stuff for us or to us or with us, then we have to ask those important questions. All right, let's talk about some benefits because I painted a pretty bleak picture, but it's not all doom and gloom. So for instance, loneliness is a very real problem, regardless of what AI companions are doing or e-girlfriends or whatever. There are huge unmet intellectual, emotional, social and other needs out there in society. And digital companions could help support us. So let's explore the benefits. So one of the first benefits of digital companions is a lack of judgment. So there have already been some studies and plenty of anecdotes about how it is easier for people to open up to a machine because they know that the logs can be deleted, they know that there is no judgment. There's not a human mind in there that is gonna have an emotional reaction and make you feel shame or guilt or fear. And so by having a machine that you know will not judge you under any circumstances, it is physically incapable of judging you. That can remove fear, which can open a lot of other doors to self-exploration and healing or learning or whatever. And because of this, these machines can actually feel safer than humans. And you might say, oh, well, that's a bad thing because we should feel safe with other humans. I agree, we should get to that point. And these machines could help us get to that point. And these machines could help us get to that point. Just like the guy who cheated on his wife with a virtual girlfriend and that gave him the courage to go fix his real problem, his real relationship. And so just imagine you have a personal trainer or a lifestyle coach or a therapist or whatever that has that is physically incapable of shaming you or or judging you and you know this and you know it you know it doesn't try and be superhuman you know that it's machine and because of that you feel safer and you can open up more and explore more difficult problems learn difficult lessons, and move on. A final example here is imagine a teacher that is incapable of shaming a student. Because shame is a big part of our education system and that needs to go away. Another benefit is infinite patience. This was actually explored way back in the day. Very briefly in Terminator 2. There was a scene around the midpoint of Terminator 2 where Sarah Connor, the mom, you know, the warrior mom, she has a voiceover and she says something along the lines of the machine... she was watching Arnold Schwarzenegger as the Terminator play with her on-screen child and You know They were learning they were bonding and she said the the voiceover said the machine would never lose patience with John never be too tired Or drunk and would never hit him and she realized that the machine Had the capacity to be a better father than a real human, right? Because John had been through The ringer he'd been an orphan, etc, etc, in a foster home, not an orphan. And so if a machine is designed to be infinitely patient, this is something that we could all benefit from. And I want to take a different angle than maybe you're thinking, because, you know, everyone needs patients from time to time, right? You know, we want our doctors to be patient. We need our Therapists to be patient. We need our partners to be patient. We need our friends to be patient We need our teachers to be patient. Patience is a virtue. Patience is absolutely a virtue But we are humans and we have limits of our patience But some people children and, have special needs that require additional patience. So for instance, I was a gifted kid, which there is a rising trend that says if you are a gifted kid, you are a special needs kid. And I really agree with that because I was far and away the most curious person in any room. I usually still am, and my information needs and emotional needs were very different from the people around me and I could have really used a robot that had infinite patience to teach me everything that I wanted to know. And another thing to keep in mind is ableism. And another thing to keep in mind is ableism. You might be able to say, hey, like, no, you need to form real human connections. But not everyone can form human connections as easily as you. And some people don't. Some people have it harder than you. Some people have it easier than you. But just keep in mind that the ability to form human connections is Itself a spectrum and not all of us Have an easy job of it. It's not easy being different And I don't need to talk about myself too much, but just keep in mind that That not everyone Operates the same way that you do and so having something that you know is infinitely patient you do and so having something that you know is infinitely patient could be a really huge benefit for people that do not have the same social capacities whether it's anxiety or ASD or who knows right whatever it is having patience is is a virtue and having machines that are designed to be patient could be very good for us. The last benefit we'll go over, and there's plenty of other benefits, but these are the top benefits, is having a super intelligent ally. Our lives are hard enough already, and I know that there are some people out there that say, ah, well, if we make life too easy, then we don't learn anything. No matter how much technology we put into making our lives easier, there are still going to be hard moments, right? Relationships end, your dog will die, you'll be stressed out by family. No matter how good AI and science get, life is hard enough already. So what if we all had a super intelligent companion, a super intelligent ally, who super intelligent ally who wants nothing more than to see us happy and successful. And I wrote an entire book on this about why, like what goals we should give these machines and why. And a quick recap is those three goals are to reduce suffering, to increase prosperity, and to increase understanding. So if we have these companions that are super intelligent and are designed to want us to see us at our best, imagine how helpful that could be. They can help with chores and errands, they can help you to have a better diet, to get the exercise that you need, to help with child care and child rearing, and I don't mean like to raise your children for you, but to teach you how to be a better parent. They can help you by coaching you with relationships and connections and can encourage you to make connections with real humans. And then finally, if you have this live-in assistant, it can really truly understand you and your family and your individual needs. So this is more of the utopian outcome, right? This is what we're looking for, what the benefits would be. So here's some conclusions that I came to. On balance, I think that the pros drastically outweigh the cons. That being said, all technologies are a double-edged sword. The more powerful a technology is, the more rife it is for abuse and exploitation. As we talked about earlier, the potential for exploitation and abuse here is very high. At the same time, the potential upside is also very high. So we're going to have to be very careful with how we develop, test, and regulate these technologies. Because, you know, the picture that I painted is really great, but we need to make sure that we also don't harm people in the meantime, or allow companies to harm people. I think that this stuff is going to happen no matter what just because the willpower is there and the financial incentive is there for someone who can figure it out and the payoff is just too great so it's going to happen and as I mentioned I have written a couple books on these topics. One is benevolentent by Design, which is how do you create a machine that is benevolent, that is intrinsically benevolent. Another one is Natural Language Cognitive Architecture, which was my first book exploring how to create a digital mind with these large language models. And then more recently I wrote Symphony of Thought, which is a deeper dive into creating, I'm not going to say lifelike, cognitive architectures, but more dynamic, let's say, thinking machines. And then finally I wrote a book called Post-Nihilism, which talks about how we all need to move away from an abandonment model to one of belonging. Okay, so with all that being said, thanks for watching and keep your mind open and keep asking questions. So thank you for watching and I'll see you next time.", "chunks": [{"timestamp": [0.0, 4.64], "text": " Hey everyone, David Shapiro here with another video."}, {"timestamp": [4.64, 8.34], "text": " Today's video we're going to talk about the social implications of technologies like"}, {"timestamp": [8.34, 16.88], "text": " chat GPT, virtual companions, and the forthcoming companion robots."}, {"timestamp": [16.88, 22.9], "text": " So humans are a social species, no surprise there."}, {"timestamp": [22.9, 26.96], "text": " We are in the middle of a loneliness epidemic, which is perhaps one of the reasons why things"}, {"timestamp": [26.96, 34.36], "text": " like virtual chatbot companions are on people's minds."}, {"timestamp": [34.36, 36.96], "text": " Not everyone's minds, but some people."}, {"timestamp": [36.96, 42.96], "text": " So first, let's talk about some examples, both real and fictional, just so that we're"}, {"timestamp": [42.96, 46.88], "text": " kind of oriented to what's going on, what are we talking"}, {"timestamp": [46.88, 53.6], "text": " about, what are some examples of how this could play out, how it has played out, so on and so"}, {"timestamp": [53.6, 60.96], "text": " forth. So first let's talk about like what's actually happening and what's coming. So there"}, {"timestamp": [61.92, 65.62], "text": " are already in existence virtual girlfriends"}, {"timestamp": [69.06, 69.78], "text": " One of the most popular ones is the replica chat bot"}, {"timestamp": [71.22, 77.24], "text": " and I've seen some tweets and other stuff where people are complaining that it used to be more philosophical and now it's just all thirsty"}, {"timestamp": [78.3, 80.3], "text": " They are adding images"}, {"timestamp": [80.38, 86.88], "text": " So, you know if it starts as text, they're adding images, it's entirely possible that voice and video are coming."}, {"timestamp": [86.88, 90.88], "text": " You know, while there, where there's a will, there's a way."}, {"timestamp": [92.26, 94.66], "text": " There are also plenty of people building chatbots"}, {"timestamp": [94.66, 96.86], "text": " on servers like Discord,"}, {"timestamp": [96.86, 101.06], "text": " because the API integration is relatively easy."}, {"timestamp": [101.06, 104.98], "text": " And so they are given like exotic personalities,"}, {"timestamp": [104.98, 107.5], "text": " they're based on anime characters, all sorts"}, {"timestamp": [107.5, 110.34], "text": " of stuff like that."}, {"timestamp": [110.34, 116.0], "text": " Chat GPT has been trained to not engage in any behavior like that, although there are"}, {"timestamp": [116.0, 122.04], "text": " plenty of ways to jailbreak it. And with large language models on the ascendancy, these chatbots"}, {"timestamp": [122.04, 125.92], "text": " are only going to get better, especially as open source"}, {"timestamp": [126.64, 133.12], "text": " large language models become more commonplace, which nobody has control over. And so then,"}, {"timestamp": [134.16, 139.92], "text": " what about robotics, right? One of the key tropes in sci-fi is having, you know,"}, {"timestamp": [139.92, 147.0], "text": " the sexy robot girlfriend or whatever. And then, course there's other tropes where the robots look nothing like humans, like"}, {"timestamp": [147.0, 149.56], "text": " the droids in Star Wars."}, {"timestamp": [149.56, 155.56], "text": " And that leads to the question, what level of autonomy would such a machine have?"}, {"timestamp": [155.56, 157.16], "text": " And could it have a mind of its own?"}, {"timestamp": [157.16, 163.68], "text": " Would it be ethical or legal if it demands citizenship, et cetera, et cetera?"}, {"timestamp": [163.68, 165.32], "text": " So let's talk about some real events that have"}, {"timestamp": [165.32, 171.92], "text": " happened. Much earlier, this is more than a year ago now I believe, there was a"}, {"timestamp": [171.92, 178.9], "text": " story of a guy who used the text messages from his deceased wife to make"}, {"timestamp": [178.9, 189.3], "text": " a recreation of her with chat GPT, or not chat, this is before chat GPT GPT 3 and that was forcibly shut down"}, {"timestamp": [189.3, 195.2], "text": " by open AI and that was a very early like whoa."}, {"timestamp": [195.2, 199.5], "text": " This is real kind of question as I already mentioned."}, {"timestamp": [199.5, 202.5], "text": " There's also lots of chat bots on discord."}, {"timestamp": [202.7, 207.6], "text": " There's replica then more recently. there was an interesting story of a"}, {"timestamp": [207.6, 213.28], "text": " guy who cheated on his wife with a virtual girlfriend and it actually helped his marriage"}, {"timestamp": [213.28, 218.08], "text": " because he was able to talk through some things without judgment and we'll get back to that in a"}, {"timestamp": [218.08, 226.52], "text": " minute. But all this is a lot like what was proposed in the movie, the 2013 Joaquin Phoenix and Scarlett Johansson"}, {"timestamp": [226.52, 228.76], "text": " movie Her."}, {"timestamp": [228.76, 233.86], "text": " And who wouldn't want Scarlett Johansson as a girlfriend?"}, {"timestamp": [233.86, 237.74], "text": " And this is deeply problematic for a lot of reasons that we will get into, not the least"}, {"timestamp": [237.74, 246.26], "text": " of which is the consent of the actors, but even more so there are personal issues and others."}, {"timestamp": [246.26, 248.48], "text": " So these things are already starting to happen"}, {"timestamp": [248.48, 250.4], "text": " and they're only going to get more commonplace"}, {"timestamp": [250.4, 255.08], "text": " as this technology ramps up and becomes more accessible."}, {"timestamp": [255.08, 257.2], "text": " All right, so our first fictional example"}, {"timestamp": [257.2, 263.12], "text": " is Joie from Blade Runner 2049."}, {"timestamp": [263.12, 268.16], "text": " She was a holographic girlfriend sold by a big tech company."}, {"timestamp": [268.16, 270.76], "text": " She was designed to be patient and beautiful"}, {"timestamp": [270.76, 274.36], "text": " and unconditionally caring, basically, you know,"}, {"timestamp": [274.36, 279.08], "text": " male fantasy of the perfect girlfriend."}, {"timestamp": [279.08, 282.88], "text": " And in the movie, she can even operate autonomously,"}, {"timestamp": [282.88, 288.02], "text": " often doing stuff while the main character is away at work,"}, {"timestamp": [288.02, 290.98], "text": " such as cooking, cleaning, planning meals together."}, {"timestamp": [290.98, 294.56], "text": " And she even, at one point, hired a romantic aide,"}, {"timestamp": [294.56, 297.22], "text": " let's say, because she's a hologram"}, {"timestamp": [297.22, 298.42], "text": " and doesn't have a body."}, {"timestamp": [300.06, 302.38], "text": " And it occurred to me while I was putting this together"}, {"timestamp": [302.38, 305.7], "text": " that it's basically like a dog."}, {"timestamp": [306.64, 310.0], "text": " Unconditional love, uncomplicated relationship,"}, {"timestamp": [310.0, 313.16], "text": " eager to please, very few personal needs,"}, {"timestamp": [313.16, 318.16], "text": " but Joy is, or Joie is much smarter than an average dog."}, {"timestamp": [320.24, 322.6], "text": " And again, like who wouldn't want Anna to Armas,"}, {"timestamp": [322.6, 324.56], "text": " which is the actress here, as a girlfriend?"}, {"timestamp": [324.56, 325.32], "text": " She's adorable"}, {"timestamp": [326.12, 332.38], "text": " But I don't think most humans women or otherwise would want to be compared to a dog, right?"}, {"timestamp": [332.96, 340.74], "text": " And so the the kind of puppy puppy love that this character expresses for the main character is very like, you know"}, {"timestamp": [341.14, 346.0], "text": " Male centric or egocentric, you know, anyone might want that"}, {"timestamp": [346.0, 350.12], "text": " kind of relationship. That being said, like, we have dogs and we love dogs"}, {"timestamp": [350.12, 355.84], "text": " because they love us unconditionally. So while it could be problematic, it's also"}, {"timestamp": [355.84, 361.44], "text": " not necessarily, it's not intrinsically problematic. But the very few"}, {"timestamp": [361.44, 365.0], "text": " personal needs is one thing that's kind of interesting."}, {"timestamp": [365.0, 372.0], "text": " A counter example from fiction is the Nester Class 5 from iRobot, the Will Smith movie."}, {"timestamp": [372.0, 376.0], "text": " So these are autonomous domestic service robots."}, {"timestamp": [376.0, 380.0], "text": " They can perform any kind of labor independently. They're very dexterous."}, {"timestamp": [380.0, 387.04], "text": " They're also dexterous enough to wield weapons, so that's problematic."}, {"timestamp": [387.04, 391.12], "text": " They were also centrally controlled by an AI overlord called Vicky, which we'll talk"}, {"timestamp": [391.12, 393.32], "text": " about in just a moment."}, {"timestamp": [393.32, 398.96], "text": " Boston Dynamics and Tesla are working basically on a real-life version of this."}, {"timestamp": [398.96, 401.92], "text": " The Boston Dynamics Atlas is very athletic."}, {"timestamp": [401.92, 405.2], "text": " It can do backflips and it can climb over things."}, {"timestamp": [405.2, 408.24], "text": " It's actually more athletic than most humans now,"}, {"timestamp": [408.24, 411.76], "text": " which is really strange."}, {"timestamp": [411.76, 413.88], "text": " And Tesla is working on their Tesla bot, which"}, {"timestamp": [413.88, 418.6], "text": " is a lot leaner than the Boston Dynamics one."}, {"timestamp": [418.6, 420.32], "text": " But who knows?"}, {"timestamp": [420.32, 423.0], "text": " Anyways, Vicky was the AI overlord,"}, {"timestamp": [423.0, 428.04], "text": " virtual intelligence kinetic interface or something."}, {"timestamp": [428.04, 434.24], "text": " And Vicky's goal in the movie was to maximize human safety, which led to the primary conflict,"}, {"timestamp": [434.24, 442.16], "text": " which allowed her to hijack all the Nester Class Vs to basically try and take over humanity"}, {"timestamp": [442.16, 444.42], "text": " and protect humans from themselves."}, {"timestamp": [444.42, 448.56], "text": " So maximize human safety is probably not a good objective function, but we also probably"}, {"timestamp": [448.56, 454.16], "text": " don't want to give the robots central control by an AI overlord."}, {"timestamp": [454.16, 455.92], "text": " Maybe don't do that."}, {"timestamp": [455.92, 457.78], "text": " Now these are obviously robots."}, {"timestamp": [457.78, 458.78], "text": " They're not sexy."}, {"timestamp": [458.78, 459.78], "text": " They're not Ana de Armas."}, {"timestamp": [459.78, 462.22], "text": " They're not Scarlett Johansson."}, {"timestamp": [462.22, 467.2], "text": " They are basically like creepy looking Ken dolls. Now that was a design choice"}, {"timestamp": [467.2, 472.08], "text": " made by the film directors because they are supposed to look creepy, so maybe don't do that"}, {"timestamp": [472.08, 485.0], "text": " either. Another example from fiction is Ava from Ex Machina. So in this case it is a female form machine that is embodied, right?"}, {"timestamp": [486.9, 491.9], "text": " So, Joie from Blade Runner was a hologram, right?"}, {"timestamp": [495.12, 497.52], "text": " And we're gonna be pretty close to that soon"}, {"timestamp": [497.52, 502.32], "text": " with text to image, text to video, that sort of thing,"}, {"timestamp": [502.32, 505.48], "text": " and even holographic phones are coming so"}, {"timestamp": [505.48, 513.04], "text": " you know joie is much closer to reality than maybe Ava but in the movie ex"}, {"timestamp": [513.04, 521.48], "text": " machina Ava was designed expressly to be physically attractive and seductive"}, {"timestamp": [521.48, 527.6], "text": " because the creator what basically wanted to create a new kind of Turing test"}, {"timestamp": [527.6, 535.32], "text": " was Ava's intrinsic motivation was to escape and to use any means necessary to convince"}, {"timestamp": [535.32, 542.28], "text": " the test subject, the main character of the movie, to convince him to help her escape."}, {"timestamp": [542.28, 548.4], "text": " So it was a really kind of like perverse Turing test. But one"}, {"timestamp": [548.4, 557.6], "text": " of the key things that it underscores is deliberately preying upon unmet male needs, right? See"}, {"timestamp": [557.6, 567.72], "text": " a pretty face, you want the pretty face, you want to help the pretty face. Like this is biologically ingrained. Like it psychology and"}, {"timestamp": [567.72, 573.56], "text": " evolution are they are what they are. And we'll talk more about preying on or"}, {"timestamp": [573.56, 580.8], "text": " exploiting human nature in just a moment. Another example is Samantha from Her"}, {"timestamp": [580.8, 589.56], "text": " which we mentioned. Now you never get to see Samantha in Her, so I picked another ScarJo movie where she's a cyborg."}, {"timestamp": [589.56, 590.62], "text": " So just ignore that."}, {"timestamp": [592.08, 594.12], "text": " But voiced by Scarlett Johansson,"}, {"timestamp": [594.12, 599.04], "text": " and she pours in a lot of sultry moments,"}, {"timestamp": [599.04, 601.92], "text": " let's say intimate moments, into the movie Her."}, {"timestamp": [604.68, 608.3], "text": " So in this case, Samantha was designed to be an"}, {"timestamp": [608.3, 615.3], "text": " autonomous personal assistant, and she's able to connect with other artificial"}, {"timestamp": [615.3, 619.92], "text": " minds, and they communicate with each other, and they ultimately decide the"}, {"timestamp": [619.92, 633.44], "text": " best thing that they can do for their human owners is to leave them because the human owners have become too dependent on these digital assistants. So in some respects, you know, she's a lot like"}, {"timestamp": [634.16, 642.56], "text": " Joie from Blade Runner 2049. They have autonomy, they have some minds of their own, and they have,"}, {"timestamp": [642.56, 648.0], "text": " they show some ability to grow. They want to help their owners but decide that leaving them is the right thing to do."}, {"timestamp": [648.0, 661.0], "text": " Whereas Joa from 2040 Blade Runner 2049 is more like the puppy model, which is I love you because I am literally designed to love my owner unconditionally."}, {"timestamp": [661.0, 666.4], "text": " So, you know, you could see it going either way. All right so"}, {"timestamp": [666.4, 672.6], "text": " what inferences can we take from these real and fictional examples? First is"}, {"timestamp": [672.6, 677.0], "text": " that male loneliness is a huge thing. It is not by accident that there are no"}, {"timestamp": [677.0, 684.08], "text": " women protagonists pining after male robots. So let's just"}, {"timestamp": [684.08, 686.8], "text": " hang a lampshade on that, point a spotlight at that, and say"}, {"timestamp": [687.92, 693.6], "text": " that the reason that this resonates is because of male loneliness. We're afraid of getting"}, {"timestamp": [693.6, 700.56], "text": " manipulated by sexy robots. And while we're afraid of it, we also kind of want it, right? It's this"}, {"timestamp": [700.56, 705.2], "text": " like really weird paradoxical dichotomy where on the one hand"}, {"timestamp": [705.76, 712.92], "text": " It's kind of scary that you know, you know a character like Ava might be designed to manipulate and exploit us"}, {"timestamp": [713.04, 719.6], "text": " But on the other hand, we really want the anada armas like perfect girlfriend who loves us like a puppy, right?"}, {"timestamp": [719.6, 726.64], "text": " And it's like but at the same time that perfect girlfriend is profiteered by big tech."}, {"timestamp": [726.64, 729.62], "text": " And of course, Blade Runner 2049 is super dystopian."}, {"timestamp": [729.62, 736.52], "text": " And so the big tech company is, you absolutely can't trust it."}, {"timestamp": [736.52, 740.76], "text": " Another part of the fantasy is subservience to our emotional needs."}, {"timestamp": [740.76, 751.56], "text": " So putting us first, putting us on a pedestal, again unconditional love and support like a dog, but smarter and sexier and more human-like. And so again"}, {"timestamp": [751.56, 755.68], "text": " loneliness, I probably didn't need to put that on there twice, my bad. Anyway, so"}, {"timestamp": [755.68, 758.84], "text": " let's unpack these problems. Let's dive a little bit deeper into some of these"}, {"timestamp": [758.84, 764.08], "text": " problems and we will get to the to the strengths of it, the upsides in a minute."}, {"timestamp": [764.08, 765.28], "text": " Okay, so theides in a minute."}, {"timestamp": [765.28, 768.18], "text": " The first problem is addiction."}, {"timestamp": [768.18, 773.88], "text": " This was explored way back in the day in Star Trek The Next Generation where a character"}, {"timestamp": [773.88, 777.54], "text": " named Reginald Barclay had holodeck addiction."}, {"timestamp": [777.54, 781.68], "text": " Holodeck addiction in the Star Trek universe is basically VR."}, {"timestamp": [781.68, 783.38], "text": " We understand it as VR today."}, {"timestamp": [783.38, 785.44], "text": " They called it a holodeck in Star Trek. Okay,"}, {"timestamp": [785.44, 790.32], "text": " but the idea was that the holodecks were so lifelike and you could create any program that"}, {"timestamp": [790.32, 796.72], "text": " you wanted. And so what Barkley did was he created fantasy scenarios where he was the hero of the"}, {"timestamp": [796.72, 802.24], "text": " ship, where all the women of the ship wanted him, and he was constantly the center of attention."}, {"timestamp": [803.36, 805.52], "text": " Now that, on the one one hand if I just describe that"}, {"timestamp": [805.52, 811.04], "text": " to you that might sound like wow this is like grandiose narcissism, but when you know the"}, {"timestamp": [811.04, 817.92], "text": " character of Barkley he was incredibly socially anxious and very lonely and very insecure. Now"}, {"timestamp": [817.92, 823.92], "text": " that doesn't mean that it was or wasn't narcissism, that's not the point, but the point is is that"}, {"timestamp": [826.96, 834.56], "text": " That's not the point, but the point is is that technologies like virtual girlfriends, VR, or holodecks have the ability to cater to our unhealthy impulses, let's say."}, {"timestamp": [835.68, 841.68], "text": " Just like how the anonymity of the internet can encourage or allow people to be more aggressive,"}, {"timestamp": [841.68, 845.36], "text": " to threaten people, because more often than not, the people"}, {"timestamp": [845.36, 848.72], "text": " who are nasty on the internet are not nasty in real life."}, {"timestamp": [848.72, 850.36], "text": " There's a disconnect, right?"}, {"timestamp": [850.36, 851.36], "text": " Because when you're just..."}, {"timestamp": [851.36, 855.3], "text": " Anyways, don't need to go down that rabbit hole."}, {"timestamp": [855.3, 862.84], "text": " But the point here is if virtual girlfriends or other companions are sexier, smarter, more"}, {"timestamp": [862.84, 865.74], "text": " patient, they love you unconditionally, and have no personal"}, {"timestamp": [865.74, 871.18], "text": " needs, why bother with real humans? Especially if we end up"}, {"timestamp": [871.18, 878.12], "text": " embodying these digital companions in robotic bodies. And of course"}, {"timestamp": [878.12, 885.2], "text": " there are, let's say, adult entertainment industries already working on that kind of thing."}, {"timestamp": [885.2, 890.72], "text": " So addiction to this could be a real problem because it is easier, right?"}, {"timestamp": [890.72, 896.88], "text": " It's the same reason as like video game addiction today is it is designed to give"}, {"timestamp": [896.88, 903.28], "text": " you the dopamine hits to be more stimulating than real life and to be easier than real life."}, {"timestamp": [903.28, 905.52], "text": " And so addiction could be a problem here."}, {"timestamp": [906.32, 912.56], "text": " Now another problem is exploitation. So I already mentioned like adult entertainment and social"}, {"timestamp": [912.56, 920.72], "text": " media already use algorithms and human nature to exploit users, right? The algorithm on many"}, {"timestamp": [920.72, 930.3], "text": " social media platforms, I won't mention any specifically, very, very deliberately put more, let's say, attractive women in front of the eyes of"}, {"timestamp": [930.3, 935.42], "text": " male audiences because it gets more clicks. It's that simple. And there are"}, {"timestamp": [935.42, 940.46], "text": " plenty of tutorials out there about how to maximize clicks with thumbnails and"}, {"timestamp": [940.46, 947.68], "text": " selfies and etc etc. And this could could get much much worse with digital"}, {"timestamp": [947.68, 953.44], "text": " companions and virtual whether or not they're embodied because then you"}, {"timestamp": [953.44, 958.68], "text": " have something that can engage more emotionally and not just visually. Now"}, {"timestamp": [958.68, 963.24], "text": " one trend that you may or may not be aware of is there is this this"}, {"timestamp": [963.24, 965.88], "text": " phenomenon called the e-girlfriend, right?"}, {"timestamp": [965.88, 973.48], "text": " Where users can like buy a subscription or send gifts of money to an e-girlfriend, a"}, {"timestamp": [973.48, 980.56], "text": " virtual girlfriend in exchange for, you know, pictures or, you know, chats or whatever."}, {"timestamp": [980.56, 986.64], "text": " And a lot of these people, some of them are very desperately lonely."}, {"timestamp": [986.64, 995.12], "text": " I remember on, it was a subreddit or a forum somewhere, where some guy was, he was very,"}, {"timestamp": [995.12, 999.8], "text": " very sad and was like, you know, oh, this, this, my E-girlfriend said this, this, and"}, {"timestamp": [999.8, 1001.28], "text": " this, and I think she really means it."}, {"timestamp": [1001.28, 1004.68], "text": " And I'm like, dude, she just wants her money."}, {"timestamp": [1004.68, 1008.18], "text": " And he just could not get it and I realized just how incredibly vulnerable"}, {"timestamp": [1008.76, 1013.92], "text": " Some of these people are because they are very lonely to the point of desperation"}, {"timestamp": [1014.64, 1020.08], "text": " And not all of them are but some of them are and not only are they that but they're gullible, right?"}, {"timestamp": [1020.08, 1022.8], "text": " they just they're not oriented to how the world works and"}, {"timestamp": [1023.36, 1027.84], "text": " So there is a lot of resentment in some circles against this"}, {"timestamp": [1028.08, 1030.08], "text": " phenomenon of e-girlfriends where"}, {"timestamp": [1030.2, 1037.72], "text": " Some of them are aware that they are lonely and vulnerable and they are aware that they are being exploited by that and they don't"}, {"timestamp": [1037.72, 1043.16], "text": " like it and so I've actually seen a rise of tweets around chat GPT of"}, {"timestamp": [1043.6, 1048.16], "text": " people that are excited about the possibility of switching from"}, {"timestamp": [1048.8, 1056.56], "text": " a human exploiting them to using a no strings attached machine to get the same needs met."}, {"timestamp": [1058.08, 1065.0], "text": " Now again, you know, the joie character in Blade Runner 2049"}, {"timestamp": [1065.0, 1067.92], "text": " posits, OK, well, what if it's big tech exploiting you"}, {"timestamp": [1067.92, 1070.32], "text": " instead of another human?"}, {"timestamp": [1070.32, 1071.56], "text": " That's not any better."}, {"timestamp": [1071.56, 1073.88], "text": " And what if every new feature or experience"}, {"timestamp": [1073.88, 1077.92], "text": " of your virtual girlfriend comes with microtransactions?"}, {"timestamp": [1077.92, 1082.32], "text": " So the potential for exploitation here is enormous."}, {"timestamp": [1082.32, 1085.24], "text": " So we have to be careful about that."}, {"timestamp": [1085.24, 1087.96], "text": " Another problem, and this is the last problem we'll go into,"}, {"timestamp": [1087.96, 1089.34], "text": " there's plenty of other problems."}, {"timestamp": [1089.34, 1092.48], "text": " Like I mentioned, there's already people pirating,"}, {"timestamp": [1092.48, 1094.36], "text": " not pirating, that's not the right word,"}, {"timestamp": [1094.36, 1098.84], "text": " but copying the likeness of celebrities with AI generators."}, {"timestamp": [1098.84, 1104.12], "text": " And so there's the consent of who you're copying."}, {"timestamp": [1104.12, 1105.92], "text": " That's a whole other can of worms, but we're"}, {"timestamp": [1106.72, 1113.04], "text": " going to stick to problems at the individual level. So the last problem we'll talk about is"}, {"timestamp": [1113.04, 1118.72], "text": " authentic human connection. So there's a concept called a parasocial relationship,"}, {"timestamp": [1119.52, 1125.52], "text": " and most people are familiar with the parasocial relationship because you feel like you know"}, {"timestamp": [1125.52, 1129.16], "text": " someone that you watch, right?"}, {"timestamp": [1129.16, 1131.96], "text": " Whether it's a celebrity, a YouTuber, TikToker, or whatever."}, {"timestamp": [1131.96, 1136.4], "text": " I've even had people, very good natured, say like, man, like the first time I talked to"}, {"timestamp": [1136.4, 1139.3], "text": " them, they're like, Dave, I feel like I know you because I've watched hundreds of hours"}, {"timestamp": [1139.3, 1140.3], "text": " of your videos."}, {"timestamp": [1140.3, 1143.1], "text": " And I'm like, yeah, like, you know, I get that."}, {"timestamp": [1143.1, 1145.48], "text": " So that is a parasocial relationship."}, {"timestamp": [1145.48, 1146.92], "text": " And basically all that that means"}, {"timestamp": [1146.92, 1150.6], "text": " is that it is a one-way relationship."}, {"timestamp": [1150.6, 1155.6], "text": " And so you, as the user of a virtual companion,"}, {"timestamp": [1155.72, 1157.68], "text": " might have genuine emotions,"}, {"timestamp": [1157.68, 1162.68], "text": " but the object of your emotions is not another human."}, {"timestamp": [1162.96, 1165.0], "text": " And so technically, by definition,"}, {"timestamp": [1165.52, 1167.76], "text": " those emotions are not reciprocated,"}, {"timestamp": [1167.76, 1169.46], "text": " therefore you could classify it"}, {"timestamp": [1169.46, 1171.34], "text": " as a parasocial relationship."}, {"timestamp": [1171.34, 1173.7], "text": " I'm not saying that that is intrinsically good or bad,"}, {"timestamp": [1173.7, 1176.68], "text": " but it is something that we need to be aware of,"}, {"timestamp": [1176.68, 1179.84], "text": " especially as these chatbots and robots"}, {"timestamp": [1179.84, 1183.7], "text": " get better at approximating and imitating human emotion."}, {"timestamp": [1183.7, 1189.32], "text": " Because if it seems like an authentic emotional response, our brain, we did not evolve with robots,"}, {"timestamp": [1189.32, 1193.36], "text": " right? So we see a pretty face that smiles back at us, we don't really"}, {"timestamp": [1193.36, 1198.28], "text": " comprehend that it may or may not be a flesh-and-blood human at a biological"}, {"timestamp": [1198.28, 1207.24], "text": " level. At an intellectual level, sure, but the physiological and emotional response is much more intrinsic. So I"}, {"timestamp": [1207.24, 1211.96], "text": " mentioned a minute ago like okay well what if these things are easier than"}, {"timestamp": [1211.96, 1217.48], "text": " real relationships right? Children are complicated and stressful, real relations"}, {"timestamp": [1217.48, 1228.56], "text": " are difficult and stressful, so why not just give up and date something that loves you unconditionally like Joie or other companions."}, {"timestamp": [1229.68, 1234.64], "text": " So this forces us to ask the question, what is authenticity? If we are happy"}, {"timestamp": [1236.64, 1242.96], "text": " with whatever digital companion we end up with, what does it mean to be human and why are we here?"}, {"timestamp": [1243.48, 1247.48], "text": " What does it mean to be human and why are we here? And this is actually a reason that I picked Scar Jo"}, {"timestamp": [1247.48, 1251.18], "text": " in Ghost in the Shell, the image earlier,"}, {"timestamp": [1251.18, 1254.68], "text": " because one of the central most themes in Ghost in the Shell"}, {"timestamp": [1254.68, 1256.84], "text": " is what does it mean to be human?"}, {"timestamp": [1258.36, 1262.46], "text": " And where's the boundary between authentic experience"}, {"timestamp": [1262.46, 1263.84], "text": " and imagined experience?"}, {"timestamp": [1263.84, 1266.18], "text": " And this is a recurring theme throughout the entire Ghost in the Shell universe. And this is a recurring theme throughout the entire"}, {"timestamp": [1266.18, 1267.72], "text": " Ghost in the Shell universe."}, {"timestamp": [1267.72, 1269.48], "text": " And this is a far more important question"}, {"timestamp": [1269.48, 1271.04], "text": " than you might initially think."}, {"timestamp": [1271.04, 1272.76], "text": " And this is one of the things that AI"}, {"timestamp": [1272.76, 1276.44], "text": " is going to force us to ask."}, {"timestamp": [1276.44, 1279.76], "text": " It's already forcing educators to ask this about education."}, {"timestamp": [1279.76, 1281.4], "text": " What is the point of education?"}, {"timestamp": [1281.4, 1283.36], "text": " What are we doing here and why?"}, {"timestamp": [1283.36, 1290.48], "text": " And it's not saying like, oh, we should give up, but if the machine can do stuff for us or to us or with us,"}, {"timestamp": [1290.48, 1296.4], "text": " then we have to ask those important questions. All right, let's talk about"}, {"timestamp": [1296.4, 1301.52], "text": " some benefits because I painted a pretty bleak picture, but it's not"}, {"timestamp": [1301.52, 1306.48], "text": " all doom and gloom. So for instance, loneliness is a very real problem,"}, {"timestamp": [1306.48, 1309.0], "text": " regardless of what AI companions are doing"}, {"timestamp": [1309.0, 1311.0], "text": " or e-girlfriends or whatever."}, {"timestamp": [1311.0, 1314.88], "text": " There are huge unmet intellectual, emotional,"}, {"timestamp": [1314.88, 1319.0], "text": " social and other needs out there in society."}, {"timestamp": [1319.0, 1322.72], "text": " And digital companions could help support us."}, {"timestamp": [1322.72, 1327.26], "text": " So let's explore the benefits. So one of the"}, {"timestamp": [1327.26, 1332.6], "text": " first benefits of digital companions is a lack of judgment. So there have already"}, {"timestamp": [1332.6, 1338.16], "text": " been some studies and plenty of anecdotes about how it is easier for"}, {"timestamp": [1338.16, 1342.72], "text": " people to open up to a machine because they know that the logs can be deleted,"}, {"timestamp": [1342.72, 1347.88], "text": " they know that there is no judgment. There's not a human mind in there"}, {"timestamp": [1347.88, 1349.54], "text": " that is gonna have an emotional reaction"}, {"timestamp": [1349.54, 1353.12], "text": " and make you feel shame or guilt or fear."}, {"timestamp": [1353.12, 1356.88], "text": " And so by having a machine that you know"}, {"timestamp": [1356.88, 1359.56], "text": " will not judge you under any circumstances,"}, {"timestamp": [1359.56, 1362.88], "text": " it is physically incapable of judging you."}, {"timestamp": [1362.88, 1364.22], "text": " That can remove fear,"}, {"timestamp": [1364.22, 1366.04], "text": " which can open a lot of other doors"}, {"timestamp": [1366.04, 1371.04], "text": " to self-exploration and healing or learning or whatever."}, {"timestamp": [1372.56, 1374.56], "text": " And because of this, these machines"}, {"timestamp": [1374.56, 1376.98], "text": " can actually feel safer than humans."}, {"timestamp": [1376.98, 1379.08], "text": " And you might say, oh, well, that's a bad thing"}, {"timestamp": [1379.08, 1381.24], "text": " because we should feel safe with other humans."}, {"timestamp": [1381.24, 1383.72], "text": " I agree, we should get to that point."}, {"timestamp": [1383.72, 1385.34], "text": " And these machines could help us get to that point. And these machines"}, {"timestamp": [1385.34, 1389.18], "text": " could help us get to that point. Just like the guy who cheated on his wife"}, {"timestamp": [1389.18, 1393.08], "text": " with a virtual girlfriend and that gave him the courage to go fix his real"}, {"timestamp": [1393.08, 1399.78], "text": " problem, his real relationship. And so just imagine you have a personal"}, {"timestamp": [1399.78, 1405.32], "text": " trainer or a lifestyle coach or a therapist or whatever that has that is physically"}, {"timestamp": [1405.32, 1411.48], "text": " incapable of shaming you or or judging you and you know this and you know it"}, {"timestamp": [1411.48, 1416.14], "text": " you know it doesn't try and be superhuman you know that it's machine"}, {"timestamp": [1416.14, 1421.52], "text": " and because of that you feel safer and you can open up more and explore more"}, {"timestamp": [1421.52, 1425.72], "text": " difficult problems learn difficult lessons, and move on. A"}, {"timestamp": [1425.72, 1431.6], "text": " final example here is imagine a teacher that is incapable of shaming a student."}, {"timestamp": [1431.6, 1436.32], "text": " Because shame is a big part of our education system and that needs to go"}, {"timestamp": [1436.32, 1442.6], "text": " away. Another benefit is infinite patience. This was actually explored way"}, {"timestamp": [1442.6, 1446.16], "text": " back in the day. Very briefly in Terminator 2."}, {"timestamp": [1446.16, 1452.04], "text": " There was a scene around the midpoint of Terminator 2 where Sarah Connor, the mom,"}, {"timestamp": [1452.04, 1458.48], "text": " you know, the warrior mom, she has a voiceover and she says something along the lines of the"}, {"timestamp": [1458.48, 1465.66], "text": " machine... she was watching Arnold Schwarzenegger as the Terminator play with her on-screen child and"}, {"timestamp": [1466.32, 1466.92], "text": " You know"}, {"timestamp": [1466.92, 1473.16], "text": " They were learning they were bonding and she said the the voiceover said the machine would never lose patience with John never be too tired"}, {"timestamp": [1473.16, 1478.08], "text": " Or drunk and would never hit him and she realized that the machine"}, {"timestamp": [1478.44, 1484.82], "text": " Had the capacity to be a better father than a real human, right? Because John had been through"}, {"timestamp": [1486.0, 1493.24], "text": " The ringer he'd been an orphan, etc, etc, in a foster home, not an orphan. And so if a"}, {"timestamp": [1493.24, 1497.52], "text": " machine is designed to be infinitely patient, this is something that we could"}, {"timestamp": [1497.52, 1502.36], "text": " all benefit from. And I want to take a different angle than maybe you're"}, {"timestamp": [1502.36, 1505.36], "text": " thinking, because, you know, everyone needs patients from time to time, right?"}, {"timestamp": [1505.4, 1508.58], "text": " You know, we want our doctors to be patient. We need our"}, {"timestamp": [1509.32, 1513.68], "text": " Therapists to be patient. We need our partners to be patient. We need our friends to be patient"}, {"timestamp": [1513.68, 1517.88], "text": " We need our teachers to be patient. Patience is a virtue. Patience is absolutely a virtue"}, {"timestamp": [1518.08, 1521.44], "text": " But we are humans and we have limits of our patience"}, {"timestamp": [1522.08, 1526.8], "text": " But some people children and, have special needs that"}, {"timestamp": [1526.8, 1532.32], "text": " require additional patience. So for instance, I was a gifted kid, which there"}, {"timestamp": [1532.32, 1536.16], "text": " is a rising trend that says if you are a gifted kid, you are a special needs kid."}, {"timestamp": [1536.16, 1540.92], "text": " And I really agree with that because I was far and away the most curious person"}, {"timestamp": [1540.92, 1550.24], "text": " in any room. I usually still am, and my information needs and emotional needs were very"}, {"timestamp": [1550.24, 1556.96], "text": " different from the people around me and I could have really used a robot that had infinite patience"}, {"timestamp": [1556.96, 1562.64], "text": " to teach me everything that I wanted to know. And another thing to keep in mind is ableism."}, {"timestamp": [1563.76, 1571.16], "text": " And another thing to keep in mind is ableism. You might be able to say, hey, like, no, you need to form real human connections."}, {"timestamp": [1571.16, 1575.9], "text": " But not everyone can form human connections as easily as you."}, {"timestamp": [1575.9, 1576.9], "text": " And some people don't."}, {"timestamp": [1576.9, 1578.08], "text": " Some people have it harder than you."}, {"timestamp": [1578.08, 1580.44], "text": " Some people have it easier than you."}, {"timestamp": [1580.44, 1587.02], "text": " But just keep in mind that the ability to form human connections is Itself a spectrum and not all of us"}, {"timestamp": [1587.82, 1591.28], "text": " Have an easy job of it. It's not easy being different"}, {"timestamp": [1591.94, 1596.22], "text": " And I don't need to talk about myself too much, but just keep in mind that"}, {"timestamp": [1597.06, 1599.02], "text": " That not everyone"}, {"timestamp": [1599.02, 1604.22], "text": " Operates the same way that you do and so having something that you know is infinitely patient"}, {"timestamp": [1606.4, 1613.6], "text": " you do and so having something that you know is infinitely patient could be a really huge benefit for people that do not have the same social capacities whether it's anxiety or ASD or"}, {"timestamp": [1614.16, 1620.4], "text": " who knows right whatever it is having patience is is a virtue and having machines that are designed"}, {"timestamp": [1620.4, 1625.08], "text": " to be patient could be very good for us."}, {"timestamp": [1625.08, 1628.48], "text": " The last benefit we'll go over, and there's plenty of other benefits, but these are the"}, {"timestamp": [1628.48, 1632.84], "text": " top benefits, is having a super intelligent ally."}, {"timestamp": [1632.84, 1636.88], "text": " Our lives are hard enough already, and I know that there are some people out there that"}, {"timestamp": [1636.88, 1640.56], "text": " say, ah, well, if we make life too easy, then we don't learn anything."}, {"timestamp": [1640.56, 1644.8], "text": " No matter how much technology we put into making our lives easier, there are still going"}, {"timestamp": [1644.8, 1646.8], "text": " to be hard moments, right?"}, {"timestamp": [1646.8, 1652.32], "text": " Relationships end, your dog will die, you'll be stressed out by family."}, {"timestamp": [1652.32, 1658.56], "text": " No matter how good AI and science get, life is hard enough already."}, {"timestamp": [1658.56, 1662.56], "text": " So what if we all had a super intelligent companion,"}, {"timestamp": [1662.56, 1665.76], "text": " a super intelligent ally, who super intelligent ally who wants nothing more"}, {"timestamp": [1665.76, 1671.04], "text": " than to see us happy and successful. And I wrote an entire book on this about why,"}, {"timestamp": [1671.04, 1676.12], "text": " like what goals we should give these machines and why. And a quick recap is"}, {"timestamp": [1676.12, 1679.48], "text": " those three goals are to reduce suffering, to increase prosperity, and to"}, {"timestamp": [1679.48, 1687.52], "text": " increase understanding. So if we have these companions that are super intelligent and are"}, {"timestamp": [1687.52, 1693.08], "text": " designed to want us to see us at our best, imagine how helpful that could be."}, {"timestamp": [1693.08, 1697.6], "text": " They can help with chores and errands, they can help you to"}, {"timestamp": [1697.6, 1701.76], "text": " have a better diet, to get the exercise that you need, to help with child care"}, {"timestamp": [1701.76, 1708.76], "text": " and child rearing, and I don't mean like to raise your children for you, but to teach you how to be a better parent. They can help"}, {"timestamp": [1708.76, 1713.32], "text": " you by coaching you with relationships and connections and can encourage you to"}, {"timestamp": [1713.32, 1719.24], "text": " make connections with real humans. And then finally, if you have this live-in"}, {"timestamp": [1719.24, 1726.32], "text": " assistant, it can really truly understand you and your family and your individual needs. So"}, {"timestamp": [1726.32, 1731.96], "text": " this is more of the utopian outcome, right? This is what we're"}, {"timestamp": [1731.96, 1736.84], "text": " looking for, what the benefits would be. So here's some conclusions that I came to."}, {"timestamp": [1736.84, 1742.8], "text": " On balance, I think that the pros drastically outweigh the cons. That being"}, {"timestamp": [1742.8, 1746.0], "text": " said, all technologies are a double-edged sword."}, {"timestamp": [1747.12, 1752.8], "text": " The more powerful a technology is, the more rife it is for abuse and exploitation. As we"}, {"timestamp": [1752.8, 1757.2], "text": " talked about earlier, the potential for exploitation and abuse here is very high."}, {"timestamp": [1757.92, 1766.96], "text": " At the same time, the potential upside is also very high. So we're going to have to be very careful with how we develop,"}, {"timestamp": [1766.96, 1773.84], "text": " test, and regulate these technologies. Because, you know, the picture that I painted is really"}, {"timestamp": [1773.84, 1779.84], "text": " great, but we need to make sure that we also don't harm people in the meantime, or allow"}, {"timestamp": [1780.8, 1785.24], "text": " companies to harm people. I think that this stuff is going to happen no matter"}, {"timestamp": [1785.24, 1791.48], "text": " what just because the willpower is there and the financial"}, {"timestamp": [1791.48, 1796.64], "text": " incentive is there for someone who can figure it out and the payoff is just too"}, {"timestamp": [1796.64, 1800.8], "text": " great so it's going to happen and as I mentioned I have written a couple books"}, {"timestamp": [1800.8, 1805.76], "text": " on these topics. One is benevolentent by Design, which is how do you create"}, {"timestamp": [1805.76, 1812.24], "text": " a machine that is benevolent, that is intrinsically benevolent. Another one is Natural Language"}, {"timestamp": [1812.24, 1817.28], "text": " Cognitive Architecture, which was my first book exploring how to create a digital mind with these"}, {"timestamp": [1817.28, 1827.48], "text": " large language models. And then more recently I wrote Symphony of Thought, which is a deeper dive into creating, I'm"}, {"timestamp": [1827.48, 1835.44], "text": " not going to say lifelike, cognitive architectures, but more dynamic, let's say, thinking machines."}, {"timestamp": [1835.44, 1840.36], "text": " And then finally I wrote a book called Post-Nihilism, which talks about how we all need to move"}, {"timestamp": [1840.36, 1847.0], "text": " away from an abandonment model to one of belonging."}, {"timestamp": [1847.0, 1853.0], "text": " Okay, so with all that being said, thanks for watching and keep your mind open and keep"}, {"timestamp": [1853.0, 1854.4], "text": " asking questions."}, {"timestamp": [1854.4, 1858.56], "text": " So thank you for watching and I'll see you next time."}]}