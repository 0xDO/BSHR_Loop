{"text": " The singularity has been cancelled. I'm sorry everybody, time to pack it up and go home. No, I'm actually kidding just a little bit, but there are a few things that I want to unpack about the singularity and some predictions that people are making, and just kind of how people engage with the idea of technological progress and exponential curves. So first we need to unpack what is the singularity. The singularity is a term that is thrown around a lot and a lot of people actually are not familiar with the real definition, they haven't read the book, but it's basically the hypothetical point in the future where technology advances faster and faster and it becomes uncontrollable and irreversible, but really the key thing that I want to draw your attention to is unforeseeable changes to human civilization. It doesn't mean that there's gonna be an event horizon beyond which all technology and all bets are off and technology can do anything that you can possibly imagine. Now, here's some of the points of evidence that lead up to this. First, exponential growth. So right now, we have things that seem to be growing exponentially or logarithmically, namely stuff like Moore's Law. Now, just because some things are measurably increasing exponentially, other things are not, or even if they are growing exponentially, it doesn't mean that it's useful. So what I mean by this is consider the fact that computers are literally millions of times more powerful than they were during the space race, but life is not millions of times more different. Likewise, the amount of data that we're generating is going up exponentially, but it's not really having that big of an impact on the way that we live or even civilization. So despite all of these things, I wanna like kind of temper your expectations about the future, and it is kind of disappointing. I would absolutely love for there to be a point in the future where we basically become, you know, godlike entities because we have mastered all of time, space, and energy, but that just might not be in the cards for us. So why canceled? What did it do wrong? Did it, did it make a bad tweet on Twitter or what? No, that's not what I mean. Uh, so first is low hanging fruit. We have been meticulously picking all of the technological and scientific low hanging fruit that we can. Uh, and we've been doing this at an increasing clip over the last century. Now, science has absolutely accelerated in the last, even just the last decade, but is this acceleration permanent? I don't think that it is and especially when I talk to my scientist friends, and I have quite a few scientist friends, they usually just kind of roll their eyes whenever I mention singularity. They're like, whatever, science is hard and it's getting harder fast. Some of my friends that they talk about like, yeah, like, there's more papers being published, but like each paper is smaller and smaller in terms of what it actually achieves. And so when you consider like, maybe there's some diminishing returns, maybe there's kind of a vicious cycle There's just not as much to like unpack about the universe anymore So speaking of that diminishing returns So I just mentioned papers, you know, the number of papers is going up exponentially the the number of like fundamental shifts in thinking is slowing down. And even if you look at the number of AI papers that are coming out, I mean there are entire papers that are dedicated to like one prompt strategy, which to me that's worthy of a tweet, not a scientific publication. And then of course, you know, like sure I've had arguments with people on LinkedIn and other places about, yeah, to anyone who's an experienced prompt engineer, a lot of the things that pass as papers, they're not worthy of that, but for some people, they only consume information from that particular source. And so scientific publications, particularly in the AI space is basically just becoming a Twitter for scientists and engineers. And it's like, that's kind of disappointing, but it also is just that's the pace of things. And that's the way things are being done. Another thing that I really want to point out is milestone gaps. So the amount of work that is required in order to get to the next milestone is increasing exponentially as well. So while we have some exponentially increasing technologies, we need those exponentially increasing technologies just in order to get to the next milestone. And so you know that I've got some concepts here like complexity ceiling. As you pick the low-hanging fruit, the fruit that is remaining to be picked is way higher and so you need increasingly more sophisticated technologies and scientific understandings and effort in order to get to that. So for instance, I don't have a chart for it, but the cost of drug discovery has gone up from the tens of thousands to hundreds of thousands to millions to literally billions of dollars for many new drug discoveries today. That is an exponential increase in cost just to discover new drugs. And yes, AI and other exponential technologies are making it a little bit easier, but that's just to keep pace with where we are. This is called Red Queen Theory in evolution, which is basically you have to run as fast as you can just to stay right where you are. And so because of these diminishing returns, I suspect that, put it this way, I don't see any reversing of this trend anytime soon. Now another thing is that there's probably just mathematical upper bounds to the laws of physics and artificial intelligence and technology. What I mean by that, and I've talked about this in recent videos, but there is a hypothetical maximum limit to the to the like efficiency of computers, it's called the Landauer limit, but we might not even be able to get remotely close to the Landauer limit. And then, you know, yes there is the hypothetical aspect of quantum supremacy. Quantum supremacy might be able to move the needle on some things, but it also might never really compete with classical computing. We don't really know. Just kind of like how analog circuits and digital circuits, they don't really, like you can compete, but it's almost kind of like comparing apples to oranges, they just do different things. There's also some growing evidence that there might be an intelligence ceiling to AI. Sam Altman of all people said the age of large models might already be over and it feels like it just got started. I've talked about this quite extensively in other videos. I call it terminal race condition where basically there's a trade-off between model size and intelligence versus speed and efficiency. And more often than not, you don't need a gigantic model, you need a smaller model that is fine-tuned for a particular purpose in order to achieve whatever goals you need. And so, even if you can hypothetically make an AI more intelligent, it just might not be practical, it might not be even necessary or useful. And then finally, there's useful knowledge, which I've got a chart coming up on that, but there is a finite amount of knowable stuff, at least useful stuff. The amount of data in the universe is hypothetically infinite, but the amount of useful and valuable data is not infinite. Now finally what I want to talk about is, at least in this section of the video, is sigmoid curves. Many, many, many things in nature follow sigmoid curves. Neuron activation, population growth, learning curves, scientific progress, and in all likelihood, AI development will eventually be following a sigmoid curve. Now, in the early phases of a sigmoid curve, it looks exponential, and if you extrapolate that curve based on early results, it looks like it'll go that way forever. However, eventually a sigmoid curve reverses. So, this is the heart of this video. So I wanna talk about, this is a sigmoid curve, this is like basically an activation function for a neural network or a neuron or population growth or whatever. So many things in nature follow sigmoid curves. The question is where are we on this sigmoid curve? We might be right in the middle. We might also be near the end of the curve. Particularly when you look at, um, at the basic sciences, uh, and I'm not saying like, oh, we're super close to like discovering everything. What I'm saying is that in order to get to that maximum part where we have that plateau of where we've mastered all of basic sciences, it's going to get exponentially more difficult and expensive to get there. And we're already seeing this in many sciences. But, you know, it might feel like we're still at the in many sciences but you know it might feel like we're still at the beginning of the curve but the the problem with sigmoid curves is that if you're in the middle third you kind of don't know how far along you are because the the slope of the curve is not very different from one point to the next and so we're not really sure like how far along we are. And it might be impossible to predict how far, like cause if we are in the bottom third still, like if we're, if we're down here then it's like, okay, well Dave, like you're completely wrong. And even just when we get to the midpoint, that'll feel like the singularity, let alone when we get near the end. But personally, when you look at the rate of change in terms of the way that society has changed, society has already slowed down drastically. Like I mentioned at the beginning of the video, we have space flight, we have infinitely more powerful computers than we used to, we have AlphaFold2, we've got DeepMind, we've got all these things, and we've got just this exponentially increasing amount of technology and science and understanding. But society hasn't really changed in 10 years, or 20 years, or 30 years. You watch videos of what happened in the 90s, and it's like we more or less live the same way. And so I'm not convinced that the singularity, even the formal definition of the singularity, where human civilization becomes unrecognizable, I'm not even convinced that's going to happen. Now with that being said, there are these, what I call these apoca thresholds, where basically like, okay, yes, for many hundreds of thousands of years, humans basically lived as hunter gatherers. And then, you know, we started to take off and we got, you know, the the Iron Age and the Bronze Age, which, you know, global phenomenon. And then we got to, you know, the age of steel and steam. And then we got to the Industrial Revolution. And so, like, yes, humanity has gone through many epochal changes, has crossed many of these thresholds. We might be in the midst of the last threshold. We might be, there might be one or two more thresholds. We don't know. But I'm not really convinced that it's gonna be like that drastically different. Because even when in like 1900, someone said it, you know, humans have already invented 90% of everything that is inventable. We still live relatively similar to how we did at the turn of the century. We go to jobs, you know, we have factories, we have machines, you know, we have a few niftier like machines, like we've got iPhones now, but that hasn't really fundamentally changed how we live. Okay, so this is a graphic that I've had in my head for a while and basically, you know, like all data in the universe is superset. So like if you if you think about the universe as an information model, there is technically an infinite amount of possible information and data in the universe. However, a much smaller subset of that is all useful knowledge. So there's raw data, there's information, and then there's knowledge, and then there's wisdom, if you want to think about it like that. The amount of information that is actually classifiable as useful knowledge is far smaller than the amount of actual data in the universe. And then of course, all human knowledge is a subset of useful knowledge. But eventually we will get to the point where we have captured all useful knowledge. Yes, like I said, there's an infinite amount of information and data in the universe, but a lot of that is just noise. And so the signal-to-noise ratio is another thing that I think is following a sigmoid curve, and it's kind of already tapering off. You know, it's like, it's not like, you know, sure we understand subatomic particles and gravitons and, and Higgs bosons and, you know, there's all kinds of tiny fundamental things. Um, and maybe I'm wrong, you know, we still haven't fully untangled dark matter and dark energy. And so maybe there are entire domains of science that are just like out there in the ether that are completely unknown, but at the same time I kind of get the sense that even if it is out there, it's part of that, it's exponent, the milestones are exponentially getting further and further apart, so I don't really see us conquering all that necessarily like in the foreseeable future, and even if we do is it going to change human society? Okay, so I've rained on everyone's parade. What are the implications? So the first and biggest question is where is the plateau? If indeed scientific and technological progress is following a sigmoid curve, which I believe there is plenty of evidence that it is, where is the plateau? Where is it going to taper off and where are we going to end up? So again, like I said, finite amount of knowledge, useful knowledge in the universe. There's also this kind of diminishing returns or vicious cycle where yes, every time we make progress, it's great, but also the complexity goes up in lockstep with that. And so it's like, okay, that's what I mean by like every threshold gets further and further apart. Now, this is one thing that I really take issue with, is the idea that there is some kind of predictability horizon or event horizon beyond which all bets are off, and everything changes, and suddenly, you know, life becomes fundamentally unrecognizable, and human civilization changes forever, and we all live as goldfish in, you know, spice tanks or whatever. I don't know. But I don't really see any evidence of that. And like I said, I'm like one of the kinds of people that like I would love to have warp drive. I would love to have like all kinds of stuff that just might not be possible. I remember I had a conversation with a friend of mine many years ago, good scientist, and I was talking to him and I'm like, when are we gonna get faster than light travel? And he was like, it might just not be possible. And I'll address that close to the end of the video. But it was like that really stuck with me. He's like, you know, we need to accept the possibility that there are just things that, yes, we can imagine them as happening, but they're just not going to happen. Jump gates might not be possible. You know, warp drive might not be possible, you know, warp drive might not be possible, hyperdrive, whatever you want to call it. These things, like we can imagine them, sure, but they might forever be within the realm of fantasy. Alright, so I already mentioned apocalypse thresholds. Typically we record apocalypse thresholds as industrial revolutions. The Renaissance was another big one, you know, the Stone Age transition to the Bronze Age and the Iron Age. Those could be viewed as epochal thresholds. The invention of sail in order to circumnavigate the world. These kinds of things. The biggest question to me is, are we in the last one? Is the Fourth Industrial Revolution the last epochal threshold? Obviously, I'm not going to be so short-sighted as to say, we have invented everything that is possible to be invented. I remember when I read that quotation, probably I was like 10 or 11 when I read that, and I'm like, wow, that dude was an idiot. So, I'm not going to fall into that trap and say, we've invented everything that it is possible to invent. No. What I am saying, though, is that even with accelerating technology and science, the way that we live is not changing at an accelerated rate. If anything, the way that we live is changing at a slower rate. So yes, can things get better? Absolutely. Can things still change? Yes, absolutely. Can we become a multi-planetary species? I don't see why not, but I'm not saying that it's going to be easy. And I think that this is one of the fantasies that people have, is that with more and more technological breakthroughs, things are just going to get exponentially easier. I do think that some things will get easier. Obviously, we would rather live today with our technology that we have today than we would like to live 200 years ago. Because why? There's a lot of things that are way easier today, but that doesn't mean that life is overall very easy so and again the event horizon is basically like I Whenever people talk about singularity and whenever I think about singularity It's like I don't really see this happening if you want to talk about a point of no return I think we crossed that a long time ago and we crossed that and it was inevitable, not by virtue of the technology or the science, but just because the planet is so huge and there's billions of us. And you can no more stop research happening in China or Russia or Africa or America or Europe than you can like stop the earth from spinning. Why? Because it's impossible to coordinate 8 billion humans. Like, granted, we didn't have 8 billion humans in 1950. had like 3 billion but the point is is that there is an inexorable process of Human progress and learning and everything that you just can't stop it So if you want to talk about a point of no return we cross that a long time ago. It's slow It's been a slow build-up but the the aspect of this you know technological event horizon and singularity that I really want to push back on is The magical thinking that seems to emerge where some people say they just there's this inflation Where the that's like, okay. Well someone predicted that, you know human society Civilization might become unrecognizable First I don't see any evidence of that and second And second, that is often inflated or conflated with we'll shatter all the laws of physics and anything you can imagine will be possible. Again, I'm not seeing any evidence of that. And in fact, I'm seeing evidence to the contrary, that even though we have exponentially better understanding of the fundamental laws of physics, things are changing slower and slower. And also the reason that I want to push back on this is it can be a very harmful narrative. Like it's it can be as bad as like, you know, narratives of destruction or utopian narratives or anything where it's like if you imagine that the future will be unimaginably better and happier and safer and everything and then you ignore the problems today and you stop putting in the effort today, well I mean that could have negative consequences as well. It could result in like learned helplessness or a sense of futility or fatality or just delaying your life. Like there's a lot to enjoy today. Okay so those are some of the implications. Here are some of my specific predictions about what will happen within the foreseeable future in terms of how it will change how we live. So first, indefinite lifespan. This is one that I think that there's plenty of evidence that we are working up to this very quickly. I don't know why, but talking about indefinite lifespan seems to trigger some people on the internet. Not most, but there's a few. I always get a couple comments where people are like, oh, well, people have been predicting the fountain of youth for centuries, and you're not gonna find it, and nobody's gonna find it. And it's like, I don't know, those people seem to have a death wish. And they're like, stop telling me that I'm gonna live forever. That makes me angry. I don't understand that reaction. But so there's plenty of evidence that we are getting close to this. And I remember there was a comment that I got a few weeks ago that someone's like, yeah, but what about these plaques and proteins and enzymes that accumulate? I'm like, the fact that you know what causes aging means that that's half the battle. There was this famous quotation. Who was it? Was it Ray Kurzweil? I think it was Ray Kurzweil. know like what causes aging means that like that's half the battle. Right. There was this famous quotation. Who was it? Was it Ray Kurzweil? I think it was Ray Kurzweil during the human genome project. Someone consulted with him and it's like, oh, well, we've only decoded 1% of the genome and he's like, okay, well, we're halfway done. That is the nature of exponential progress. And that is one place that I agree with him because as an automation engineer, if you can automate 1% of the job job you can automate a hundred percent of the job. Why? Because it's just a matter of like one more step to get something that will finish the process for you. And I've had chats with other people in automation and they agree it's like with automation and that kind of thing it's like it feels like you achieve nothing until the very end, then you hit go, and then it's done. But yeah, so the combination of precedents that we see in nature, the rapid pace of understanding genetics, nanotechnology, like man, some of the stuff that I've seen just in the last few weeks about nanotech being able to like have programmatic, like programmable nanoparticles that will deliver drugs to specific tissues. Honestly, I don't see any reason, any physical reason that we could not, within a reasonable time frame, relatively soon, overcome all of the causes of aging and death, at least all the known ones. Obviously, it's entirely possible that the longer you live, the more likelihood there will be, you know, for accidents or unpredictable diseases. For instance, you know, a hundred years ago, there was probably a lot less understanding of things like Alzheimer's and stuff just because people didn't live long enough to have those diseases. But I do suspect that indefinite lifespan is coming relatively soon. And this might very well be the biggest single impact to the way that we live. It's going to change the way that we relate to ourselves, to each other, to politics, to economics, to power. It's going to change the way that we do family planning. It's going to change the way that we engage with life and fun and leisure and all that kind of stuff. So this, I think, is going to be the biggest, like most fundamental shift in society. Cybernetic integration. I did do a recent video about Neuralink. I think that Neuralink as it is is very immature and I don't mean like childish I just mean it's it's an immature technology. That being said, there is a lot of other research being done with implantbernetic implants of all different kinds, not just brain-computer interfaces. There are rejuvenation things such as bioengineered semi-living implants that can cure type 1 diabetes. I just saw that the other day. That's really cool. There's also the possibility of another implant that I was watching a video about that it can regrow your liver. So it's like, okay, cool. So we have lots and lots of implants and cybernetic integration coming down the pipeline. So most of these are focused on disease and injury. So like, there's some electrical implants that looks like they can cause your spine to regrow if you've broken your broken your spine and you've been paralyzed that's really cool but there's a really big difference between repairing damage and and enhancements with new capabilities and there's also possibly or likely limitations to the level of integration now in fictional places like cyberpunk, there's this disease called cyberpsychosis, where basically if you have too many implants, you start to go crazy. In Ghost in the Shell, there is a cyberbrain sclerosis, which is basically like your immune system, and inflammation responses to implants basically cause your brain to harden and you lose your ability to think. Really horrible possible diseases that could emerge like we could create new diseases with cybernetics so we need to be careful with that. Now that being said, maybe in the long run there's no reason we can't overcome these things especially if you have forever to figure it all out. Okay great. Robotic workforce. I am a huge proponent of what I call post-labor economics, and I just think that it makes sense to get humans out of the workforce as much as possible. And I think it's inevitable. I think it makes economic sense to replace human labor. I think that there is no reason that we need jobs. So this is another thing that seems to trigger some people. I've talked about the existence of leisure classes so Greek aristocracy back in the day Roman aristocracy back in the day British aristocracy up through today Like there are literally entire civilizations that had classes of people who were not allowed to work So like and they were fine like you don't need work to have a meaningful fulfilling life And they were fine like you don't need work to have a meaningful fulfilling life Spartan Spartan men citizens like they were literally not allowed to have a job you were not allowed to have a profession If you were a member of a certain crust of society and in fact you can even see this go watch Downton Abbey When what's-his-name joins, and he's like a lawyer. It's like oh well. That's kindbrow. Like, why are you still working for money? You're one of us now. Like this still exists today. So I don't know why talking about a leisure class, like triggers some people, but it does. But I want to point out the fact that like there have been millions and millions of people throughout all of history that did not have a profession. And in some cases were legally prohibited from having a profession and they were perfectly happy. They had really cool parties. But yeah, and so the primary the primary KPI that I look for as evidence for replacing human labor is better, faster, cheaper, and safer. Those are the like four criteria that pay attention to that in terms of artificial intelligence and AI and I still get like comments saying, someone like oh well, I'd love to see a robot take my job doing tiling it's like you should check on some of the latest things that robots are capable of doing. Robots are taking really cool form factors they're getting much more dexterous very quickly and then you look at the the work that I'm doing on the ACE framework that Google's doing on RTX and like these these robots are going to be able to do pretty much anything very soon. I'm predicting probably this time next year We're going to start to see Commercial robots that are able to do pretty much any blue-collar work Like mark my words. I'll probably do like a prediction poll for that Okay, so then probably the most extreme thing is going to be transgenic technology. We can already do a lot of this. It's still a very naive technology or an immature technology, but the fact that we can even replace organelles in cells and then inject that into the germline, and what I mean by that is like there are certain diseases that are based on defective mitochondria, and so what you can do is you can take a healthy mitochondria from another cell and replace your mitochondria with it. And then because mitochondria have their own DNA, it reproduces when your cells go through mitosis. And so it's like, hey, you've now created a cell that is a Franken cell based on input from multiple organisms. So between genome editing and epigenomic editing and organelle replacement, we literally have actual control over the fundamental levers of biology. Now, again, like most technologies and sciences, we are going to find maybe some diminishing returns, some increase in complexity, some increasing complexity, but there is no physical barrier to, like, modifying our genes. Now, are we going to all be cat people one day? Some people might. You know, if that's what they want, great. It's not what I want. I probably will remain, like, kind of in this form factor more or less for the foreseeable future now granted You know you live for 10,000 years you might get bored and you want to be a cat person for a while I don't know but there's also like It's difficult to talk about this stuff without saying like wow, but that is intrinsically wrong because we should just be humans forever but like I don't know that's It's weird also because this because this is super polarizing. Where some people are like, well yeah, obviously, like if we have control over that, and we want to change ourselves, we should be allowed to do so. And then there are other people that just really cringe at that, and they're like, no, that like is an affront to, you know, God or whatever, like, if you change yourself, then that's evil or whatever. I don't know. I remember like, so here's the story that I'm thinking of I remember my stepbrother wanted to have jaw surgery to cure his overbite and his religious family like like like got really bent out of shape because it's like well God gave you that jaw and now you're your desire to go through cosmetic surgery is an affront to God. And it's like, okay, well, I mean, that's them. But you know, people have an impulse to control each other. Anyways, I'm getting lost in a rabbit hole. Okay, so I did promise that I would address this. So this is, we're winding down the video. What about aliens? So there have been some recent disclosures and it's really difficult to think about, like, okay, if any of the testimony that has been given to Congress, which for some background, uh, was his name, David Grush and a few others have testified that like, yes, we have recovered non-human biological entities. We have recovered extraterrestrial craft. We have documented evidence of these crafts that are able to do things that we cannot physically explain. Um, mostly pertaining to acceleration, uh, and deceleration. Documented evidence of these crafts that are able to do things that we cannot physically explain mostly pertaining to acceleration And deceleration so it's like okay. Well, how do they accelerate and decelerate that fast? so what is what is the scientific implication of this and One thing I want to say is like, okay. Yes, some of these things seem to be magical But just because you have a craft that defies the laws of physics as we know it doesn't mean that it is magic or that it that also doesn't immediately translate to well because that's possible everything else is possible. And so I want to leave you with a quote, any sufficiently advanced technology is indistinguishable from magic. This was Arthur C. Clarke, he called it his third law or whatever I guess. But here's an example that I want to leave you with. Think of your cell phone, your smart phone. If you were to tell someone or show someone in the 1500s what a cell phone was and what it could do and the fact that you could literally call someone instantaneously on the other side of the planet, you would have been burned at the stake as a witch. Because that technological capacity was just not within the realm of consciousness until this last century. Now obviously the telegraph is over a century old and people started realizing that you could communicate vast different distances instantaneously So maybe a century ago you wouldn't have been burned at the stake, but certainly five centuries ago if you would have said Oh, yeah, here's a magical device It has no physical connections to anything else and I can talk to someone on the other side of the planet You could even talk to people in space if you wanted to They would have literally burned you at the stake because that is some devilry witchcraft stuff. Now, to a mind 500 years ago, your iPhone would have appeared to be pure magic, but today we understand that it has very mundane explanations of electrical circuits and radio signals, and once you have radio signals and integrated circuits, the rest is pretty much a given. But if you like, there was a few comments on recent videos, like just imagine trying to explain language models to someone 20 years ago. And they would have been like, what? I don't get it. So, but today it has a very mundane explanation. And so one thing that I want to just kind of really push back on is, is just because you can imagine something and just because something seems magical to you today that doesn't mean that it is all that different or all that exotic and it it really comes down to perception and so yes like well dave like you're saying like okay so let me just unpack this you know there are things that we can't imagine being possible today that might be possible tomorrow. And so like, let's reverse that. Like, okay, so what is what is the iPhone 500 years from now that we can't possibly imagine today? Yes, that kind of technological leap is possible, but it's not necessarily going to be physics shattering, especially as we learn more and more about science and physics and technology and we get those diminishing returns. And I suspect that we're going to have a different orientation towards science and technology eventually. And so this is something that kind of I've been thinking about is what happens when we get to a steady state world where it's just kind of a foregone conclusion that like, yeah, we do know 95% of all science out there, and the last 5% is going to be really difficult and expensive to get, but like, the frontiers of scientific discovery might eventually be known. Kind of like the age of discovery when we were sailing around the planet Earth, eventually all of planet Earth was known. Now granted, there's, you know, infinite more planets out there to discover. So I don't know. Let me know what you think in the comments. Like, subscribe, etc, etc. Thanks for watching. I hope this gave you some food for thought. Cheers.", "chunks": [{"timestamp": [0.0, 6.56], "text": " The singularity has been cancelled. I'm sorry everybody, time to pack it up and go home."}, {"timestamp": [7.2, 11.36], "text": " No, I'm actually kidding just a little bit, but there are a few things that I want to unpack"}, {"timestamp": [11.36, 16.16], "text": " about the singularity and some predictions that people are making, and just kind of how people"}, {"timestamp": [16.16, 22.72], "text": " engage with the idea of technological progress and exponential curves. So first we need to unpack"}, {"timestamp": [22.72, 25.14], "text": " what is the singularity. The singularity is a"}, {"timestamp": [25.14, 28.82], "text": " term that is thrown around a lot and a lot of people actually are not familiar"}, {"timestamp": [28.82, 35.0], "text": " with the real definition, they haven't read the book, but it's basically the"}, {"timestamp": [35.0, 40.3], "text": " hypothetical point in the future where technology advances faster and faster"}, {"timestamp": [40.3, 44.36], "text": " and it becomes uncontrollable and irreversible, but really the key thing"}, {"timestamp": [44.36, 45.6], "text": " that I want to draw your attention"}, {"timestamp": [45.6, 49.36], "text": " to is unforeseeable changes to human civilization."}, {"timestamp": [49.36, 51.66], "text": " It doesn't mean that there's gonna be an event horizon"}, {"timestamp": [51.66, 55.0], "text": " beyond which all technology and all bets are off"}, {"timestamp": [55.0, 58.32], "text": " and technology can do anything that you can possibly imagine."}, {"timestamp": [58.32, 60.4], "text": " Now, here's some of the points of evidence"}, {"timestamp": [60.4, 61.24], "text": " that lead up to this."}, {"timestamp": [61.24, 63.38], "text": " First, exponential growth."}, {"timestamp": [63.38, 67.56], "text": " So right now, we have things that seem to be growing"}, {"timestamp": [67.56, 69.68], "text": " exponentially or logarithmically,"}, {"timestamp": [69.68, 71.88], "text": " namely stuff like Moore's Law."}, {"timestamp": [71.88, 76.88], "text": " Now, just because some things are measurably"}, {"timestamp": [77.56, 79.84], "text": " increasing exponentially, other things are not,"}, {"timestamp": [79.84, 81.56], "text": " or even if they are growing exponentially,"}, {"timestamp": [81.56, 83.2], "text": " it doesn't mean that it's useful."}, {"timestamp": [83.2, 85.4], "text": " So what I mean by this is consider the fact"}, {"timestamp": [85.4, 87.76], "text": " that computers are literally millions of times"}, {"timestamp": [87.76, 90.6], "text": " more powerful than they were during the space race,"}, {"timestamp": [90.6, 93.72], "text": " but life is not millions of times more different."}, {"timestamp": [93.72, 96.0], "text": " Likewise, the amount of data that we're generating"}, {"timestamp": [96.0, 98.0], "text": " is going up exponentially,"}, {"timestamp": [98.0, 100.6], "text": " but it's not really having that big of an impact"}, {"timestamp": [100.6, 103.96], "text": " on the way that we live or even civilization."}, {"timestamp": [103.96, 106.82], "text": " So despite all of these things,"}, {"timestamp": [106.82, 110.32], "text": " I wanna like kind of temper your expectations"}, {"timestamp": [110.32, 113.36], "text": " about the future, and it is kind of disappointing."}, {"timestamp": [113.36, 116.82], "text": " I would absolutely love for there to be a point"}, {"timestamp": [116.82, 119.44], "text": " in the future where we basically become, you know,"}, {"timestamp": [119.44, 121.54], "text": " godlike entities because we have mastered"}, {"timestamp": [121.54, 123.7], "text": " all of time, space, and energy,"}, {"timestamp": [123.7, 127.64], "text": " but that just might not be in the cards for us. So why canceled?"}, {"timestamp": [128.02, 132.56], "text": " What did it do wrong? Did it, did it make a bad tweet on Twitter or what? No,"}, {"timestamp": [132.56, 136.92], "text": " that's not what I mean. Uh, so first is low hanging fruit."}, {"timestamp": [137.44, 141.4], "text": " We have been meticulously picking all of the technological and scientific low"}, {"timestamp": [141.4, 143.68], "text": " hanging fruit that we can. Uh,"}, {"timestamp": [143.7, 148.9], "text": " and we've been doing this at an increasing clip over the last century. Now,"}, {"timestamp": [149.7, 154.12], "text": " science has absolutely accelerated in the last, even just the last decade,"}, {"timestamp": [154.6, 157.28], "text": " but is this acceleration permanent?"}, {"timestamp": [157.28, 162.88], "text": " I don't think that it is and especially when I talk to my scientist friends, and I have quite a few scientist friends,"}, {"timestamp": [162.88, 167.2], "text": " they usually just kind of roll their eyes whenever I mention singularity. They're like, whatever, science is"}, {"timestamp": [167.2, 172.4], "text": " hard and it's getting harder fast. Some of my friends that they talk about like, yeah, like,"}, {"timestamp": [172.4, 179.04], "text": " there's more papers being published, but like each paper is smaller and smaller in terms of what it"}, {"timestamp": [179.04, 187.4], "text": " actually achieves. And so when you consider like, maybe there's some diminishing returns, maybe there's kind of a vicious cycle"}, {"timestamp": [187.84, 193.48], "text": " There's just not as much to like unpack about the universe anymore"}, {"timestamp": [194.4, 196.4], "text": " So speaking of that diminishing returns"}, {"timestamp": [197.36, 205.76], "text": " So I just mentioned papers, you know, the number of papers is going up exponentially the the number of like fundamental shifts in thinking is"}, {"timestamp": [205.76, 210.96], "text": " slowing down. And even if you look at the number of AI papers that are coming out,"}, {"timestamp": [211.52, 215.44], "text": " I mean there are entire papers that are dedicated to like one prompt strategy,"}, {"timestamp": [216.08, 220.96], "text": " which to me that's worthy of a tweet, not a scientific publication. And then of course,"}, {"timestamp": [220.96, 226.18], "text": " you know, like sure I've had arguments with people on LinkedIn and other places about, yeah,"}, {"timestamp": [226.18, 228.36], "text": " to anyone who's an experienced prompt engineer,"}, {"timestamp": [228.36, 231.44], "text": " a lot of the things that pass as papers,"}, {"timestamp": [231.44, 234.04], "text": " they're not worthy of that, but for some people,"}, {"timestamp": [234.04, 237.52], "text": " they only consume information from that particular source."}, {"timestamp": [237.52, 241.08], "text": " And so scientific publications, particularly in the AI space"}, {"timestamp": [241.08, 242.5], "text": " is basically just becoming a Twitter"}, {"timestamp": [242.5, 244.36], "text": " for scientists and engineers."}, {"timestamp": [244.36, 249.36], "text": " And it's like, that's kind of disappointing, but it also is just that's the pace of things."}, {"timestamp": [249.36, 250.96], "text": " And that's the way things are being done."}, {"timestamp": [250.96, 254.96], "text": " Another thing that I really want to point out is milestone gaps."}, {"timestamp": [254.96, 261.36], "text": " So the amount of work that is required in order to get to the next milestone is increasing"}, {"timestamp": [261.36, 262.8], "text": " exponentially as well."}, {"timestamp": [262.8, 270.28], "text": " So while we have some exponentially increasing technologies, we need those exponentially increasing technologies"}, {"timestamp": [270.28, 275.4], "text": " just in order to get to the next milestone. And so you know that I've got"}, {"timestamp": [275.4, 279.84], "text": " some concepts here like complexity ceiling. As you pick the low-hanging"}, {"timestamp": [279.84, 284.56], "text": " fruit, the fruit that is remaining to be picked is way higher and so you need"}, {"timestamp": [284.56, 288.2], "text": " increasingly more sophisticated technologies and scientific"}, {"timestamp": [288.2, 292.26], "text": " understandings and effort in order to get to that. So for instance, I don't have"}, {"timestamp": [292.26, 297.22], "text": " a chart for it, but the cost of drug discovery has gone up from the tens of"}, {"timestamp": [297.22, 300.72], "text": " thousands to hundreds of thousands to millions to literally billions of"}, {"timestamp": [300.72, 305.46], "text": " dollars for many new drug discoveries today. That is an exponential"}, {"timestamp": [305.46, 311.04], "text": " increase in cost just to discover new drugs. And yes, AI and other exponential"}, {"timestamp": [311.04, 315.48], "text": " technologies are making it a little bit easier, but that's just to keep pace with"}, {"timestamp": [315.48, 318.96], "text": " where we are. This is called Red Queen Theory in evolution, which is basically"}, {"timestamp": [318.96, 323.32], "text": " you have to run as fast as you can just to stay right where you are. And so"}, {"timestamp": [323.32, 330.94], "text": " because of these diminishing returns, I suspect that, put it this way, I don't see any reversing of"}, {"timestamp": [330.94, 335.6], "text": " this trend anytime soon. Now another thing is that there's probably just"}, {"timestamp": [335.6, 340.44], "text": " mathematical upper bounds to the laws of physics and artificial intelligence and"}, {"timestamp": [340.44, 344.12], "text": " technology. What I mean by that, and I've talked about this in recent videos, but"}, {"timestamp": [344.12, 348.72], "text": " there is a hypothetical maximum limit to the to the like efficiency of"}, {"timestamp": [348.72, 352.72], "text": " computers, it's called the Landauer limit, but we might not even be able to get"}, {"timestamp": [352.72, 356.52], "text": " remotely close to the Landauer limit. And then, you know, yes there is the"}, {"timestamp": [356.52, 362.62], "text": " hypothetical aspect of quantum supremacy. Quantum supremacy might be able to move"}, {"timestamp": [362.62, 365.72], "text": " the needle on some things, but it also might never"}, {"timestamp": [365.72, 367.8], "text": " really compete with classical computing."}, {"timestamp": [367.8, 369.52], "text": " We don't really know."}, {"timestamp": [369.52, 373.2], "text": " Just kind of like how analog circuits and digital circuits, they don't really, like"}, {"timestamp": [373.2, 377.32], "text": " you can compete, but it's almost kind of like comparing apples to oranges, they just do"}, {"timestamp": [377.32, 379.28], "text": " different things."}, {"timestamp": [379.28, 384.4], "text": " There's also some growing evidence that there might be an intelligence ceiling to AI."}, {"timestamp": [384.4, 388.0], "text": " Sam Altman of all people said the age of large models"}, {"timestamp": [388.0, 392.0], "text": " might already be over and it feels like it just got started."}, {"timestamp": [392.0, 396.0], "text": " I've talked about this quite extensively in other videos. I call it terminal race"}, {"timestamp": [396.0, 400.0], "text": " condition where basically there's a trade-off between model size and intelligence"}, {"timestamp": [400.0, 404.0], "text": " versus speed and efficiency. And more"}, {"timestamp": [404.0, 407.52], "text": " often than not, you don't need a gigantic model,"}, {"timestamp": [407.52, 410.18], "text": " you need a smaller model that is fine-tuned"}, {"timestamp": [410.18, 413.02], "text": " for a particular purpose in order to achieve"}, {"timestamp": [413.02, 414.3], "text": " whatever goals you need."}, {"timestamp": [414.3, 418.7], "text": " And so, even if you can hypothetically make an AI"}, {"timestamp": [418.7, 421.74], "text": " more intelligent, it just might not be practical,"}, {"timestamp": [421.74, 424.1], "text": " it might not be even necessary or useful."}, {"timestamp": [425.12, 429.36], "text": " And then finally, there's useful knowledge, which I've got a chart coming up on that,"}, {"timestamp": [429.36, 435.76], "text": " but there is a finite amount of knowable stuff, at least useful stuff. The amount of data in"}, {"timestamp": [435.76, 442.16], "text": " the universe is hypothetically infinite, but the amount of useful and valuable data is not infinite."}, {"timestamp": [443.76, 446.2], "text": " Now finally what I want to talk about is,"}, {"timestamp": [446.2, 449.4], "text": " at least in this section of the video, is sigmoid curves."}, {"timestamp": [449.4, 452.8], "text": " Many, many, many things in nature follow sigmoid curves."}, {"timestamp": [452.8, 457.6], "text": " Neuron activation, population growth, learning curves, scientific progress,"}, {"timestamp": [457.6, 462.4], "text": " and in all likelihood, AI development will eventually be following a sigmoid curve."}, {"timestamp": [462.4, 465.32], "text": " Now, in the early phases of a sigmoid curve,"}, {"timestamp": [465.32, 466.48], "text": " it looks exponential,"}, {"timestamp": [466.48, 469.72], "text": " and if you extrapolate that curve based on early results,"}, {"timestamp": [469.72, 471.68], "text": " it looks like it'll go that way forever."}, {"timestamp": [471.68, 475.16], "text": " However, eventually a sigmoid curve reverses."}, {"timestamp": [475.16, 478.06], "text": " So, this is the heart of this video."}, {"timestamp": [478.06, 480.66], "text": " So I wanna talk about, this is a sigmoid curve,"}, {"timestamp": [480.66, 483.12], "text": " this is like basically an activation function"}, {"timestamp": [483.12, 488.2], "text": " for a neural network or a neuron or population growth or whatever."}, {"timestamp": [488.92, 491.28], "text": " So many things in nature follow sigmoid curves."}, {"timestamp": [491.6, 495.36], "text": " The question is where are we on this sigmoid curve?"}, {"timestamp": [495.68, 499.52], "text": " We might be right in the middle. We might also be near the end of the curve."}, {"timestamp": [500.12, 504.48], "text": " Particularly when you look at, um, at the basic sciences, uh,"}, {"timestamp": [504.52, 506.48], "text": " and I'm not saying like, oh, we're super close to"}, {"timestamp": [506.48, 511.92], "text": " like discovering everything. What I'm saying is that in order to get to that maximum part"}, {"timestamp": [512.48, 517.28], "text": " where we have that plateau of where we've mastered all of basic sciences, it's going to get"}, {"timestamp": [517.28, 522.4], "text": " exponentially more difficult and expensive to get there. And we're already seeing this in many"}, {"timestamp": [522.4, 525.8], "text": " sciences. But, you know, it might feel like we're still at the in many sciences but you know it might feel"}, {"timestamp": [525.8, 529.48], "text": " like we're still at the beginning of the curve but the the problem with sigmoid"}, {"timestamp": [529.48, 534.04], "text": " curves is that if you're in the middle third you kind of don't know how far"}, {"timestamp": [534.04, 539.92], "text": " along you are because the the slope of the curve is not very different from one"}, {"timestamp": [539.92, 546.0], "text": " point to the next and so we're not really sure like how far along we are."}, {"timestamp": [546.2, 548.36], "text": " And it might be impossible to predict how far,"}, {"timestamp": [548.36, 552.2], "text": " like cause if we are in the bottom third still, like if we're,"}, {"timestamp": [552.24, 555.0], "text": " if we're down here then it's like, okay, well Dave,"}, {"timestamp": [555.0, 558.24], "text": " like you're completely wrong. And even just when we get to the midpoint,"}, {"timestamp": [558.24, 561.04], "text": " that'll feel like the singularity, let alone when we get near the end."}, {"timestamp": [561.56, 565.48], "text": " But personally, when you look at the rate of change"}, {"timestamp": [565.48, 568.86], "text": " in terms of the way that society has changed,"}, {"timestamp": [568.86, 571.98], "text": " society has already slowed down drastically."}, {"timestamp": [571.98, 574.04], "text": " Like I mentioned at the beginning of the video,"}, {"timestamp": [574.04, 575.46], "text": " we have space flight,"}, {"timestamp": [575.46, 579.9], "text": " we have infinitely more powerful computers than we used to,"}, {"timestamp": [579.9, 583.36], "text": " we have AlphaFold2, we've got DeepMind,"}, {"timestamp": [583.36, 584.5], "text": " we've got all these things,"}, {"timestamp": [584.5, 585.28], "text": " and we've got just this"}, {"timestamp": [585.28, 591.42], "text": " exponentially increasing amount of technology and science and understanding."}, {"timestamp": [591.42, 595.4], "text": " But society hasn't really changed in 10 years, or 20 years, or 30 years."}, {"timestamp": [595.4, 600.08], "text": " You watch videos of what happened in the 90s, and it's like we more or less live the same"}, {"timestamp": [600.08, 601.36], "text": " way."}, {"timestamp": [601.36, 608.72], "text": " And so I'm not convinced that the singularity, even the formal definition of the singularity,"}, {"timestamp": [608.72, 614.4], "text": " where human civilization becomes unrecognizable, I'm not even convinced that's going to happen."}, {"timestamp": [614.4, 618.68], "text": " Now with that being said, there are these, what I call these apoca thresholds, where"}, {"timestamp": [618.68, 625.2], "text": " basically like, okay, yes, for many hundreds of thousands of years, humans basically lived as hunter gatherers. And"}, {"timestamp": [625.2, 632.0], "text": " then, you know, we started to take off and we got, you know, the the Iron Age and the Bronze Age,"}, {"timestamp": [632.0, 636.88], "text": " which, you know, global phenomenon. And then we got to, you know, the age of steel and steam."}, {"timestamp": [636.88, 642.08], "text": " And then we got to the Industrial Revolution. And so, like, yes, humanity has gone through many"}, {"timestamp": [642.72, 645.92], "text": " epochal changes, has crossed many of these thresholds."}, {"timestamp": [646.88, 649.96], "text": " We might be in the midst of the last threshold."}, {"timestamp": [649.96, 652.98], "text": " We might be, there might be one or two more thresholds."}, {"timestamp": [652.98, 654.46], "text": " We don't know."}, {"timestamp": [654.46, 656.6], "text": " But I'm not really convinced that it's gonna be"}, {"timestamp": [656.6, 658.44], "text": " like that drastically different."}, {"timestamp": [658.44, 661.48], "text": " Because even when in like 1900, someone said it,"}, {"timestamp": [661.48, 663.4], "text": " you know, humans have already invented 90%"}, {"timestamp": [663.4, 665.2], "text": " of everything that is inventable."}, {"timestamp": [670.16, 676.88], "text": " We still live relatively similar to how we did at the turn of the century. We go to jobs, you know, we have factories, we have machines, you know, we have a few niftier like machines, like we've got"}, {"timestamp": [676.88, 685.88], "text": " iPhones now, but that hasn't really fundamentally changed how we live. Okay, so this is a graphic that I've had in my head for a"}, {"timestamp": [685.88, 691.7], "text": " while and basically, you know, like all data in the universe is superset. So like"}, {"timestamp": [691.7, 696.02], "text": " if you if you think about the universe as an information model, there is"}, {"timestamp": [696.02, 700.26], "text": " technically an infinite amount of possible information and data in the"}, {"timestamp": [700.26, 706.24], "text": " universe. However, a much smaller subset of that is all useful knowledge. So there's"}, {"timestamp": [706.24, 709.6], "text": " raw data, there's information, and then there's knowledge, and then there's wisdom, if you"}, {"timestamp": [709.6, 715.42], "text": " want to think about it like that. The amount of information that is actually classifiable"}, {"timestamp": [715.42, 720.84], "text": " as useful knowledge is far smaller than the amount of actual data in the universe. And"}, {"timestamp": [720.84, 726.0], "text": " then of course, all human knowledge is a subset of useful knowledge."}, {"timestamp": [726.0, 730.0], "text": " But eventually we will get to the point where we have captured all useful knowledge."}, {"timestamp": [730.0, 734.0], "text": " Yes, like I said, there's an infinite amount of information and data in the universe,"}, {"timestamp": [734.0, 736.0], "text": " but a lot of that is just noise."}, {"timestamp": [736.0, 740.0], "text": " And so the signal-to-noise ratio is another thing that I think is following a sigmoid curve,"}, {"timestamp": [740.0, 745.04], "text": " and it's kind of already tapering off. You know, it's like, it's not like, you know,"}, {"timestamp": [745.04, 750.48], "text": " sure we understand subatomic particles and gravitons and, and Higgs bosons and, you know,"}, {"timestamp": [750.48, 755.92], "text": " there's all kinds of tiny fundamental things. Um, and maybe I'm wrong, you know, we still haven't"}, {"timestamp": [755.92, 761.12], "text": " fully untangled dark matter and dark energy. And so maybe there are entire domains of science that"}, {"timestamp": [761.12, 767.2], "text": " are just like out there in the ether that are completely unknown, but at the same time I kind of get the sense that even if it"}, {"timestamp": [767.2, 771.1], "text": " is out there, it's part of that, it's exponent, the milestones are"}, {"timestamp": [771.1, 775.26], "text": " exponentially getting further and further apart, so I don't really see us"}, {"timestamp": [775.26, 779.74], "text": " conquering all that necessarily like in the foreseeable future, and even if we do"}, {"timestamp": [779.74, 785.82], "text": " is it going to change human society? Okay, so I've rained on everyone's parade. What"}, {"timestamp": [785.82, 790.28], "text": " are the implications? So the first and biggest question is where is the plateau?"}, {"timestamp": [790.28, 795.0], "text": " If indeed scientific and technological progress is following a sigmoid curve,"}, {"timestamp": [795.0, 798.52], "text": " which I believe there is plenty of evidence that it is, where is the plateau?"}, {"timestamp": [798.52, 803.4], "text": " Where is it going to taper off and where are we going to end up? So again, like I"}, {"timestamp": [803.4, 806.78], "text": " said, finite amount of knowledge, useful knowledge in the universe."}, {"timestamp": [807.1, 811.58], "text": " There's also this kind of diminishing returns or vicious cycle where yes,"}, {"timestamp": [811.58, 813.38], "text": " every time we make progress, it's great,"}, {"timestamp": [813.58, 818.34], "text": " but also the complexity goes up in lockstep with that. And so it's like, okay,"}, {"timestamp": [818.78, 821.78], "text": " that's what I mean by like every threshold gets further and further apart."}, {"timestamp": [822.94, 823.62], "text": " Now,"}, {"timestamp": [823.62, 826.44], "text": " this is one thing that I really take issue with, is the idea"}, {"timestamp": [826.44, 832.44], "text": " that there is some kind of predictability horizon or event horizon beyond which all bets are off,"}, {"timestamp": [832.44, 840.0], "text": " and everything changes, and suddenly, you know, life becomes fundamentally unrecognizable,"}, {"timestamp": [840.0, 844.16], "text": " and human civilization changes forever, and we all live as goldfish in, you know,"}, {"timestamp": [844.16, 845.28], "text": " spice tanks or whatever."}, {"timestamp": [845.28, 846.12], "text": " I don't know."}, {"timestamp": [846.98, 848.88], "text": " But I don't really see any evidence of that."}, {"timestamp": [848.88, 850.92], "text": " And like I said, I'm like one of the kinds of people"}, {"timestamp": [850.92, 852.6], "text": " that like I would love to have warp drive."}, {"timestamp": [852.6, 855.02], "text": " I would love to have like all kinds of stuff"}, {"timestamp": [855.02, 857.48], "text": " that just might not be possible."}, {"timestamp": [857.48, 860.08], "text": " I remember I had a conversation with a friend of mine"}, {"timestamp": [860.08, 862.4], "text": " many years ago, good scientist,"}, {"timestamp": [862.4, 863.64], "text": " and I was talking to him and I'm like,"}, {"timestamp": [863.64, 865.44], "text": " when are we gonna get faster than light travel?"}, {"timestamp": [865.44, 867.74], "text": " And he was like, it might just not be possible."}, {"timestamp": [868.4, 870.14], "text": " And I'll address that close to the end of the video."}, {"timestamp": [870.14, 871.54], "text": " But it was like that really stuck with me."}, {"timestamp": [871.54, 874.2], "text": " He's like, you know, we need to accept the possibility"}, {"timestamp": [874.58, 878.34], "text": " that there are just things that, yes, we can imagine them as happening,"}, {"timestamp": [878.8, 881.24], "text": " but they're just not going to happen."}, {"timestamp": [881.24, 883.8], "text": " Jump gates might not be possible."}, {"timestamp": [883.8, 885.16], "text": " You know, warp drive might not be possible, you know, warp drive might not"}, {"timestamp": [885.16, 888.72], "text": " be possible, hyperdrive, whatever you want to call it. These things, like we can"}, {"timestamp": [888.72, 893.56], "text": " imagine them, sure, but they might forever be within the realm of fantasy."}, {"timestamp": [893.56, 897.92], "text": " Alright, so I already mentioned apocalypse thresholds. Typically we record"}, {"timestamp": [897.92, 901.6], "text": " apocalypse thresholds as industrial revolutions. The Renaissance was another"}, {"timestamp": [901.6, 907.0], "text": " big one, you know, the Stone Age transition to the Bronze Age and the Iron Age."}, {"timestamp": [907.0, 910.0], "text": " Those could be viewed as epochal thresholds."}, {"timestamp": [910.0, 914.0], "text": " The invention of sail in order to circumnavigate the world."}, {"timestamp": [914.0, 916.0], "text": " These kinds of things."}, {"timestamp": [916.0, 918.0], "text": " The biggest question to me is, are we in the last one?"}, {"timestamp": [918.0, 921.0], "text": " Is the Fourth Industrial Revolution the last epochal threshold?"}, {"timestamp": [921.0, 924.0], "text": " Obviously, I'm not going to be so short-sighted as to say,"}, {"timestamp": [924.0, 927.0], "text": " we have invented everything that is possible to be invented."}, {"timestamp": [927.0, 929.0], "text": " I remember when I read that quotation,"}, {"timestamp": [929.0, 932.0], "text": " probably I was like 10 or 11 when I read that,"}, {"timestamp": [932.0, 934.0], "text": " and I'm like, wow, that dude was an idiot."}, {"timestamp": [934.0, 936.0], "text": " So, I'm not going to fall into that trap and say,"}, {"timestamp": [936.0, 938.0], "text": " we've invented everything that it is possible to invent."}, {"timestamp": [938.0, 943.0], "text": " No. What I am saying, though, is that even with accelerating technology and science,"}, {"timestamp": [943.0, 945.06], "text": " the way that we live is not changing at an"}, {"timestamp": [945.06, 946.42], "text": " accelerated rate."}, {"timestamp": [946.42, 951.0], "text": " If anything, the way that we live is changing at a slower rate."}, {"timestamp": [951.0, 953.72], "text": " So yes, can things get better?"}, {"timestamp": [953.72, 954.72], "text": " Absolutely."}, {"timestamp": [954.72, 955.72], "text": " Can things still change?"}, {"timestamp": [955.72, 956.72], "text": " Yes, absolutely."}, {"timestamp": [956.72, 958.76], "text": " Can we become a multi-planetary species?"}, {"timestamp": [958.76, 962.08], "text": " I don't see why not, but I'm not saying that it's going to be easy."}, {"timestamp": [962.08, 967.32], "text": " And I think that this is one of the fantasies that people have, is that with more and more technological breakthroughs,"}, {"timestamp": [967.32, 969.6], "text": " things are just going to get exponentially easier."}, {"timestamp": [969.6, 971.68], "text": " I do think that some things will get easier."}, {"timestamp": [971.68, 975.76], "text": " Obviously, we would rather live today with our technology"}, {"timestamp": [975.76, 979.52], "text": " that we have today than we would like to live 200 years ago."}, {"timestamp": [979.52, 980.64], "text": " Because why?"}, {"timestamp": [980.64, 982.84], "text": " There's a lot of things that are way easier today,"}, {"timestamp": [982.84, 985.0], "text": " but that doesn't mean that life is overall very easy"}, {"timestamp": [986.0, 990.8], "text": " so and again the event horizon is basically like I"}, {"timestamp": [991.28, 994.88], "text": " Whenever people talk about singularity and whenever I think about singularity"}, {"timestamp": [994.88, 999.04], "text": " It's like I don't really see this happening if you want to talk about a point of no return"}, {"timestamp": [999.04, 1001.04], "text": " I think we crossed that a long time ago"}, {"timestamp": [1001.48, 1005.84], "text": " and we crossed that and it was inevitable, not by virtue of the technology or"}, {"timestamp": [1005.84, 1011.12], "text": " the science, but just because the planet is so huge and there's billions of us. And you can no"}, {"timestamp": [1011.12, 1016.16], "text": " more stop research happening in China or Russia or Africa or America or Europe than you can like"}, {"timestamp": [1016.16, 1021.28], "text": " stop the earth from spinning. Why? Because it's impossible to coordinate 8 billion humans. Like,"}, {"timestamp": [1021.28, 1028.72], "text": " granted, we didn't have 8 billion humans in 1950. had like 3 billion but the point is is that there is an inexorable process of"}, {"timestamp": [1030.0, 1033.48], "text": " Human progress and learning and everything that you just can't stop it"}, {"timestamp": [1033.6, 1037.84], "text": " So if you want to talk about a point of no return we cross that a long time ago. It's slow"}, {"timestamp": [1037.84, 1039.84], "text": " It's been a slow build-up"}, {"timestamp": [1040.0, 1041.16], "text": " but"}, {"timestamp": [1041.16, 1042.84], "text": " the the aspect of this"}, {"timestamp": [1042.84, 1047.08], "text": " you know technological event horizon and singularity that I really want to push back on is"}, {"timestamp": [1047.38, 1052.88], "text": " The magical thinking that seems to emerge where some people say they just there's this inflation"}, {"timestamp": [1053.42, 1059.62], "text": " Where the that's like, okay. Well someone predicted that, you know human society"}, {"timestamp": [1060.18, 1062.18], "text": " Civilization might become unrecognizable"}, {"timestamp": [1062.34, 1068.2], "text": " First I don't see any evidence of that and second And second, that is often inflated or conflated"}, {"timestamp": [1068.2, 1070.26], "text": " with we'll shatter all the laws of physics"}, {"timestamp": [1070.26, 1072.68], "text": " and anything you can imagine will be possible."}, {"timestamp": [1072.68, 1075.5], "text": " Again, I'm not seeing any evidence of that."}, {"timestamp": [1075.5, 1077.64], "text": " And in fact, I'm seeing evidence to the contrary,"}, {"timestamp": [1077.64, 1080.8], "text": " that even though we have exponentially better understanding"}, {"timestamp": [1080.8, 1082.96], "text": " of the fundamental laws of physics,"}, {"timestamp": [1082.96, 1086.72], "text": " things are changing slower and slower."}, {"timestamp": [1086.72, 1092.04], "text": " And also the reason that I want to push back on this is it can be a very harmful narrative."}, {"timestamp": [1092.04, 1098.76], "text": " Like it's it can be as bad as like, you know, narratives of destruction or utopian narratives"}, {"timestamp": [1098.76, 1102.8], "text": " or anything where it's like if you imagine that the future will be unimaginably better"}, {"timestamp": [1102.8, 1110.2], "text": " and happier and safer and everything and then you ignore the problems today and you stop putting in the effort today,"}, {"timestamp": [1110.2, 1113.72], "text": " well I mean that could have negative consequences as well."}, {"timestamp": [1113.72, 1119.48], "text": " It could result in like learned helplessness or a sense of futility or fatality or just"}, {"timestamp": [1119.48, 1120.76], "text": " delaying your life."}, {"timestamp": [1120.76, 1123.24], "text": " Like there's a lot to enjoy today."}, {"timestamp": [1123.24, 1126.2], "text": " Okay so those are some of the implications."}, {"timestamp": [1126.2, 1131.46], "text": " Here are some of my specific predictions about what will happen within the foreseeable future"}, {"timestamp": [1131.46, 1134.52], "text": " in terms of how it will change how we live."}, {"timestamp": [1134.52, 1137.04], "text": " So first, indefinite lifespan."}, {"timestamp": [1137.04, 1141.14], "text": " This is one that I think that there's plenty of evidence that we are working up to this"}, {"timestamp": [1141.14, 1142.14], "text": " very quickly."}, {"timestamp": [1142.14, 1145.86], "text": " I don't know why, but talking about indefinite lifespan"}, {"timestamp": [1145.86, 1147.56], "text": " seems to trigger some people on the internet."}, {"timestamp": [1147.56, 1149.42], "text": " Not most, but there's a few."}, {"timestamp": [1149.42, 1151.96], "text": " I always get a couple comments where people are like,"}, {"timestamp": [1151.96, 1153.72], "text": " oh, well, people have been predicting"}, {"timestamp": [1153.72, 1156.28], "text": " the fountain of youth for centuries,"}, {"timestamp": [1156.28, 1158.56], "text": " and you're not gonna find it, and nobody's gonna find it."}, {"timestamp": [1158.56, 1159.84], "text": " And it's like, I don't know,"}, {"timestamp": [1159.84, 1161.68], "text": " those people seem to have a death wish."}, {"timestamp": [1161.68, 1163.08], "text": " And they're like, stop telling me"}, {"timestamp": [1163.08, 1164.64], "text": " that I'm gonna live forever."}, {"timestamp": [1164.64, 1165.76], "text": " That makes me angry."}, {"timestamp": [1165.76, 1168.16], "text": " I don't understand that reaction."}, {"timestamp": [1168.16, 1171.08], "text": " But so there's plenty of evidence"}, {"timestamp": [1171.08, 1172.68], "text": " that we are getting close to this."}, {"timestamp": [1172.68, 1173.76], "text": " And I remember there was a comment"}, {"timestamp": [1173.76, 1175.76], "text": " that I got a few weeks ago that someone's like, yeah,"}, {"timestamp": [1175.76, 1178.2], "text": " but what about these plaques and proteins and enzymes"}, {"timestamp": [1178.2, 1178.88], "text": " that accumulate?"}, {"timestamp": [1178.88, 1182.6], "text": " I'm like, the fact that you know what causes aging"}, {"timestamp": [1182.6, 1184.96], "text": " means that that's half the battle."}, {"timestamp": [1184.96, 1185.1], "text": " There was this famous quotation. Who was it? Was it Ray Kurzweil? I think it was Ray Kurzweil. know like what causes aging means that like that's half the battle. Right."}, {"timestamp": [1185.1, 1186.3], "text": " There was this famous quotation."}, {"timestamp": [1186.3, 1186.7], "text": " Who was it?"}, {"timestamp": [1186.7, 1187.7], "text": " Was it Ray Kurzweil?"}, {"timestamp": [1187.7, 1191.0], "text": " I think it was Ray Kurzweil during the human genome project."}, {"timestamp": [1191.0, 1195.0], "text": " Someone consulted with him and it's like, oh, well, we've only decoded"}, {"timestamp": [1195.0, 1197.6], "text": " 1% of the genome and he's like, okay, well, we're halfway done."}, {"timestamp": [1197.6, 1200.4], "text": " That is the nature of exponential progress."}, {"timestamp": [1200.4, 1203.5], "text": " And that is one place that I agree with him because as an automation"}, {"timestamp": [1203.5, 1208.72], "text": " engineer, if you can automate 1% of the job job you can automate a hundred percent of the job."}, {"timestamp": [1208.72, 1213.68], "text": " Why? Because it's just a matter of like one more step to get something that will finish the process"}, {"timestamp": [1213.68, 1219.6], "text": " for you. And I've had chats with other people in automation and they agree it's like with automation"}, {"timestamp": [1219.6, 1231.76], "text": " and that kind of thing it's like it feels like you achieve nothing until the very end, then you hit go, and then it's done. But yeah, so the combination of precedents that we see in nature, the rapid"}, {"timestamp": [1231.76, 1237.44], "text": " pace of understanding genetics, nanotechnology, like man, some of the stuff that I've seen just"}, {"timestamp": [1237.44, 1242.08], "text": " in the last few weeks about nanotech being able to like have programmatic, like programmable"}, {"timestamp": [1242.08, 1245.04], "text": " nanoparticles that will deliver drugs to specific tissues."}, {"timestamp": [1246.8, 1252.72], "text": " Honestly, I don't see any reason, any physical reason that we could not, within a reasonable"}, {"timestamp": [1252.72, 1259.84], "text": " time frame, relatively soon, overcome all of the causes of aging and death, at least all the known"}, {"timestamp": [1259.84, 1268.32], "text": " ones. Obviously, it's entirely possible that the longer you live, the more likelihood there will be, you know, for accidents or unpredictable diseases."}, {"timestamp": [1268.32, 1274.58], "text": " For instance, you know, a hundred years ago, there was probably a lot less understanding"}, {"timestamp": [1274.58, 1278.18], "text": " of things like Alzheimer's and stuff just because people didn't live long enough to"}, {"timestamp": [1278.18, 1280.38], "text": " have those diseases."}, {"timestamp": [1280.38, 1290.0], "text": " But I do suspect that indefinite lifespan is coming relatively soon. And this might very well be the biggest single impact to the way that we live."}, {"timestamp": [1290.0, 1294.4], "text": " It's going to change the way that we relate to ourselves, to each other, to politics,"}, {"timestamp": [1294.4, 1296.16], "text": " to economics, to power."}, {"timestamp": [1296.16, 1298.32], "text": " It's going to change the way that we do family planning."}, {"timestamp": [1298.32, 1302.56], "text": " It's going to change the way that we engage with life and fun and leisure and all that"}, {"timestamp": [1302.56, 1303.44], "text": " kind of stuff."}, {"timestamp": [1303.44, 1309.08], "text": " So this, I think, is going to be the biggest, like most fundamental shift in society."}, {"timestamp": [1309.08, 1313.52], "text": " Cybernetic integration. I did do a recent video about Neuralink. I think that"}, {"timestamp": [1313.52, 1318.28], "text": " Neuralink as it is is very immature and I don't mean like childish I just mean"}, {"timestamp": [1318.28, 1323.24], "text": " it's it's an immature technology. That being said, there is a lot of other"}, {"timestamp": [1323.24, 1327.6], "text": " research being done with implantbernetic implants of all"}, {"timestamp": [1327.6, 1330.56], "text": " different kinds, not just brain-computer interfaces."}, {"timestamp": [1330.56, 1337.68], "text": " There are rejuvenation things such as bioengineered semi-living implants that can cure type 1"}, {"timestamp": [1337.68, 1338.68], "text": " diabetes."}, {"timestamp": [1338.68, 1339.68], "text": " I just saw that the other day."}, {"timestamp": [1339.68, 1341.06], "text": " That's really cool."}, {"timestamp": [1341.06, 1345.66], "text": " There's also the possibility of another implant that I was watching a video about"}, {"timestamp": [1345.66, 1347.6], "text": " that it can regrow your liver."}, {"timestamp": [1347.6, 1349.56], "text": " So it's like, okay, cool."}, {"timestamp": [1349.56, 1353.04], "text": " So we have lots and lots of implants"}, {"timestamp": [1353.04, 1356.38], "text": " and cybernetic integration coming down the pipeline."}, {"timestamp": [1356.38, 1360.74], "text": " So most of these are focused on disease and injury."}, {"timestamp": [1360.74, 1363.28], "text": " So like, there's some electrical implants"}, {"timestamp": [1363.28, 1367.5], "text": " that looks like they can cause your spine to regrow if you've broken your broken your spine and"}, {"timestamp": [1367.5, 1372.14], "text": " you've been paralyzed that's really cool but there's a really big difference"}, {"timestamp": [1372.14, 1377.78], "text": " between repairing damage and and enhancements with new capabilities and"}, {"timestamp": [1377.78, 1382.44], "text": " there's also possibly or likely limitations to the level of integration"}, {"timestamp": [1382.44, 1388.44], "text": " now in fictional places like cyberpunk, there's this disease called cyberpsychosis, where basically if you"}, {"timestamp": [1388.44, 1393.72], "text": " have too many implants, you start to go crazy. In Ghost in the Shell, there is a"}, {"timestamp": [1393.72, 1397.7], "text": " cyberbrain sclerosis, which is basically like your immune system,"}, {"timestamp": [1397.7, 1402.16], "text": " and inflammation responses to implants basically cause your brain to harden and"}, {"timestamp": [1402.16, 1405.06], "text": " you lose your ability to think."}, {"timestamp": [1405.06, 1409.56], "text": " Really horrible possible diseases that could emerge like we could create new diseases with"}, {"timestamp": [1409.56, 1411.72], "text": " cybernetics so we need to be careful with that."}, {"timestamp": [1411.72, 1415.54], "text": " Now that being said, maybe in the long run there's no reason we can't overcome these"}, {"timestamp": [1415.54, 1419.48], "text": " things especially if you have forever to figure it all out."}, {"timestamp": [1419.48, 1421.44], "text": " Okay great."}, {"timestamp": [1421.44, 1422.44], "text": " Robotic workforce."}, {"timestamp": [1422.44, 1431.0], "text": " I am a huge proponent of what I call post-labor economics, and I just think that it makes sense to get humans out of the workforce as much as possible."}, {"timestamp": [1431.0, 1440.0], "text": " And I think it's inevitable. I think it makes economic sense to replace human labor. I think that there is no reason that we need jobs."}, {"timestamp": [1440.0, 1445.28], "text": " So this is another thing that seems to trigger some people. I've talked about the existence of leisure classes"}, {"timestamp": [1446.54, 1452.64], "text": " so Greek aristocracy back in the day Roman aristocracy back in the day British aristocracy up through today"}, {"timestamp": [1453.2, 1458.2], "text": " Like there are literally entire civilizations that had classes of people who were not allowed to work"}, {"timestamp": [1458.96, 1464.08], "text": " So like and they were fine like you don't need work to have a meaningful fulfilling life"}, {"timestamp": [1464.08, 1465.28], "text": " And they were fine like you don't need work to have a meaningful fulfilling life"}, {"timestamp": [1472.0, 1472.4], "text": " Spartan Spartan men citizens like they were literally not allowed to have a job you were not allowed to have a profession"}, {"timestamp": [1478.16, 1478.32], "text": " If you were a member of a certain crust of society and in fact you can even see this go watch Downton Abbey"}, {"timestamp": [1484.12, 1485.52], "text": " When what's-his-name joins, and he's like a lawyer. It's like oh well. That's kindbrow. Like, why are you still working for money? You're one of us now."}, {"timestamp": [1485.88, 1487.72], "text": " Like this still exists today."}, {"timestamp": [1487.72, 1490.86], "text": " So I don't know why talking about a leisure class, like triggers some people,"}, {"timestamp": [1490.86, 1491.7], "text": " but it does."}, {"timestamp": [1491.8, 1495.0], "text": " But I want to point out the fact that like there have been millions and millions"}, {"timestamp": [1495.0, 1498.16], "text": " of people throughout all of history that did not have a profession."}, {"timestamp": [1498.16, 1502.56], "text": " And in some cases were legally prohibited from having a profession and they were"}, {"timestamp": [1502.56, 1503.4], "text": " perfectly happy."}, {"timestamp": [1504.4, 1506.0], "text": " They had really cool parties."}, {"timestamp": [1506.0, 1508.0], "text": " But yeah, and so the primary"}, {"timestamp": [1508.0, 1510.0], "text": " the primary KPI that I"}, {"timestamp": [1510.0, 1512.0], "text": " look for as evidence"}, {"timestamp": [1512.0, 1514.0], "text": " for replacing human labor"}, {"timestamp": [1514.0, 1516.0], "text": " is better, faster, cheaper, and safer."}, {"timestamp": [1516.0, 1518.0], "text": " Those are the like four criteria"}, {"timestamp": [1518.0, 1520.0], "text": " that pay attention to that in terms of"}, {"timestamp": [1520.0, 1522.0], "text": " artificial intelligence and AI"}, {"timestamp": [1522.0, 1524.0], "text": " and I still get like comments saying, someone like"}, {"timestamp": [1524.0, 1529.42], "text": " oh well, I'd love to see a robot take my job doing tiling it's like you should check on some of the latest"}, {"timestamp": [1529.42, 1535.36], "text": " things that robots are capable of doing. Robots are taking really cool form factors they're getting"}, {"timestamp": [1535.36, 1540.58], "text": " much more dexterous very quickly and then you look at the the work that I'm doing on the ACE"}, {"timestamp": [1540.58, 1549.92], "text": " framework that Google's doing on RTX and like these these robots are going to be able to do pretty much anything very soon. I'm predicting probably this time next year"}, {"timestamp": [1549.92, 1551.92], "text": " We're going to start to see"}, {"timestamp": [1551.92, 1554.92], "text": " Commercial robots that are able to do pretty much any blue-collar work"}, {"timestamp": [1556.24, 1559.68], "text": " Like mark my words. I'll probably do like a prediction poll for that"}, {"timestamp": [1560.68, 1566.2], "text": " Okay, so then probably the most extreme thing is going to be transgenic technology."}, {"timestamp": [1566.2, 1568.22], "text": " We can already do a lot of this."}, {"timestamp": [1568.22, 1573.02], "text": " It's still a very naive technology or an immature technology, but the fact that we can even"}, {"timestamp": [1573.02, 1578.84], "text": " replace organelles in cells and then inject that into the germline, and what I mean by"}, {"timestamp": [1578.84, 1583.68], "text": " that is like there are certain diseases that are based on defective mitochondria, and so"}, {"timestamp": [1583.68, 1587.46], "text": " what you can do is you can take a healthy mitochondria from another cell and replace"}, {"timestamp": [1587.46, 1588.84], "text": " your mitochondria with it."}, {"timestamp": [1588.84, 1595.8], "text": " And then because mitochondria have their own DNA, it reproduces when your cells go through"}, {"timestamp": [1595.8, 1596.8], "text": " mitosis."}, {"timestamp": [1596.8, 1602.28], "text": " And so it's like, hey, you've now created a cell that is a Franken cell based on input"}, {"timestamp": [1602.28, 1608.0], "text": " from multiple organisms. So between genome editing and epigenomic editing and organelle"}, {"timestamp": [1608.0, 1612.0], "text": " replacement, we literally have"}, {"timestamp": [1612.0, 1616.0], "text": " actual control over the fundamental levers of biology."}, {"timestamp": [1616.0, 1620.0], "text": " Now, again, like most technologies and sciences,"}, {"timestamp": [1620.0, 1624.0], "text": " we are going to find maybe some diminishing returns,"}, {"timestamp": [1624.0, 1625.6], "text": " some increase in complexity, some increasing complexity,"}, {"timestamp": [1625.6, 1630.4], "text": " but there is no physical barrier to, like, modifying our genes."}, {"timestamp": [1630.4, 1632.8], "text": " Now, are we going to all be cat people one day?"}, {"timestamp": [1632.8, 1634.4], "text": " Some people might."}, {"timestamp": [1634.4, 1639.0], "text": " You know, if that's what they want, great. It's not what I want."}, {"timestamp": [1639.0, 1645.64], "text": " I probably will remain, like, kind of in this form factor more or less for the foreseeable future now granted"}, {"timestamp": [1645.64, 1649.32], "text": " You know you live for 10,000 years you might get bored and you want to be a cat person for a while"}, {"timestamp": [1649.32, 1650.4], "text": " I don't know"}, {"timestamp": [1650.4, 1652.52], "text": " but there's also like"}, {"timestamp": [1653.76, 1659.76], "text": " It's difficult to talk about this stuff without saying like wow, but that is intrinsically wrong because we should just be humans forever"}, {"timestamp": [1660.44, 1662.44], "text": " but like I don't know that's"}, {"timestamp": [1662.8, 1666.04], "text": " It's weird also because this because this is super polarizing."}, {"timestamp": [1666.04, 1667.8], "text": " Where some people are like, well yeah, obviously,"}, {"timestamp": [1667.8, 1670.2], "text": " like if we have control over that,"}, {"timestamp": [1670.2, 1671.38], "text": " and we want to change ourselves,"}, {"timestamp": [1671.38, 1672.92], "text": " we should be allowed to do so."}, {"timestamp": [1672.92, 1674.04], "text": " And then there are other people"}, {"timestamp": [1674.04, 1675.28], "text": " that just really cringe at that,"}, {"timestamp": [1675.28, 1677.52], "text": " and they're like, no, that like is an affront to,"}, {"timestamp": [1677.52, 1679.12], "text": " you know, God or whatever, like,"}, {"timestamp": [1679.12, 1681.76], "text": " if you change yourself, then that's evil or whatever."}, {"timestamp": [1681.76, 1682.6], "text": " I don't know."}, {"timestamp": [1682.6, 1686.32], "text": " I remember like, so here's the story that I'm thinking of I remember my stepbrother"}, {"timestamp": [1686.9, 1691.06], "text": " wanted to have jaw surgery to cure his overbite and"}, {"timestamp": [1691.58, 1697.86], "text": " his religious family like like like got really bent out of shape because it's like well"}, {"timestamp": [1697.86, 1705.2], "text": " God gave you that jaw and now you're your desire to go through cosmetic surgery is an affront to God."}, {"timestamp": [1705.2, 1708.36], "text": " And it's like, okay, well, I mean, that's them."}, {"timestamp": [1708.36, 1710.68], "text": " But you know, people have an impulse to control each other."}, {"timestamp": [1710.68, 1713.44], "text": " Anyways, I'm getting lost in a rabbit hole."}, {"timestamp": [1713.44, 1716.04], "text": " Okay, so I did promise that I would address this."}, {"timestamp": [1716.04, 1717.64], "text": " So this is, we're winding down the video."}, {"timestamp": [1717.64, 1719.06], "text": " What about aliens?"}, {"timestamp": [1719.06, 1723.68], "text": " So there have been some recent disclosures and it's really difficult to think about,"}, {"timestamp": [1723.68, 1725.3], "text": " like, okay, if any"}, {"timestamp": [1725.3, 1730.48], "text": " of the testimony that has been given to Congress, which for some background, uh, was his name,"}, {"timestamp": [1730.48, 1735.08], "text": " David Grush and a few others have testified that like, yes, we have recovered non-human"}, {"timestamp": [1735.08, 1736.66], "text": " biological entities."}, {"timestamp": [1736.66, 1739.38], "text": " We have recovered extraterrestrial craft."}, {"timestamp": [1739.38, 1743.32], "text": " We have documented evidence of these crafts that are able to do things that we cannot"}, {"timestamp": [1743.32, 1744.88], "text": " physically explain."}, {"timestamp": [1744.88, 1745.08], "text": " Um, mostly pertaining to acceleration, uh, and deceleration. Documented evidence of these crafts that are able to do things that we cannot physically explain"}, {"timestamp": [1747.44, 1747.96], "text": " mostly pertaining to acceleration"}, {"timestamp": [1752.0, 1753.24], "text": " And deceleration so it's like okay. Well, how do they accelerate and decelerate that fast?"}, {"timestamp": [1756.2, 1758.18], "text": " so what is what is the scientific implication of this and"}, {"timestamp": [1762.54, 1763.46], "text": " One thing I want to say is like, okay. Yes, some of these things seem to be magical"}, {"timestamp": [1765.56, 1771.06], "text": " But just because you have a craft that defies the laws of physics as we know it doesn't mean that it is"}, {"timestamp": [1771.06, 1775.26], "text": " magic or that it that also doesn't immediately translate to well because"}, {"timestamp": [1775.26, 1779.2], "text": " that's possible everything else is possible. And so I want to leave you with"}, {"timestamp": [1779.2, 1783.62], "text": " a quote, any sufficiently advanced technology is indistinguishable from"}, {"timestamp": [1783.62, 1788.0], "text": " magic. This was Arthur C. Clarke, he called it his third law or whatever I guess."}, {"timestamp": [1788.0, 1791.0], "text": " But here's an example that I want to leave you with."}, {"timestamp": [1791.0, 1794.0], "text": " Think of your cell phone, your smart phone."}, {"timestamp": [1794.0, 1799.0], "text": " If you were to tell someone or show someone in the 1500s"}, {"timestamp": [1799.0, 1801.0], "text": " what a cell phone was and what it could do"}, {"timestamp": [1801.0, 1804.0], "text": " and the fact that you could literally call someone instantaneously"}, {"timestamp": [1804.0, 1807.56], "text": " on the other side of the planet, you would have been"}, {"timestamp": [1807.56, 1813.48], "text": " burned at the stake as a witch. Because that technological capacity was just"}, {"timestamp": [1813.48, 1819.72], "text": " not within the realm of consciousness until this last century. Now obviously"}, {"timestamp": [1819.72, 1823.66], "text": " the telegraph is over a century old and people started realizing"}, {"timestamp": [1823.66, 1827.16], "text": " that you could communicate vast different distances instantaneously"}, {"timestamp": [1827.56, 1832.68], "text": " So maybe a century ago you wouldn't have been burned at the stake, but certainly five centuries ago if you would have said"}, {"timestamp": [1832.68, 1834.0], "text": " Oh, yeah, here's a magical device"}, {"timestamp": [1834.0, 1838.86], "text": " It has no physical connections to anything else and I can talk to someone on the other side of the planet"}, {"timestamp": [1838.86, 1841.32], "text": " You could even talk to people in space if you wanted to"}, {"timestamp": [1841.4, 1852.08], "text": " They would have literally burned you at the stake because that is some devilry witchcraft stuff. Now, to a mind 500 years ago, your iPhone would have"}, {"timestamp": [1852.08, 1857.6], "text": " appeared to be pure magic, but today we understand that it has very mundane explanations of electrical"}, {"timestamp": [1857.6, 1862.8], "text": " circuits and radio signals, and once you have radio signals and integrated circuits, the rest"}, {"timestamp": [1862.8, 1866.04], "text": " is pretty much a given. But if you like,"}, {"timestamp": [1866.4, 1868.12], "text": " there was a few comments on recent videos,"}, {"timestamp": [1868.12, 1871.6], "text": " like just imagine trying to explain language models to someone 20 years ago."}, {"timestamp": [1871.6, 1874.08], "text": " And they would have been like, what? I don't get it. So,"}, {"timestamp": [1874.36, 1876.92], "text": " but today it has a very mundane explanation."}, {"timestamp": [1876.96, 1881.36], "text": " And so one thing that I want to just kind of really push back on is,"}, {"timestamp": [1882.32, 1887.44], "text": " is just because you can imagine something and just because something seems magical"}, {"timestamp": [1887.44, 1893.68], "text": " to you today that doesn't mean that it is all that different or all that exotic and it it really"}, {"timestamp": [1893.68, 1901.92], "text": " comes down to perception and so yes like well dave like you're saying like okay so let me just unpack"}, {"timestamp": [1901.92, 1907.2], "text": " this you know there are things that we can't imagine being possible today that might be possible"}, {"timestamp": [1907.2, 1908.2], "text": " tomorrow."}, {"timestamp": [1908.2, 1909.48], "text": " And so like, let's reverse that."}, {"timestamp": [1909.48, 1913.36], "text": " Like, okay, so what is what is the iPhone 500 years from now that we can't possibly"}, {"timestamp": [1913.36, 1915.0], "text": " imagine today?"}, {"timestamp": [1915.0, 1922.64], "text": " Yes, that kind of technological leap is possible, but it's not necessarily going to be physics"}, {"timestamp": [1922.64, 1928.9], "text": " shattering, especially as we learn more and more about science and physics and technology and"}, {"timestamp": [1929.4, 1930.84], "text": " we get those diminishing returns."}, {"timestamp": [1931.16, 1935.46], "text": " And I suspect that we're going to have a different orientation towards science"}, {"timestamp": [1935.46, 1936.86], "text": " and technology eventually."}, {"timestamp": [1937.18, 1940.86], "text": " And so this is something that kind of I've been thinking about is what happens"}, {"timestamp": [1940.86, 1944.54], "text": " when we get to a steady state world where it's just kind of a foregone"}, {"timestamp": [1944.54, 1945.5], "text": " conclusion that like,"}, {"timestamp": [1945.5, 1948.8], "text": " yeah, we do know 95% of all science out there,"}, {"timestamp": [1948.8, 1952.2], "text": " and the last 5% is going to be really difficult and expensive to get,"}, {"timestamp": [1952.2, 1955.5], "text": " but like, the frontiers of scientific discovery"}, {"timestamp": [1955.5, 1957.2], "text": " might eventually be known."}, {"timestamp": [1957.2, 1961.3], "text": " Kind of like the age of discovery when we were sailing around the planet Earth,"}, {"timestamp": [1961.3, 1963.3], "text": " eventually all of planet Earth was known."}, {"timestamp": [1963.3, 1967.18], "text": " Now granted, there's, you know, infinite more planets out there to discover."}, {"timestamp": [1967.18, 1968.46], "text": " So I don't know."}, {"timestamp": [1968.46, 1970.22], "text": " Let me know what you think in the comments."}, {"timestamp": [1970.22, 1971.7], "text": " Like, subscribe, etc, etc."}, {"timestamp": [1971.7, 1972.7], "text": " Thanks for watching."}, {"timestamp": [1972.7, 1974.7], "text": " I hope this gave you some food for thought."}, {"timestamp": [1974.7, null], "text": " Cheers."}]}