{"text": " Morning everybody David Shapiro here with your weekly video. So today's video is about layer 6 of the Gato framework which calls for international treaties or in other words global AI based agencies. what would those look like? Because in many cases, people are just not aware of existing work that has been done on an international or global scale. So I figured we would talk about those and then also first talk about what exists and then also talk about how a version of those for AI would look. Apologies. So real quick, just before we jump in, I'll plug my Patreon. I have a private Discord server for all Patreon supporters, and I also have weekly office hours for the premium tier Patreon supporters. I also do have a higher tier, which allows for one-on-one calls, but at least as of the recording of this, I have no slots available. That being said I do add slots occasionally. You know there's churn. It happens. Okay moving right along. So for some background, a few weeks ago Sam Altman, Gary Marcus, and Christina Montgomery testified before Congress about artificial intelligence and one of the things that they asked for was regulation. All three of them asked that they asked for was regulation. All three of them asked for it in certain respects. Sam Altman, obviously the CEO of OpenAI, has been calling for various kinds of regulation for a while. Christina, who comes from IBM, she was a little bit more, let's say, corporate sanitized in the way that she asked. But she basically said that IBM's policy has always been to be more in favor of regulation, including going back to social media. And I checked on IBM's website and they actually do have some policies and recommendations, obviously, they have to be very diplomatic about it because they are not a political entity. And of course, we already have a lot of, in my opinion, too much interference between the corporate establishment and American politics. That being said, you know, IBM has expressly asked for more regulation on social media, AI, and other uses of technology for a while. So Gary Marcus is a professor and researcher. So this this panel if you missed it was a good mix of private industry as well as academia and they were all basically saying the same thing. So Gary Marcus explicitly said we need a new cabinet level agency. So cabinet level agency is like FDA, you know, or or some someone who's the head of which reports directly to like the White House or or the like, you know, Joint Chiefs of Staff or whatever. I know the Joint Chiefs of Staff is for military, but you never know. Like we created a space force, you know, NASA was the research branch and now we have a Space Force and who knows maybe we will ultimately have an AI division for military. But anyways, so one of the when when pressed Gary Marcus said that, you know, one model that we could pursue would be the FDA but for AI and the the example that he gave is that when you release a drug to you know 300 million people you you make sure that it's safe you make sure that it has that has really passed muster one of the senators interviewing him said he disagreed but you know he appreciated the sentiment and then there was also talk about well what what other existing entities could be empowered, right? Like, what about the FTC or SEC or whatever? And there's actually a lot of people that advocate that say, like, yes, all government agencies must become AI-aware, AI-literate. But another point is that AI is such a distinctive and powerful force that it warrants its own agency. Just like how America has the Department of Energy, which focuses specifically on generation and management of energy, OpenAI has also explicitly called for an international agency. They call for IAEA, but for AI. So the IAEA is the International Atomic Energy Agency which has to do with inspecting nuclear sites. So the conversation is there the conversation is happening. People are calling for national and international levels of A.I. not just regulation. Yes. But I'm also calling for AI research. And I've got plenty of examples of existing international research bodies to share. So first we're going to talk a little bit about the IAEA. It was established in 1957 under the United Nations. It is an autonomous entity. Its primary purpose is, of course, to promote the peaceful use of nuclear energy, inhibit its use for military purposes, and ensure nuclear safety and security. You swap that out with artificial intelligence, and that's exactly what we need. It is governed by the General Conference of the UN and has a board of governors that is appointed from 35 members of the UN. As of 2021, it had 171 member states, and its annual budget is only 500 million euros, which is probably lower than you might think, especially when we're talking about the astronomical amount of money that artificial intelligence could possibly generate. And so then if you say, OK, well, we are asking for the foundation of something similar, but for artificial intelligence, maybe we start at the same part, at about half a billion euros. If the entire world chips in, that's actually a pretty trivial amount of money. So you divide 171 member states by 500 million euros, and like 3 million euros or $3 million per member state. That's a drop in the bucket. So we could easily, easily, easily afford to fund such an agency. So you know, well, who's going to pay for it? I don't even want to hear that argument. Like that is a trivial like nations could sneeze that and not even remember that they spent that money. One of the things that they do is, as I mentioned, they do inspections to verify compliance with nuclear nonproliferation. That they also assist in the development of peaceful nuclear programs. So they have kind of a one, two thing where they're they're regulating, but they're also educating and supporting and it is based in Vienna, Austria. So you might say, okay, well, yeah, but it's the United Nations. It has no track record or the United Nations isn't effective or whatever, you know, but there is quite a few things that the IAEA has helped with. So the nuclear non-Proliferation Treaty, it actually has a dedicated organization within itself based upon nuclear non-proliferation. It helped after the Chernobyl explosion, which of course, you know, the IAEA could not prevent the Chernobyl explosion, but it helped respond. And so that's another key thing is that a global entity shouldn't just be about regulation and enforcement, but also like disaster mitigation if or when it does happen. Nuclear test ban treaty was instrumental in that. North Korea, of course, has nuclear ambitions, and the IAEA provides constant monitoring for that. It was also instrumental in helping with the Iran nuclear deal, which of course, the relationship between Iran and the rest of the world, particularly the West, has been very strained for many years, but it hasn't been in the news lately, due largely to that nuclear deal that happened under Obama. I'm not saying that Obama is responsible for it, it was an international effort, but due largely to that nuclear deal that happened under Obama. I'm not saying that Obama is responsible for it, it was an international effort, but just pointing out he was president at the time. The Fukushima disaster, so that was after the tsunami that hit Japan. The IAEA was part of the coordination effort. And then finally, the Director General of the IAEA, Mohammed ElBaradei, got the Nobel Peace Prize in 2005. So, I just want to point out that, yes, this organization does have a track record and has made a name for itself. Now, one of the organizations that I like to think about is CERN. So CERN is European. So it is international, but it's not global. But it is there to study particle physics. And so this was established in 1954 by 12 member countries. It also now has 23 total members, including observers. There's a few categories. So there's the founders, which are Europe. And then there's contributors and observers, which includes the United States, Japan, and a few other nations. And so this is an international effort to understand the fundamental structure of the universe. Its entire mission is literally understand the fundamental structure of the universe, specifically the particles that compose matter and the forces that hold them together. So as of 2020, for whatever reason, finding the budget of CERN is rather difficult. All nations report in terms of like percentages of how much they support it, but like getting a total number like what was your budget, hard to find for whatever reason. Anyways, I think that the annual budget of certain is about 1.1 billion dollars and of course they run large Hadron Collider and a few other major major major experiments. So CERN if you are not aware of is the organization that invented the World Wide Web. This is a copy of the original proposal that led to the World Wide Web, and at the top, someone wrote, vague but exciting. So that is, many people, particularly in computer science, will understand that reference. So this was the initial proposal for the World Wide Web. It's discovered in a whole raft of fundamental elementary particles, bosons, Higgs boson, creation of antimatter using neutrinos, all sorts of stuff. And of course, we've got the Large Hadron Collider, which generates many, many hundreds of terabytes of data. And it's interesting to bring this one up, because actually, as a science nerd, I was watching a documentary about CERN and LHC a few years ago. And the LHC actually generates so much data that they need artificial intelligence to sift through the data to help find the phenomenon, to find the anomalies. And so there's actually a very tight feedback loop between, for instance, nuclear research and artificial intelligence. So those are two organizations that have kind of the research mandate and then the regulation and safety mandate. And I think we need both for artificial intelligence. There's a few other international bodies that we can pay attention to that are probably either going to be good models that we can base this on or they could actually even be partners. So one another global organization that is more for emergency response is the World Health Organization which of course helped coordinate global the global response to the covid epidemic, but they've also responded to SARS MERS Ebola and other stuff. So my uncle is a microbiologist and so a few years ago when there was a couple of outbreaks of Ebola. He actually traveled the world to help be part of the World Health Organization response to contain Ebola and then of course MERS is something that you might not have heard of, but it was infinitely more dangerous than COVID. The mortality rate of MERS can be over 10 percent, and so like it's a there's some really horrible diseases that you have never heard of because of the World Health Organization. There's two financial global entities. Both were created at Bretton Woods after World War two and So World War two caused a lot of people to come together and say we need to prevent this from happening again And so one of the things that they decided after World War two was that economic? Improvement and economic stability and economic cooperation were critical to maintaining global peace Which has more or less worked up until now. But it's, you know, time will tell because we're facing a backlash against globalization. Anyways, getting lost in the weeds. So the point of the IMF is to stabilize the global economy through cooperation, trade, exchange, and so on. so members of the IMF Will get loans the IMF has been responsible for some bailouts. They also have been responsible for not necessarily Economic sanctions but economic requirements. So for instance during the global recession The IMF was the entity responsible for telling nations such as Greece You need austerity measures before we're going to bail you out. And so the idea of the IMF is that it uses that ability to withhold funds in order to shape national policy more towards stability rather than things like hyperinflation or economic collapse. And the situation in Greece is still not good after many, many years. That being said, we don't hear about the Greek economy collapsing in the news all the time. Granted, I don't pay attention to Greek news, but it doesn't make it into American financial news. The World Bank has a slightly different mandate than the IMF. So while the IMF more focuses on developed nations, the World Bank has the goal of ending extreme poverty through financial means and also to boost global prosperity through lending and advising. So the World Bank is more likely to issue loans to developing nations. And the reason that I bring both of these up is because artificial intelligence has the ability to profoundly impact artificial intelligence all over the world and and greatly advance the missions of both of these entities. And one of the best ways to incentivize aligned development is to pay for it. We'll talk about some of those tactics near the end of the slide. I also have other videos that I'm working on talking more about some of these specific tactics. Then finally, another research body is ITER, the is the International Fusion Research entity. It's got 35 nations working together to solve fusion. And so the point point being is that there are actually many many many examples of international and global cooperation in order to provide safety stability and research as well as regulations. So when we propose to do the same thing for artificial intelligence, it's not like this has never been done before. We've actually done this many times before. So let's talk about how these hypothetical global entities might work. So the first one that I propose is Gaia, the global AI agency. And of course, Gaia also means Earth. So the mandate for Gaia would be very, very, very simple. Study and prevent existential risks from AI. That's it. That is its primary purpose. It would publish open source scientific research, papers, data sets, and align models. And by making those models publicly available to everyone, that will one, make access to artificial intelligence much more democratic. models and by making those models publicly available to everyone, it will that will one make access to artificial intelligence much more democratic, but it will also help saturate the world with alignment, research and alignment data and alignment models. It would also participate in global policy recommendations, advising nations, advising militaries, and it would also establish best practices and guidelines that could be used by everyone, nations, corporations, and so on. And so by creating a global authority, a global scientific authority that says, yes, we understand, and the idea is just to comprehend this problem. Not to punish anyone, not to put on the brakes, but actually to focus exclusively on research. Initial funding should be around $500 million, similar to the IAEA. And membership should be probably pretty similar to CERN or NATO, which are international but not necessarily global. And the reason that I suggest that is because there is presently a competitive dynamic in the world. And so basically, in order to benefit from this global AI research effort, then nations should have to pass certain muster. For instance, non-aggressive use of AI and not actively be at war or whatever, something like that. I could be wrong. I'm not an international policy expert yet, so it might be that there are problems with that. But between CERN, ITER, and other entities, it looks like that there are problems with that, but between CERN, EDAR, and other entities, it looks like that global research is not necessarily something that has been done yet, but certainly international research. Yep, so that's it for Gaia. The next one is GARSA or Garcia, the Global AI Regulatory and Compliance Agency. So this one would basically be like kind of a combination of GDPR, but for the globe and for AI, right? So it would inspect, certify, and regulate AI hardware and software. So this looks at the hardware and software aspects of AI, rather than the data or policy. But what it would use is it would use similar litmus tests and also like sanctions or regulations as to what the IMF does. in the investment world, in the finance world, if a company is not GDPR compliant, it will not get any investment. Why? Because investors say you're not compliant, you're at risk of getting shut down. The same is also true of ESG, which ESG is an inside the industry standard. So ESG means environmental, social, and governance. So the idea is that if you don't get that ESG stamp of approval, you're going to have a much harder time getting investment. And so rather than enforcing it through more strong arm approaches, my recommendation for the Global AI Regulatory and Compliance Agency is to perform those inspections, to perform those tests, to basically be an underwriter, a global underwriter of AI companies' products and services. And so then if the Garcia agency decertifies a company, then one, their share price is gonna go down because everyone's like, oh, they're not AI compliant, they might get shut down, they might get raided or investigated or sued or whatever. But then if, conversely, if they are, if they do get certified as AI alignment compliant, then you know, they get more grants, more handouts, more whatever. And so this is, this is why I included the IMF in the World Bank, is because you can, you can absolutely steer policy, research policy research development and other behaviors with financial incentives. And that also creates a relatively lightweight agency that they don't have to do a whole lot of heavy lifting themselves, but rather they provide that underwriting that certification and decertification, which can then steer the behaviors of the rest of the world. So this overall strategy is about having gas and brakes because one thing that people are legitimately worried about is that if we slow down too much someone else is going to pick up the speed right. In a global competitive landscape the nation that slows down is the one that loses. So we need gas, but we also need brakes. In order to win any race, you actually need both. So I play Forza. I've actually been, I've played Forza since the very original Forza, and so if you're not familiar, Forza is a simulation grade racing game. And you know, if you're driving a Ferrari or a Lamborghini or you know whatever else you know high performance your Mercedes AMG around a track you don't just use the gas if you just use the gas you crash. So in order to win a race you actually do need both gas and brakes. And so this is the one-two punch of creating two different entities, one for acceleration, Gaia, and the other for braking, Garcia. And the idea is that they will have independent oversight and funding, which means that also because they have entirely different mandates, those entities are going to have different methods of acting, as well as different incentive structures. So they have those different mandates, they have different KPI. Now that being said, they also both would have an international or global scope, and the reason is because AI is going to affect everyone on the planet, whether or not they participate. And then finally part of the strategy is is both risk mitigation and encouraging innovation. And so if we do both then we should be on the right track. So here's a few more tactics. I promise that we would talk about some various tactics that they can use. So the first tactic is just grants. If you want to fund research you hand out money to do it. It's really that simple you you incentivize the behavior you want to see with you know, you know you dangle money and people will go do it certification and compliance. Like I said GDPR is a pretty good example because GDPR is a pretty powerful lever in order to get companies to comply with data policy. Training and education. So many of the organizations that we talked about do provide training and education. And so by providing training and education, you can raise the global literacy on artificial intelligence, whether it's just AI ethics and safety or the existential risks. So by by having global authorities that provide this training and education and certification programs, you can say like, you know, I'm a guy, a certified existential expert or whatever, because right now we don't have any global standard of, yes, this is what the global experts agree on are the issues and the concerns and stuff. Certainly we have those conversations, right? If you're watching my channel, you probably watch like Robert Miles and AI Explained and everyone else, Eliezer, like, so you probably are aware that these conversations are happening, but there is no coherent authority. There is no establishment saying, yes yes we are working on this. Which is part of the reason that a lot of us are like hey we need to do something about this. Another possibility is that you can actually do competitions. So in terms of AI one of the best competitions is Kaggle which is a it's a competition platform where independent sponsors can come in and say, hey, we want you to compete to try and solve this problem over here. OpenAI is doing their competition right now, which is based on grants for the independent or democratic inputs to AI. DARPA is another one. So DARPA is the Defense Advanced Research Projects Agency here in America, which funds amongst many many other things advanced research on things like PTSD regeneration but also self-driving cars. So the DARPA like I can't remember the name of the challenge was like the desert challenge or something started many many years ago was about creating self-driving cars and so by creating competitions you get all kinds of teams coming to you, whether it's universities and independent research groups, corporations, all participating in the research for the lure of a prize, which of course is a good way to surface innovative ideas. Putting on conferences. now. There are there are international artificial intelligence conferences like Nureps, but none of them are focused exclusively on global safety, whether it's existential risks from you know, autonomous AGI or even just the escalating risk of autonomous and semi autonomous systems such as weapon systems and so on. So by creating international or global conferences where you deliberately get all the experts in a room talking together that is a good way to advance the conversation. Policy recommendations I already mentioned this earlier in the video where if you have a global authority on something if a nation comes to you and says, hey, we want to spurn AI development, what kind of policies do we do in order to attract that talent? Right, that's an example of a policy recommendation. Or in other cases where a nation might come to these international agencies and say, hey, we have a lot of AI abuse going on, people are using it to be exploitative, how do we tamp down on that successfully while avoiding unintended consequences? Industry partnerships are another way that these agencies could help bring about the change. An example is the IEEE, kind of help bring about the change which so an example is the IEEE which is a which is a was it the international engineering something or other anyways sets a lot of standards for and work shopping for standards basically created wi-fi bluetooth a whole bunch of other stuff that you are familiar with which also helps helps establish standards and interoperability. Consultation and review. So this is something that I do at a very low level through my Patreon, is I have a bunch of small and medium businesses come to me where they just want consultation. How do I align AI? How do I use AI responsibly, but also make money at the same time? And I would certainly encourage anyone who has expertise in AI to build a startup or something around this idea. But this is also something that can be done at the national or international level, where not just providing policy advice, but actually providing technical assistance where required, especially in the deployment of AI safety and alignment research. Published standards and guidelines, I already mentioned that. And then finally, public awareness and messaging. That's what I and a lot of other people do with our YouTube platforms, TikTok, and everything else. But again, there is no global authority taking any responsibility for this messaging, which we view as problematic because, you know, basically it comes down to it feels like there's no adults in the room. And that's really scary. Can you imagine if we lived in a world still where the World Health Organization didn't exist, even for some of their faults and failures, you still prefer that the World Health Organization exists. Because like I said, there's a lot of diseases that you've probably never heard about because of the work that they do. Likewise, you want to live in a world where if there are nuclear weapons and nuclear reactors, you want to live in a world where the IAEA exists. nuclear weapons and nuclear reactors, you want to live in a world where the IAEA exists. And so because of the existence of those organizations, we have this feeling that there are adults in the room and that there are people paying attention to it and they have the resources that they need in order to effect good change and guidance. And so this is why one of the primary things that I advocate for, and as part of the GATO framework, the Global Alignment Taxonomy Omnibus, is the establishment of these international treaties, whether they're modeled on GDPR or these other organizations. This is what we see as a critical path towards AI alignment. And this is not just for mitigating existential risk. This is also to avoid dystopian outcomes of hyper corporations becoming quadrillionaires while the rest of us are poor and live under bridges or whatever. So one thing that I will say is that these are necessary but not sufficient. And so what I mean by that is that as my work has progressed as my messaging has progressed the conversation has been shifting. So for instance after my axiomatic alignment video came out a lot of people reached out saying like OK yes you know but there's there's a lot of challenges like you know who gets to who does this research but also like what about what about right what about all these other stuff and not every what about argument is is disingenuous in these cases the conversation has shifted to these other whatabouts not because of doubt but because of like okay we overcome that problem what are the next problems and so this list is some other challenges above and beyond the the you know let's let's say you know we get to wave a magic wand and tomorrow the two organizations that I recommended exist. OK still what's going to happen first is economic barriers. So what I mean by economic barriers is that not every nation is able to contribute or compete at the same way. Certainly the economic lure is there for artificial intelligence. That being said, there might still be some economic barriers, especially when some people are going to be throwing on the brakes. One thing that people are concerned about is regulatory capture. If you raise the bar so high that nobody else can participate except the largest players, they have a de facto monopoly, which is not a good thing. Cultural differences. So the work that I've been doing on axiomatic alignment and convergence has to do with finding the underpinning and universal cultural values that all humans share. After all, yes, there are many differences between nations and cultures, but we're all still the same species, and we're all still on the same planet. So based on those assumptions, or facts, based on those facts, I assume that we can find some common ground somewhere. That being said, there are still pretty fundamental differences between some cultures. Geopolitical tensions, so this is a very diplomatic way of saying that some nations kind of want to shoot at each other. And they are in either conflict or under competition, which is not necessarily, I'm not going to say that it's good or bad, it's problematic in some respects. And then of course scientific breakthroughs. All of this presumes that with the adequate funding and research that we will have scientific breakthroughs on alignment, on AI safety. But this again is aspirational just like how the Eater experiment, the nuclear fusion experiment, it is aspirational. We don't know if it's actually possible. We are hoping that it is possible. And then the next category is game theory. So one of the most common whatabouts that I get now after axiomatic alignment came out is what about people that just are not going to play ball? What about the downstream effects of toxic competition, which you might have also heard, you know, we talked about Moloch and other things. So toxic competition is a very simple way of just saying that in a competitive environment, people, it creates a race to the bottom basically. Perverse incentives and unintended consequences, these are all kind of related to the game theory aspect of this, which is that despite best intentions and best efforts towards achieving a better outcome, you still end up inevitably falling towards dystopia or extinction or collapse. And then of course there's reach and limitations. Just because we create these international organizations doesn't mean that they're going to work. You know if if you get adoption if you get buy in if people blacklist the organizations or whatever. And then finally unknown unknowns. You know we're still we're still working our way to the future. So we need constant vigilance. Anyways, thanks for watching. I hope you got a lot out of this. In the long run, I'm hoping that all of my videos are completely irrelevant because some organizations like this get created and then the real experts get to comment and kind of steer the ship, which we don't have right now, which is really terrifying. So, thanks. I hope I hope this made you feel a little bit better, at least in terms of options that we have before us. Thanks for watching.", "chunks": [{"timestamp": [0.0, 4.0], "text": " Morning everybody David Shapiro here with your weekly video."}, {"timestamp": [4.0, 27.16], "text": " So today's video is about layer 6 of the Gato framework which calls for international treaties or in other words global AI based agencies. what would those look like? Because in many cases, people are just not aware of existing"}, {"timestamp": [27.16, 33.44], "text": " work that has been done on an international or global scale. So I figured we would talk"}, {"timestamp": [33.44, 40.96], "text": " about those and then also first talk about what exists and then also talk about how a"}, {"timestamp": [40.96, 47.38], "text": " version of those for AI would look. Apologies. So real quick, just before we jump in,"}, {"timestamp": [47.38, 48.76], "text": " I'll plug my Patreon."}, {"timestamp": [48.76, 52.28], "text": " I have a private Discord server for all Patreon supporters,"}, {"timestamp": [52.28, 55.56], "text": " and I also have weekly office hours"}, {"timestamp": [55.56, 57.84], "text": " for the premium tier Patreon supporters."}, {"timestamp": [57.84, 59.44], "text": " I also do have a higher tier,"}, {"timestamp": [59.44, 60.9], "text": " which allows for one-on-one calls,"}, {"timestamp": [60.9, 63.8], "text": " but at least as of the recording of this,"}, {"timestamp": [63.8, 70.72], "text": " I have no slots available. That being said I do add slots occasionally. You know there's churn. It"}, {"timestamp": [70.72, 76.28], "text": " happens. Okay moving right along. So for some background, a few weeks ago Sam"}, {"timestamp": [76.28, 79.92], "text": " Altman, Gary Marcus, and Christina Montgomery testified before Congress"}, {"timestamp": [79.92, 83.76], "text": " about artificial intelligence and one of the things that they asked for was"}, {"timestamp": [83.76, 86.0], "text": " regulation. All three of them asked that they asked for was regulation."}, {"timestamp": [86.0, 89.32], "text": " All three of them asked for it in certain respects."}, {"timestamp": [89.32, 92.76], "text": " Sam Altman, obviously the CEO of OpenAI,"}, {"timestamp": [92.76, 94.88], "text": " has been calling for various kinds of regulation"}, {"timestamp": [94.88, 96.16], "text": " for a while."}, {"timestamp": [96.16, 98.88], "text": " Christina, who comes from IBM, she"}, {"timestamp": [98.88, 100.92], "text": " was a little bit more, let's say,"}, {"timestamp": [100.92, 103.18], "text": " corporate sanitized in the way that she asked."}, {"timestamp": [103.18, 105.52], "text": " But she basically said that IBM's"}, {"timestamp": [105.52, 112.8], "text": " policy has always been to be more in favor of regulation, including going back to social"}, {"timestamp": [112.8, 113.8], "text": " media."}, {"timestamp": [113.8, 119.08], "text": " And I checked on IBM's website and they actually do have some policies and recommendations,"}, {"timestamp": [119.08, 123.12], "text": " obviously, they have to be very diplomatic about it because they are not a political"}, {"timestamp": [123.12, 130.16], "text": " entity. And of course, we already have a lot of, in my opinion, too much interference between"}, {"timestamp": [130.16, 134.28], "text": " the corporate establishment and American politics."}, {"timestamp": [134.28, 143.72], "text": " That being said, you know, IBM has expressly asked for more regulation on social media,"}, {"timestamp": [143.72, 146.8], "text": " AI, and other uses of technology for a while."}, {"timestamp": [146.8, 165.68], "text": " So Gary Marcus is a professor and researcher. So this this panel if you missed it was a good mix of private industry as well as academia and they were all basically saying the same thing. So Gary Marcus explicitly said we need a new cabinet level agency. So"}, {"timestamp": [165.68, 172.4], "text": " cabinet level agency is like FDA, you know, or or some someone who's the head of which reports"}, {"timestamp": [172.4, 177.2], "text": " directly to like the White House or or the like, you know, Joint Chiefs of Staff or whatever."}, {"timestamp": [177.92, 183.12], "text": " I know the Joint Chiefs of Staff is for military, but you never know. Like we created a space force,"}, {"timestamp": [183.76, 185.14], "text": " you know, NASA was the research"}, {"timestamp": [185.14, 190.04], "text": " branch and now we have a Space Force and who knows maybe we will ultimately have an AI"}, {"timestamp": [190.04, 192.48], "text": " division for military."}, {"timestamp": [192.48, 197.54], "text": " But anyways, so one of the when when pressed Gary Marcus said that, you know, one model"}, {"timestamp": [197.54, 206.24], "text": " that we could pursue would be the FDA but for AI and the the example that he gave is that when you release a drug to"}, {"timestamp": [206.24, 211.44], "text": " you know 300 million people you you make sure that it's safe you make sure that"}, {"timestamp": [211.44, 216.88], "text": " it has that has really passed muster one of the senators interviewing him said he"}, {"timestamp": [216.88, 221.24], "text": " disagreed but you know he appreciated the sentiment and then there was also"}, {"timestamp": [221.24, 226.3], "text": " talk about well what what other existing entities could be empowered, right?"}, {"timestamp": [226.3, 230.0], "text": " Like, what about the FTC or SEC or whatever?"}, {"timestamp": [230.0, 238.3], "text": " And there's actually a lot of people that advocate that say, like, yes, all government agencies must become AI-aware, AI-literate."}, {"timestamp": [238.3, 246.96], "text": " But another point is that AI is such a distinctive and powerful force that it warrants its own agency. Just like"}, {"timestamp": [246.96, 253.44], "text": " how America has the Department of Energy, which focuses specifically on generation and management"}, {"timestamp": [253.44, 261.52], "text": " of energy, OpenAI has also explicitly called for an international agency. They call for IAEA,"}, {"timestamp": [261.52, 269.92], "text": " but for AI. So the IAEA is the International Atomic Energy Agency which has to do with inspecting nuclear sites."}, {"timestamp": [271.16, 279.68], "text": " So the conversation is there the conversation is happening. People are calling for national and international levels of A.I."}, {"timestamp": [280.2, 285.0], "text": " not just regulation. Yes. But I'm also calling for AI research."}, {"timestamp": [285.0, 290.0], "text": " And I've got plenty of examples of existing international research bodies to share."}, {"timestamp": [290.0, 294.0], "text": " So first we're going to talk a little bit about the IAEA."}, {"timestamp": [294.0, 299.0], "text": " It was established in 1957 under the United Nations."}, {"timestamp": [299.0, 302.0], "text": " It is an autonomous entity."}, {"timestamp": [302.0, 310.36], "text": " Its primary purpose is, of course, to promote the peaceful use of nuclear energy, inhibit its use for military purposes, and ensure nuclear safety and security."}, {"timestamp": [310.36, 315.64], "text": " You swap that out with artificial intelligence, and that's exactly what we need."}, {"timestamp": [315.64, 326.72], "text": " It is governed by the General Conference of the UN and has a board of governors that is appointed from 35 members of the UN."}, {"timestamp": [326.72, 333.6], "text": " As of 2021, it had 171 member states, and its annual budget is only 500 million euros,"}, {"timestamp": [333.6, 339.04], "text": " which is probably lower than you might think, especially when we're talking about the astronomical"}, {"timestamp": [339.04, 343.2], "text": " amount of money that artificial intelligence could possibly generate."}, {"timestamp": [343.2, 348.3], "text": " And so then if you say, OK, well, we are asking for the foundation of something similar,"}, {"timestamp": [348.3, 354.1], "text": " but for artificial intelligence, maybe we start at the same part, at about half a billion euros."}, {"timestamp": [354.1, 359.8], "text": " If the entire world chips in, that's actually a pretty trivial amount of money."}, {"timestamp": [359.8, 363.5], "text": " So you divide 171 member states by 500 million euros,"}, {"timestamp": [363.5, 367.64], "text": " and like 3 million euros or $3 million"}, {"timestamp": [367.64, 369.9], "text": " per member state."}, {"timestamp": [369.9, 371.2], "text": " That's a drop in the bucket."}, {"timestamp": [371.2, 376.74], "text": " So we could easily, easily, easily afford to fund such an agency."}, {"timestamp": [376.74, 378.2], "text": " So you know, well, who's going to pay for it?"}, {"timestamp": [378.2, 379.82], "text": " I don't even want to hear that argument."}, {"timestamp": [379.82, 384.96], "text": " Like that is a trivial like nations could sneeze that and not even remember that they"}, {"timestamp": [384.96, 387.8], "text": " spent that money."}, {"timestamp": [387.8, 395.8], "text": " One of the things that they do is, as I mentioned, they do inspections to verify compliance with nuclear nonproliferation."}, {"timestamp": [395.8, 400.92], "text": " That they also assist in the development of peaceful nuclear programs."}, {"timestamp": [400.92, 412.16], "text": " So they have kind of a one, two thing where they're they're regulating, but they're also educating and supporting and it is based in Vienna, Austria. So you might say, okay,"}, {"timestamp": [412.16, 415.96], "text": " well, yeah, but it's the United Nations. It has no track record or the United Nations"}, {"timestamp": [415.96, 422.2], "text": " isn't effective or whatever, you know, but there is quite a few things that the IAEA"}, {"timestamp": [422.2, 427.36], "text": " has helped with. So the nuclear non-Proliferation Treaty, it actually has"}, {"timestamp": [427.36, 436.24], "text": " a dedicated organization within itself based upon nuclear non-proliferation. It helped after the"}, {"timestamp": [436.24, 442.24], "text": " Chernobyl explosion, which of course, you know, the IAEA could not prevent the Chernobyl explosion,"}, {"timestamp": [442.24, 450.26], "text": " but it helped respond. And so that's another key thing is that a global entity shouldn't just be about regulation"}, {"timestamp": [450.26, 455.74], "text": " and enforcement, but also like disaster mitigation if or when it does happen."}, {"timestamp": [455.74, 459.9], "text": " Nuclear test ban treaty was instrumental in that."}, {"timestamp": [459.9, 466.44], "text": " North Korea, of course, has nuclear ambitions, and the IAEA provides constant monitoring"}, {"timestamp": [466.44, 467.44], "text": " for that."}, {"timestamp": [467.44, 471.9], "text": " It was also instrumental in helping with the Iran nuclear deal, which of course, the relationship"}, {"timestamp": [471.9, 476.84], "text": " between Iran and the rest of the world, particularly the West, has been very strained for many"}, {"timestamp": [476.84, 483.8], "text": " years, but it hasn't been in the news lately, due largely to that nuclear deal that happened"}, {"timestamp": [483.8, 484.8], "text": " under Obama."}, {"timestamp": [484.8, 485.28], "text": " I'm not saying that Obama is responsible for it, it was an international effort, but due largely to that nuclear deal that happened under Obama."}, {"timestamp": [485.28, 489.36], "text": " I'm not saying that Obama is responsible for it, it was an international effort, but just"}, {"timestamp": [489.36, 491.96], "text": " pointing out he was president at the time."}, {"timestamp": [491.96, 498.0], "text": " The Fukushima disaster, so that was after the tsunami that hit Japan."}, {"timestamp": [498.0, 500.88], "text": " The IAEA was part of the coordination effort."}, {"timestamp": [500.88, 508.36], "text": " And then finally, the Director General of the IAEA, Mohammed ElBaradei, got the Nobel"}, {"timestamp": [508.36, 514.36], "text": " Peace Prize in 2005. So, I just want to point out that, yes, this organization does have"}, {"timestamp": [514.36, 520.52], "text": " a track record and has made a name for itself. Now, one of the organizations that I like"}, {"timestamp": [520.52, 525.04], "text": " to think about is CERN. So CERN is European."}, {"timestamp": [525.04, 528.4], "text": " So it is international, but it's not global."}, {"timestamp": [528.4, 532.0], "text": " But it is there to study particle physics."}, {"timestamp": [532.0, 537.08], "text": " And so this was established in 1954 by 12 member countries."}, {"timestamp": [537.08, 541.04], "text": " It also now has 23 total members, including observers."}, {"timestamp": [541.04, 542.2], "text": " There's a few categories."}, {"timestamp": [542.2, 543.96], "text": " So there's the founders, which are Europe."}, {"timestamp": [543.96, 546.7], "text": " And then there's contributors and observers,"}, {"timestamp": [546.7, 548.82], "text": " which includes the United States, Japan,"}, {"timestamp": [548.82, 550.78], "text": " and a few other nations."}, {"timestamp": [550.78, 552.5], "text": " And so this is an international effort"}, {"timestamp": [552.5, 556.86], "text": " to understand the fundamental structure of the universe."}, {"timestamp": [556.86, 559.8], "text": " Its entire mission is literally understand"}, {"timestamp": [559.8, 561.5], "text": " the fundamental structure of the universe,"}, {"timestamp": [561.5, 564.24], "text": " specifically the particles that compose matter"}, {"timestamp": [564.24, 571.04], "text": " and the forces that hold them together. So as of 2020, for whatever reason, finding the budget of"}, {"timestamp": [571.04, 577.68], "text": " CERN is rather difficult. All nations report in terms of like percentages of how much they support"}, {"timestamp": [577.68, 581.84], "text": " it, but like getting a total number like what was your budget, hard to find for whatever reason."}, {"timestamp": [582.48, 588.28], "text": " Anyways, I think that the annual budget of certain is about 1.1 billion dollars and of"}, {"timestamp": [588.28, 596.16], "text": " course they run large Hadron Collider and a few other major major major experiments."}, {"timestamp": [596.16, 602.1], "text": " So CERN if you are not aware of is the organization that invented the World Wide Web."}, {"timestamp": [602.1, 610.0], "text": " This is a copy of the original proposal that led to the World Wide Web, and at the top, someone wrote,"}, {"timestamp": [610.0, 620.0], "text": " vague but exciting. So that is, many people, particularly in computer science, will understand that reference."}, {"timestamp": [620.0, 632.52], "text": " So this was the initial proposal for the World Wide Web. It's discovered in a whole raft of fundamental elementary particles, bosons, Higgs boson,"}, {"timestamp": [632.52, 637.0], "text": " creation of antimatter using neutrinos, all sorts of stuff."}, {"timestamp": [637.0, 642.16], "text": " And of course, we've got the Large Hadron Collider, which generates many, many hundreds"}, {"timestamp": [642.16, 643.96], "text": " of terabytes of data."}, {"timestamp": [643.96, 645.88], "text": " And it's interesting to bring this one up,"}, {"timestamp": [645.88, 648.84], "text": " because actually, as a science nerd,"}, {"timestamp": [648.84, 651.82], "text": " I was watching a documentary about CERN and LHC"}, {"timestamp": [651.82, 653.18], "text": " a few years ago."}, {"timestamp": [653.18, 656.72], "text": " And the LHC actually generates so much data"}, {"timestamp": [656.72, 658.5], "text": " that they need artificial intelligence"}, {"timestamp": [658.5, 661.72], "text": " to sift through the data to help find the phenomenon,"}, {"timestamp": [661.72, 663.68], "text": " to find the anomalies."}, {"timestamp": [663.68, 670.24], "text": " And so there's actually a very tight feedback loop between, for instance, nuclear research and artificial intelligence."}, {"timestamp": [671.2, 676.64], "text": " So those are two organizations that have kind of the research mandate and then the regulation and"}, {"timestamp": [676.64, 681.76], "text": " safety mandate. And I think we need both for artificial intelligence. There's a few other"}, {"timestamp": [681.76, 685.2], "text": " international bodies that we can pay attention to that are probably"}, {"timestamp": [685.2, 690.88], "text": " either going to be good models that we can base this on or they could actually even be"}, {"timestamp": [690.88, 692.44], "text": " partners."}, {"timestamp": [692.44, 697.5], "text": " So one another global organization that is more for emergency response is the World Health"}, {"timestamp": [697.5, 705.2], "text": " Organization which of course helped coordinate global the global response to the covid epidemic,"}, {"timestamp": [705.2, 709.2], "text": " but they've also responded to SARS MERS Ebola and other stuff."}, {"timestamp": [709.2, 716.2], "text": " So my uncle is a microbiologist and so a few years ago when there was a couple of outbreaks of Ebola."}, {"timestamp": [716.2, 723.2], "text": " He actually traveled the world to help be part of the World Health Organization response to contain Ebola"}, {"timestamp": [723.2, 726.48], "text": " and then of course MERS is something that you might not have heard of,"}, {"timestamp": [726.48, 732.32], "text": " but it was infinitely more dangerous than COVID. The mortality rate of MERS can be over 10 percent,"}, {"timestamp": [733.52, 739.04], "text": " and so like it's a there's some really horrible diseases that you have never heard of because of"}, {"timestamp": [739.04, 747.34], "text": " the World Health Organization. There's two financial global entities. Both were created at Bretton Woods after World War two and"}, {"timestamp": [747.78, 752.96], "text": " So World War two caused a lot of people to come together and say we need to prevent this from happening again"}, {"timestamp": [752.96, 757.1], "text": " And so one of the things that they decided after World War two was that economic?"}, {"timestamp": [758.2, 764.34], "text": " Improvement and economic stability and economic cooperation were critical to maintaining global peace"}, {"timestamp": [764.34, 765.52], "text": " Which has more or"}, {"timestamp": [765.52, 772.24], "text": " less worked up until now. But it's, you know, time will tell because we're facing a backlash"}, {"timestamp": [772.24, 778.72], "text": " against globalization. Anyways, getting lost in the weeds. So the point of the IMF is to stabilize"}, {"timestamp": [778.72, 791.02], "text": " the global economy through cooperation, trade, exchange, and so on. so members of the IMF Will get loans the IMF has been responsible for some bailouts. They also have been responsible for"}, {"timestamp": [792.24, 794.2], "text": " not necessarily"}, {"timestamp": [794.2, 798.68], "text": " Economic sanctions but economic requirements. So for instance during the global recession"}, {"timestamp": [799.2, 804.04], "text": " The IMF was the entity responsible for telling nations such as Greece"}, {"timestamp": [804.2, 805.34], "text": " You need austerity"}, {"timestamp": [805.34, 808.06], "text": " measures before we're going to bail you out."}, {"timestamp": [808.06, 815.96], "text": " And so the idea of the IMF is that it uses that ability to withhold funds in order to"}, {"timestamp": [815.96, 822.62], "text": " shape national policy more towards stability rather than things like hyperinflation or"}, {"timestamp": [822.62, 829.4], "text": " economic collapse. And the situation in Greece is still not good"}, {"timestamp": [829.4, 831.24], "text": " after many, many years."}, {"timestamp": [831.24, 835.02], "text": " That being said, we don't hear about the Greek economy"}, {"timestamp": [835.02, 836.56], "text": " collapsing in the news all the time."}, {"timestamp": [836.56, 838.6], "text": " Granted, I don't pay attention to Greek news,"}, {"timestamp": [838.6, 843.34], "text": " but it doesn't make it into American financial news."}, {"timestamp": [843.34, 847.96], "text": " The World Bank has a slightly different mandate than the IMF."}, {"timestamp": [847.96, 854.02], "text": " So while the IMF more focuses on developed nations, the World Bank has the goal of ending"}, {"timestamp": [854.02, 860.88], "text": " extreme poverty through financial means and also to boost global prosperity through lending"}, {"timestamp": [860.88, 862.16], "text": " and advising."}, {"timestamp": [862.16, 865.82], "text": " So the World Bank is more likely to issue loans"}, {"timestamp": [865.82, 871.14], "text": " to developing nations. And the reason that I bring both of these up is because"}, {"timestamp": [871.14, 875.9], "text": " artificial intelligence has the ability to profoundly impact artificial"}, {"timestamp": [875.9, 881.24], "text": " intelligence all over the world and and greatly advance the missions of both of"}, {"timestamp": [881.24, 885.52], "text": " these entities. And one of the best ways to incentivize aligned"}, {"timestamp": [885.52, 887.4], "text": " development is to pay for it."}, {"timestamp": [887.4, 892.2], "text": " We'll talk about some of those tactics near the end of the slide."}, {"timestamp": [892.2, 896.04], "text": " I also have other videos that I'm working on talking more about some of these specific"}, {"timestamp": [896.04, 897.04], "text": " tactics."}, {"timestamp": [897.04, 907.2], "text": " Then finally, another research body is ITER, the is the International Fusion Research entity."}, {"timestamp": [907.2, 910.6], "text": " It's got 35 nations working together to solve fusion."}, {"timestamp": [910.6, 914.9], "text": " And so the point point being is that there are actually many many many"}, {"timestamp": [914.9, 921.2], "text": " examples of international and global cooperation in order to provide safety"}, {"timestamp": [921.2, 924.1], "text": " stability and research as well as regulations."}, {"timestamp": [924.1, 927.16], "text": " So when we propose to do the same thing"}, {"timestamp": [927.16, 930.84], "text": " for artificial intelligence, it's"}, {"timestamp": [930.84, 932.48], "text": " not like this has never been done before."}, {"timestamp": [932.48, 935.28], "text": " We've actually done this many times before."}, {"timestamp": [935.28, 938.08], "text": " So let's talk about how these hypothetical global entities"}, {"timestamp": [938.08, 940.24], "text": " might work."}, {"timestamp": [940.24, 942.04], "text": " So the first one that I propose is"}, {"timestamp": [942.04, 944.84], "text": " Gaia, the global AI agency."}, {"timestamp": [944.84, 946.64], "text": " And of course, Gaia also means Earth."}, {"timestamp": [946.64, 950.56], "text": " So the mandate for Gaia would be very, very, very simple."}, {"timestamp": [950.56, 953.2], "text": " Study and prevent existential risks from AI."}, {"timestamp": [953.2, 953.6], "text": " That's it."}, {"timestamp": [953.6, 955.04], "text": " That is its primary purpose."}, {"timestamp": [956.08, 960.24], "text": " It would publish open source scientific research, papers, data sets, and align models."}, {"timestamp": [961.12, 964.64], "text": " And by making those models publicly available to everyone,"}, {"timestamp": [965.0, 965.2], "text": " that will one, make access to artificial intelligence much more democratic. models and by making those models publicly available to everyone,"}, {"timestamp": [969.44, 969.64], "text": " it will that will one make access to artificial intelligence much more"}, {"timestamp": [974.36, 974.56], "text": " democratic, but it will also help saturate the world with alignment,"}, {"timestamp": [977.32, 977.52], "text": " research and alignment data and alignment models."}, {"timestamp": [980.04, 980.24], "text": " It would also participate in global"}, {"timestamp": [984.32, 989.68], "text": " policy recommendations, advising nations, advising militaries, and it would also establish best practices and guidelines"}, {"timestamp": [989.68, 993.16], "text": " that could be used by everyone, nations, corporations,"}, {"timestamp": [993.16, 994.52], "text": " and so on."}, {"timestamp": [994.52, 998.16], "text": " And so by creating a global authority,"}, {"timestamp": [998.16, 1003.2], "text": " a global scientific authority that says, yes, we understand,"}, {"timestamp": [1003.2, 1007.56], "text": " and the idea is just to comprehend this problem."}, {"timestamp": [1007.56, 1010.72], "text": " Not to punish anyone, not to put on the brakes,"}, {"timestamp": [1010.72, 1015.2], "text": " but actually to focus exclusively on research."}, {"timestamp": [1015.2, 1018.56], "text": " Initial funding should be around $500 million,"}, {"timestamp": [1018.56, 1020.28], "text": " similar to the IAEA."}, {"timestamp": [1020.28, 1023.7], "text": " And membership should be probably pretty similar"}, {"timestamp": [1023.7, 1025.0], "text": " to CERN or NATO,"}, {"timestamp": [1025.0, 1028.0], "text": " which are international but not necessarily global."}, {"timestamp": [1028.0, 1036.0], "text": " And the reason that I suggest that is because there is presently a competitive dynamic in the world."}, {"timestamp": [1036.0, 1041.0], "text": " And so basically, in order to benefit from this global AI research effort,"}, {"timestamp": [1041.0, 1045.32], "text": " then nations should have to pass certain muster."}, {"timestamp": [1045.32, 1048.44], "text": " For instance, non-aggressive use of AI"}, {"timestamp": [1048.44, 1054.12], "text": " and not actively be at war or whatever, something like that."}, {"timestamp": [1054.12, 1057.16], "text": " I could be wrong."}, {"timestamp": [1057.16, 1059.44], "text": " I'm not an international policy expert yet,"}, {"timestamp": [1059.44, 1062.8], "text": " so it might be that there are problems with that."}, {"timestamp": [1062.8, 1067.2], "text": " But between CERN, ITER, and other entities, it looks like that there are problems with that, but between CERN, EDAR, and other entities,"}, {"timestamp": [1067.2, 1071.28], "text": " it looks like that global research is not necessarily something that has been done yet,"}, {"timestamp": [1071.28, 1079.12], "text": " but certainly international research. Yep, so that's it for Gaia. The next one is"}, {"timestamp": [1079.12, 1089.48], "text": " GARSA or Garcia, the Global AI Regulatory and Compliance Agency. So this one would basically be like kind of a combination"}, {"timestamp": [1089.48, 1093.66], "text": " of GDPR, but for the globe and for AI, right?"}, {"timestamp": [1093.66, 1095.86], "text": " So it would inspect, certify, and regulate"}, {"timestamp": [1095.86, 1097.7], "text": " AI hardware and software."}, {"timestamp": [1097.7, 1102.74], "text": " So this looks at the hardware and software aspects of AI,"}, {"timestamp": [1102.74, 1126.88], "text": " rather than the data or policy. But what it would use is it would use similar litmus tests and also like sanctions or regulations as to what the IMF does. in the investment world, in the finance world, if a company is not GDPR compliant,"}, {"timestamp": [1126.88, 1128.6], "text": " it will not get any investment."}, {"timestamp": [1128.6, 1129.44], "text": " Why?"}, {"timestamp": [1129.44, 1130.48], "text": " Because investors say you're not compliant,"}, {"timestamp": [1130.48, 1132.28], "text": " you're at risk of getting shut down."}, {"timestamp": [1132.28, 1134.98], "text": " The same is also true of ESG,"}, {"timestamp": [1134.98, 1138.32], "text": " which ESG is an inside the industry standard."}, {"timestamp": [1138.32, 1141.64], "text": " So ESG means environmental, social, and governance."}, {"timestamp": [1141.64, 1144.52], "text": " So the idea is that if you don't get that ESG stamp"}, {"timestamp": [1144.52, 1145.78], "text": " of approval, you're going to have"}, {"timestamp": [1145.78, 1148.08], "text": " a much harder time getting investment."}, {"timestamp": [1148.08, 1157.66], "text": " And so rather than enforcing it through more strong arm approaches, my recommendation for"}, {"timestamp": [1157.66, 1162.24], "text": " the Global AI Regulatory and Compliance Agency is to perform those inspections, to perform"}, {"timestamp": [1162.24, 1166.12], "text": " those tests, to basically be an underwriter, a global underwriter"}, {"timestamp": [1166.12, 1169.12], "text": " of AI companies' products and services."}, {"timestamp": [1169.12, 1174.12], "text": " And so then if the Garcia agency decertifies a company,"}, {"timestamp": [1174.72, 1177.56], "text": " then one, their share price is gonna go down"}, {"timestamp": [1177.56, 1180.42], "text": " because everyone's like, oh, they're not AI compliant,"}, {"timestamp": [1180.42, 1182.56], "text": " they might get shut down, they might get raided"}, {"timestamp": [1182.56, 1186.0], "text": " or investigated or sued or whatever."}, {"timestamp": [1186.0, 1193.18], "text": " But then if, conversely, if they are, if they do get certified as AI alignment compliant,"}, {"timestamp": [1193.18, 1198.3], "text": " then you know, they get more grants, more handouts, more whatever."}, {"timestamp": [1198.3, 1203.58], "text": " And so this is, this is why I included the IMF in the World Bank, is because you can,"}, {"timestamp": [1203.58, 1210.68], "text": " you can absolutely steer policy, research policy research development and other behaviors with financial incentives."}, {"timestamp": [1210.68, 1219.4], "text": " And that also creates a relatively lightweight agency that they don't have to do a whole lot of heavy lifting themselves,"}, {"timestamp": [1219.4, 1232.56], "text": " but rather they provide that underwriting that certification and decertification, which can then steer the behaviors of the rest of the world. So this overall strategy is about having gas and brakes because"}, {"timestamp": [1232.56, 1236.72], "text": " one thing that people are legitimately worried about is that if we slow down too much someone"}, {"timestamp": [1236.72, 1242.0], "text": " else is going to pick up the speed right. In a global competitive landscape the nation that"}, {"timestamp": [1242.0, 1248.04], "text": " slows down is the one that loses. So we need gas, but we also need brakes."}, {"timestamp": [1248.04, 1251.4], "text": " In order to win any race, you actually need both."}, {"timestamp": [1251.4, 1252.72], "text": " So I play Forza."}, {"timestamp": [1252.72, 1257.92], "text": " I've actually been, I've played Forza since the very original Forza, and so if you're"}, {"timestamp": [1257.92, 1262.96], "text": " not familiar, Forza is a simulation grade racing game."}, {"timestamp": [1262.96, 1266.6], "text": " And you know, if you're driving a Ferrari or a Lamborghini"}, {"timestamp": [1266.6, 1269.9], "text": " or you know whatever else you know high performance"}, {"timestamp": [1269.9, 1273.8], "text": " your Mercedes AMG around a track you don't just use the"}, {"timestamp": [1273.8, 1276.9], "text": " gas if you just use the gas you crash."}, {"timestamp": [1276.9, 1282.0], "text": " So in order to win a race you actually do need both gas"}, {"timestamp": [1282.0, 1283.3], "text": " and brakes."}, {"timestamp": [1283.3, 1287.6], "text": " And so this is the one-two punch of creating two different entities,"}, {"timestamp": [1288.32, 1293.84], "text": " one for acceleration, Gaia, and the other for braking, Garcia. And the idea is that they will"}, {"timestamp": [1293.84, 1300.64], "text": " have independent oversight and funding, which means that also because they have entirely different"}, {"timestamp": [1300.64, 1305.04], "text": " mandates, those entities are going to have different methods of acting,"}, {"timestamp": [1305.04, 1310.4], "text": " as well as different incentive structures. So they have those different mandates, they have"}, {"timestamp": [1310.4, 1316.88], "text": " different KPI. Now that being said, they also both would have an international or global scope,"}, {"timestamp": [1317.52, 1328.32], "text": " and the reason is because AI is going to affect everyone on the planet, whether or not they participate. And then finally part of the strategy is is both"}, {"timestamp": [1328.4, 1331.04], "text": " risk mitigation and encouraging innovation."}, {"timestamp": [1331.88, 1335.48], "text": " And so if we do both then we should be on the"}, {"timestamp": [1335.48, 1339.72], "text": " right track. So here's a few more tactics. I"}, {"timestamp": [1339.72, 1341.32], "text": " promise that we would talk about some various"}, {"timestamp": [1341.32, 1344.2], "text": " tactics that they can use. So the first tactic is"}, {"timestamp": [1344.2, 1345.8], "text": " just grants."}, {"timestamp": [1345.8, 1348.7], "text": " If you want to fund research you hand out money to do it."}, {"timestamp": [1348.7, 1355.1], "text": " It's really that simple you you incentivize the behavior you want to see with you know,"}, {"timestamp": [1355.1, 1358.6], "text": " you know you dangle money and people will go do it certification"}, {"timestamp": [1358.6, 1362.3], "text": " and compliance. Like I said GDPR is a pretty good example"}, {"timestamp": [1362.3, 1366.0], "text": " because GDPR is a pretty powerful lever"}, {"timestamp": [1366.0, 1370.0], "text": " in order to get companies to comply with data policy."}, {"timestamp": [1370.0, 1371.08], "text": " Training and education."}, {"timestamp": [1371.08, 1373.8], "text": " So many of the organizations that we talked about"}, {"timestamp": [1373.8, 1376.2], "text": " do provide training and education."}, {"timestamp": [1376.2, 1378.84], "text": " And so by providing training and education,"}, {"timestamp": [1378.84, 1381.12], "text": " you can raise the global literacy"}, {"timestamp": [1381.12, 1383.56], "text": " on artificial intelligence, whether it's just"}, {"timestamp": [1383.56, 1385.16], "text": " AI ethics and safety"}, {"timestamp": [1386.48, 1386.84], "text": " or the existential risks."}, {"timestamp": [1388.92, 1390.56], "text": " So by by having global authorities that provide this training and education"}, {"timestamp": [1391.4, 1392.88], "text": " and certification programs,"}, {"timestamp": [1393.12, 1395.16], "text": " you can say like, you know, I'm a guy,"}, {"timestamp": [1395.16, 1397.08], "text": " a certified existential"}, {"timestamp": [1397.08, 1398.08], "text": " expert or whatever,"}, {"timestamp": [1398.76, 1400.6], "text": " because right now we don't have any"}, {"timestamp": [1401.32, 1403.1], "text": " global standard of, yes,"}, {"timestamp": [1403.16, 1406.76], "text": " this is what the global experts agree on are the issues"}, {"timestamp": [1406.76, 1408.68], "text": " and the concerns and stuff."}, {"timestamp": [1408.68, 1411.22], "text": " Certainly we have those conversations, right?"}, {"timestamp": [1411.22, 1415.28], "text": " If you're watching my channel, you probably watch like Robert Miles and AI Explained and"}, {"timestamp": [1415.28, 1420.54], "text": " everyone else, Eliezer, like, so you probably are aware that these conversations are happening,"}, {"timestamp": [1420.54, 1422.38], "text": " but there is no coherent authority."}, {"timestamp": [1422.38, 1426.72], "text": " There is no establishment saying, yes yes we are working on this."}, {"timestamp": [1426.72, 1430.88], "text": " Which is part of the reason that a lot of us are like hey we need to do something about this."}, {"timestamp": [1430.88, 1435.04], "text": " Another possibility is that you can actually do competitions."}, {"timestamp": [1435.04, 1444.88], "text": " So in terms of AI one of the best competitions is Kaggle which is a it's a competition platform where independent sponsors can come in"}, {"timestamp": [1444.88, 1445.0], "text": " and say,"}, {"timestamp": [1445.0, 1449.0], "text": " hey, we want you to compete to try and solve this problem over here."}, {"timestamp": [1449.0, 1452.0], "text": " OpenAI is doing their competition right now,"}, {"timestamp": [1452.0, 1457.0], "text": " which is based on grants for the independent or democratic inputs to AI."}, {"timestamp": [1457.0, 1458.0], "text": " DARPA is another one."}, {"timestamp": [1458.0, 1463.0], "text": " So DARPA is the Defense Advanced Research Projects Agency here in America,"}, {"timestamp": [1463.0, 1465.0], "text": " which funds"}, {"timestamp": [1466.8, 1467.0], "text": " amongst many many other things"}, {"timestamp": [1469.5, 1470.4], "text": " advanced research on things like PTSD regeneration"}, {"timestamp": [1470.5, 1472.2], "text": " but also self-driving cars."}, {"timestamp": [1473.0, 1474.0], "text": " So the DARPA"}, {"timestamp": [1474.6, 1476.3], "text": " like I can't remember the name of the challenge"}, {"timestamp": [1476.3, 1478.0], "text": " was like the desert challenge or something"}, {"timestamp": [1479.0, 1481.3], "text": " started many many years ago was about creating"}, {"timestamp": [1481.3, 1482.4], "text": " self-driving cars"}, {"timestamp": [1483.1, 1484.7], "text": " and so by creating competitions"}, {"timestamp": [1486.0, 1492.48], "text": " you get all kinds of teams coming to you, whether it's universities and independent research groups, corporations,"}, {"timestamp": [1492.48, 1499.36], "text": " all participating in the research for the lure of a prize, which of course is a good way to surface"}, {"timestamp": [1499.36, 1505.5], "text": " innovative ideas. Putting on conferences. now. There are there are"}, {"timestamp": [1505.5, 1508.46], "text": " international artificial intelligence conferences like"}, {"timestamp": [1508.46, 1512.62], "text": " Nureps, but none of them are focused exclusively on global"}, {"timestamp": [1512.62, 1517.02], "text": " safety, whether it's existential risks from you know, autonomous"}, {"timestamp": [1517.02, 1521.42], "text": " AGI or even just the escalating risk of autonomous and semi"}, {"timestamp": [1521.42, 1525.36], "text": " autonomous systems such as weapon systems and so on."}, {"timestamp": [1527.8, 1529.86], "text": " So by creating international or global conferences where you"}, {"timestamp": [1529.86, 1531.92], "text": " deliberately get all the experts in a room talking"}, {"timestamp": [1531.92, 1534.24], "text": " together that is a good way"}, {"timestamp": [1534.24, 1535.88], "text": " to advance the conversation."}, {"timestamp": [1536.4, 1538.4], "text": " Policy recommendations I already mentioned this"}, {"timestamp": [1538.4, 1540.6], "text": " earlier in the video where if"}, {"timestamp": [1540.6, 1542.6], "text": " you have a global authority on something"}, {"timestamp": [1542.92, 1545.08], "text": " if a nation comes to you and says,"}, {"timestamp": [1545.08, 1550.08], "text": " hey, we want to spurn AI development,"}, {"timestamp": [1550.28, 1552.28], "text": " what kind of policies do we do"}, {"timestamp": [1552.28, 1554.4], "text": " in order to attract that talent?"}, {"timestamp": [1554.4, 1557.08], "text": " Right, that's an example of a policy recommendation."}, {"timestamp": [1557.08, 1560.6], "text": " Or in other cases where a nation might come"}, {"timestamp": [1560.6, 1563.44], "text": " to these international agencies and say,"}, {"timestamp": [1563.44, 1567.68], "text": " hey, we have a lot of AI abuse going on,"}, {"timestamp": [1567.68, 1571.68], "text": " people are using it to be exploitative, how do we tamp down on that successfully"}, {"timestamp": [1571.68, 1576.88], "text": " while avoiding unintended consequences? Industry partnerships are another way"}, {"timestamp": [1576.88, 1584.72], "text": " that these agencies could help bring about the change. An example is the IEEE,"}, {"timestamp": [1586.8, 1587.76], "text": " kind of help bring about the change which so an example is the IEEE which is a which is a"}, {"timestamp": [1594.48, 1600.0], "text": " was it the international engineering something or other anyways sets a lot of standards for and work shopping for standards basically created wi-fi bluetooth a whole bunch of other stuff that"}, {"timestamp": [1600.0, 1607.92], "text": " you are familiar with which also helps helps establish standards and interoperability."}, {"timestamp": [1607.92, 1609.68], "text": " Consultation and review."}, {"timestamp": [1609.68, 1612.96], "text": " So this is something that I do at a very low level"}, {"timestamp": [1612.96, 1615.36], "text": " through my Patreon, is I have a bunch"}, {"timestamp": [1615.36, 1617.16], "text": " of small and medium businesses come to me"}, {"timestamp": [1617.16, 1619.08], "text": " where they just want consultation."}, {"timestamp": [1619.08, 1621.12], "text": " How do I align AI?"}, {"timestamp": [1621.12, 1627.08], "text": " How do I use AI responsibly, but also make money at the same time?"}, {"timestamp": [1627.08, 1632.28], "text": " And I would certainly encourage anyone who has expertise in AI to build a startup or"}, {"timestamp": [1632.28, 1634.08], "text": " something around this idea."}, {"timestamp": [1634.08, 1639.0], "text": " But this is also something that can be done at the national or international level, where"}, {"timestamp": [1639.0, 1647.1], "text": " not just providing policy advice, but actually providing technical assistance where required, especially"}, {"timestamp": [1647.1, 1652.4], "text": " in the deployment of AI safety and alignment research."}, {"timestamp": [1652.4, 1654.68], "text": " Published standards and guidelines, I already mentioned that."}, {"timestamp": [1654.68, 1657.22], "text": " And then finally, public awareness and messaging."}, {"timestamp": [1657.22, 1663.44], "text": " That's what I and a lot of other people do with our YouTube platforms, TikTok, and everything"}, {"timestamp": [1663.44, 1666.0], "text": " else. But again, there is no global"}, {"timestamp": [1666.0, 1668.0], "text": " authority taking any responsibility"}, {"timestamp": [1668.0, 1670.0], "text": " for this messaging, which"}, {"timestamp": [1670.0, 1672.0], "text": " we view as problematic"}, {"timestamp": [1672.0, 1674.0], "text": " because, you know,"}, {"timestamp": [1674.0, 1676.0], "text": " basically it comes down to it feels like there's no"}, {"timestamp": [1676.0, 1678.0], "text": " adults in the room. And that's really scary."}, {"timestamp": [1678.0, 1680.0], "text": " Can you imagine if"}, {"timestamp": [1680.0, 1682.0], "text": " we lived in a world still"}, {"timestamp": [1682.0, 1684.0], "text": " where the World Health Organization"}, {"timestamp": [1684.0, 1691.16], "text": " didn't exist, even for some of their faults and failures, you still prefer that the World Health Organization exists."}, {"timestamp": [1691.44, 1696.28], "text": " Because like I said, there's a lot of diseases that you've probably never heard about because of the work that they do."}, {"timestamp": [1696.8, 1704.4], "text": " Likewise, you want to live in a world where if there are nuclear weapons and nuclear reactors, you want to live in a world where the IAEA exists."}, {"timestamp": [1705.6, 1710.76], "text": " nuclear weapons and nuclear reactors, you want to live in a world where the IAEA exists. And so because of the existence of those organizations, we have this feeling that there are adults"}, {"timestamp": [1710.76, 1715.32], "text": " in the room and that there are people paying attention to it and they have the resources"}, {"timestamp": [1715.32, 1720.06], "text": " that they need in order to effect good change and guidance."}, {"timestamp": [1720.06, 1725.48], "text": " And so this is why one of the primary things that I advocate for, and as part of the GATO"}, {"timestamp": [1725.48, 1729.92], "text": " framework, the Global Alignment Taxonomy Omnibus, is the establishment of these international"}, {"timestamp": [1729.92, 1735.2], "text": " treaties, whether they're modeled on GDPR or these other organizations."}, {"timestamp": [1735.2, 1739.8], "text": " This is what we see as a critical path towards AI alignment."}, {"timestamp": [1739.8, 1751.12], "text": " And this is not just for mitigating existential risk. This is also to avoid dystopian outcomes of hyper corporations becoming quadrillionaires"}, {"timestamp": [1751.12, 1756.26], "text": " while the rest of us are poor and live under bridges or whatever."}, {"timestamp": [1756.26, 1762.12], "text": " So one thing that I will say is that these are necessary but not sufficient."}, {"timestamp": [1762.12, 1765.76], "text": " And so what I mean by that is that as my work has progressed as my"}, {"timestamp": [1766.08, 1767.42], "text": " messaging has progressed the"}, {"timestamp": [1767.78, 1769.38], "text": " conversation has been shifting."}, {"timestamp": [1770.44, 1772.28], "text": " So for instance after my"}, {"timestamp": [1772.32, 1774.28], "text": " axiomatic alignment video came out"}, {"timestamp": [1774.6, 1776.44], "text": " a lot of people reached out saying like"}, {"timestamp": [1776.48, 1778.2], "text": " OK yes you know but there's"}, {"timestamp": [1778.44, 1780.3], "text": " there's a lot of challenges like you know who"}, {"timestamp": [1780.32, 1782.4], "text": " gets to who does this research"}, {"timestamp": [1783.76, 1787.88], "text": " but also like what about what about right"}, {"timestamp": [1787.88, 1791.48], "text": " what about all these other stuff and not every what about argument is is"}, {"timestamp": [1791.48, 1796.12], "text": " disingenuous in these cases the conversation has shifted to these other"}, {"timestamp": [1796.12, 1800.52], "text": " whatabouts not because of doubt but because of like okay we overcome that"}, {"timestamp": [1800.52, 1805.54], "text": " problem what are the next problems and so this list is some other challenges"}, {"timestamp": [1805.56, 1807.52], "text": " above and beyond the"}, {"timestamp": [1808.16, 1810.68], "text": " the you know let's let's say you know we get to"}, {"timestamp": [1810.68, 1813.08], "text": " wave a magic wand and tomorrow the two"}, {"timestamp": [1813.08, 1815.28], "text": " organizations that I recommended exist."}, {"timestamp": [1815.48, 1818.26], "text": " OK still what's going to happen first is economic"}, {"timestamp": [1818.26, 1820.82], "text": " barriers. So what I mean by economic barriers"}, {"timestamp": [1821.16, 1823.5], "text": " is that not"}, {"timestamp": [1823.5, 1826.4], "text": " every nation is able to contribute or compete at the same way."}, {"timestamp": [1826.4, 1831.4], "text": " Certainly the economic lure is there for artificial intelligence."}, {"timestamp": [1831.4, 1839.8], "text": " That being said, there might still be some economic barriers, especially when some people are going to be throwing on the brakes."}, {"timestamp": [1839.8, 1843.6], "text": " One thing that people are concerned about is regulatory capture."}, {"timestamp": [1843.6, 1848.34], "text": " If you raise the bar so high that nobody else can participate except the largest players,"}, {"timestamp": [1848.34, 1851.5], "text": " they have a de facto monopoly, which is not a good thing."}, {"timestamp": [1851.5, 1852.5], "text": " Cultural differences."}, {"timestamp": [1852.5, 1859.16], "text": " So the work that I've been doing on axiomatic alignment and convergence has to do with finding"}, {"timestamp": [1859.16, 1863.36], "text": " the underpinning and universal cultural values that all humans share."}, {"timestamp": [1863.36, 1865.34], "text": " After all, yes, there are many differences"}, {"timestamp": [1865.34, 1868.34], "text": " between nations and cultures, but we're all still"}, {"timestamp": [1868.34, 1871.42], "text": " the same species, and we're all still on the same planet."}, {"timestamp": [1871.42, 1876.42], "text": " So based on those assumptions, or facts,"}, {"timestamp": [1877.18, 1879.98], "text": " based on those facts, I assume that we can find"}, {"timestamp": [1879.98, 1881.72], "text": " some common ground somewhere."}, {"timestamp": [1882.54, 1885.86], "text": " That being said, there are still pretty fundamental differences"}, {"timestamp": [1885.86, 1887.82], "text": " between some cultures."}, {"timestamp": [1887.82, 1891.74], "text": " Geopolitical tensions, so this is a very diplomatic way"}, {"timestamp": [1891.74, 1895.38], "text": " of saying that some nations kind of want to shoot at each other."}, {"timestamp": [1895.38, 1901.02], "text": " And they are in either conflict or under competition,"}, {"timestamp": [1901.02, 1904.02], "text": " which is not necessarily, I'm not"}, {"timestamp": [1904.02, 1905.84], "text": " going to say that it's good or bad, it's"}, {"timestamp": [1905.84, 1911.72], "text": " problematic in some respects. And then of course scientific breakthroughs."}, {"timestamp": [1911.72, 1916.84], "text": " All of this presumes that with the adequate funding and research that we"}, {"timestamp": [1916.84, 1922.8], "text": " will have scientific breakthroughs on alignment, on AI safety. But this again is"}, {"timestamp": [1922.8, 1927.84], "text": " aspirational just like how the Eater experiment, the nuclear fusion"}, {"timestamp": [1927.84, 1932.96], "text": " experiment, it is aspirational. We don't know if it's actually possible. We are hoping that it is"}, {"timestamp": [1932.96, 1940.0], "text": " possible. And then the next category is game theory. So one of the most common whatabouts that"}, {"timestamp": [1940.0, 1950.12], "text": " I get now after axiomatic alignment came out is what about people that just are not going to play ball? What about the downstream effects of toxic"}, {"timestamp": [1950.12, 1954.16], "text": " competition, which you might have also heard, you know, we talked about Moloch"}, {"timestamp": [1954.16, 1958.08], "text": " and other things. So toxic competition is a very simple way of just saying that"}, {"timestamp": [1958.08, 1962.8], "text": " in a competitive environment, people, it creates a race to the bottom basically."}, {"timestamp": [1962.8, 1970.4], "text": " Perverse incentives and unintended consequences, these are all kind of related to the game theory"}, {"timestamp": [1970.4, 1974.48], "text": " aspect of this, which is that despite best intentions and best efforts towards"}, {"timestamp": [1974.48, 1980.58], "text": " achieving a better outcome, you still end up inevitably falling towards dystopia"}, {"timestamp": [1980.58, 1985.84], "text": " or extinction or collapse. And then of course there's reach and limitations."}, {"timestamp": [1986.4, 1990.08], "text": " Just because we create these international organizations doesn't mean that they're going to work."}, {"timestamp": [1991.12, 1998.16], "text": " You know if if you get adoption if you get buy in if people blacklist the organizations or whatever."}, {"timestamp": [1998.56, 2000.16], "text": " And then finally unknown unknowns."}, {"timestamp": [2000.88, 2003.52], "text": " You know we're still we're still working our way to the future."}, {"timestamp": [2004.4, 2006.6], "text": " So we need constant vigilance."}, {"timestamp": [2006.6, 2008.52], "text": " Anyways, thanks for watching."}, {"timestamp": [2008.52, 2012.04], "text": " I hope you got a lot out of this."}, {"timestamp": [2012.04, 2015.76], "text": " In the long run, I'm hoping that all of my videos are completely irrelevant because some"}, {"timestamp": [2015.76, 2023.4], "text": " organizations like this get created and then the real experts get to comment and kind of"}, {"timestamp": [2023.4, 2025.8], "text": " steer the ship, which we don't have right now, which"}, {"timestamp": [2025.8, 2026.8], "text": " is really terrifying."}, {"timestamp": [2026.8, 2027.8], "text": " So, thanks."}, {"timestamp": [2027.8, 2031.24], "text": " I hope I hope this made you feel a little bit better, at least in terms of options that"}, {"timestamp": [2031.24, 2032.24], "text": " we have before us."}, {"timestamp": [2032.24, 2032.26], "text": " Thanks for watching."}]}