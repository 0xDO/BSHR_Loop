{"text": " All right gang, David Shapiro here. We are going to wrap up this tutorial series on using ChatGPT to code. So first though I need to do a couple of plugs. So one, I just recorded a really great podcast episode with BaxTeaFuture. That'll be coming out on his channel probably later this week. It was a three and a half hour long conversation and we talked about the, it was in one, one part was a recap of 2022 in terms of AI and technology. And then we pivoted to talk about AI startups because that's all the rage right now. Yeah. So look for, look for that over on his channel. Number two is I need to do a plug for myself. So one of my goals is to be able to do this full-time and I'm not gonna do it with ad revenue. So please consider jumping over to my Patreon page and supporting me on Patreon. One person said that they were confused by the levels. They're no different. I just give you different options for level of support. What I used to do was I used to have where if you paid enough I would give you one-on-one time but I don't have enough time to do that. So instead I just added levels and what you do get if you support me on Patreon is access to my exclusive blog where I'll give you insider updates as to what I'm up to some of my thoughts and also you get like priority access because sometimes I'll ask my patreon's like hey can you connect me to something or I want to talk to you guys so if you want to get on the inside definitely hop over to patreon and then lastly if you want to sync on the inside, definitely hop over to Patreon. And then lastly, if you want to sync up and collaborate with me or my team, please feel free to come and connect with me on LinkedIn. I check LinkedIn far more than Twitter or Discord nowadays. So with that out of the way, let's get back to what we were working on. So here's where we left off. Oh, nope, you don't need to see my Spotify. Let's get back to what we were working on. So here's where we left off. Oh, nope, you don't need to see my Spotify. So we got to the point where we have all of our opinions broken down into JSON files. So let's see, the biggest one is six kilobytes, so that's not too big. And this one got cut off, so this one's not even good, not even usable. That's fine. This one got cut off as well. Part of that was probably token limits. This one was finished. A lot of this is not going to be usable. Remember, this is rapid prototyping. That's why I'm just going as fast as I can and I'm not really trying to make a finished product, but this is proof of concept. We do have some that are good, or mostly good at least. So let's see what we can do. Now, I went to ask GPT, chat GPT, how do we visualize it in a Gephi? So I've seen people talk about Gephi. So I went and downloaded it, got it installed. It's definitely like a free open source one, but unfortunately it only uses GXF or GraphML or CSV, but we've got everything in JSON. So if we wanna visualize any of these, we've got to do it in GXF. I'm not sure what the correct pronunciation is, but graphic exchange or Graph Exchange file. So it's basically a type of XML. So let's see. Let's talk to this guy and say, okay, I've got a folder called, let's see, what did I call this folder? KG underscore JSON. That is full of .json LD formatted KG files. I need to convert them to GXF for Gephi. but here's the problem. Some of the JSON files are malformed, not completed, so we need to first check if they render properly. If not, we can ignore them and skip them. But the second problem is they don't all follow the same format. So let me show you what I mean. So for instance. In this one, there's no graph element, but in others there are. Right. So there's there's no graph element in this one, but then we grab another one. This one has similar. Oh, and so by the way, this is why I say we need to keep fine-tuning, is because when you get to really specific cases like this, you want a very consistent format. But just telling it instructs... So here's an example where there's context and like, yeah, they, there's different like methods. Anyways, so some have, let's see, for instance, some have graph properties and others don't. uh, graph properties and others don't. Um, we need to write a python script that will open them, validate them, um, and homogenize them. We need the the ultimate goal is to output a single Gexf file. Is this even possible? Do we need to break this down into multiple steps? Alright. Let's see what it says. Okay, so it's going to walk through the reasoning that it uses. Okay, there's a valid just walked through the entire process. Someone on the internet, I think it was on LinkedIn, said, ChatGPT is going to make everyone dumber and lazier. You should learn to do it yourself. And I definitely agree. So let's talk about this because this video is not going to take too long. But let's talk about the implications of this for a second. I'm in this headspace because I just had that interview with Bax. So this just taught me a whole bunch of stuff that I didn't know. I didn't know about the Pi LD thing. I didn't know about the PyLD thing. I didn't know about NetworkX. So I just had a problem and I said, help me solve this problem. Now does that make me dumber? Because I didn't go read the hard way. I downloaded the Gephi documentation, but this is still like I have to skim and it's 32 pages, that's a lot of reading. What is ultimately valuable? Time. Time is the most valuable commodity in all of existence. It's more precious than gold. So the fact that this is able to help me do more in less time, and I will learn some of the underlying stuff in the wash. So here's the thing is like, we build machines to abstract away some of our labor. That's what computers do. That's why they have the name computer, they compute math. That was how they started was, what some of the first use cases of mechanical computers was to calculate firing solutions for big Navy guns during World War II. And the women who did that, who did all the math, they were called computers. It was the computer pool, but it was human computers. Anyways, so we always build machines to offload our mental labor. So this is just the next iteration of that. Now I'm not saying this is not the same as a TI-83 calculator. This is miles beyond that. But at the same time, this will ultimately allow me to do more, experiment faster, and generally accelerate things. And nobody bemoans databases, right? To me, if someone's complaining like, oh, this just makes you lazy, that's about the same as saying like, oh, well, you should just print everything out and manually collate your database. Like, no, we're not going to do that. Use SQL. And so to me, it's like, and I'm saying this as someone who is typically like a Luddite, like I am the last person to adopt new technologies usually, especially in my day job, in my professional life, because you know what? New stuff is fragile and it breaks, and it's expensive, and it's difficult to integrate, whatever, et cetera, et cetera. But this is different. ChatGPT is different because this is helping me do better. Here, I'm going to give you a nice little kudos feedback. This is great. I don't know why you have to like ... All you need is a true false, right? Actually no. I bet they're asking you why because that is an even better label and they can improve it further. Anyways, so ... All right, get off my soapbox. That's not why y'all are here, let's move on. Excuse me. Okay, so this is fine. Use it to parse and load it into Python dictionary, that's fine. All right, so let's see. Great idea. Let's start with the first script. This first one will use JSON module to try to load the JSON. We should use a try except clause in case it blows up. If the JSON doesn't even load, we can move on. Okay, cool. Let's see. Once the JSON object is loaded into memory, then please use the pyld library function is valid JSON LD to check if it is legit. Assuming it passes that, let's see. Assuming it passes that, well, actually here, please write this script. Yeah. And then while it's doing that, I'm going to go ahead and see if I need to install anything. So pip install pild. And then let's see what else did I need. We need, I think that's as far as we need right now. So let's do pip install network x. All right. This looks good. We're gonna need to add the encoding UTF-8. Okay, so it'll tell us if it is valid and if not. Excellent, so let's go ahead and give this a try. If not, excellent. So let's go ahead and give this a try. So then we'll save this here as step 03, validate JSON.py. Excuse me. All right, and then let's come over here, let me zoom in a little bit. And we'll do CD to SCOTUS. And then we'll do Python. Wow. Sorry, my typing is horrible. I think I moved my keyboard around and it's like just slightly to the left. And so like my fingers are wrong. Muscle memory is everything, man. All right. Python. What was it? Step? I have two step threes. That's that's incorrect. That's going to mess with my my OCD. Sorry, buddy. Step 0 4. No, don't keep it in. That's the wrong file. All right. Come back here. Step 0 4. My counting is off. My typing is off. It's fine. I'm doing great. Doing great, sweetie. All right. No, my thing has no is valid JSON-LD. So, it just made that up. Okay. Let's see. Let's see. Okay, we got an error. Are you sure this is a real function? This might be harder than I thought. Chat GPT loading wheel. I'm sorry, Dave. I can't let you ask that question, Dave. It's going to get mad at me. All right, let's see if it works. We might not even need to validate it because if it does have a function that allows us to convert. If JSON-LDError. Okay. All right, let's try this. Oh, and also, I just remembered that we need to replace, we need to do encoding equals UTF-8. Anytime we have an open statement, we need to do that because I encode everything in UTF-8. All right, let's try this again it didn'tp 8. Python philosophy says it's better to ask forgiveness than permission. So instead of validating, let's just try to convert it directly to GIFX. Is that the file type? GIFX, yeah. So let's just try and convert it directly to GIFX. Again, using a try-except clause, I'd like you to update the try-accept clauses to catch the errors and print them so I can see what happened. So in total, this script should be simpler. load the JSON and then try to convert to GIF X in both steps output any errors. If it is successful. Actually, yeah. Just print the results as we go for this script. Okay, so let's see what it does. So basically what I'm doing is I'm having it write a script to do an experiment just to see if it'll get all the way through. Because since the cognitive labor is less on me, I'm like, just write this script, let's see what happens, right? As I was talking to some people about this kind of technology, I realized we are infinitely closer to having Star Trek level computers than anyone realizes. Or maybe we do realize, that's why it's exciting. Because with just a little bit more logic behind this, I could say, computer, download all the Supreme Court opinions about antitrust laws. And chat GPT says, okay, cool. And if you give it an internet connection, it can go find it and go find that data, download it. You say, okay, cool. What does the data look like? And computer says it's in PDF format. Cool, scrape it. And it goes from there and then it says, okay, now what do you want me to do? And you just have a conversation with the machine. This is capable of that, just with a little bit more behind the scenes. Okay, let's see. Excellent. I love it. So by it by rapidly iterating and I have done no coding except for adding the encoding thing actually here. Great. I just need you to make one last change, and that is to always include encoding equals UTF8, while opening, reading, and writing files. Everything is in UTF-8. So let's just set that as standard for all our scripts. Hello, computer. Would that be worth something to you? Okay. So, if, so I was, when I was talking with Bax, one of the things he said is he suspects that chat GPT has a scratch pad. So what does that mean? In technical terms, it doesn't mean that it's writing on a notepad, although that would be cool. But what it, what it, what it could mean is that if, if it does have a sidebar document where it can remember critical pieces of information regardless of how long the conversation gets. So if it does have that, then it's like, hey, let me just keep track of the top 10 most important facts about this conversation. But yeah, let's see if it works. All right. Cool. So, let's come back here and do this. Validate JSON. So, look at this. 28 lines. Not bad. What am I doing? Run the script. Just run the script. Just run the script. Error while converting. So it looked like all of them failed, but it did something. Yeah, this is not bad. Not bad at all. What might behoove us, so if I were doing this project, let's say, for instance, I think I got as far as I can get, but let me show you what I would do. So if I were doing this project, let's say for instance, I think I got as far as I can get, but let me show you what I would do. So let's rewind a little bit, because I think that this is just gonna blow up. Yeah, I don't think it didn't succeed on a single one of them. So clearly there's some fragility here. We got to JSON files files but they're all inconsistent and they're all different sizes and so on. So what we would need to do is when we're extracting the knowledge graph, what we would need to do is probably come here and specify a format. Now the problem here is if we use Fushot, so this is why I say we need fine-tuning, if we use Fushot we're going to run out of tokens. And even if they double the token count, we're still going to like, the more tokens we can fit in at once, the better. But now, so there's probably some intermediary steps, right? Because rather than just going straight from documents to knowledge graphs, which it works, right? Works rather well, but the process is fragile. We might need to have other intermediary steps such as distilling the information down. So let me show you what I mean by that. Here, let me pause it for just a second as I change workspaces. Okay, we're right back. So I took one of these chunks, it's 7,600 characters long. So rather than go straight to Knowledge Graph, let's see, let's do some prompt engineering and see, cause like we basically have to start over. All right, so there's a lot of superfluous information. So let's see, how did I word this prompt? This is a super valuable prompt, by the way. And I don't mind sharing it because I've talked to other people and they've figured it out. So this is the most valuable, one of the most valuable prompts I have ever figured out. So write notes about the following document. Let's see use bullet points in complete sentences. I think that's all you need and then you say notes. So this compression method usually is like the best way to compress anything. Now one thing I don't like is that it actually used the actual bullet point character rather than a dash. Use bullet points in complete sentences. Use hyphen for the point. So this is like, you know, blah, blah, blah. So just it's a list of assertions. Cedric Kushner promotions does this. Don King is the president of that petition of Don King allegedly that he had done this part through a Rico pattern, petitioner sued Don King, but this is not good, right? This is, so the reason I'm okay with sharing this is because while this is a really powerful prompt, it's not quite universal. And the reason that it's not universal is because you still lose a little bit too much context. And so you always have to modify this prompt. So the second circuit expressed the view that 1862 is blah blah blah. Great. So we're getting some of this, but for instance, we lost like the title, right? Like what is going on? So we lost this. So we need to say like, what is the document about? We need to include all details such as, yeah. So I'll just tell you, include all details such as titles, citations, dates, and so on. So that should work. So from the last time we stopped here, right, and then I've doubled the length of the instruction. So I also want to point out this instruction would not work in Text Da Vinci 02. These instructions only work now with Text Da Vinci 03. All right, so let's see what happens. There we go. See how the sentences are much longer? So Cedric Kushner Productions v. King is a case from October term 2000 in which the Supreme Court of the United States reversed and remanded the decision of the United States Courts of Appeals for the Second Circuit. Bam! Perfect. Perfect. So this is the kind of information, it's almost even written like a lawyer would speak, right? This tells you real fast in very plain language, what happened? So this is information that is one, useful, and two, could be embedded in a knowledge graph or could be used to extract the information. Now let me show you something. This is actually a really good prompt. I'm going to save this. Whenever you come up with a really good prompt, save it. Prompt notes detailed. Yeah, so we took, let's do some token counts. So we took... All right, so without it, it is 1966 tokens. And then we compress that down to 221 tokens. So we got a compression ratio of almost 10 to 1, and we kept the most salient details. And those salient details were kept with enough context that like it's still useful. Like you read this and it's like, oh, this is a great executive summary. So there you go. So this is probably the direction that I would go, like rewind, let's take this and instead of going to JSON, let's try and do this with GexF. I think you guys get the point. And also we're already like at 30 minutes. So we'll say that we, we'll call this a partial success. We got really far. We got exceptional use of chat GPT. We found a huge fragility. It was confabulating modules and functions that didn't exist. Now, this isn't necessarily a bad thing. So let me tell you why. It's because it used its imagination, and I'm anthropomorphizing it on purpose, it used its imagination to imagine this is what we would need. And then it just kind of went and looked for it. to imagine this is what we would need. And then it just kind of went and looked for it. Now, here's the thing. It doesn't take a whole lot of cognitive architecture to find those mistakes and then say, actually, this is something that would be great if it existed. Why don't I go write it? And so then it keeps track of its dependencies. It could write its own user stories. Say, here, actually, let me just show you. Okay, think about everything that didn't work. Write some user stories to submit to various projects like PyLD and NetworkX and network X. That would have made this project easier. I think this is going to work. Because here's the thing, by breaking it down into steps, there we go. Yes, yes, yes, look at this, look at this, look at this. Even if something doesn't work, it doesn't have to necessarily fix it live, in vivo. This is the process that we follow as humans. There's no need to actually just like, excuse me, to fix it live, it's, I ran into a problem, let's fire this off and then have another system integrate these. Look at this. Oh man, oh man. As a developer, I want to be able to validate JSON-LD data without having to manually catch errors so that I can quickly identify and fix issues with my data. Yes. As a developer, I want to be able to easily convert JSON-LD data to a standardized format so that I can process and visualize the data consistently regardless of its original format. Yes, perfect developer story or user story. As a developer, I want to have simple and intuitive way to create and save knowledge graphs in a variety of formats such as GexEF so that I can use a tool that is most suitable for my needs. Excellent. Universal converter. As a developer, I want to have access to a wide range of layout algorithms and visualization options so that I can create clear and informative visuals of my knowledge graphs. That's already solved, but great. As a developer, I want to be able to easily filter and analyze my knowledge graphs so that I can gain insights into the relationships between different nodes and edges. Fantastic. These first four or three, perfect. Okay, I'm going to stop here because I'm about to go down a really deep rabbit hole, but I think I know what my next videos are going to be, and that is using ChatGPT for every aspect of the development lifecycle. We're going to explore Agile, CI, CD, web-native, all that, because this is incredible. All right, thanks for watching. CI CD, web native, all that because this is incredible. All right, thanks for watching.", "chunks": [{"timestamp": [0.0, 7.4], "text": " All right gang, David Shapiro here. We are going to wrap up this tutorial series on using"}, {"timestamp": [7.4, 16.84], "text": " ChatGPT to code. So first though I need to do a couple of plugs. So one, I just recorded"}, {"timestamp": [16.84, 31.9], "text": " a really great podcast episode with BaxTeaFuture. That'll be coming out on his channel probably later this week. It was a three and a half hour long conversation and we talked about the, it was in one, one"}, {"timestamp": [31.9, 37.36], "text": " part was a recap of 2022 in terms of AI and technology."}, {"timestamp": [37.36, 42.08], "text": " And then we pivoted to talk about AI startups because that's all the rage right now."}, {"timestamp": [42.08, 43.08], "text": " Yeah."}, {"timestamp": [43.08, 45.86], "text": " So look for, look for that over on his channel."}, {"timestamp": [47.08, 50.22], "text": " Number two is I need to do a plug for myself."}, {"timestamp": [51.76, 55.2], "text": " So one of my goals is to be able to do this full-time"}, {"timestamp": [55.2, 57.32], "text": " and I'm not gonna do it with ad revenue."}, {"timestamp": [57.32, 61.0], "text": " So please consider jumping over to my Patreon page"}, {"timestamp": [61.0, 62.84], "text": " and supporting me on Patreon."}, {"timestamp": [62.84, 65.84], "text": " One person said that they were confused by the levels."}, {"timestamp": [65.84, 66.84], "text": " They're no different."}, {"timestamp": [66.84, 70.8], "text": " I just give you different options for level of support."}, {"timestamp": [70.8, 76.0], "text": " What I used to do was I used to have where if you paid enough I would give you one-on-one"}, {"timestamp": [76.0, 78.68], "text": " time but I don't have enough time to do that."}, {"timestamp": [78.68, 84.52], "text": " So instead I just added levels and what you do get if you support me on Patreon is access"}, {"timestamp": [84.52, 88.96], "text": " to my exclusive blog where I'll give you insider updates as to what I'm up to"}, {"timestamp": [88.96, 94.44], "text": " some of my thoughts and also you get like priority access because sometimes"}, {"timestamp": [94.44, 98.16], "text": " I'll ask my patreon's like hey can you connect me to something or I want to"}, {"timestamp": [98.16, 103.8], "text": " talk to you guys so if you want to get on the inside definitely hop over to"}, {"timestamp": [103.8, 105.24], "text": " patreon and then lastly if you want to sync on the inside, definitely hop over to Patreon."}, {"timestamp": [105.24, 111.88], "text": " And then lastly, if you want to sync up and collaborate with me or my team, please feel"}, {"timestamp": [111.88, 114.28], "text": " free to come and connect with me on LinkedIn."}, {"timestamp": [114.28, 118.76], "text": " I check LinkedIn far more than Twitter or Discord nowadays."}, {"timestamp": [118.76, 123.28], "text": " So with that out of the way, let's get back to what we were working on."}, {"timestamp": [123.28, 124.68], "text": " So here's where we left off."}, {"timestamp": [124.68, 125.0], "text": " Oh, nope, you don't need to see my Spotify. Let's get back to what we were working on. So here's where we left off."}, {"timestamp": [125.0, 127.88], "text": " Oh, nope, you don't need to see my Spotify."}, {"timestamp": [127.88, 132.88], "text": " So we got to the point where we have all of our opinions"}, {"timestamp": [134.12, 136.3], "text": " broken down into JSON files."}, {"timestamp": [138.08, 140.56], "text": " So let's see, the biggest one is six kilobytes,"}, {"timestamp": [140.56, 141.72], "text": " so that's not too big."}, {"timestamp": [144.24, 150.8], "text": " And this one got cut off, so this one's not even good, not even usable."}, {"timestamp": [150.8, 153.2], "text": " That's fine."}, {"timestamp": [153.2, 155.76], "text": " This one got cut off as well."}, {"timestamp": [155.76, 159.56], "text": " Part of that was probably token limits."}, {"timestamp": [159.56, 165.2], "text": " This one was finished."}, {"timestamp": [165.2, 166.92], "text": " A lot of this is not going to be usable."}, {"timestamp": [166.92, 170.88], "text": " Remember, this is rapid prototyping."}, {"timestamp": [170.88, 176.28], "text": " That's why I'm just going as fast as I can and I'm not really trying to make a finished"}, {"timestamp": [176.28, 180.28], "text": " product, but this is proof of concept."}, {"timestamp": [180.28, 187.84], "text": " We do have some that are good, or mostly good at least. So let's see what we can do. Now,"}, {"timestamp": [187.84, 194.4], "text": " I went to ask GPT, chat GPT, how do we visualize it in a Gephi? So I've seen people talk about"}, {"timestamp": [194.4, 208.68], "text": " Gephi. So I went and downloaded it, got it installed. It's definitely like a free open source one, but unfortunately it only uses GXF or GraphML or CSV, but we've got everything in JSON."}, {"timestamp": [212.72, 215.46], "text": " So if we wanna visualize any of these,"}, {"timestamp": [215.46, 218.8], "text": " we've got to do it in GXF."}, {"timestamp": [218.8, 222.46], "text": " I'm not sure what the correct pronunciation is,"}, {"timestamp": [223.64, 229.96], "text": " but graphic exchange or Graph Exchange file."}, {"timestamp": [229.96, 232.04], "text": " So it's basically a type of XML."}, {"timestamp": [232.04, 234.32], "text": " So let's see."}, {"timestamp": [234.32, 241.08], "text": " Let's talk to this guy and say, okay, I've got a folder called, let's see, what did I"}, {"timestamp": [241.08, 246.32], "text": " call this folder? KG underscore JSON."}, {"timestamp": [246.32, 256.88], "text": " That is full of .json LD formatted KG files."}, {"timestamp": [256.88, 275.52], "text": " I need to convert them to GXF for Gephi. but here's the problem. Some of the JSON files are malformed, not"}, {"timestamp": [275.52, 291.12], "text": " completed, so we need to first check if they render properly. If not, we can ignore them and skip them. But the second"}, {"timestamp": [291.12, 305.0], "text": " problem is they don't all follow the same format. So let me show you what I mean."}, {"timestamp": [305.0, 310.0], "text": " So for instance."}, {"timestamp": [310.0, 315.0], "text": " In this one, there's no graph element, but in others there are."}, {"timestamp": [315.0, 320.0], "text": " Right."}, {"timestamp": [320.0, 325.16], "text": " So there's there's no graph element in this one, but then we grab another one."}, {"timestamp": [325.16, 326.56], "text": " This one has similar."}, {"timestamp": [326.56, 332.64], "text": " Oh, and so by the way, this is why I say we need to keep fine-tuning, is because when"}, {"timestamp": [332.64, 341.04], "text": " you get to really specific cases like this, you want a very consistent format."}, {"timestamp": [341.04, 343.16], "text": " But just telling it instructs..."}, {"timestamp": [343.16, 345.16], "text": " So here's an example where there's context"}, {"timestamp": [345.16, 348.5], "text": " and like, yeah, they, there's different like methods."}, {"timestamp": [348.5, 353.5], "text": " Anyways, so some have, let's see, for instance,"}, {"timestamp": [357.16, 362.16], "text": " some have graph properties and others don't."}, {"timestamp": [364.7, 364.72], "text": " uh, graph properties and others don't."}, {"timestamp": [373.52, 374.8], "text": " Um, we need to write a python script that will open them,"}, {"timestamp": [381.32, 381.9], "text": " validate them, um, and homogenize them."}, {"timestamp": [384.12, 392.0], "text": " We need the the ultimate goal is to output a single"}, {"timestamp": [392.0, 400.32], "text": " Gexf file. Is this even possible? Do we need to break"}, {"timestamp": [400.32, 405.28], "text": " this down into multiple steps? Alright. Let's see what"}, {"timestamp": [405.28, 407.76], "text": " it says."}, {"timestamp": [416.0, 418.66], "text": " Okay, so it's going to walk through the reasoning that it"}, {"timestamp": [418.66, 421.14], "text": " uses."}, {"timestamp": [457.76, 462.92], "text": " Okay, there's a valid just walked through the entire process. Someone on the internet, I think it was on LinkedIn, said, ChatGPT is going to make everyone"}, {"timestamp": [462.92, 464.08], "text": " dumber and lazier."}, {"timestamp": [464.08, 465.9], "text": " You should learn to do it yourself."}, {"timestamp": [465.9, 466.9], "text": " And I definitely agree."}, {"timestamp": [466.9, 471.76], "text": " So let's talk about this because this video is not going to take too long."}, {"timestamp": [471.76, 474.38], "text": " But let's talk about the implications of this for a second."}, {"timestamp": [474.38, 477.92], "text": " I'm in this headspace because I just had that interview with Bax."}, {"timestamp": [477.92, 484.34], "text": " So this just taught me a whole bunch of stuff that I didn't know."}, {"timestamp": [484.34, 486.92], "text": " I didn't know about the Pi LD thing. I didn't know about the PyLD thing."}, {"timestamp": [486.92, 489.04], "text": " I didn't know about NetworkX."}, {"timestamp": [489.04, 492.44], "text": " So I just had a problem and I said, help me solve this problem."}, {"timestamp": [492.44, 495.04], "text": " Now does that make me dumber?"}, {"timestamp": [495.04, 498.6], "text": " Because I didn't go read the hard way."}, {"timestamp": [498.6, 508.04], "text": " I downloaded the Gephi documentation, but this is still like I have to skim and it's 32 pages, that's a"}, {"timestamp": [508.04, 510.16], "text": " lot of reading."}, {"timestamp": [510.16, 512.56], "text": " What is ultimately valuable?"}, {"timestamp": [512.56, 513.92], "text": " Time."}, {"timestamp": [513.92, 518.48], "text": " Time is the most valuable commodity in all of existence."}, {"timestamp": [518.48, 521.04], "text": " It's more precious than gold."}, {"timestamp": [521.04, 525.0], "text": " So the fact that this is able to help me do more in less time,"}, {"timestamp": [526.32, 530.32], "text": " and I will learn some of the underlying stuff in the wash."}, {"timestamp": [530.32, 532.5], "text": " So here's the thing is like,"}, {"timestamp": [532.5, 537.5], "text": " we build machines to abstract away some of our labor."}, {"timestamp": [537.72, 539.1], "text": " That's what computers do."}, {"timestamp": [539.1, 541.88], "text": " That's why they have the name computer, they compute math."}, {"timestamp": [541.88, 543.88], "text": " That was how they started was,"}, {"timestamp": [543.88, 545.2], "text": " what some of the first use cases"}, {"timestamp": [545.2, 551.92], "text": " of mechanical computers was to calculate firing solutions for big Navy guns during World War"}, {"timestamp": [551.92, 557.52], "text": " II. And the women who did that, who did all the math, they were called computers. It was"}, {"timestamp": [557.52, 565.76], "text": " the computer pool, but it was human computers. Anyways, so we always build machines to offload our mental labor."}, {"timestamp": [565.76, 570.88], "text": " So this is just the next iteration of that."}, {"timestamp": [570.88, 575.58], "text": " Now I'm not saying this is not the same as a TI-83 calculator."}, {"timestamp": [575.58, 577.9], "text": " This is miles beyond that."}, {"timestamp": [577.9, 583.48], "text": " But at the same time, this will ultimately allow me to do more, experiment faster, and"}, {"timestamp": [583.48, 585.16], "text": " generally accelerate things."}, {"timestamp": [585.16, 588.76], "text": " And nobody bemoans databases, right?"}, {"timestamp": [588.76, 592.5], "text": " To me, if someone's complaining like, oh, this just makes you lazy, that's about the"}, {"timestamp": [592.5, 596.34], "text": " same as saying like, oh, well, you should just print everything out and manually collate"}, {"timestamp": [596.34, 597.34], "text": " your database."}, {"timestamp": [597.34, 599.12], "text": " Like, no, we're not going to do that."}, {"timestamp": [599.12, 600.74], "text": " Use SQL."}, {"timestamp": [600.74, 605.76], "text": " And so to me, it's like, and I'm saying this as someone who is typically like a Luddite,"}, {"timestamp": [605.76, 611.04], "text": " like I am the last person to adopt new technologies usually, especially in my day job, in my professional"}, {"timestamp": [611.04, 612.72], "text": " life, because you know what?"}, {"timestamp": [612.72, 618.6], "text": " New stuff is fragile and it breaks, and it's expensive, and it's difficult to integrate,"}, {"timestamp": [618.6, 620.28], "text": " whatever, et cetera, et cetera."}, {"timestamp": [620.28, 621.28], "text": " But this is different."}, {"timestamp": [621.28, 624.68], "text": " ChatGPT is different because this is helping me do better."}, {"timestamp": [624.68, 628.36], "text": " Here, I'm going to give you a nice little kudos feedback."}, {"timestamp": [628.36, 629.36], "text": " This is great."}, {"timestamp": [629.36, 635.68], "text": " I don't know why you have to like ... All you need is a true false, right?"}, {"timestamp": [635.68, 636.68], "text": " Actually no."}, {"timestamp": [636.68, 643.04], "text": " I bet they're asking you why because that is an even better label and they can improve"}, {"timestamp": [643.04, 644.4], "text": " it further."}, {"timestamp": [644.4, 649.4], "text": " Anyways, so ... All right, get off my soapbox."}, {"timestamp": [649.6, 651.84], "text": " That's not why y'all are here, let's move on."}, {"timestamp": [651.84, 652.68], "text": " Excuse me."}, {"timestamp": [652.68, 655.86], "text": " Okay, so this is fine."}, {"timestamp": [655.86, 659.22], "text": " Use it to parse and load it into Python dictionary,"}, {"timestamp": [659.22, 660.98], "text": " that's fine."}, {"timestamp": [660.98, 665.08], "text": " All right, so let's see. Great idea."}, {"timestamp": [665.08, 669.0], "text": " Let's start with the first script."}, {"timestamp": [669.0, 678.24], "text": " This first one will use JSON module to try to load the JSON."}, {"timestamp": [678.24, 690.56], "text": " We should use a try except clause in case it blows up."}, {"timestamp": [690.56, 696.2], "text": " If the JSON doesn't even load, we can move on."}, {"timestamp": [696.2, 705.16], "text": " Okay, cool. Let's see."}, {"timestamp": [705.16, 729.96], "text": " Once the JSON object is loaded into memory, then please use the pyld library function is valid JSON LD to check if it is legit."}, {"timestamp": [729.96, 737.24], "text": " Assuming it passes that, let's see."}, {"timestamp": [743.44, 749.6], "text": " Assuming it passes that, well, actually here,"}, {"timestamp": [749.6, 752.72], "text": " please write this script."}, {"timestamp": [756.2, 758.18], "text": " Yeah."}, {"timestamp": [758.18, 759.68], "text": " And then while it's doing that, I'm"}, {"timestamp": [759.68, 762.02], "text": " going to go ahead and see if I need to install anything."}, {"timestamp": [762.02, 766.8], "text": " So pip install pild."}, {"timestamp": [776.44, 787.62], "text": " And then let's see what else did I need. We need, I think that's as far as we need right now. So let's do pip install network x."}, {"timestamp": [787.62, 798.88], "text": " All right."}, {"timestamp": [798.88, 817.04], "text": " This looks good. We're gonna need to add the encoding UTF-8."}, {"timestamp": [821.38, 823.82], "text": " Okay, so it'll tell us if it is valid and if not. Excellent, so let's go ahead and give this a try."}, {"timestamp": [821.96, 823.92], "text": " If not, excellent. So let's go ahead and give this a try."}, {"timestamp": [828.76, 831.36], "text": " So then we'll save this here as"}, {"timestamp": [833.98, 838.68], "text": " step 03, validate JSON.py."}, {"timestamp": [839.84, 840.68], "text": " Excuse me."}, {"timestamp": [840.68, 842.32], "text": " All right, and then let's come over here,"}, {"timestamp": [842.32, 843.68], "text": " let me zoom in a little bit."}, {"timestamp": [844.84, 847.76], "text": " And we'll do CD to SCOTUS."}, {"timestamp": [849.04, 857.36], "text": " And then we'll do Python. Wow. Sorry, my typing is horrible. I think I moved my keyboard around"}, {"timestamp": [857.36, 861.76], "text": " and it's like just slightly to the left. And so like my fingers are wrong. Muscle memory is"}, {"timestamp": [861.76, 867.4], "text": " everything, man. All right. Python. What was it? Step?"}, {"timestamp": [867.4, 873.6], "text": " I have two step threes. That's that's incorrect. That's going to mess with my my OCD. Sorry,"}, {"timestamp": [873.6, 880.0], "text": " buddy. Step 0 4. No, don't keep it in. That's the wrong file. All right. Come back here."}, {"timestamp": [880.0, 886.72], "text": " Step 0 4. My counting is off. My typing is off. It's fine. I'm doing great. Doing great, sweetie."}, {"timestamp": [887.68, 893.76], "text": " All right. No, my thing has no is valid JSON-LD. So, it just made that up. Okay."}, {"timestamp": [897.76, 898.4], "text": " Let's see."}, {"timestamp": [905.44, 913.4], "text": " Let's see. Okay, we got an error."}, {"timestamp": [913.4, 921.84], "text": " Are you sure this is a real function?"}, {"timestamp": [921.84, 924.56], "text": " This might be harder than I thought."}, {"timestamp": [924.56, 927.8], "text": " Chat GPT loading wheel."}, {"timestamp": [927.8, 928.8], "text": " I'm sorry, Dave."}, {"timestamp": [928.8, 935.68], "text": " I can't let you ask that question, Dave."}, {"timestamp": [935.68, 940.88], "text": " It's going to get mad at me."}, {"timestamp": [940.88, 958.56], "text": " All right, let's see if it works."}, {"timestamp": [958.56, 972.0], "text": " We might not even need to validate it because if it does have a function that allows us to convert."}, {"timestamp": [972.0, 977.0], "text": " If JSON-LDError. Okay."}, {"timestamp": [982.0, 985.0], "text": " All right, let's try this."}, {"timestamp": [985.0, 995.04], "text": " Oh, and also, I just remembered that we need to replace, we need to do encoding equals"}, {"timestamp": [995.04, 1000.04], "text": " UTF-8."}, {"timestamp": [1000.04, 1008.24], "text": " Anytime we have an open statement, we need to do that because I encode everything in UTF-8."}, {"timestamp": [1008.24, 1047.0], "text": " All right, let's try this again it didn'tp 8."}, {"timestamp": [1047.0, 1057.0], "text": " Python philosophy says it's better to ask forgiveness than permission."}, {"timestamp": [1057.0, 1067.0], "text": " So instead of validating, let's just try to convert it directly to GIFX."}, {"timestamp": [1067.0, 1072.0], "text": " Is that the file type?"}, {"timestamp": [1072.0, 1075.0], "text": " GIFX, yeah."}, {"timestamp": [1075.0, 1079.0], "text": " So let's just try and convert it directly to GIFX."}, {"timestamp": [1079.0, 1101.64], "text": " Again, using a try-except clause, I'd like you to update"}, {"timestamp": [1101.64, 1108.8], "text": " the try-accept clauses to catch the errors and print them so I can"}, {"timestamp": [1108.8, 1111.96], "text": " see what happened."}, {"timestamp": [1111.96, 1129.2], "text": " So in total, this script should be simpler. load the JSON and then try to convert to GIF X in both steps"}, {"timestamp": [1129.2, 1140.0], "text": " output any errors. If it is successful. Actually, yeah."}, {"timestamp": [1141.5, 1146.44], "text": " Just print the results as we go for this script."}, {"timestamp": [1146.44, 1148.76], "text": " Okay, so let's see what it does."}, {"timestamp": [1148.76, 1152.46], "text": " So basically what I'm doing is I'm having it write a script to do an experiment just"}, {"timestamp": [1152.46, 1154.8], "text": " to see if it'll get all the way through."}, {"timestamp": [1154.8, 1159.48], "text": " Because since the cognitive labor is less on me, I'm like, just write this script, let's"}, {"timestamp": [1159.48, 1162.72], "text": " see what happens, right?"}, {"timestamp": [1162.72, 1168.12], "text": " As I was talking to some people about this kind of technology, I realized we are infinitely"}, {"timestamp": [1168.12, 1173.64], "text": " closer to having Star Trek level computers than anyone realizes."}, {"timestamp": [1173.64, 1177.94], "text": " Or maybe we do realize, that's why it's exciting."}, {"timestamp": [1177.94, 1187.0], "text": " Because with just a little bit more logic behind this, I could say, computer, download all the Supreme Court opinions about"}, {"timestamp": [1187.0, 1194.0], "text": " antitrust laws. And chat GPT says, okay, cool. And if you give it an internet connection,"}, {"timestamp": [1195.2, 1200.28], "text": " it can go find it and go find that data, download it. You say, okay, cool. What does the data"}, {"timestamp": [1200.28, 1207.72], "text": " look like? And computer says it's in PDF format. Cool, scrape it. And it goes from there and then it says, okay, now what do you want me to do?"}, {"timestamp": [1207.72, 1209.92], "text": " And you just have a conversation with the machine."}, {"timestamp": [1209.92, 1214.24], "text": " This is capable of that, just with a little bit more behind the scenes."}, {"timestamp": [1214.24, 1222.04], "text": " Okay, let's see."}, {"timestamp": [1222.04, 1227.0], "text": " Excellent."}, {"timestamp": [1227.0, 1232.36], "text": " I love it."}, {"timestamp": [1232.36, 1238.88], "text": " So by it by rapidly iterating and I have done no coding except for adding the encoding thing"}, {"timestamp": [1238.88, 1240.76], "text": " actually here."}, {"timestamp": [1240.76, 1252.0], "text": " Great. I just need you to make one last change, and that is to always include"}, {"timestamp": [1252.0, 1265.88], "text": " encoding equals UTF8, while opening, reading, and writing files."}, {"timestamp": [1265.88, 1271.46], "text": " Everything is in UTF-8."}, {"timestamp": [1271.46, 1278.84], "text": " So let's just set that as standard for all our scripts."}, {"timestamp": [1278.84, 1282.28], "text": " Hello, computer."}, {"timestamp": [1282.28, 1284.84], "text": " Would that be worth something to you?"}, {"timestamp": [1284.84, 1285.4], "text": " Okay."}, {"timestamp": [1285.4, 1291.16], "text": " So, if, so I was, when I was talking with Bax, one of the things he said is he suspects"}, {"timestamp": [1291.16, 1293.52], "text": " that chat GPT has a scratch pad."}, {"timestamp": [1293.52, 1294.52], "text": " So what does that mean?"}, {"timestamp": [1294.52, 1297.52], "text": " In technical terms, it doesn't mean that it's writing on a notepad, although that would"}, {"timestamp": [1297.52, 1298.68], "text": " be cool."}, {"timestamp": [1298.68, 1303.24], "text": " But what it, what it, what it could mean is that if, if it does have a sidebar document"}, {"timestamp": [1303.24, 1306.56], "text": " where it can remember critical pieces of information"}, {"timestamp": [1306.56, 1309.84], "text": " regardless of how long the conversation gets."}, {"timestamp": [1309.84, 1315.68], "text": " So if it does have that, then it's like, hey, let me just keep track of the top 10 most"}, {"timestamp": [1315.68, 1318.32], "text": " important facts about this conversation."}, {"timestamp": [1318.32, 1330.0], "text": " But yeah, let's see if it works."}, {"timestamp": [1330.0, 1331.0], "text": " All right."}, {"timestamp": [1331.0, 1332.0], "text": " Cool."}, {"timestamp": [1332.0, 1337.4], "text": " So, let's come back here and do this."}, {"timestamp": [1337.4, 1338.4], "text": " Validate JSON."}, {"timestamp": [1338.4, 1339.4], "text": " So, look at this."}, {"timestamp": [1339.4, 1341.08], "text": " 28 lines."}, {"timestamp": [1341.08, 1342.08], "text": " Not bad."}, {"timestamp": [1342.08, 1343.08], "text": " What am I doing?"}, {"timestamp": [1343.08, 1344.08], "text": " Run the script."}, {"timestamp": [1344.08, 1345.4], "text": " Just run the script. Just run the script."}, {"timestamp": [1346.62, 1347.82], "text": " Error while converting."}, {"timestamp": [1348.86, 1350.68], "text": " So it looked like all of them failed,"}, {"timestamp": [1350.68, 1351.9], "text": " but it did something."}, {"timestamp": [1354.76, 1356.24], "text": " Yeah, this is not bad."}, {"timestamp": [1356.24, 1357.28], "text": " Not bad at all."}, {"timestamp": [1358.16, 1360.32], "text": " What might behoove us,"}, {"timestamp": [1360.32, 1363.52], "text": " so if I were doing this project,"}, {"timestamp": [1363.52, 1364.96], "text": " let's say, for instance,"}, {"timestamp": [1364.96, 1365.0], "text": " I think I got as far as I can get, but let me show you what I would do. So if I were doing this project, let's say for instance,"}, {"timestamp": [1365.0, 1366.72], "text": " I think I got as far as I can get,"}, {"timestamp": [1366.72, 1368.48], "text": " but let me show you what I would do."}, {"timestamp": [1369.5, 1371.12], "text": " So let's rewind a little bit,"}, {"timestamp": [1371.12, 1373.52], "text": " because I think that this is just gonna blow up."}, {"timestamp": [1375.44, 1376.84], "text": " Yeah, I don't think it didn't succeed"}, {"timestamp": [1376.84, 1378.92], "text": " on a single one of them."}, {"timestamp": [1378.92, 1381.6], "text": " So clearly there's some fragility here."}, {"timestamp": [1382.96, 1385.6], "text": " We got to JSON files files but they're all inconsistent"}, {"timestamp": [1385.6, 1390.9], "text": " and they're all different sizes and so on. So what we would need to do is when"}, {"timestamp": [1390.9, 1395.12], "text": " we're extracting the knowledge graph, what we would need to do is probably"}, {"timestamp": [1395.12, 1403.12], "text": " come here and specify a format. Now the problem here is if we use Fushot, so this"}, {"timestamp": [1403.12, 1406.4], "text": " is why I say we need fine-tuning, if we use"}, {"timestamp": [1406.4, 1408.64], "text": " Fushot we're going to run out of tokens."}, {"timestamp": [1408.64, 1414.08], "text": " And even if they double the token count, we're still going to like, the more tokens we can"}, {"timestamp": [1414.08, 1417.84], "text": " fit in at once, the better."}, {"timestamp": [1417.84, 1421.8], "text": " But now, so there's probably some intermediary steps, right?"}, {"timestamp": [1421.8, 1429.0], "text": " Because rather than just going straight from documents to knowledge graphs, which it works, right? Works rather well, but the process is"}, {"timestamp": [1429.0, 1433.16], "text": " fragile. We might need to have other intermediary steps such as distilling"}, {"timestamp": [1433.16, 1438.26], "text": " the information down. So let me show you what I mean by that. Here, let me"}, {"timestamp": [1438.26, 1444.12], "text": " pause it for just a second as I change workspaces. Okay, we're right back."}, {"timestamp": [1444.12, 1445.68], "text": " So I took one of these chunks,"}, {"timestamp": [1445.68, 1448.66], "text": " it's 7,600 characters long."}, {"timestamp": [1448.66, 1453.36], "text": " So rather than go straight to Knowledge Graph,"}, {"timestamp": [1453.36, 1456.32], "text": " let's see, let's do some prompt engineering and see,"}, {"timestamp": [1456.32, 1458.48], "text": " cause like we basically have to start over."}, {"timestamp": [1459.36, 1464.08], "text": " All right, so there's a lot of superfluous information."}, {"timestamp": [1464.08, 1468.22], "text": " So let's see, how did I word this prompt?"}, {"timestamp": [1468.22, 1471.1], "text": " This is a super valuable prompt, by the way."}, {"timestamp": [1471.1, 1475.38], "text": " And I don't mind sharing it because I've talked to other people and they've figured it out."}, {"timestamp": [1475.38, 1481.18], "text": " So this is the most valuable, one of the most valuable prompts I have ever figured out."}, {"timestamp": [1481.18, 1487.68], "text": " So write notes about the following document."}, {"timestamp": [1487.68, 1491.84], "text": " Let's see use bullet points"}, {"timestamp": [1491.84, 1495.52], "text": " in complete sentences."}, {"timestamp": [1495.52, 1500.64], "text": " I think that's all you need and then you say notes."}, {"timestamp": [1514.0, 1526.48], "text": " So this compression method usually is like the best way to compress anything. Now one thing I don't like is that it actually used the actual bullet point character rather than a dash. Use bullet points in complete sentences."}, {"timestamp": [1526.48, 1535.52], "text": " Use hyphen for the point."}, {"timestamp": [1535.52, 1538.32], "text": " So this is like, you know, blah, blah, blah."}, {"timestamp": [1538.32, 1540.04], "text": " So just it's a list of assertions."}, {"timestamp": [1540.04, 1542.16], "text": " Cedric Kushner promotions does this."}, {"timestamp": [1542.16, 1547.28], "text": " Don King is the president of that petition of Don King allegedly that he had done this"}, {"timestamp": [1548.28, 1549.74], "text": " part through a Rico pattern,"}, {"timestamp": [1551.68, 1553.62], "text": " petitioner sued Don King,"}, {"timestamp": [1553.62, 1555.88], "text": " but this is not good, right?"}, {"timestamp": [1555.88, 1558.9], "text": " This is, so the reason I'm okay with sharing this"}, {"timestamp": [1558.9, 1562.02], "text": " is because while this is a really powerful prompt,"}, {"timestamp": [1562.02, 1564.22], "text": " it's not quite universal."}, {"timestamp": [1564.22, 1565.68], "text": " And the reason that it's not universal"}, {"timestamp": [1565.68, 1571.52], "text": " is because you still lose a little bit too much context. And so you always have to modify this"}, {"timestamp": [1571.52, 1579.6], "text": " prompt. So the second circuit expressed the view that 1862 is blah blah blah. Great. So we're"}, {"timestamp": [1579.6, 1586.48], "text": " getting some of this, but for instance, we lost like the title, right? Like what is going on?"}, {"timestamp": [1588.0, 1594.8], "text": " So we lost this. So we need to say like, what is the document about? We need to include all details"}, {"timestamp": [1595.84, 1612.64], "text": " such as, yeah. So I'll just tell you, include all details such as titles, citations, dates, and so on. So that should work. So from"}, {"timestamp": [1612.64, 1618.4], "text": " the last time we stopped here, right, and then I've doubled the length of the instruction."}, {"timestamp": [1618.4, 1628.16], "text": " So I also want to point out this instruction would not work in Text Da Vinci 02. These instructions only work now with Text Da Vinci 03."}, {"timestamp": [1630.44, 1633.52], "text": " All right, so let's see what happens."}, {"timestamp": [1634.66, 1635.66], "text": " There we go."}, {"timestamp": [1636.58, 1639.4], "text": " See how the sentences are much longer?"}, {"timestamp": [1639.4, 1641.96], "text": " So Cedric Kushner Productions v. King"}, {"timestamp": [1641.96, 1644.24], "text": " is a case from October term 2000"}, {"timestamp": [1644.24, 1645.02], "text": " in which the Supreme Court"}, {"timestamp": [1645.02, 1648.72], "text": " of the United States reversed and remanded the decision of the United States Courts of"}, {"timestamp": [1648.72, 1650.48], "text": " Appeals for the Second Circuit."}, {"timestamp": [1650.48, 1651.48], "text": " Bam!"}, {"timestamp": [1651.48, 1652.48], "text": " Perfect."}, {"timestamp": [1652.48, 1653.48], "text": " Perfect."}, {"timestamp": [1653.48, 1658.44], "text": " So this is the kind of information, it's almost even written like a lawyer would speak, right?"}, {"timestamp": [1658.44, 1671.96], "text": " This tells you real fast in very plain language, what happened? So this is information that is one, useful, and two, could be embedded in a knowledge"}, {"timestamp": [1671.96, 1674.4], "text": " graph or could be used to extract the information."}, {"timestamp": [1674.4, 1676.2], "text": " Now let me show you something."}, {"timestamp": [1676.2, 1680.32], "text": " This is actually a really good prompt."}, {"timestamp": [1680.32, 1683.84], "text": " I'm going to save this."}, {"timestamp": [1683.84, 1689.44], "text": " Whenever you come up with a really good prompt, save it."}, {"timestamp": [1689.44, 1706.56], "text": " Prompt notes detailed. Yeah, so we took, let's do some token counts. So we took..."}, {"timestamp": [1706.56, 1710.0], "text": " All right, so without it, it is 1966 tokens."}, {"timestamp": [1710.88, 1714.88], "text": " And then we compress that down to 221 tokens."}, {"timestamp": [1715.44, 1722.24], "text": " So we got a compression ratio of almost 10 to 1, and we kept the most salient details."}, {"timestamp": [1722.24, 1727.28], "text": " And those salient details were kept with enough context"}, {"timestamp": [1727.28, 1729.26], "text": " that like it's still useful."}, {"timestamp": [1729.26, 1730.38], "text": " Like you read this and it's like,"}, {"timestamp": [1730.38, 1732.34], "text": " oh, this is a great executive summary."}, {"timestamp": [1733.76, 1734.6], "text": " So there you go."}, {"timestamp": [1736.22, 1739.18], "text": " So this is probably the direction that I would go,"}, {"timestamp": [1739.18, 1741.5], "text": " like rewind, let's take this"}, {"timestamp": [1741.5, 1743.0], "text": " and instead of going to JSON,"}, {"timestamp": [1743.0, 1747.36], "text": " let's try and do this with GexF."}, {"timestamp": [1747.36, 1749.22], "text": " I think you guys get the point."}, {"timestamp": [1749.22, 1752.72], "text": " And also we're already like at 30 minutes."}, {"timestamp": [1752.72, 1756.04], "text": " So we'll say that we, we'll call this a partial success."}, {"timestamp": [1756.04, 1758.02], "text": " We got really far."}, {"timestamp": [1758.02, 1762.14], "text": " We got exceptional use of chat GPT."}, {"timestamp": [1762.14, 1764.44], "text": " We found a huge fragility."}, {"timestamp": [1764.44, 1767.68], "text": " It was confabulating modules and functions that didn't"}, {"timestamp": [1767.68, 1774.16], "text": " exist. Now, this isn't necessarily a bad thing. So let me tell you why. It's because it used its"}, {"timestamp": [1774.16, 1781.04], "text": " imagination, and I'm anthropomorphizing it on purpose, it used its imagination to imagine"}, {"timestamp": [1781.04, 1784.16], "text": " this is what we would need. And then it just kind of went and looked for it."}, {"timestamp": [1784.16, 1784.96], "text": " to imagine this is what we would need. And then it just kind of went and looked for it."}, {"timestamp": [1790.88, 1794.96], "text": " Now, here's the thing. It doesn't take a whole lot of cognitive architecture to find those mistakes and then say, actually, this is something that would be great if it existed. Why don't I go"}, {"timestamp": [1794.96, 1800.48], "text": " write it? And so then it keeps track of its dependencies. It could write its own user"}, {"timestamp": [1800.48, 1808.64], "text": " stories. Say, here, actually, let me just show you. Okay, think about everything"}, {"timestamp": [1808.64, 1822.56], "text": " that didn't work. Write some user stories to submit to various projects like PyLD and NetworkX"}, {"timestamp": [1823.0, 1832.0], "text": " and network X. That would have made this project easier."}, {"timestamp": [1836.0, 1837.0], "text": " I think this is going to work."}, {"timestamp": [1837.0, 1841.0], "text": " Because here's the thing, by breaking it down into steps,"}, {"timestamp": [1841.0, 1843.0], "text": " there we go."}, {"timestamp": [1843.0, 1848.02], "text": " Yes, yes, yes, look at this, look at this, look at this."}, {"timestamp": [1848.02, 1854.96], "text": " Even if something doesn't work, it doesn't have to necessarily fix it live, in vivo."}, {"timestamp": [1854.96, 1857.58], "text": " This is the process that we follow as humans."}, {"timestamp": [1857.58, 1867.28], "text": " There's no need to actually just like, excuse me, to fix it live, it's, I ran into a problem, let's fire this off and then have"}, {"timestamp": [1867.28, 1870.4], "text": " another system integrate these."}, {"timestamp": [1870.4, 1871.4], "text": " Look at this."}, {"timestamp": [1871.4, 1873.24], "text": " Oh man, oh man."}, {"timestamp": [1873.24, 1876.64], "text": " As a developer, I want to be able to validate JSON-LD data without having to manually catch"}, {"timestamp": [1876.64, 1879.52], "text": " errors so that I can quickly identify and fix issues with my data."}, {"timestamp": [1879.52, 1880.52], "text": " Yes."}, {"timestamp": [1880.52, 1884.04], "text": " As a developer, I want to be able to easily convert JSON-LD data to a standardized format"}, {"timestamp": [1884.04, 1888.36], "text": " so that I can process and visualize the data consistently regardless of its original format."}, {"timestamp": [1888.36, 1891.6], "text": " Yes, perfect developer story or user story."}, {"timestamp": [1891.6, 1895.24], "text": " As a developer, I want to have simple and intuitive way to create and save knowledge"}, {"timestamp": [1895.24, 1899.44], "text": " graphs in a variety of formats such as GexEF so that I can use a tool that is most suitable"}, {"timestamp": [1899.44, 1900.44], "text": " for my needs."}, {"timestamp": [1900.44, 1901.44], "text": " Excellent."}, {"timestamp": [1901.44, 1902.44], "text": " Universal converter."}, {"timestamp": [1902.44, 1906.5], "text": " As a developer, I want to have access to a wide range of layout algorithms and visualization"}, {"timestamp": [1906.5, 1909.72], "text": " options so that I can create clear and informative visuals of my knowledge graphs."}, {"timestamp": [1909.72, 1911.28], "text": " That's already solved, but great."}, {"timestamp": [1911.28, 1914.36], "text": " As a developer, I want to be able to easily filter and analyze my knowledge graphs so"}, {"timestamp": [1914.36, 1918.8], "text": " that I can gain insights into the relationships between different nodes and edges."}, {"timestamp": [1918.8, 1920.32], "text": " Fantastic."}, {"timestamp": [1920.32, 1926.48], "text": " These first four or three, perfect."}, {"timestamp": [1926.48, 1931.44], "text": " Okay, I'm going to stop here because I'm about to go down a really deep rabbit hole, but"}, {"timestamp": [1931.44, 1936.16], "text": " I think I know what my next videos are going to be, and that is using ChatGPT for every"}, {"timestamp": [1936.16, 1938.68], "text": " aspect of the development lifecycle."}, {"timestamp": [1938.68, 1945.28], "text": " We're going to explore Agile, CI, CD, web-native, all that, because this is incredible."}, {"timestamp": [1945.28, 1946.96], "text": " All right, thanks for watching."}, {"timestamp": [1943.46, 1948.46], "text": " CI CD, web native, all that because this is incredible."}, {"timestamp": [1949.54, 1951.04], "text": " All right, thanks for watching."}]}