{"text": " Hey everyone, David Shapiro here. Hoo, I don't know when I'm gonna post this video, but GPT-4 just dropped, and so I'm already experimenting with it. Now, the biggest thing that I noticed in the live stream demo was that the chat GPT-4 has a token count of 32,000 tokens. And the ratio of tokens to words is roughly 2 thirds. So that's about 20,000 words. 20,000 words is a lot. That is about 100 pages, just shy of 100 pages of text, which is enough working memory to do basically any human task, almost any human task, especially when you consider the amount of intrinsic knowledge or background knowledge or latent knowledge that the model has. So we just hit a new era of AI. So the only way you can use GPT-4 right now is if you're on chat GPT plus. And I already signed up for the API of course, but it looks like it'll be a minute. So anyways, so I'm going back to Ascension. So here's the notes that I had for Ascension. And then I also have the previous one right here. So what I'm doing is I'm adding in some of the information that I was brainstorming last time do do do do do do okay, so Let's see, what are the specific milestones? There we go. Alright, so let me add some of these notes and We're just gonna we're just gonna go go. Okay, here, I'm going to refresh Ascension part two. Great. Here are some other notes we worked on in another session. Here, actually, let me just grab this as a whole. And. Now. Now. Now. Now. Now. Now. Now. Now. Now. Now. Now. Now. Now. Now. Now. Now. Now. Now. Now. Now. Now. Now. Now. Now. Now. Wait, there's more. Are you ready? So one thing I've noticed already is that GPT-4 is a little bit more hot on the biscuit ready to go. So you got to tell it like, wait. Of course, I am here to help. Take your time. Okay. Blah, blah, blah, blah, blah. I don't want to interrupt it. So you'll notice that GPT-4 is a little bit slower. So that's fine. All right, so then we'll come up here. Let's see, I just got this one. Here are some possible milestones. Here. Actually let's just grab all this. Great. Actually, no, that's fine. Oops. Let me check if there's more. So basically, sorry for the silence. I was just kind of thinking. So I'm giving it everything. And this is, let's just, oops, let's just copy paste everything into a new Word document and see how many words this is. So this is only 2,300 words. So this is about a tenth of the context window. So we're already planning the entire story, basically copy pasting everything that I've already got. Let's see. There we go. Okay, great. So now that we've got about story so far. Please recap everything in totality about this story. Please capture all details in a complete report. I will be using this document to some... let's see... to... what's the word? Let's see... as the main... let's see... there's a term for it in in fiction where you use it like it's your main Bible. It's the main Bible for the story. OK so while that's going let's talk about GPT-4. So I watched the whole live stream GPT-4 is multimodal. It can accept images. If you look at product, they mention, I think they mentioned videos. Did they? No. Okay. So, basically, it has, it can understand images, which means that it can look at a screen, right? It can look at your code, it can look at what you're doing and understand what it's doing. So it's multimodal on the input. I don't think it's multimodal on the output. That's fine. And you can see, okay, here it is. It's going a little bit slower. There we go. Yeah, but, you know, so in terms of the cognitive performance of GPT-4, it looks like it's an incremental improvement over GPT-3.5. So that is like where we're starting. But on top of the incremental improvements there is there's this the cognitive improvement and so if you look on this it they talk about like how much it has improved on benchmarks. So the uniform bar exam, CHAT-GPT placed in the 10th percentile, so it passed the bar. GPT-4 placed in the 90th percentile. So that means that GPT-4 now outperforms 90% of lawyers on the bar exam. And then the Biology Olympiad, it was in the 31st percentile now it is in the 99th percentile. So to say that this is a quantum leap forward is not an exaggeration. So I just posted a poll a couple days ago. I guess it was actually one day ago I said will we achieve AGI this year and 20% 19% say yes AGI this year 73% so almost three-quarters of people say no AGI in the future and then 9% say AGI already happened I suspect this is going to change after people see what what GPT-4 is capable of. Okay, cool. Disentangling from power, there we go. Moment of truth. Great. Okay, this is not quite as detailed as I'd hoped, but that's okay because all the information is here. Let's see. You seem to be missing Act 1 plot beats. So let's see what it says. Okay. Okay, so I was just talking to my fiance about the scale of a 32,000 token memory. That's about 20,000 words, which when you combine that 20,000 words with the intrinsic knowledge that the model already has, that means that you only need to give it the relevant updated details like the documentation that you're working on or some episodic memory or whatever, and it can kind of confabulate or triangulate the rest of the missing information. So for instance, I don't need to describe Rome to the model when I'm talking about Rome. So that is pretty interesting. Not only that, it surpasses human abilities in a lot of things. And so here, I'm just giving it a little bit of steering and off it goes to the races. And I'm like, okay, great. Great. What do you think? Should we try to write Act 1 or plot the rest of Act 2 and 3? So let's see what it says. As a language model, I'm happy to help you with either option. Okay. So that's actually good. I did say at the beginning that it seems like it's a little bit hot on the biscuit, so I would have expected it to say, let's write, but it seems like it's a little bit hot on the biscuit, so I would have expected it to say, let's rate! But it seems like it's taking a little bit more balanced proposal right now. Yeah. You know what? We don't know exactly where the story's going to end up, so I would say let's, because 20,000 words, that's going to basically be the first act. So let's see what it says. Okay. I think we should go ahead and plan and write act one in a bit more detail Most novels are 30 to 50 chapters So act one should be 8 to What's that about 15? 8 to 15 chapters or so Can you? Take those main plot beats we discussed and map those onto about a dozen chapters or so. Please include details about what happens in each chapter. Be sure to include information about plot advancement, character development, world building, and themes for each chapter. So one thing that I have found in using ChatGPT to help me write is you can weave together all four of those pillars of storytelling in one go. Plot, character, setting, theme. Those are the four primary ingredients. You put those together, you tell ChatGPT that's what you want, and I won't say nine times out of 10, about 50% of the time it does pretty good. A couple other times you have to say let's look at this from a slightly different perspective and that's where I use Jungian archetypes and Joseph Campbell so that it basically adopts like oh actually I know what I'm talking about when we talk about constructing a story. You could also use Save the Cat or any other models for storytelling. So you can say like, let's do a five-act structure, like a Shakespeare or a four-act TV structure. So anyways, let's see what it does with this. So one of the common rules is less is more. And so this is becoming increasingly true as these models become smarter. You give it just enough information to know what your goal is and then you kind of set it free. All right, so introduction, selling the heirloom. There we go, chapter three, exploring Rome, experiencing the city's vibrant atmosphere, Rome's landmarks, social classes, daily life, themes, discovery, contrast between rich and poor. Chapter four, a chance encounter. I love these titles. Okay, so because Let's see, I don't think I think the first patron that's too soon Because also she's like a teenager. Yeah, I don't know. Well, I guess she if she's 16 or whatever So Yeah explores the city a public event meets an influential woman, confronts her mother. Yeah, that was act, yeah, hold on, hold on, stop, stop, stop, stop. Hold on a second. So in this case, it clearly lost the plot. So because we had five plot beats here. So let's see. Let's see. Please expand the five plot beats listed below into 12 chapters. Because right now it's confabulating stuff. So we can see that this task complexity is not quite up to snuff. It needs a little bit more help. Yep, there we go. All right, so let's try again. Here's a detailed breakdown of Act 1, expanding the 5 plot beats into 12 chapters. Okay, so it was off to an okay start. I probably should have saved that, but when I saw that it was kind of rushing through the story, and to be fair, rushing through the story like that is pretty typical for amateur writers actually is it takes a lot of discipline to slow down and say we'll get there. There we go. I like how we're kind of starting off nice and slow. The sale of the heirloom, Cornelia explores Rome, the public event. So public event is there. A new mentor. Court intrigue and social climbing. She's the first major patron. Okay, so it's really hell bent on just jumping the gun. Okay, so this is an example of what I mean by hot on the biscuit. Hang on, you're getting to the end game now. Let's say too fast. Let's slow this down. Think through everything that that happens in Act 1 of a story based on the three-act structure or Joseph Campbell's Hero's Journey. Now based on that, let's brainstorm. So telling it to brainstorm rather than just go ahead and write. 12 chapters that only adhere to Act 1. Therefore, Act 1 must end with the crossing the Rubicon moment of no return. Maybe we need to discuss that before proceeding. Okay, let's see what it says. You're right, I may have progressed too quickly through act one. Again, pretty typical amateur move. Since I know better, I can keep it on track. I was hoping that it would be able to figure that out, but that's fine. Okay, for the crossing the Rubicon moment, this could be when Cornelia makes a decision that commits her to the path of becoming a courtesan. There we go. So the refusal will actually probably be refusing the mentor, the mysterious influential woman. Okay, so since I gave it a little bit of feedback and guidance, let's see if it's able to figure out that. Okay, so she's exploring Rome, the sale of the family heirloom. Okay, there we go. There we go. So it's slowing it down. So she discovers the heirloom in chapter two. Then she explores Rome, she's exploring, She doesn't know what's going on. Then she sells it. She decides to sell it because she realizes, oh here we go. And then, okay, so the mysterious figure gets there. Better life and loyalty to the family. Ooh, here we go. A chance encounter. She meets her future mentor who introduces her to the world of courtesans. She attends a public event where she'll make important connections, allies and enemies among the event's guests. Ooh, so a lot happens at this event. The mentor's offer, there we go. The mentor offers her guidance and assistance in becoming a successful courtesan. There we go. The mentor provides her with resources and connections to get started. Family tension. She faces disapproval and concern. Yes, that is the debate. Perfect. Weighing the options. Cornelia considers the consequences and the values. She crosses the Rubicon. She accepts her mentor's offer. There we go. Much better. Excellent. Much better. Excellent. Much better. Okay. Let's take that exact outline of 12 chapters and expand on the details for each one. Let's start by... So this is what I found ChatGPT does the best, is once you have the chapter, then you say, give me the scenes in the chapter. And honestly, this is not a bad way for humans to outline it too. Let's start by expanding the list with scenes. So each chapter should be between one and let's say three or four scenes. I think most chapters in novels are one to three, so that's fine. So given this, please restate the chapters, but expand upon them by listing, listing out and describing scenes. Yeah, all right, let's see if I can handle that. Yeah, all right, let's see if it can handle that. So again, you can tell that I as an expert am providing a lot of structure and guidance to this, so that's fine. Cornelia and her family are shown struggling in their daily life, showcasing this, blah, blah, blah. Okay, so it's just defaulting to two scenes. That's fine. Certainly for for more amateur writers, just following something more algorithmic like this is perfectly fine. I mean, you hear me talking about, you know, the three act structure and Joseph Campbell and and that so on and so forth. So I can there there was someone had wrote a comment like, what was it, my university literature professor complained that they have spent the last 30 years trying to undo the damage that Joseph Campbell did. And it's like, you know what, Joseph Campbell's work has produced many billion dollar movies, so you know, if you watch the special features of Avengers Endgame, actually, there's a... Or maybe it was Iron Man. One of them. Anyways, so in the special features of some of the MCU movies near the end of Phase 4, they had a roundtable with all of the directors, and they kept alluding to the old book. And I'm like, hmm, I wonder if that's the hero's journey. Because if you're familiar with the hero's journey in Joseph Campbell's work, you watch, you know, particularly the Iron Man movies and the Avenger movies, they very, very algorithmically follow those kinds of things. Okay, so there we go. We're almost done. We've got two scenes for each one. That's fine. She confides in a close friend or sibling. So it's still kind of waffling, like it's being kind of generic. But given how long this is and the fact that it's staying on the plot is pretty impressive. I really like this. Okay, cool. I'm going to go ahead and copy this out actually because this is really good. So we come back here. So Act 1. So then we'll do, let's see, chapters. Let's see. Unformatted text. There we go. Let's see, how long are we at? We're only at 22 minutes. We can keep going. We can keep going. Let's see, where should we go next? Okay, where should we go next? What do you think? What typically goes into planning scenes? Alright, so let's see if it knows. Now that you have a detailed outline for Act 1, you can consider moving on to planning Act 2 and Act 3. However, if you prefer to focus on Act 1 for now, you can delve deeper into the planning of the scenes. Let's see, when planning scenes, consider the following aspects. Purpose, ensure each scene has a clear purpose in advancing the plot, developing characters, or building the world. Setting, okay, yep, choose an appropriate setting. Characters, okay, so this is pretty generic, but it's good in order to remind itself. So there's this concept in neuroscience called priming. I'm actually reading this book, Behave. It is a very dense book, but it's actually hilarious. The dude who wrote it is sarcastic as hell. Anyways, so even just reading words of a particular tone can really drastically change your cognition and decisions and behavior. The same is also true of language models. Just by priming it with some ideas, like when I said think about Joseph Campbell and what goes into an Act One and you saw how much it improved. So this is called priming. So a big part of using language models is priming. Great. Cool. So I like that. Let's start with chapter one. Please write out a much more detailed outline of chapter one. Chapter one, the desperate decision. Scene one, introducing Cornelia, the story opens with Cornelia and her family's modest home providing a brief description of her appearance and personality. Again this is all kind of algorithmic. If you open it this way, like so if you describe the main character's personality or show it right off the bat, that's going to be a little bit like kind of on the nose. Whereas you definitely should demonstrate your main character in the first chapter, but if you just describe it with an info dump, that's not the best. Let's see. It moved on to scene 3, deciding to sell the heirloom. Yeah, we didn't go that far. I like that it invented the name. Okay, while searching for something valuable to sell, she discovers the family's heirloom. Okay, but that doesn't happen until chapter 2. Yeah. So it looks like we need to prime it again. Here. here. So we'll do, we'll come back here and say after outline of chapter one, as a reminder, here is the grand totality of chapter one that we've discussed so far. Please stay within the bounds of chapter one. Okay. Now, please expand this brief outline into a more detailed outline. So you might have noticed that sometimes what I'm doing is I'm rewriting the last one because what you want is if it gets something catastrophically wrong like this, you want to remove it from the chat history because otherwise you end up with what's called prompt contamination. Remember how I just talked about priming? Priming works both ways. It can be positive in that you can prime the model to think in the way that you want it to, but if it has wrong information in the history, that's gonna continue polluting it. And humans can get stuck in a rut like this too, right? Remember, if you're ever having a discussion or you're in a meeting or whatever, and you get the wrong idea in your head, it can be really hard to get out of that rut. So in that case, it's actually kind of similar to humans. One advantage that these models have is you can just flat out erase the wrong information from its memory. Okay, so let's see if it does a little bit better this time. Also I'm still contending with burnout myself and so I probably shouldn't be doing this right now, but it's just too exciting. Okay. I like this. Description of the modest home with her family highlighted in contrast between their current circumstances and their once prosperous past. There we go. Cornelia helps her mother with chores, revealing her dutiful nature and her desire to contribute to the family. Oh, that's good. So this is showing instead of telling. Much, much better. So remember when the last time it was like, oh, we're just going to tell you about her personality. No, wrong. You show their personality. And so you show that she's helping her mother with chores. You show that she's bickering with her siblings. You show them talking about how things used to be. Great. Cornelius's father returns looking weary and defeated. The family gathers for a simple frugal meal, highlighting their financial difficulties. This is phenomenal. I'm gonna call this a day because holy crap, this is exciting. And just to think that ChatGPT just came out a few months ago. That was what, four months ago? And we're already quadrupling, going from 8,000 tokens to 32,000 tokens. This poll that I did, AGI this year, yeah, tell me what you think now. All right, that's it. Wrapping it up. Bye. now. Alright, that's it. Wrapping it up. Bye.", "chunks": [{"timestamp": [0.0, 2.12], "text": " Hey everyone, David Shapiro here."}, {"timestamp": [3.7, 5.48], "text": " Hoo, I don't know when I'm gonna post this video,"}, {"timestamp": [5.48, 7.94], "text": " but GPT-4 just dropped,"}, {"timestamp": [7.94, 10.78], "text": " and so I'm already experimenting with it."}, {"timestamp": [13.06, 15.92], "text": " Now, the biggest thing that I noticed"}, {"timestamp": [15.92, 20.74], "text": " in the live stream demo was that the chat GPT-4"}, {"timestamp": [20.74, 23.48], "text": " has a token count of 32,000 tokens."}, {"timestamp": [24.36, 28.36], "text": " And the ratio of tokens to words is roughly 2 thirds."}, {"timestamp": [28.36, 30.56], "text": " So that's about 20,000 words."}, {"timestamp": [30.56, 34.0], "text": " 20,000 words is a lot."}, {"timestamp": [34.0, 39.0], "text": " That is about 100 pages, just shy of 100 pages of text,"}, {"timestamp": [39.08, 43.08], "text": " which is enough working memory"}, {"timestamp": [43.08, 46.36], "text": " to do basically any human task, almost any human task,"}, {"timestamp": [46.36, 47.8], "text": " especially when you consider the amount"}, {"timestamp": [47.8, 49.9], "text": " of intrinsic knowledge or background knowledge"}, {"timestamp": [49.9, 52.02], "text": " or latent knowledge that the model has."}, {"timestamp": [52.98, 57.32], "text": " So we just hit a new era of AI."}, {"timestamp": [57.32, 61.04], "text": " So the only way you can use GPT-4 right now"}, {"timestamp": [61.04, 63.78], "text": " is if you're on chat GPT plus."}, {"timestamp": [65.04, 68.94], "text": " And I already signed up for the API of course,"}, {"timestamp": [68.94, 70.34], "text": " but it looks like it'll be a minute."}, {"timestamp": [70.34, 73.34], "text": " So anyways, so I'm going back to Ascension."}, {"timestamp": [73.34, 75.54], "text": " So here's the notes that I had for Ascension."}, {"timestamp": [77.02, 82.02], "text": " And then I also have the previous one right here."}, {"timestamp": [82.46, 88.2], "text": " So what I'm doing is I'm adding in some of the information that I was brainstorming last time"}, {"timestamp": [89.04, 91.04], "text": " do do do do do do okay, so"}, {"timestamp": [92.96, 96.28], "text": " Let's see, what are the specific milestones? There we go. Alright, so"}, {"timestamp": [97.4, 99.4], "text": " let me add some of these notes and"}, {"timestamp": [100.76, 106.52], "text": " We're just gonna we're just gonna go go. Okay, here, I'm going to refresh Ascension part two."}, {"timestamp": [106.52, 107.52], "text": " Great."}, {"timestamp": [107.52, 114.68], "text": " Here are some other notes we worked on in another session."}, {"timestamp": [114.68, 125.0], "text": " Here, actually, let me just grab this as a whole. And. Now."}, {"timestamp": [125.0, 126.0], "text": " Now."}, {"timestamp": [126.0, 127.0], "text": " Now."}, {"timestamp": [127.0, 128.0], "text": " Now."}, {"timestamp": [128.0, 129.0], "text": " Now."}, {"timestamp": [129.0, 130.0], "text": " Now."}, {"timestamp": [130.0, 131.0], "text": " Now."}, {"timestamp": [131.0, 132.0], "text": " Now."}, {"timestamp": [132.0, 133.0], "text": " Now."}, {"timestamp": [133.0, 134.0], "text": " Now."}, {"timestamp": [134.0, 135.0], "text": " Now."}, {"timestamp": [135.0, 136.0], "text": " Now."}, {"timestamp": [136.0, 137.0], "text": " Now."}, {"timestamp": [137.0, 138.0], "text": " Now."}, {"timestamp": [138.0, 139.0], "text": " Now."}, {"timestamp": [139.0, 140.0], "text": " Now."}, {"timestamp": [140.0, 141.0], "text": " Now."}, {"timestamp": [141.0, 142.0], "text": " Now."}, {"timestamp": [142.0, 143.0], "text": " Now."}, {"timestamp": [143.0, 144.0], "text": " Now."}, {"timestamp": [144.0, 145.76], "text": " Now. Now. Now. Now. Now. Wait, there's more. Are you ready?"}, {"timestamp": [145.76, 149.84], "text": " So one thing I've noticed already is that GPT-4 is a little bit more hot on the biscuit"}, {"timestamp": [149.84, 151.02], "text": " ready to go."}, {"timestamp": [151.02, 156.0], "text": " So you got to tell it like, wait."}, {"timestamp": [156.0, 157.4], "text": " Of course, I am here to help."}, {"timestamp": [157.4, 158.4], "text": " Take your time."}, {"timestamp": [158.4, 159.4], "text": " Okay."}, {"timestamp": [159.4, 160.4], "text": " Blah, blah, blah, blah, blah."}, {"timestamp": [160.4, 161.48], "text": " I don't want to interrupt it."}, {"timestamp": [161.48, 164.6], "text": " So you'll notice that GPT-4 is a little bit slower."}, {"timestamp": [164.6, 165.8], "text": " So that's fine."}, {"timestamp": [165.8, 168.1], "text": " All right, so then we'll come up here."}, {"timestamp": [168.1, 174.1], "text": " Let's see, I just got this one."}, {"timestamp": [174.1, 177.74], "text": " Here are some possible milestones."}, {"timestamp": [177.74, 180.84], "text": " Here."}, {"timestamp": [180.84, 185.76], "text": " Actually let's just grab all this."}, {"timestamp": [186.6, 190.68], "text": " Great."}, {"timestamp": [191.98, 204.56], "text": " Actually, no, that's fine."}, {"timestamp": [213.76, 216.44], "text": " Oops. Let me check if there's more."}, {"timestamp": [216.44, 218.08], "text": " So basically, sorry for the silence."}, {"timestamp": [218.08, 220.92], "text": " I was just kind of thinking."}, {"timestamp": [220.92, 222.88], "text": " So I'm giving it everything."}, {"timestamp": [222.88, 231.96], "text": " And this is, let's just, oops, let's just copy paste everything into a new Word document"}, {"timestamp": [231.96, 235.16], "text": " and see how many words this is."}, {"timestamp": [235.16, 237.18], "text": " So this is only 2,300 words."}, {"timestamp": [237.18, 242.48], "text": " So this is about a tenth of the context window."}, {"timestamp": [242.48, 249.72], "text": " So we're already planning the entire story, basically copy pasting everything that I've"}, {"timestamp": [249.72, 251.52], "text": " already got."}, {"timestamp": [251.52, 252.52], "text": " Let's see."}, {"timestamp": [252.52, 253.52], "text": " There we go."}, {"timestamp": [253.52, 254.52], "text": " Okay, great."}, {"timestamp": [254.52, 270.4], "text": " So now that we've got about story so far."}, {"timestamp": [270.4, 290.6], "text": " Please recap everything in totality about this story. Please capture all details in a complete report. I will be"}, {"timestamp": [290.6, 303.28], "text": " using this document to some... let's see... to... what's the word? Let's see... as the"}, {"timestamp": [303.28, 310.1], "text": " main... let's see... there's a term for it in in fiction where you use it like it's your"}, {"timestamp": [310.1, 311.1], "text": " main Bible."}, {"timestamp": [311.1, 315.7], "text": " It's the main Bible for the story."}, {"timestamp": [315.7, 320.82], "text": " OK so while that's going let's talk about GPT-4."}, {"timestamp": [320.82, 324.3], "text": " So I watched the whole live stream GPT-4 is multimodal."}, {"timestamp": [324.3, 326.78], "text": " It can accept images."}, {"timestamp": [326.78, 341.0], "text": " If you look at product, they mention, I think they mentioned videos."}, {"timestamp": [341.0, 342.0], "text": " Did they?"}, {"timestamp": [342.0, 343.0], "text": " No."}, {"timestamp": [343.0, 344.0], "text": " Okay."}, {"timestamp": [344.0, 347.08], "text": " So, basically, it has, it can understand images,"}, {"timestamp": [347.08, 349.82], "text": " which means that it can look at a screen, right?"}, {"timestamp": [349.82, 352.34], "text": " It can look at your code, it can look at what you're doing"}, {"timestamp": [352.34, 353.72], "text": " and understand what it's doing."}, {"timestamp": [353.72, 355.76], "text": " So it's multimodal on the input."}, {"timestamp": [355.76, 358.08], "text": " I don't think it's multimodal on the output."}, {"timestamp": [358.08, 358.92], "text": " That's fine."}, {"timestamp": [359.78, 361.66], "text": " And you can see, okay, here it is."}, {"timestamp": [361.66, 363.34], "text": " It's going a little bit slower."}, {"timestamp": [364.56, 365.64], "text": " There we go."}, {"timestamp": [369.24, 371.3], "text": " Yeah, but, you know,"}, {"timestamp": [371.3, 376.12], "text": " so in terms of the cognitive performance of GPT-4,"}, {"timestamp": [376.12, 381.12], "text": " it looks like it's an incremental improvement over GPT-3.5."}, {"timestamp": [382.56, 389.4], "text": " So that is like where we're starting. But on top of"}, {"timestamp": [389.4, 395.4], "text": " the incremental improvements there is there's this the cognitive improvement"}, {"timestamp": [395.4, 400.92], "text": " and so if you look on this it they talk about like how much it has improved on"}, {"timestamp": [400.92, 405.18], "text": " benchmarks. So the uniform bar exam, CHAT-GPT placed in the"}, {"timestamp": [405.18, 410.54], "text": " 10th percentile, so it passed the bar. GPT-4 placed in the 90th percentile. So"}, {"timestamp": [410.54, 419.3], "text": " that means that GPT-4 now outperforms 90% of lawyers on the bar exam. And then the"}, {"timestamp": [419.3, 425.72], "text": " Biology Olympiad, it was in the 31st percentile now it is in the 99th percentile."}, {"timestamp": [425.72, 433.28], "text": " So to say that this is a quantum leap forward is not an exaggeration."}, {"timestamp": [433.28, 441.8], "text": " So I just posted a poll a couple days ago."}, {"timestamp": [441.8, 446.72], "text": " I guess it was actually one day ago I said will we achieve AGI this year and"}, {"timestamp": [446.72, 453.64], "text": " 20% 19% say yes AGI this year 73% so almost three-quarters of people say no"}, {"timestamp": [453.64, 459.88], "text": " AGI in the future and then 9% say AGI already happened I suspect this is going"}, {"timestamp": [459.88, 469.4], "text": " to change after people see what what GPT-4 is capable of. Okay, cool."}, {"timestamp": [469.4, 474.68], "text": " Disentangling from power, there we go."}, {"timestamp": [474.68, 478.6], "text": " Moment of truth."}, {"timestamp": [478.6, 480.64], "text": " Great."}, {"timestamp": [480.64, 486.42], "text": " Okay, this is not quite as detailed as I'd hoped, but that's okay because all the information"}, {"timestamp": [486.42, 488.84], "text": " is here."}, {"timestamp": [488.84, 489.84], "text": " Let's see."}, {"timestamp": [489.84, 496.2], "text": " You seem to be missing Act 1 plot beats."}, {"timestamp": [496.2, 501.2], "text": " So let's see what it says."}, {"timestamp": [501.2, 514.8], "text": " Okay. Okay, so I was just talking to my fiance about the scale of a 32,000 token memory."}, {"timestamp": [514.8, 519.78], "text": " That's about 20,000 words, which when you combine that 20,000 words with the intrinsic"}, {"timestamp": [519.78, 523.34], "text": " knowledge that the model already has, that means that you only need to give it the relevant"}, {"timestamp": [523.34, 529.64], "text": " updated details like the documentation that you're working on or some episodic memory"}, {"timestamp": [529.64, 535.6], "text": " or whatever, and it can kind of confabulate or triangulate the rest of the missing information."}, {"timestamp": [535.6, 542.88], "text": " So for instance, I don't need to describe Rome to the model when I'm talking about Rome."}, {"timestamp": [542.88, 546.2], "text": " So that is pretty interesting."}, {"timestamp": [546.2, 551.56], "text": " Not only that, it surpasses human abilities in a lot of things."}, {"timestamp": [551.56, 556.52], "text": " And so here, I'm just giving it a little bit of steering and off it goes to the races."}, {"timestamp": [556.52, 560.36], "text": " And I'm like, okay, great."}, {"timestamp": [560.36, 561.64], "text": " Great."}, {"timestamp": [561.64, 572.36], "text": " What do you think? Should we try to write Act 1 or plot the rest of Act 2 and 3?"}, {"timestamp": [572.36, 573.94], "text": " So let's see what it says."}, {"timestamp": [573.94, 576.92], "text": " As a language model, I'm happy to help you with either option."}, {"timestamp": [576.92, 577.92], "text": " Okay."}, {"timestamp": [577.92, 580.0], "text": " So that's actually good."}, {"timestamp": [580.0, 583.8], "text": " I did say at the beginning that it seems like it's a little bit hot on the biscuit, so I"}, {"timestamp": [583.8, 586.32], "text": " would have expected it to say, let's write, but it seems like it's a little bit hot on the biscuit, so I would have expected it to say, let's rate!"}, {"timestamp": [586.32, 592.88], "text": " But it seems like it's taking a little bit more balanced proposal right now."}, {"timestamp": [592.88, 596.96], "text": " Yeah."}, {"timestamp": [596.96, 598.42], "text": " You know what?"}, {"timestamp": [598.42, 609.52], "text": " We don't know exactly where the story's going to end up, so I would say let's, because 20,000 words, that's going to basically be the first"}, {"timestamp": [609.52, 628.64], "text": " act. So let's see what it says. Okay. I think we should go ahead and plan and write act one in a bit more detail Most novels are 30 to 50 chapters"}, {"timestamp": [630.04, 632.6], "text": " So act one should be"}, {"timestamp": [634.16, 635.96], "text": " 8 to"}, {"timestamp": [635.96, 637.96], "text": " What's that about 15?"}, {"timestamp": [638.04, 641.24], "text": " 8 to 15 chapters or so"}, {"timestamp": [642.08, 644.08], "text": " Can you?"}, {"timestamp": [644.56, 655.28], "text": " Take those main plot beats we discussed and map those onto about"}, {"timestamp": [655.28, 658.48], "text": " a dozen chapters or so."}, {"timestamp": [658.48, 665.0], "text": " Please include details about what happens in each chapter."}, {"timestamp": [665.0, 671.0], "text": " Be sure to include information about plot advancement,"}, {"timestamp": [671.0, 678.0], "text": " character development, world building,"}, {"timestamp": [678.0, 683.0], "text": " and themes for each chapter."}, {"timestamp": [683.0, 685.76], "text": " So one thing that I have found in using ChatGPT"}, {"timestamp": [685.76, 689.32], "text": " to help me write is you can weave together"}, {"timestamp": [689.32, 693.28], "text": " all four of those pillars of storytelling in one go."}, {"timestamp": [693.28, 695.68], "text": " Plot, character, setting, theme."}, {"timestamp": [695.68, 697.56], "text": " Those are the four primary ingredients."}, {"timestamp": [697.56, 699.68], "text": " You put those together, you tell ChatGPT"}, {"timestamp": [699.68, 703.36], "text": " that's what you want, and I won't say nine times out of 10,"}, {"timestamp": [703.36, 706.24], "text": " about 50% of the time it does pretty good."}, {"timestamp": [706.24, 711.96], "text": " A couple other times you have to say let's look at this from a slightly different perspective"}, {"timestamp": [711.96, 717.2], "text": " and that's where I use Jungian archetypes and Joseph Campbell so that it basically adopts"}, {"timestamp": [717.2, 721.28], "text": " like oh actually I know what I'm talking about when we talk about constructing a story."}, {"timestamp": [721.28, 726.96], "text": " You could also use Save the Cat or any other models for storytelling."}, {"timestamp": [726.96, 729.24], "text": " So you can say like, let's do a five-act structure,"}, {"timestamp": [729.24, 732.98], "text": " like a Shakespeare or a four-act TV structure."}, {"timestamp": [732.98, 736.04], "text": " So anyways, let's see what it does with this."}, {"timestamp": [736.04, 740.4], "text": " So one of the common rules is less is more."}, {"timestamp": [742.0, 744.8], "text": " And so this is becoming increasingly true"}, {"timestamp": [744.8, 746.84], "text": " as these models become smarter."}, {"timestamp": [746.84, 751.8], "text": " You give it just enough information to know what your goal is and then you kind of set"}, {"timestamp": [751.8, 752.8], "text": " it free."}, {"timestamp": [752.8, 761.52], "text": " All right, so introduction, selling the heirloom."}, {"timestamp": [761.52, 767.0], "text": " There we go, chapter three, exploring Rome, experiencing the city's vibrant atmosphere,"}, {"timestamp": [767.0, 771.12], "text": " Rome's landmarks, social classes, daily life, themes, discovery, contrast between rich and"}, {"timestamp": [771.12, 772.64], "text": " poor."}, {"timestamp": [772.64, 773.8], "text": " Chapter four, a chance encounter."}, {"timestamp": [773.8, 777.84], "text": " I love these titles."}, {"timestamp": [777.84, 788.88], "text": " Okay, so because Let's see, I don't think I think the first patron that's too soon"}, {"timestamp": [793.92, 799.88], "text": " Because also she's like a teenager. Yeah, I don't know. Well, I guess she if she's 16 or whatever"}, {"timestamp": [802.32, 804.32], "text": " So"}, {"timestamp": [808.8, 809.8], "text": " Yeah explores the city a public event meets an influential woman, confronts her mother."}, {"timestamp": [809.8, 818.32], "text": " Yeah, that was act, yeah, hold on, hold on, stop, stop, stop, stop."}, {"timestamp": [818.32, 820.0], "text": " Hold on a second."}, {"timestamp": [820.0, 824.48], "text": " So in this case, it clearly lost the plot."}, {"timestamp": [824.48, 827.86], "text": " So because we had five plot beats here."}, {"timestamp": [827.86, 831.04], "text": " So let's see."}, {"timestamp": [831.04, 832.04], "text": " Let's see."}, {"timestamp": [832.04, 843.2], "text": " Please expand the five plot beats listed below into 12 chapters."}, {"timestamp": [843.2, 845.0], "text": " Because right now it's confabulating stuff."}, {"timestamp": [847.84, 851.96], "text": " So we can see that this task complexity"}, {"timestamp": [851.96, 853.88], "text": " is not quite up to snuff."}, {"timestamp": [853.88, 855.62], "text": " It needs a little bit more help."}, {"timestamp": [862.56, 863.88], "text": " Yep, there we go."}, {"timestamp": [865.0, 868.72], "text": " All right, so let's try again."}, {"timestamp": [868.72, 872.64], "text": " Here's a detailed breakdown of Act 1, expanding the 5 plot beats into 12 chapters."}, {"timestamp": [872.64, 874.96], "text": " Okay, so it was off to an okay start."}, {"timestamp": [874.96, 878.84], "text": " I probably should have saved that, but when I saw that it was kind of rushing through"}, {"timestamp": [878.84, 884.44], "text": " the story, and to be fair, rushing through the story like that is pretty typical for"}, {"timestamp": [884.44, 885.52], "text": " amateur writers"}, {"timestamp": [885.52, 892.08], "text": " actually is it takes a lot of discipline to slow down and say we'll get there."}, {"timestamp": [892.08, 896.4], "text": " There we go."}, {"timestamp": [896.4, 899.44], "text": " I like how we're kind of starting off nice and slow."}, {"timestamp": [899.44, 913.28], "text": " The sale of the heirloom, Cornelia explores Rome, the public event. So public event is there. A new mentor."}, {"timestamp": [913.28, 919.34], "text": " Court intrigue and social climbing. She's the first major patron. Okay, so it's really"}, {"timestamp": [919.34, 925.14], "text": " hell bent on just jumping the gun. Okay, so this is an example of what I mean"}, {"timestamp": [925.14, 926.58], "text": " by hot on the biscuit."}, {"timestamp": [928.72, 933.72], "text": " Hang on, you're getting to the end game now."}, {"timestamp": [934.96, 938.12], "text": " Let's say too fast."}, {"timestamp": [939.06, 941.76], "text": " Let's slow this down."}, {"timestamp": [944.16, 953.68], "text": " Think through everything that that happens in Act 1 of a story based"}, {"timestamp": [953.68, 970.4], "text": " on the three-act structure or Joseph Campbell's Hero's Journey."}, {"timestamp": [970.4, 975.24], "text": " Now based on that, let's brainstorm."}, {"timestamp": [975.24, 989.0], "text": " So telling it to brainstorm rather than just go ahead and write. 12 chapters that only adhere to Act 1."}, {"timestamp": [989.0, 1000.84], "text": " Therefore, Act 1 must end with the crossing the Rubicon moment of no return."}, {"timestamp": [1000.84, 1005.0], "text": " Maybe we need to discuss that before proceeding."}, {"timestamp": [1006.58, 1008.62], "text": " Okay, let's see what it says."}, {"timestamp": [1008.62, 1010.98], "text": " You're right, I may have progressed too quickly"}, {"timestamp": [1010.98, 1012.3], "text": " through act one."}, {"timestamp": [1012.3, 1017.16], "text": " Again, pretty typical amateur move."}, {"timestamp": [1017.16, 1019.28], "text": " Since I know better, I can keep it on track."}, {"timestamp": [1019.28, 1021.66], "text": " I was hoping that it would be able to figure that out,"}, {"timestamp": [1021.66, 1022.56], "text": " but that's fine."}, {"timestamp": [1024.82, 1028.56], "text": " Okay, for the crossing the Rubicon moment, this could be when Cornelia makes a decision"}, {"timestamp": [1028.56, 1030.76], "text": " that commits her to the path of becoming a courtesan."}, {"timestamp": [1030.76, 1032.2], "text": " There we go."}, {"timestamp": [1032.2, 1039.72], "text": " So the refusal will actually probably be refusing the mentor, the mysterious influential woman."}, {"timestamp": [1039.72, 1047.32], "text": " Okay, so since I gave it a little bit of feedback and guidance, let's see if it's able to figure"}, {"timestamp": [1047.32, 1048.32], "text": " out that."}, {"timestamp": [1048.32, 1052.52], "text": " Okay, so she's exploring Rome, the sale of the family heirloom."}, {"timestamp": [1052.52, 1054.6], "text": " Okay, there we go."}, {"timestamp": [1054.6, 1055.6], "text": " There we go."}, {"timestamp": [1055.6, 1056.6], "text": " So it's slowing it down."}, {"timestamp": [1056.6, 1061.08], "text": " So she discovers the heirloom in chapter two."}, {"timestamp": [1061.08, 1065.0], "text": " Then she explores Rome, she's exploring, She doesn't know what's going on."}, {"timestamp": [1070.24, 1071.08], "text": " Then she sells it. She decides to sell it because she realizes, oh here we go."}, {"timestamp": [1074.2, 1075.08], "text": " And then, okay, so the mysterious figure gets there."}, {"timestamp": [1082.76, 1087.12], "text": " Better life and loyalty to the family. Ooh, here we go. A chance encounter. She meets her future mentor who introduces her to the world of courtesans."}, {"timestamp": [1087.12, 1093.96], "text": " She attends a public event where she'll make important connections, allies and enemies"}, {"timestamp": [1093.96, 1094.96], "text": " among the event's guests."}, {"timestamp": [1094.96, 1098.0], "text": " Ooh, so a lot happens at this event."}, {"timestamp": [1098.0, 1100.5], "text": " The mentor's offer, there we go."}, {"timestamp": [1100.5, 1103.76], "text": " The mentor offers her guidance and assistance in becoming a successful courtesan."}, {"timestamp": [1103.76, 1104.76], "text": " There we go."}, {"timestamp": [1104.76, 1106.84], "text": " The mentor provides her with resources and connections to get started."}, {"timestamp": [1107.4, 1111.46], "text": " Family tension. She faces disapproval and concern. Yes, that is the debate."}, {"timestamp": [1112.0, 1119.2], "text": " Perfect. Weighing the options. Cornelia considers the consequences and the values. She crosses the Rubicon. She accepts her mentor's offer."}, {"timestamp": [1120.24, 1122.24], "text": " There we go. Much better."}, {"timestamp": [1124.48, 1126.0], "text": " Excellent. Much better. Excellent. Much better."}, {"timestamp": [1126.0, 1132.0], "text": " Okay. Let's take that exact outline of 12 chapters"}, {"timestamp": [1132.0, 1139.0], "text": " and expand on the details for each one."}, {"timestamp": [1139.0, 1143.0], "text": " Let's start by..."}, {"timestamp": [1143.0, 1149.0], "text": " So this is what I found ChatGPT does the best, is once you have the chapter,"}, {"timestamp": [1149.0, 1151.58], "text": " then you say, give me the scenes in the chapter."}, {"timestamp": [1151.58, 1156.04], "text": " And honestly, this is not a bad way for humans to outline it too."}, {"timestamp": [1156.04, 1172.4], "text": " Let's start by expanding the list with scenes. So each chapter should be between one and let's say three or four scenes."}, {"timestamp": [1173.76, 1194.0], "text": " I think most chapters in novels are one to three, so that's fine. So given this, please restate the chapters, but expand upon them by listing,"}, {"timestamp": [1194.8, 1202.8], "text": " listing out and describing scenes. Yeah, all right, let's see if I can handle that."}, {"timestamp": [1207.0, 1213.84], "text": " Yeah, all right, let's see if it can handle that. So again, you can tell that I as an expert am providing a lot of structure and guidance"}, {"timestamp": [1213.84, 1219.44], "text": " to this, so that's fine."}, {"timestamp": [1219.44, 1222.88], "text": " Cornelia and her family are shown struggling in their daily life, showcasing this, blah,"}, {"timestamp": [1222.88, 1223.88], "text": " blah, blah."}, {"timestamp": [1223.88, 1225.64], "text": " Okay, so it's just defaulting to two scenes."}, {"timestamp": [1225.64, 1227.92], "text": " That's fine."}, {"timestamp": [1227.92, 1233.16], "text": " Certainly for for more amateur writers, just following something more algorithmic like"}, {"timestamp": [1233.16, 1234.6], "text": " this is perfectly fine."}, {"timestamp": [1234.6, 1238.44], "text": " I mean, you hear me talking about, you know, the three act structure and Joseph Campbell"}, {"timestamp": [1238.44, 1240.82], "text": " and and that so on and so forth."}, {"timestamp": [1240.82, 1247.92], "text": " So I can there there was someone had wrote a comment like, what was it, my university literature"}, {"timestamp": [1247.92, 1252.82], "text": " professor complained that they have spent the last 30 years trying to undo the damage"}, {"timestamp": [1252.82, 1255.18], "text": " that Joseph Campbell did."}, {"timestamp": [1255.18, 1260.26], "text": " And it's like, you know what, Joseph Campbell's work has produced many billion dollar movies,"}, {"timestamp": [1260.26, 1266.24], "text": " so you know, if you watch the special features of Avengers Endgame, actually, there's a..."}, {"timestamp": [1266.24, 1268.76], "text": " Or maybe it was Iron Man."}, {"timestamp": [1268.76, 1269.76], "text": " One of them."}, {"timestamp": [1269.76, 1275.38], "text": " Anyways, so in the special features of some of the MCU movies near the end of Phase 4,"}, {"timestamp": [1275.38, 1281.48], "text": " they had a roundtable with all of the directors, and they kept alluding to the old book."}, {"timestamp": [1281.48, 1285.84], "text": " And I'm like, hmm, I wonder if that's the hero's journey. Because if you're"}, {"timestamp": [1285.84, 1293.08], "text": " familiar with the hero's journey in Joseph Campbell's work, you watch, you know, particularly"}, {"timestamp": [1293.08, 1300.1], "text": " the Iron Man movies and the Avenger movies, they very, very algorithmically follow those"}, {"timestamp": [1300.1, 1306.12], "text": " kinds of things. Okay, so there we go."}, {"timestamp": [1306.12, 1307.16], "text": " We're almost done."}, {"timestamp": [1307.16, 1309.16], "text": " We've got two scenes for each one."}, {"timestamp": [1309.16, 1311.04], "text": " That's fine."}, {"timestamp": [1311.04, 1312.92], "text": " She confides in a close friend or sibling."}, {"timestamp": [1312.92, 1317.36], "text": " So it's still kind of waffling, like it's being kind of generic."}, {"timestamp": [1317.36, 1325.24], "text": " But given how long this is and the fact that it's staying on the plot is pretty impressive."}, {"timestamp": [1325.24, 1327.6], "text": " I really like this."}, {"timestamp": [1327.6, 1329.72], "text": " Okay, cool."}, {"timestamp": [1329.72, 1339.36], "text": " I'm going to go ahead and copy this out actually because this is really good."}, {"timestamp": [1339.36, 1340.96], "text": " So we come back here."}, {"timestamp": [1340.96, 1354.4], "text": " So Act 1. So then we'll do, let's see, chapters. Let's see. Unformatted text. There"}, {"timestamp": [1354.4, 1359.28], "text": " we go. Let's see, how long are we at? We're only at 22 minutes. We can keep going. We"}, {"timestamp": [1359.28, 1367.0], "text": " can keep going. Let's see, where should we go next? Okay, where should we go next?"}, {"timestamp": [1367.0, 1369.0], "text": " What do you think?"}, {"timestamp": [1369.0, 1373.0], "text": " What typically goes into planning scenes?"}, {"timestamp": [1373.0, 1376.0], "text": " Alright, so let's see if it knows."}, {"timestamp": [1376.0, 1381.0], "text": " Now that you have a detailed outline for Act 1, you can consider moving on to planning Act 2 and Act 3."}, {"timestamp": [1381.0, 1388.16], "text": " However, if you prefer to focus on Act 1 for now, you can delve deeper into the planning of the scenes."}, {"timestamp": [1388.16, 1391.04], "text": " Let's see, when planning scenes, consider the following aspects."}, {"timestamp": [1391.04, 1394.92], "text": " Purpose, ensure each scene has a clear purpose in advancing the plot, developing characters,"}, {"timestamp": [1394.92, 1397.4], "text": " or building the world."}, {"timestamp": [1397.4, 1402.16], "text": " Setting, okay, yep, choose an appropriate setting."}, {"timestamp": [1402.16, 1411.34], "text": " Characters, okay, so this is pretty generic, but it's good in order to remind itself."}, {"timestamp": [1411.34, 1419.64], "text": " So there's this concept in neuroscience called priming. I'm actually reading this book, Behave."}, {"timestamp": [1419.64, 1432.0], "text": " It is a very dense book, but it's actually hilarious. The dude who wrote it is sarcastic as hell. Anyways, so even just reading words of a particular tone can really"}, {"timestamp": [1432.0, 1436.28], "text": " drastically change your cognition and decisions and behavior. The same is also"}, {"timestamp": [1436.28, 1440.42], "text": " true of language models. Just by priming it with some ideas, like when I said"}, {"timestamp": [1440.42, 1444.48], "text": " think about Joseph Campbell and what goes into an Act One and you saw how"}, {"timestamp": [1444.48, 1445.6], "text": " much it improved."}, {"timestamp": [1445.6, 1447.4], "text": " So this is called priming."}, {"timestamp": [1447.4, 1452.4], "text": " So a big part of using language models is priming."}, {"timestamp": [1452.4, 1453.72], "text": " Great. Cool."}, {"timestamp": [1453.72, 1458.72], "text": " So I like that."}, {"timestamp": [1462.0, 1465.86], "text": " Let's start with chapter one."}, {"timestamp": [1465.86, 1478.58], "text": " Please write out a much more detailed outline of chapter one."}, {"timestamp": [1478.58, 1480.9], "text": " Chapter one, the desperate decision."}, {"timestamp": [1480.9, 1484.22], "text": " Scene one, introducing Cornelia, the story opens with Cornelia and her family's modest"}, {"timestamp": [1484.22, 1488.6], "text": " home providing a brief description of her appearance and personality."}, {"timestamp": [1488.6, 1492.56], "text": " Again this is all kind of algorithmic."}, {"timestamp": [1492.56, 1499.08], "text": " If you open it this way, like so if you describe the main character's personality or show it"}, {"timestamp": [1499.08, 1505.56], "text": " right off the bat, that's going to be a little bit like kind of on the nose."}, {"timestamp": [1505.56, 1512.56], "text": " Whereas you definitely should demonstrate your main character in the first chapter,"}, {"timestamp": [1512.56, 1517.24], "text": " but if you just describe it with an info dump, that's not the best."}, {"timestamp": [1517.24, 1530.4], "text": " Let's see. It moved on to scene 3, deciding to sell the heirloom."}, {"timestamp": [1530.4, 1536.84], "text": " Yeah, we didn't go that far."}, {"timestamp": [1536.84, 1538.84], "text": " I like that it invented the name."}, {"timestamp": [1538.84, 1552.12], "text": " Okay, while searching for something valuable to sell, she discovers the family's heirloom. Okay, but that doesn't happen until chapter 2."}, {"timestamp": [1552.12, 1556.1], "text": " Yeah."}, {"timestamp": [1556.1, 1560.6], "text": " So it looks like we need to prime it again."}, {"timestamp": [1560.6, 1571.08], "text": " Here. here. So we'll do, we'll come back here and say after outline of chapter one, as a reminder,"}, {"timestamp": [1571.08, 1587.0], "text": " here is the grand totality of chapter one that we've discussed so far. Please stay within the bounds of chapter one."}, {"timestamp": [1587.0, 1592.0], "text": " Okay."}, {"timestamp": [1592.0, 1600.0], "text": " Now, please expand this brief outline into a more detailed outline."}, {"timestamp": [1600.0, 1605.76], "text": " So you might have noticed that sometimes what I'm doing is I'm rewriting the last one"}, {"timestamp": [1605.76, 1609.84], "text": " because what you want is if it gets something catastrophically wrong like this, you want to"}, {"timestamp": [1609.84, 1614.64], "text": " remove it from the chat history because otherwise you end up with what's called prompt contamination."}, {"timestamp": [1614.64, 1619.84], "text": " Remember how I just talked about priming? Priming works both ways. It can be positive in that you"}, {"timestamp": [1619.84, 1626.1], "text": " can prime the model to think in the way that you want it to, but if it has wrong information in the history,"}, {"timestamp": [1626.1, 1628.18], "text": " that's gonna continue polluting it."}, {"timestamp": [1628.18, 1631.86], "text": " And humans can get stuck in a rut like this too, right?"}, {"timestamp": [1631.86, 1634.26], "text": " Remember, if you're ever having a discussion"}, {"timestamp": [1634.26, 1635.7], "text": " or you're in a meeting or whatever,"}, {"timestamp": [1635.7, 1637.3], "text": " and you get the wrong idea in your head,"}, {"timestamp": [1637.3, 1639.66], "text": " it can be really hard to get out of that rut."}, {"timestamp": [1639.66, 1642.02], "text": " So in that case, it's actually kind of similar to humans."}, {"timestamp": [1642.02, 1643.62], "text": " One advantage that these models have"}, {"timestamp": [1643.62, 1646.16], "text": " is you can just flat out erase the wrong information"}, {"timestamp": [1646.16, 1648.64], "text": " from its memory."}, {"timestamp": [1648.64, 1652.8], "text": " Okay, so let's see if it does a little bit better this time."}, {"timestamp": [1652.8, 1662.96], "text": " Also I'm still contending with burnout myself and so I probably shouldn't be doing this"}, {"timestamp": [1662.96, 1665.88], "text": " right now, but it's just too exciting."}, {"timestamp": [1665.88, 1667.4], "text": " Okay."}, {"timestamp": [1667.4, 1668.4], "text": " I like this."}, {"timestamp": [1668.4, 1671.48], "text": " Description of the modest home with her family highlighted in contrast between their current"}, {"timestamp": [1671.48, 1674.24], "text": " circumstances and their once prosperous past."}, {"timestamp": [1674.24, 1675.24], "text": " There we go."}, {"timestamp": [1675.24, 1678.84], "text": " Cornelia helps her mother with chores, revealing her dutiful nature and her desire to contribute"}, {"timestamp": [1678.84, 1679.84], "text": " to the family."}, {"timestamp": [1679.84, 1681.12], "text": " Oh, that's good."}, {"timestamp": [1681.12, 1684.6], "text": " So this is showing instead of telling."}, {"timestamp": [1684.6, 1687.72], "text": " Much, much better. So remember when the last"}, {"timestamp": [1687.72, 1692.44], "text": " time it was like, oh, we're just going to tell you about her personality. No, wrong."}, {"timestamp": [1692.44, 1697.36], "text": " You show their personality. And so you show that she's helping her mother with chores."}, {"timestamp": [1697.36, 1703.7], "text": " You show that she's bickering with her siblings. You show them talking about how things used"}, {"timestamp": [1703.7, 1705.44], "text": " to be. Great."}, {"timestamp": [1705.44, 1708.24], "text": " Cornelius's father returns looking weary and defeated."}, {"timestamp": [1708.24, 1710.44], "text": " The family gathers for a simple frugal meal,"}, {"timestamp": [1710.44, 1712.72], "text": " highlighting their financial difficulties."}, {"timestamp": [1712.72, 1714.68], "text": " This is phenomenal."}, {"timestamp": [1714.68, 1718.84], "text": " I'm gonna call this a day because holy crap,"}, {"timestamp": [1718.84, 1721.56], "text": " this is exciting."}, {"timestamp": [1721.56, 1726.56], "text": " And just to think that ChatGPT just came out a few months ago. That was what,"}, {"timestamp": [1726.56, 1734.0], "text": " four months ago? And we're already quadrupling, going from 8,000 tokens to 32,000 tokens."}, {"timestamp": [1735.6, 1740.32], "text": " This poll that I did, AGI this year, yeah, tell me what you think now."}, {"timestamp": [1741.12, 1744.32], "text": " All right, that's it. Wrapping it up. Bye."}, {"timestamp": [1739.58, 1745.5], "text": " now. Alright, that's it. Wrapping it up. Bye."}]}