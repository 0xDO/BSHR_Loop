{"text": " As it seems like it's a foregone conclusion that we will have AGI within the next year, or at least really advanced AI plus robotics, whether or not you define it as AGI, it is time to start preparing and adapting. So today we will go over how businesses, governments, and individuals can prepare for the coming change. So for the sake of this video, I've had a few people ask what do I mean when I say AGI. Now my personal prediction is that any definition you have of AGI will be satisfied within the next year. So what I mean by that is the compounding returns of multimodal AI plus robotics research plus everything else going on means that basically anything that people that any definition that I've seen of AGI, with the exception of a few like really extreme ones, will be satisfied within the next year. So, but what do I mean by that? So, what are some of the examples? So, first, multimodal. We're already, we're seeing models that are trained with image, text, embodiment data, all kinds of stuff. So, basically, every kind of data we can throw at models they're being trained with, and maybe there's even gonna be more kinds of modalities. Greater than median human cognitive abilities is another thing that we should expect. Already, depending on how you measure it, the IQ of some of these models is far above most humans, particularly when you consider how fast they work. Uh, now, of course, some people argue, well, it's not even thinking. And it's like, I'm not going to get lost in that. Cause that's a red herring. Like, you know, uh, like look at its functional capacities, look at what is it, what it is able to achieve and what it is not able to achieve. Not saying like, well, it's not human. Therefore it's not thinking. Cause those are just semantic word games and they're not actually helpful. And it's, to me, that looks like just a defensive mechanism, just some coping. Anyways, so another aspect is gonna be autonomy. So the rumors are swirling that OpenAI and others are training autonomous AI, and they worked very, very hard to make ChatGPT not autonomous. They worked very hard to make it passive, and like, I am a helpful assistant. So, okay, sure, whatever. Another thing that we should expect to see is continual self-improvement once we get AGI. And so this is kind of something that is debatable, because the thing is, is these models already have the capacity for in-context learning. So that means the accumulation of information that it can just use in real time still counts as learning. However, what we want to see is also the ability to update its models, update its underlying models and software as well. And of course, you know, GPT models already have the ability to code. They already have the ability to synthesize data. So there's no reason right now, today, there are no barriers to having architectures that can modify themselves, except maybe the context window and the level of sophistication of some of these models. But all we need is the architecture and it is there. And I suspect that we will have all of this within the next 12 calendar months. So what we're coming for is a paradigm shift, and what I mean by a paradigm shift is that the impact of AGI is going to have a greater impact than both mechanization of the second industrial revolution and the digital revolution of the third industrial revolution combined. This is basically inventing all of human history and doubling that. It's going to have a huge social impact, it's going to have a huge economic impact, it's going to be a technological leap forward, it's going to have huge geopolitical ramifications, and finally it's also going to impact the government. AGI is literally going to impact every pillar of society across the entire planet. And the biggest threat here is normalcy bias. So, I guess the primary purpose of this video is let's address the normalcy bias in these three main pillars. On an individual basis, on a governmental basis, and on a business basis. And so what is normalcy bias? Normalcy bias is a cognitive bias where you just basically say, well, the status quo is things are this way today, and I'm looking at the past as an anchoring, and so I'm going to say, okay, well, because of the past and the way things are today, this is how it's always going to say, okay, well, because of the past and the way things are today, this is how it's always going to be. And you always see this normalcy bias in any kind of forecast. And a lot of people fail to take into account just how fast AI has advanced just from a year ago. So I like pointing this out. So think about where we were a year ago and think about where we are today, and then extrapolate that out another year forward. A year ago we weren't even talking about multimodal models and now we all have, or at least most of us, have access to multimodal models. A year ago you weren't even aware of chat GPT because it didn't exist yet. We still had only GPT-3. Now we've got GPT-4 vision, we've got memGPT, we've got all kinds of other things out there, we've got Google's RTX. Guys, I can't tell you how fast things are going. So the reason that I bring up normalcy bias as a major risk is because I'm seeing a lot of normalcy bias out there in the world. Obviously if you're watching this channel, you are probably ahead of the curve because you watch me, you watch AI Explained, you might watch Matt Wolff and a few others, so like you're aware of what the cutting edge is, but as many of you comment, a lot of people don't. I actually just saw a news article that only two out of five teenagers even know what chat GPT is, so we're still in the minority, which is really crazy considering how much is gonna change in the next year. So we're still in the minority, which is really crazy considering how much is going to change in the next year. So this kind of complacency is a huge risk and this is why I'm making this video. So like share this video or use it to you know get familiar with how to change people's minds, whatever. Alright so first government. What can the government do to adapt to the coming AI wave? So there's two primary problems that I see in the government. And this is not just me observing the news. Some of my clients and other people that I work with either are government contractors or government employees. And so the first aspect is potential widespread unemployment. Obviously, many governments around the world are experimenting with UBI, so that's good. But there's many people within the government that are just not aware of what's coming. They're not aware of the narrative, or their current narrative is it's just a new technology. The second thing that governments can do to adapt is to just start adopting AI services for themselves. And I've got examples for both of these. But the first big thing is, and this is what I've talked to some government researchers about all over the world. I've talked to government policy people in Europe, Australia, not as many in America for whatever reason. people in Europe, Australia, not as many in America for whatever reason, but basically one of the things, one of the problems is that convincing people inside of governments of what is happening is really difficult, because they look, like they have that very much normalcy bias where they're like, well, I'm not hearing about massive unemployment from AI, so what are you talking about? It doesn't physically exist right now, so I don't think that it's a thing. And this is a cognitive bias that most humans have. So, they're not doing much to prepare for post-labor economics. They're not even studying it because the current economic doctrine is neoliberalism, which says you should aim for around 3-5% unemployment, but otherwise let the free market make up its own decisions. And so we're basically going to have an entirely new economic paradigm that's coming that many people are not preparing for. Now, the fact that some governments are experimenting with UBI tells me that maybe they're trying to hedge their bets, but they're not talking about it. And as many of you commenters have pointed out in the past, the current system breaks down once you get above like 20 to 30 percent unemployment. I think what there's like a there's a predicted threshold. I think it's like 35 percent unemployment. Once you get to that, like you're basically like society collapses or something. Now, obviously, it'll take a while to get to get there. And right right now unemployment is very low. So post-labor economics, as I'm talking about, this is basically, it's not just automation, it's not just saying, okay, well, machines are able to do a couple things and they're going to display some stuff, but humans are just intrinsically exceptional and are intrinsically different. No, post-labor economics is a fundamental shift in the way that labor is done. And so there's, I've characterized it into a couple of subcategories. So it's a, it's more than just automation. Automation is actually, like, that's one way you can characterize it, but you're basically automating almost everything away. So one thing to keep in mind is human preferred jobs. So this is a demand side look at it, which is like, okay, supply side. So if you look at labor supply, labor supply is what are the workers that are out there? What is their training? What is their capabilities and so on. But if machines are able to satisfy all supply, if they're able to do work better, faster, cheaper, and safer than humans, then the supply side is fully occupied. So then you have to look at the demand side, which the demand side is, what are people willing to pay for? And so there will always be a few jobs that humans will just want other humans to be doing, like influencers and content creators. If you're watching me and not watching one of the, you know, AI generated channels, then it's like you prefer a real human. So there will always be some human preferred sectors. And what we're going to be seeing is a very skewed labor market. So basically, as machines are able to do more human jobs, companies are just going to prefer to use machines to do those jobs. Why? It makes economic sense, and that push for innovation is actually part of neoliberalism. So if you're a government employee or government contractor and you're watching this, what you need to understand is that neoliberalism is a push for efficiency. It is a system that is put in place that incentivizes increasing efficiency. That's exactly what we're aiming for. And so if you're also in the government and you are trying to say like, okay, well, what are we looking for? You're going to look for high unemployment and you're also going to look for declining total labor force participation rate. So if you look at charts, total labor force participation rate has, it peaked in America at around 66% and it has never recovered since the Great Recession, I think is when it kind of peaked. And then it dropped even further during the pandemic and it is kind of slowly recovering, but I think that we are permanently on a downward trend where total labor participation force rates are just going to be slowly deflating from here on out. And I think that unemployment is actually not going to be the best metric because some people are just checking out of the economy for good. We're going to need a new social contract. So what is a social contract? The social contract is basically the unspoken or spoken agreement between all the pillars of society So in the past the pillars of society might have been the church and the monarchy and the peasants and whatever else Today the three pillars of society are government business and the people So the power the balance of power is going to be disrupted Because labor force is going to be on the decline. Labor power is going to be fully disrupted by this and so worker power is going to be completely thrown out the window, or by and large thrown out the window. And you already see this with some of the union stuff. So the like the Hollywood writer strike that is an early example of people kind of rebelling against the inevitable change towards AI Hollywood writers like yes, human writers are still better than AI in some respects. Although if you watch some movies coming out of Hollywood, it's like yeah, AI could do a better job than this. So like fight it as you as you might, but but we're gonna have you know personalized movies and books and AI generated content all over and yes some people will still prefer to see Hollywood actors but many people won't. So that that that is evidence of the erosion of worker power and so what we're gonna need to do is negotiate a new balance of power, which is how do we reshape the government and business and everything else to ensure that we don't end up in a dystopian hellscape. Next up is government AI adoption. So I mentioned this, and that is that the government will need to adopt AI products and services. And I actually have a connection on LinkedIn who runs a startup and this startup he has a really great track record of basically accelerating government programs. And so in this one case he had a contract with the Veterans Affairs Office, the VA, and they were able to clear a three-year backlog of medical paperwork in a matter of weeks using generative AI. And so this is an example that I've been wanting to share for a while, because what I want to do is show that, yes, AGI is going to change everything, but AI today can start changing stuff now. And so this is why I created this graphic. I was like, imagine that the government is as lean and fast as a Ferrari. But the idea is that sticking your head in the sand and ignoring AI and keeping the government in the current status quo is a bad idea. What we need to be doing is adopting AI so that the government becomes leaner, faster, less corrupt, more transparent, more representative of people's actual best interests. The story from AskSage is a really good one. I was able to chat with the founder for a little bit and he said, oh yeah, like everything that we're doing, none of it was possible just a couple of years ago because that's how fast AI has advanced. So first mover advantage. One thing that has been more and more talked about is UBI, so universal basic income, but also universal basic services. And what I realized after talking to a bunch of people is that we already actually have a decent model of basic services in the form of K-12 public education. So obviously, there's also roads are maintained by the state, and there's lots of other things that are maintained by the state. But the school system is the only thing that is universal. We literally have a federal mandate that every child is entitled to an education, and we figured that out. We run the school system. Now, obviously, when you look at problems like inequality and blooms to sigma problems, you know, our public schooling system is not perfect but it does serve every single child. And so this is actually a decent enough model for universal basic services. So how is this going to look? Now obviously a lot of people say like yeah, good luck living on $1,200 a month from the government and I agree that's pretty slim. I would not want to live on only $1,200 a month from the government. Now however there are many levels of government. There is federal, there is state, there is county, there is municipal. And so what I anticipate actually is that we will have a multi-layered set of safety nets that are a Combination of UBI and UBS and so we might have a federal UBI basically, you know federal taxes tax the companies that are Churning out trillions of dollars worth of value with AI. That's That would be appropriate. You tax and redistribute that. Then you also do the same thing at the state level, but then also at the state and county and municipal level, you provide basic services like hospitals. You provide basic services like power, food, maybe even housing in many cases. And so this is one thing that really gives me a lot of encouragement, is because many of the experiments going on around the world about UBI are actually being run by cities, or states, or counties, or provinces. They're not being run at the federal level. And so, you combine AI efficiency with some of these multi-layered approaches, and I think that what we're going to have is this multi-layered safety net of UBI and UBS, and I think that we're actually going to end up in a much better place than we are today, certainly here in America, because in America it's like, you're on your own, scrub, get good. Okay, so let's move on to businesses. What can businesses do to adapt to AI? Well, first and foremost, you have to recognize that this is the most significant paradigm shift in all of human history, both economically and technologically. This is nothing short of the fourth industrial revolution, probably the biggest one yet. This is going to change the competitive landscape, which basically means if you're not adopting AI, your competitors are, so if you're not adopting AI, good luck. I've actually heard, I don't have any clients, obviously if someone comes to me they want AI, but I've heard of people out there that are like, no, AI is just a fad, it's just a hype cycle, we're not going to invest, we're going to let it blow over.\" And I'm like, okay, we'll see how that plays out. Now, another thing about this changing landscape is some businesses, I think, are going to see thinning margins. And that is just because the marginal cost of using AI to do some things is near zero, which means if your margin goes from 50% to 1%, you can't skim anything off the top for yourself. We've already seen this with some sectors collapsing, such as the creative sector, such as customer service jobs, and then also HR. We've seen a lot of layoffs in the HR departments. I think it was Satya Nadella, one of the CEOs, or maybe it was, what's his name at IBM? Anyways, he predicted that back office workers are gonna be the first to go. Those are white collar jobs. And so any companies that serve HR purposes, any companies that serve customer service positions, any companies that focus on copywriting and images and that sort of stuff, they're all gone. And so that's what thinning margins results in, is companies collapsing just because there's no room left to scrape out. This can also be called creative destruction, where it's basically an entire sector is just invalidated by a new technology. Either way, there's going to be a lot of companies that collapse. Then investing in AI, both in terms of products and services, and developing AI talent, which we'll unpack more right now. So the first thing that you need to know as a business is adapt or die. This is the same as companies that you know that were late to adopt electrification and the internet. Many of them went out of business and those that were able to pivot and adapt, some of them are still around like IBM. What you might not realize about IBM is that they started as mechanical time clocks. And so, obviously, IBM now working on quantum computing, they have pivoted several times, which is why they've been around for more than 100 years. Many of their competitors no longer exist. Another example is borders. Borders failed to pivot to adapt to the internet and so what were they replaced by? Barnes & Noble and Amazon. Again, we do have living memory of companies failing to adapt to the internet and therefore collapsing. So I'm here to tell you AI is not hype. It will change everything and even if you look at like, well, it's not capable of stuff today, look at what it was capable of last year, which in comparison, AI was not capable of hardly anything this time last year. And now it's like, well, a lot of us use AI every day all day to do our work. And so this time next year, you're not going to be able to get away without using AI. So you, you will adapt or you will die. It's that simple. And I'm also here to tell you that this is kind of bad news, but AI is going to destroy a lot of jobs and a lot of businesses, and there's not much we can do about it. So the beginning of my career back in 2007 was as the tech industry was recovering from the dot-com revolution and crash And so, you know, there was I remember growing up hearing like there are 50,000 unfilled IT jobs I was like, okay, I guess I'll get an IT job and it was really easy because there's such a huge vacuum There was a huge need for IT people. It's like oh, hey, you can program a home router. Great. You've got a job It wasn't quite that easy, but it was close And so we're seeing the same thing with AI talent right now AI is the new IT AI is the new software engineering I remember my mom's boyfriend back in the early 2000s like he came back from the army got a Microsoft certification and immediately had it like Back then man, it was easy., got a Microsoft certification, and immediately had it. Like, back then, man, it was easy. You get one Microsoft certification, instant job that pays 50,000 a year. You get a handful of certifications, 80,000 a year. And your companies would pay for it, too. Most of my training at the beginning of my career paid for by my company because there was so little talent. Now, one thing that is not necessarily possible because a lot of the training programs don't even exist yet is you need to focus on your internal talent development. So for the last 10 to 15 years, we've had this glut of in the labor market, in the technology space where pretty much anything you need, if you need a database administrator, you need a C sharp developer, there was someone out there. And so companies have gotten really lazy about talent development. Like I said, 15 years ago, at the beginning of my career, all of all of my talent development was paid for by my company because it wasn't there in the last 10 years, companies have gotten really lazy. And so what I've had to do with some of my clients is say, hey, the thing, the skills and experience that you want to hire for isn't out there. You need to develop it. So like one of my clients was basically saying like, hey, how do we find someone who is a director who understands like cognitive architecture? I'm like, you don't because the only people who understand cognitive architecture are a few of us Lunatics out here and then like PhDs that have been studying it since the 80s, but they're not looking for a you know Director of technology job So I was like what you do what you need to do Then is you hire for personality and the two primary traits that I recommend that people hire for is hunger I don't mean like physical hunger. I mean people that are hungry for AI and and and hungry for the job and then curiosity because those are two inborn traits and then then you backfill in with the talent and skills and other things that can be trained in because you can't train someone to be hungry for their for their job. You can't train someone to be curious. Those are just fixed personality traits. So you focus on those two things and develop your own internal talent. Companies that go all in on AI, companies that focus on the AI talent, people that develop their own internal AI talent, they're going to have a much better chance at surviving this coming AI wave than those that don't. And mark my word there are plenty of companies out there that are basically sticking their head in the sand and ignoring the stuff so if you if you're watching this i know that there's a lot of c-suite people and senior vice presidents and other folks that watch like if you're watching this you are ahead of of the curve. Now I'm not saying that it's going to be easy because like I said, there are macroscopic economic macroeconomic forces at play here that could just cut out your legs from underneath you. So I know that's a really grim outlook, but like that's how it is and that is how every industrial revolution has happened up until this point. And this one's going to be no different in that respect. Okay. has happened up until this point and this one's going to be no different in that respect. Okay, so finally on a personal level how can you brace for impact? First and foremost is emotional adaptation. It is perfectly natural to have a very wide range of emotions as you contemplate these changes. Just last night it took me like an hour and a half to get to sleep because I didn't know what I was feeling. I was like, am I angry about this? Am I hopeful? Am I worried? Like, it was just like, just this potpourri of random nebulous emotions. Cause I'm like, man, like, cause I was making the slide deck last night and so I'm like, you know, I need to take my own advice here. Anyways, this is all natural. When you're facing a huge paradigm shift, it is natural to have the occasional existential crisis like this dude at the bar being served by a robot bartender. Uh, the best analogy that I have is it's like, you know that there's a big storm coming. You can prepare for the storm, you can brace for the storm, but eventually the storm is going to get here and all you can do is ride it out. Um, and so, yeah, like that's that. And you have to acknowledge these emotions. You have to accept them, work with them, talk about them. And so back when I was still hosting AI meetups, like a lot of people were like giddy. Like it was really validating to have a bunch of people like 20 and 30 people like at the bar together like talking about like yeah, this is so exciting and so like it was actually very normalizing for us to like feel saying like yeah, we're not making this up right like so many of the conversations were like we're checking in with each other like are we crazy or are we just like have the lunatics taken over the assignment it could be a little bit of both but it was really validating to get together with a bunch of other people and say like, hey, this is happening, right? Yes, cool. Okay, now what? So and that's why I have an existential coping channel in my discord server. Another thing you can do to prepare is start moving towards a forever job. And so a forever job, this is the other side of post labor economics, which is there will always be some jobs that people just want other people to do now I'm not saying go start an only fans go start. You know your YouTube career I don't know what kind of jobs are gonna be forever jobs But this is why I'm here on YouTube is because as long as there are humans I suspect there are gonna be humans that want to see my dumb face talking about AI or whatever it is that I ultimately talk about are going to be humans that want to see my dumb face talking about AI or whatever it is that I ultimately talk about. So but yeah, so be thinking about and talking about like, okay, what are some things that will stick around forever? And these are the demand side jobs. Now, obviously, not everyone can become a content creator. Not everyone wants to get into into childcare. And so that leads to another part, which is redefining how you achieve social status. So I've been reading this book it was recommended to me by a good friend and mentor called The Status Game by William Storr and this book is the single most profound book on human psychology I have ever read. It explains so much about the human condition, it blows sapiens out of the water. And I know that that's like heretical to say, but like this book is so well researched and it is so practical and it is so useful. So, basically the TLDR is that all humans across the entire planet all care about social status above all else. Everything else that we care about social status above all else. Everything else that we care about flows from this central foundational desire and it makes sense. We are a social species. Your survival is predicated on your social status and your success and happiness in life is predicated on your social status. So I strongly recommend you read this game, this book. But basically, there are three kinds of status games that we all play. And these status games are also rooted in our ancient evolution, because we see them in bonobos, we see it in chimps, we even see it in lions and other social mammals. So there's the success game, which is often material success or financial success. And so this is associated with career and conspicuous consumption. And one piece of evidence for this, and everyone has seen this, is that even toddlers are possessive. So our instinct for private property is inborn. Why? Because if you possess the neat things, you have higher social status. And this goes way, way, way before capitalism, way before neoliberalism. This is deeply embedded in our DNA. So material success, the possession of cool things, the nicer house, the cool shells, you know, the fancy car, this is an evolutionary artifact that is deeply embedded in us. Now obviously, if careers go away, like, okay, you're not going to have financial success through your career, but there will still be ways to have that kind of material success. Next up is the dominance game. So, dominance game is, you know, showing your muscles, intimidation, fear, physical prowess, sexual prowess, that sort of stuff. Part of the dominance game, you see this more often with militaries, sports, and you know people that like to pump iron and get on the beach and you know winning right you know dominance is all about winning it's about conquering your enemies. And then there the the third game is the virtue or prestige game which this is more about like people that are either spiritual or intellectual or emotional and so there's depending on which kind of virtues you prefer this is something that like I guess what I'm trying to say is like say for instance you are a very religious person part of your virtue is how well you adhere to your religious doctrine that's another way to get social status or if you're an academic if you're a researcher part of your virtue is how well you adhere to your religious doctrine. That's another way to get social status. Or, if you're an academic, if you're a researcher, part of the virtue or prestige is about intellectual contribution. So, that's another example of the status game. By recognizing that your social standing comes from multiple dimensions, because everyone plays a little bit of all three of these games, everyone cares about some material success. Everyone cares about some dominance and everyone cares about some virtue or prestige. It's just a matter of which one you prefer and what your particular social tribe prefers as well. But everyone does all three. And so recognizing and learning about social status is one of the number one ways to prepare for and adapt for the possibility of post-labor economics and no longer having a career. After reading this book I'm like, oh man, nobody needs a career. There are so many other ways to establish your social rank and to make sure that you have social standing in your tribe. Yeah, no, we're gonna be fine there. Another thing you can do is, as you have more time, because either you lose your job, and there's plenty of people that I talk to, some of the folks that have volunteered for some of the open source projects that I'm running, they lost their job six months ago, and they don't know if they're ever going to have a job again, and they're trying to find their way back in. But as we pivot to post-labor economics, as people lose their jobs or only have gig work or whatever, one of the most powerful frameworks for living happily on a day-to-day basis is Dr. Walsh's TLC, Therapeutic Lifestyle Changes. It is a framework of eight behaviors that you can engage in on a daily or weekly basis that really, really helps you feel better. But basically it's like, okay, so a TLC specialist is going to say, all right, let's fix your exercise. Like let's fix your, your diet and nutrition. Let's fix your relationships. Let's make sure you're spending time in nature. Let's make sure that you're doing your recreational stuff, your fun, your hobbies. Let's make sure that you're getting some relaxation and stress management. Let's make sure that you're engaging with your religious or spiritual side. And then finally, let's make sure that you are engaging in some kind of community service or giving back. So I learned about TLC many, many years ago, way back on the days of StumbleUpon, which doesn't even exist anymore. But this framework is super helpful and it's just like a checklist. You can just go through this every day and say like, hey, can I invest some time in this? Cool. And you do this and you'll feel better, I promise. Another thing, and this has been kind of a personal insight as I am acclimating to this change that we're facing, is forget about tomorrow. And you know, you might say like, Dave, you're always predicting like, you know, into the future, you're obviously not forgetting about tomorrow. And what I mean by this is, no, I'm not forgetting about tomorrow, like not in that sense, but I'm not worrying about tomorrow. It's like, okay, I see everything that everyone is doing. Like I go on archive on a regular basis. And I see that there are literally like thousands upon thousands of scientists, hundreds of labs and universities all over the world working on AI alignment and bias and safety. And, and I'm like, okay, the collective brainpower of those like literally tens of thousands of students and researchers. So I'm pretty sure we're going to figure out safety like this is a solvable problem and we will solve it. And then on the on the other side, there is the geopolitical and governmental side. There's the business side and it's like, okay, well, you know, as I've covered in some of my recent videos, all the halls of power are talking about AI, the EU, the UN, NATO, America, like ASEAN, like literally every international organization on the planet is aware of AI and they are doing something about it. Now, I might not agree with their closed door meetings, I might not agree with exactly how they're conducting it, but that's why I'm commenting on it. But the fact of the matter is, there are adults in the room and they are working on this stuff. And so it's like, you know what? I'm doing everything that I can. So I'm going to let go of the worry and I'm just going to forget about tomorrow and enjoy today. So like adopting a carpe diem mentality and just trusting that it'll work out. And I don't mean blind trust. I'm never one to argue for blind trust. I keep my ear to the ground, but it's like, yeah, I think generally things are going in the right direction. And then finally simplify your life. This is something that I realized that I've been doing lately, which is just, you know, the rat race is ending. Um, you know, the, the, the competition for a better job and you know, the, the fancy house on the cul-de-sac like, yeah, we can still want those things, but the current American dream has like, it's, it's, it's on its deathbed and it's just circling the drain and it's going to go any minute now. And like, yes, the status game will be forever, you know, so we're going to find new ways to compete. But this, this workaholic treadmill that we've been on, that's what's going away. And like the question that my wife and I have been asking each other and asking ourselves for the last few months is how do we want to live with all this cultural baggage of middle-class America and all that stuff? It's going away, it's dying. And so we're like, well, how do we want to live instead? And so, you know, we, we have been kind of critically recalibrating our own lives. And so one thing that I do is like when I'm done with work for the day, sometimes I'll go to see a movie sometime. Like we love going to Panera after we go hiking and it's just like, we're engaging with life on our own terms. And obviously like I recognize not everyone can do this yet, but I certainly recommend that everyone try, you know, like, whatever your dream is, like, why not start now if you can and look forward to that in the future. And this is why, like, I'm trying to thread the needle when I talk about post-labor economics and preparing for these changes, because if we all work together, if we work hard to make sure that AI is implemented in the ways that are best for everyone, if we work with the government and the businesses to make sure that it's not heavily skewed or lopsided and keeps everyone in a cyberpunk dystopian hellscape, then there's no reason, I don't see any reason no physical reason, no economic reason don't see any reason no physical reason no economic reason No game theory reason that we all couldn't live in a much more harmonious way That would be closer to our preference very soon And I mean like within the next two to five years I could see some of these major transitions happening which you know The like call that acceleration ism call it whatever you want, but like it's not a foregone conclusion that it will work out that way. But I don't see any reason that it can't. There's no fundamental reason that this is not the natural flow of things, except of course as some people will say like the billionaires are greedy and they of course want to make sure that they control everything and I'm like, I think maybe some do, but I don't know. I see it playing out really well. Anyways, thanks for watching. I hope you got a lot out of this. Let me know what you think in the comments. How are you preparing? Is there anything that I missed? So on and so forth. Have a good one. Cheers. Have a good one. Cheers.", "chunks": [{"timestamp": [0.0, 5.72], "text": " As it seems like it's a foregone conclusion that we will have AGI within the next year, or at least"}, {"timestamp": [6.16, 13.56], "text": " really advanced AI plus robotics, whether or not you define it as AGI, it is time to start preparing and adapting."}, {"timestamp": [13.68, 20.72], "text": " So today we will go over how businesses, governments, and individuals can prepare for the coming change."}, {"timestamp": [21.44, 25.12], "text": " So for the sake of this video, I've had a few people ask what do I mean"}, {"timestamp": [25.12, 30.04], "text": " when I say AGI. Now my personal prediction is that any definition you"}, {"timestamp": [30.04, 34.96], "text": " have of AGI will be satisfied within the next year. So what I mean by that is the"}, {"timestamp": [34.96, 39.04], "text": " compounding returns of multimodal AI plus robotics research plus everything"}, {"timestamp": [39.04, 43.5], "text": " else going on means that basically anything that people that any definition"}, {"timestamp": [43.5, 45.0], "text": " that I've seen of AGI,"}, {"timestamp": [45.0, 48.2], "text": " with the exception of a few like really extreme ones,"}, {"timestamp": [48.2, 50.6], "text": " will be satisfied within the next year."}, {"timestamp": [50.6, 52.2], "text": " So, but what do I mean by that?"}, {"timestamp": [52.2, 53.9], "text": " So, what are some of the examples?"}, {"timestamp": [53.9, 56.5], "text": " So, first, multimodal."}, {"timestamp": [56.5, 60.0], "text": " We're already, we're seeing models that are trained with"}, {"timestamp": [60.0, 63.4], "text": " image, text, embodiment data, all kinds of stuff."}, {"timestamp": [63.4, 66.84], "text": " So, basically, every kind of data we can throw at models"}, {"timestamp": [66.84, 68.56], "text": " they're being trained with,"}, {"timestamp": [68.56, 72.7], "text": " and maybe there's even gonna be more kinds of modalities."}, {"timestamp": [72.7, 75.72], "text": " Greater than median human cognitive abilities"}, {"timestamp": [75.72, 77.52], "text": " is another thing that we should expect."}, {"timestamp": [77.52, 79.84], "text": " Already, depending on how you measure it,"}, {"timestamp": [79.84, 84.28], "text": " the IQ of some of these models is far above most humans,"}, {"timestamp": [84.28, 88.08], "text": " particularly when you consider how fast they work. Uh, now,"}, {"timestamp": [88.08, 90.28], "text": " of course, some people argue, well, it's not even thinking."}, {"timestamp": [90.28, 93.36], "text": " And it's like, I'm not going to get lost in that. Cause that's a red herring."}, {"timestamp": [93.56, 97.8], "text": " Like, you know, uh, like look at its functional capacities, look at what is it,"}, {"timestamp": [97.82, 102.36], "text": " what it is able to achieve and what it is not able to achieve. Not saying like,"}, {"timestamp": [102.36, 104.76], "text": " well, it's not human. Therefore it's not thinking."}, {"timestamp": [106.64, 108.16], "text": " Cause those are just semantic word games and they're not actually helpful."}, {"timestamp": [108.16, 111.0], "text": " And it's, to me, that looks like just a defensive mechanism,"}, {"timestamp": [111.0, 113.0], "text": " just some coping."}, {"timestamp": [113.0, 117.2], "text": " Anyways, so another aspect is gonna be autonomy."}, {"timestamp": [117.2, 121.24], "text": " So the rumors are swirling that OpenAI and others"}, {"timestamp": [121.24, 125.68], "text": " are training autonomous AI, and they worked very, very hard"}, {"timestamp": [125.68, 127.6], "text": " to make ChatGPT not autonomous."}, {"timestamp": [127.6, 130.24], "text": " They worked very hard to make it passive,"}, {"timestamp": [130.24, 132.6], "text": " and like, I am a helpful assistant."}, {"timestamp": [132.6, 134.52], "text": " So, okay, sure, whatever."}, {"timestamp": [134.52, 136.24], "text": " Another thing that we should expect to see"}, {"timestamp": [136.24, 140.0], "text": " is continual self-improvement once we get AGI."}, {"timestamp": [140.0, 144.54], "text": " And so this is kind of something that is debatable,"}, {"timestamp": [144.54, 146.76], "text": " because the thing is, is these models already have"}, {"timestamp": [146.76, 149.2], "text": " the capacity for in-context learning."}, {"timestamp": [149.2, 151.28], "text": " So that means the accumulation of information"}, {"timestamp": [151.28, 155.1], "text": " that it can just use in real time still counts as learning."}, {"timestamp": [155.1, 159.16], "text": " However, what we want to see is also the ability"}, {"timestamp": [159.16, 162.74], "text": " to update its models, update its underlying models"}, {"timestamp": [162.74, 164.54], "text": " and software as well."}, {"timestamp": [164.54, 169.0], "text": " And of course, you know, GPT models already have the ability to code."}, {"timestamp": [169.0, 171.5], "text": " They already have the ability to synthesize data."}, {"timestamp": [171.5, 174.5], "text": " So there's no reason right now, today,"}, {"timestamp": [174.5, 178.5], "text": " there are no barriers to having architectures that can modify themselves,"}, {"timestamp": [178.5, 183.5], "text": " except maybe the context window and the level of sophistication of some of these models."}, {"timestamp": [183.5, 186.0], "text": " But all we need is the architecture and it is there."}, {"timestamp": [186.0, 189.0], "text": " And I suspect that we will have all of this within"}, {"timestamp": [189.0, 192.0], "text": " the next 12 calendar months."}, {"timestamp": [192.0, 195.0], "text": " So what we're coming for is a paradigm shift, and what I mean by a paradigm shift"}, {"timestamp": [195.0, 198.0], "text": " is that the impact of AGI"}, {"timestamp": [198.0, 201.0], "text": " is going to have a greater impact than both"}, {"timestamp": [201.0, 204.0], "text": " mechanization of the second industrial revolution"}, {"timestamp": [204.0, 209.76], "text": " and the digital revolution of the third industrial revolution combined. This is basically inventing all of"}, {"timestamp": [209.76, 215.12], "text": " human history and doubling that. It's going to have a huge social impact, it's going to have a"}, {"timestamp": [215.12, 220.4], "text": " huge economic impact, it's going to be a technological leap forward, it's going to have huge geopolitical"}, {"timestamp": [220.4, 230.7], "text": " ramifications, and finally it's also going to impact the government. AGI is literally going to impact every pillar of society across the entire planet."}, {"timestamp": [231.36, 233.66], "text": " And the biggest threat here is normalcy bias."}, {"timestamp": [233.66, 240.48], "text": " So, I guess the primary purpose of this video is let's address the normalcy bias in these three main pillars."}, {"timestamp": [240.92, 246.26], "text": " On an individual basis, on a governmental basis, and on a business basis."}, {"timestamp": [246.26, 248.24], "text": " And so what is normalcy bias?"}, {"timestamp": [248.24, 253.26], "text": " Normalcy bias is a cognitive bias where you just basically say, well, the status quo is"}, {"timestamp": [253.26, 260.18], "text": " things are this way today, and I'm looking at the past as an anchoring, and so I'm going"}, {"timestamp": [260.18, 263.9], "text": " to say, okay, well, because of the past and the way things are today, this is how it's"}, {"timestamp": [263.9, 265.24], "text": " always going to say, okay, well, because of the past and the way things are today, this is how it's always going to be."}, {"timestamp": [265.24, 267.2], "text": " And you always see this normalcy bias"}, {"timestamp": [267.2, 268.94], "text": " in any kind of forecast."}, {"timestamp": [268.94, 271.16], "text": " And a lot of people fail to take into account"}, {"timestamp": [271.16, 275.2], "text": " just how fast AI has advanced just from a year ago."}, {"timestamp": [275.2, 277.14], "text": " So I like pointing this out."}, {"timestamp": [277.14, 279.28], "text": " So think about where we were a year ago"}, {"timestamp": [279.28, 281.4], "text": " and think about where we are today,"}, {"timestamp": [281.4, 284.2], "text": " and then extrapolate that out another year forward."}, {"timestamp": [284.2, 285.16], "text": " A year ago we"}, {"timestamp": [285.16, 288.88], "text": " weren't even talking about multimodal models and now we all have, or at least"}, {"timestamp": [288.88, 293.2], "text": " most of us, have access to multimodal models. A year ago you weren't even"}, {"timestamp": [293.2, 298.44], "text": " aware of chat GPT because it didn't exist yet. We still had only GPT-3. Now"}, {"timestamp": [298.44, 303.16], "text": " we've got GPT-4 vision, we've got memGPT, we've got all kinds of other things out"}, {"timestamp": [303.16, 306.48], "text": " there, we've got Google's RTX."}, {"timestamp": [306.48, 311.46], "text": " Guys, I can't tell you how fast things are going."}, {"timestamp": [311.46, 317.12], "text": " So the reason that I bring up normalcy bias as a major risk is because I'm seeing a lot"}, {"timestamp": [317.12, 319.72], "text": " of normalcy bias out there in the world."}, {"timestamp": [319.72, 323.72], "text": " Obviously if you're watching this channel, you are probably ahead of the curve because"}, {"timestamp": [323.72, 328.16], "text": " you watch me, you watch AI Explained, you might watch Matt Wolff and a few others, so"}, {"timestamp": [328.16, 332.8], "text": " like you're aware of what the cutting edge is, but as many of you comment, a"}, {"timestamp": [332.8, 337.16], "text": " lot of people don't. I actually just saw a news article that only two out of"}, {"timestamp": [337.16, 343.28], "text": " five teenagers even know what chat GPT is, so we're still in the minority, which"}, {"timestamp": [343.28, 345.88], "text": " is really crazy considering how much is gonna change in the next year. So we're still in the minority, which is really crazy considering how much is"}, {"timestamp": [345.88, 351.32], "text": " going to change in the next year. So this kind of complacency is a huge risk and"}, {"timestamp": [351.32, 355.36], "text": " this is why I'm making this video. So like share this video or use it to you"}, {"timestamp": [355.36, 360.6], "text": " know get familiar with how to change people's minds, whatever. Alright so first"}, {"timestamp": [360.6, 366.0], "text": " government. What can the government do to adapt to the coming AI wave?"}, {"timestamp": [366.0, 371.0], "text": " So there's two primary problems that I see in the government."}, {"timestamp": [371.0, 377.0], "text": " And this is not just me observing the news. Some of my clients and other people that I work with"}, {"timestamp": [377.0, 381.0], "text": " either are government contractors or government employees."}, {"timestamp": [381.0, 388.0], "text": " And so the first aspect is potential widespread unemployment."}, {"timestamp": [388.0, 392.0], "text": " Obviously, many governments around the world are experimenting with UBI, so that's good."}, {"timestamp": [392.0, 399.0], "text": " But there's many people within the government that are just not aware of what's coming."}, {"timestamp": [399.0, 405.2], "text": " They're not aware of the narrative, or their current narrative is it's just a new technology."}, {"timestamp": [410.0, 414.32], "text": " The second thing that governments can do to adapt is to just start adopting AI services for themselves. And I've got examples for both of these. But the first big thing is,"}, {"timestamp": [414.32, 417.92], "text": " and this is what I've talked to some government researchers about all over the world. I've talked"}, {"timestamp": [417.92, 423.84], "text": " to government policy people in Europe, Australia, not as many in America for whatever reason."}, {"timestamp": [423.2, 427.32], "text": " people in Europe, Australia, not as many in America for whatever reason, but basically one of the things,"}, {"timestamp": [427.32, 429.8], "text": " one of the problems is that convincing people"}, {"timestamp": [429.8, 432.2], "text": " inside of governments of what is happening"}, {"timestamp": [432.2, 434.16], "text": " is really difficult, because they look,"}, {"timestamp": [434.16, 436.24], "text": " like they have that very much normalcy bias"}, {"timestamp": [436.24, 439.12], "text": " where they're like, well, I'm not hearing about"}, {"timestamp": [439.12, 441.74], "text": " massive unemployment from AI, so what are you talking about?"}, {"timestamp": [441.74, 444.08], "text": " It doesn't physically exist right now,"}, {"timestamp": [444.08, 446.0], "text": " so I don't think that it's a thing."}, {"timestamp": [446.0, 453.0], "text": " And this is a cognitive bias that most humans have. So, they're not doing much to prepare for post-labor economics."}, {"timestamp": [453.0, 458.0], "text": " They're not even studying it because the current economic doctrine is neoliberalism, which says"}, {"timestamp": [458.0, 465.76], "text": " you should aim for around 3-5% unemployment, but otherwise let the free market make up its own decisions."}, {"timestamp": [465.76, 471.44], "text": " And so we're basically going to have an entirely new economic paradigm that's coming that many"}, {"timestamp": [471.44, 472.72], "text": " people are not preparing for."}, {"timestamp": [472.72, 477.96], "text": " Now, the fact that some governments are experimenting with UBI tells me that maybe they're trying"}, {"timestamp": [477.96, 481.68], "text": " to hedge their bets, but they're not talking about it."}, {"timestamp": [481.68, 487.04], "text": " And as many of you commenters have pointed out in the past, the current system breaks down"}, {"timestamp": [487.04, 492.48], "text": " once you get above like 20 to 30 percent unemployment. I think what there's like a"}, {"timestamp": [492.48, 496.88], "text": " there's a predicted threshold. I think it's like 35 percent unemployment. Once you get to that,"}, {"timestamp": [496.88, 501.84], "text": " like you're basically like society collapses or something. Now, obviously, it'll take a while to"}, {"timestamp": [501.84, 506.4], "text": " get to get there. And right right now unemployment is very low."}, {"timestamp": [506.4, 511.6], "text": " So post-labor economics, as I'm talking about, this is basically, it's not just automation,"}, {"timestamp": [511.6, 516.16], "text": " it's not just saying, okay, well, machines are able to do a couple things and they're"}, {"timestamp": [516.16, 521.2], "text": " going to display some stuff, but humans are just intrinsically exceptional and are intrinsically"}, {"timestamp": [521.2, 522.2], "text": " different."}, {"timestamp": [522.2, 526.04], "text": " No, post-labor economics is a fundamental shift in the"}, {"timestamp": [526.04, 528.64], "text": " way that labor is done. And so there's,"}, {"timestamp": [528.64, 531.2], "text": " I've characterized it into a couple of"}, {"timestamp": [531.2, 534.24], "text": " subcategories. So it's a, it's more than"}, {"timestamp": [534.24, 536.44], "text": " just automation. Automation is actually,"}, {"timestamp": [536.44, 537.92], "text": " like, that's one way you can"}, {"timestamp": [537.92, 539.4], "text": " characterize it, but you're basically"}, {"timestamp": [539.4, 542.36], "text": " automating almost everything away. So"}, {"timestamp": [542.36, 544.88], "text": " one thing to keep in mind is human"}, {"timestamp": [544.88, 546.56], "text": " preferred jobs. So this is"}, {"timestamp": [546.56, 552.68], "text": " a demand side look at it, which is like, okay, supply side. So if you look at labor supply,"}, {"timestamp": [552.68, 556.36], "text": " labor supply is what are the workers that are out there? What is their training? What"}, {"timestamp": [556.36, 561.58], "text": " is their capabilities and so on. But if machines are able to satisfy all supply, if they're"}, {"timestamp": [561.58, 565.96], "text": " able to do work better, faster, cheaper, and safer than humans, then"}, {"timestamp": [565.96, 569.88], "text": " the supply side is fully occupied."}, {"timestamp": [569.88, 573.28], "text": " So then you have to look at the demand side, which the demand side is, what are people"}, {"timestamp": [573.28, 575.02], "text": " willing to pay for?"}, {"timestamp": [575.02, 580.4], "text": " And so there will always be a few jobs that humans will just want other humans to be doing,"}, {"timestamp": [580.4, 583.34], "text": " like influencers and content creators."}, {"timestamp": [583.34, 586.7], "text": " If you're watching me and not watching one of the, you know,"}, {"timestamp": [586.7, 591.4], "text": " AI generated channels, then it's like you prefer a real human."}, {"timestamp": [591.4, 595.8], "text": " So there will always be some human preferred sectors."}, {"timestamp": [595.8, 600.1], "text": " And what we're going to be seeing is a very skewed labor market."}, {"timestamp": [600.1, 607.46], "text": " So basically, as machines are able to do more human jobs, companies are just going to prefer"}, {"timestamp": [607.46, 609.68], "text": " to use machines to do those jobs."}, {"timestamp": [609.68, 610.68], "text": " Why?"}, {"timestamp": [610.68, 615.34], "text": " It makes economic sense, and that push for innovation is actually part of neoliberalism."}, {"timestamp": [615.34, 619.16], "text": " So if you're a government employee or government contractor and you're watching this, what"}, {"timestamp": [619.16, 623.62], "text": " you need to understand is that neoliberalism is a push for efficiency."}, {"timestamp": [623.62, 628.72], "text": " It is a system that is put in place that incentivizes increasing efficiency."}, {"timestamp": [628.72, 631.14], "text": " That's exactly what we're aiming for."}, {"timestamp": [631.14, 635.72], "text": " And so if you're also in the government and you are trying to say like, okay, well, what"}, {"timestamp": [635.72, 636.72], "text": " are we looking for?"}, {"timestamp": [636.72, 640.32], "text": " You're going to look for high unemployment and you're also going to look for declining"}, {"timestamp": [640.32, 642.48], "text": " total labor force participation rate."}, {"timestamp": [642.48, 648.16], "text": " So if you look at charts, total labor force participation rate has, it peaked in America"}, {"timestamp": [648.16, 652.96], "text": " at around 66% and it has never recovered since the Great Recession, I think is when it kind"}, {"timestamp": [652.96, 654.4], "text": " of peaked."}, {"timestamp": [654.4, 659.62], "text": " And then it dropped even further during the pandemic and it is kind of slowly recovering,"}, {"timestamp": [659.62, 664.94], "text": " but I think that we are permanently on a downward trend where total labor participation force"}, {"timestamp": [664.94, 669.0], "text": " rates are just going to be slowly deflating from here on out."}, {"timestamp": [669.0, 677.0], "text": " And I think that unemployment is actually not going to be the best metric because some people are just checking out of the economy for good."}, {"timestamp": [677.0, 680.0], "text": " We're going to need a new social contract. So what is a social contract?"}, {"timestamp": [680.0, 685.72], "text": " The social contract is basically the unspoken or spoken agreement"}, {"timestamp": [686.16, 688.16], "text": " between all the pillars of society"}, {"timestamp": [688.4, 695.28], "text": " So in the past the pillars of society might have been the church and the monarchy and the peasants and whatever else"}, {"timestamp": [695.54, 699.46], "text": " Today the three pillars of society are government business and the people"}, {"timestamp": [699.84, 704.5], "text": " So the power the balance of power is going to be disrupted"}, {"timestamp": [709.2, 717.28], "text": " Because labor force is going to be on the decline. Labor power is going to be fully disrupted by this and so worker power is going to be completely thrown out the window,"}, {"timestamp": [717.28, 719.52], "text": " or by and large thrown out the window."}, {"timestamp": [719.52, 726.48], "text": " And you already see this with some of the union stuff. So the like the Hollywood writer strike that is an early example of"}, {"timestamp": [726.48, 730.24], "text": " people kind of rebelling against the inevitable change"}, {"timestamp": [730.24, 734.48], "text": " towards AI Hollywood writers like yes, human writers are"}, {"timestamp": [734.48, 737.04], "text": " still better than AI in some respects. Although if you"}, {"timestamp": [737.04, 739.36], "text": " watch some movies coming out of Hollywood, it's like yeah,"}, {"timestamp": [739.36, 742.96], "text": " AI could do a better job than this. So like fight it as you"}, {"timestamp": [742.96, 745.12], "text": " as you might, but but we're gonna have"}, {"timestamp": [745.12, 751.24], "text": " you know personalized movies and books and AI generated content all over and"}, {"timestamp": [751.24, 755.56], "text": " yes some people will still prefer to see Hollywood actors but many people won't."}, {"timestamp": [755.56, 761.96], "text": " So that that that is evidence of the erosion of worker power and so what"}, {"timestamp": [761.96, 767.08], "text": " we're gonna need to do is negotiate a new balance of power, which is how do we"}, {"timestamp": [767.08, 772.72], "text": " reshape the government and business and everything else to ensure that we don't end up in a dystopian"}, {"timestamp": [772.72, 774.4], "text": " hellscape."}, {"timestamp": [774.4, 776.02], "text": " Next up is government AI adoption."}, {"timestamp": [776.02, 781.64], "text": " So I mentioned this, and that is that the government will need to adopt AI products"}, {"timestamp": [781.64, 788.24], "text": " and services. And I actually have a connection on LinkedIn who runs a startup"}, {"timestamp": [788.8, 795.6], "text": " and this startup he has a really great track record of basically accelerating government"}, {"timestamp": [795.6, 801.68], "text": " programs. And so in this one case he had a contract with the Veterans Affairs Office, the VA,"}, {"timestamp": [802.56, 805.84], "text": " and they were able to clear a three-year backlog"}, {"timestamp": [805.84, 810.52], "text": " of medical paperwork in a matter of weeks using generative AI."}, {"timestamp": [810.52, 812.48], "text": " And so this is an example that I've"}, {"timestamp": [812.48, 815.0], "text": " been wanting to share for a while, because what I want"}, {"timestamp": [815.0, 819.72], "text": " to do is show that, yes, AGI is going to change everything,"}, {"timestamp": [819.72, 823.0], "text": " but AI today can start changing stuff now."}, {"timestamp": [823.0, 824.76], "text": " And so this is why I created this graphic."}, {"timestamp": [824.76, 826.76], "text": " I was like, imagine that the government"}, {"timestamp": [826.76, 829.12], "text": " is as lean and fast as a Ferrari."}, {"timestamp": [829.12, 832.6], "text": " But the idea is that sticking your head in the sand"}, {"timestamp": [832.6, 835.48], "text": " and ignoring AI and keeping the government"}, {"timestamp": [835.48, 838.16], "text": " in the current status quo is a bad idea."}, {"timestamp": [838.16, 840.68], "text": " What we need to be doing is adopting AI"}, {"timestamp": [840.68, 843.6], "text": " so that the government becomes leaner, faster,"}, {"timestamp": [843.6, 846.04], "text": " less corrupt, more transparent, more"}, {"timestamp": [846.04, 849.4], "text": " representative of people's actual best interests."}, {"timestamp": [849.4, 851.96], "text": " The story from AskSage is a really good one."}, {"timestamp": [851.96, 857.52], "text": " I was able to chat with the founder for a little bit and he said, oh yeah, like everything"}, {"timestamp": [857.52, 861.74], "text": " that we're doing, none of it was possible just a couple of years ago because that's"}, {"timestamp": [861.74, 864.46], "text": " how fast AI has advanced."}, {"timestamp": [864.46, 867.36], "text": " So first mover advantage."}, {"timestamp": [867.36, 870.4], "text": " One thing that has been more and more talked about"}, {"timestamp": [870.4, 872.36], "text": " is UBI, so universal basic income,"}, {"timestamp": [872.36, 874.96], "text": " but also universal basic services."}, {"timestamp": [874.96, 877.24], "text": " And what I realized after talking to a bunch of people"}, {"timestamp": [877.24, 880.0], "text": " is that we already actually have a decent model"}, {"timestamp": [880.0, 885.2], "text": " of basic services in the form of K-12 public education."}, {"timestamp": [885.2, 890.64], "text": " So obviously, there's also roads are maintained by the state, and there's lots of other things"}, {"timestamp": [890.64, 892.54], "text": " that are maintained by the state."}, {"timestamp": [892.54, 895.76], "text": " But the school system is the only thing that is universal."}, {"timestamp": [895.76, 901.16], "text": " We literally have a federal mandate that every child is entitled to an education, and we"}, {"timestamp": [901.16, 902.16], "text": " figured that out."}, {"timestamp": [902.16, 903.16], "text": " We run the school system."}, {"timestamp": [903.16, 905.14], "text": " Now, obviously, when you look at problems like"}, {"timestamp": [906.14, 911.78], "text": " inequality and blooms to sigma problems, you know, our public schooling system is not perfect"}, {"timestamp": [912.34, 918.0], "text": " but it does serve every single child. And so this is actually a decent enough model for"}, {"timestamp": [918.64, 920.9], "text": " universal basic services. So how is this going to look?"}, {"timestamp": [921.3, 926.2], "text": " Now obviously a lot of people say like yeah, good luck living on $1,200 a month from the"}, {"timestamp": [926.2, 930.72], "text": " government and I agree that's pretty slim."}, {"timestamp": [930.72, 934.36], "text": " I would not want to live on only $1,200 a month from the government."}, {"timestamp": [934.36, 937.08], "text": " Now however there are many levels of government."}, {"timestamp": [937.08, 941.52], "text": " There is federal, there is state, there is county, there is municipal."}, {"timestamp": [941.52, 945.92], "text": " And so what I anticipate actually is that we will have a multi-layered"}, {"timestamp": [946.66, 949.0], "text": " set of safety nets that are a"}, {"timestamp": [950.08, 958.0], "text": " Combination of UBI and UBS and so we might have a federal UBI basically, you know federal taxes tax the companies that are"}, {"timestamp": [958.72, 962.94], "text": " Churning out trillions of dollars worth of value with AI. That's"}, {"timestamp": [963.64, 965.0], "text": " That would be appropriate."}, {"timestamp": [966.04, 968.28], "text": " You tax and redistribute that."}, {"timestamp": [968.28, 970.08], "text": " Then you also do the same thing at the state level,"}, {"timestamp": [970.08, 973.16], "text": " but then also at the state and county and municipal level,"}, {"timestamp": [973.16, 976.48], "text": " you provide basic services like hospitals."}, {"timestamp": [976.48, 979.4], "text": " You provide basic services like power, food,"}, {"timestamp": [979.4, 981.58], "text": " maybe even housing in many cases."}, {"timestamp": [981.58, 988.16], "text": " And so this is one thing that really gives me a lot of encouragement, is because"}, {"timestamp": [988.16, 993.28], "text": " many of the experiments going on around the world about UBI are actually being run by cities,"}, {"timestamp": [993.28, 998.08], "text": " or states, or counties, or provinces. They're not being run at the federal level. And so,"}, {"timestamp": [998.08, 1006.0], "text": " you combine AI efficiency with some of these multi-layered approaches, and I think that what we're going to have is"}, {"timestamp": [1006.0, 1010.0], "text": " this multi-layered safety net of UBI and UBS,"}, {"timestamp": [1010.0, 1014.0], "text": " and I think that we're actually going to end up in a much better place than we are today,"}, {"timestamp": [1014.0, 1018.0], "text": " certainly here in America, because in America it's like, you're on your own, scrub, get good."}, {"timestamp": [1018.0, 1021.0], "text": " Okay, so let's move on to businesses."}, {"timestamp": [1021.0, 1024.0], "text": " What can businesses do to adapt to AI?"}, {"timestamp": [1024.0, 1031.0], "text": " Well, first and foremost, you have to recognize that this is the most significant paradigm"}, {"timestamp": [1031.0, 1036.28], "text": " shift in all of human history, both economically and technologically."}, {"timestamp": [1036.28, 1042.36], "text": " This is nothing short of the fourth industrial revolution, probably the biggest one yet."}, {"timestamp": [1042.36, 1045.44], "text": " This is going to change the competitive landscape, which basically"}, {"timestamp": [1045.44, 1050.32], "text": " means if you're not adopting AI, your competitors are, so if you're not adopting AI, good luck."}, {"timestamp": [1051.68, 1056.24], "text": " I've actually heard, I don't have any clients, obviously if someone comes to me they want AI,"}, {"timestamp": [1056.24, 1061.28], "text": " but I've heard of people out there that are like, no, AI is just a fad, it's just a hype cycle,"}, {"timestamp": [1061.28, 1070.72], "text": " we're not going to invest, we're going to let it blow over.\" And I'm like, okay, we'll see how that plays out. Now, another thing about this changing landscape is some"}, {"timestamp": [1070.72, 1074.48], "text": " businesses, I think, are going to see thinning margins. And that is just because the marginal"}, {"timestamp": [1074.48, 1082.08], "text": " cost of using AI to do some things is near zero, which means if your margin goes from 50% to 1%,"}, {"timestamp": [1082.72, 1087.4], "text": " you can't skim anything off the top for yourself."}, {"timestamp": [1087.4, 1092.06], "text": " We've already seen this with some sectors collapsing, such as the creative sector, such"}, {"timestamp": [1092.06, 1095.44], "text": " as customer service jobs, and then also HR."}, {"timestamp": [1095.44, 1098.28], "text": " We've seen a lot of layoffs in the HR departments."}, {"timestamp": [1098.28, 1103.28], "text": " I think it was Satya Nadella, one of the CEOs, or maybe it was, what's his name at IBM?"}, {"timestamp": [1103.28, 1105.32], "text": " Anyways, he predicted that back office workers"}, {"timestamp": [1105.32, 1106.88], "text": " are gonna be the first to go."}, {"timestamp": [1106.88, 1108.86], "text": " Those are white collar jobs."}, {"timestamp": [1108.86, 1111.6], "text": " And so any companies that serve HR purposes,"}, {"timestamp": [1111.6, 1115.84], "text": " any companies that serve customer service positions,"}, {"timestamp": [1115.84, 1118.4], "text": " any companies that focus on copywriting"}, {"timestamp": [1118.4, 1121.96], "text": " and images and that sort of stuff, they're all gone."}, {"timestamp": [1121.96, 1124.48], "text": " And so that's what thinning margins results in,"}, {"timestamp": [1124.48, 1127.0], "text": " is companies collapsing just because there's"}, {"timestamp": [1127.0, 1129.02], "text": " no room left to scrape out."}, {"timestamp": [1129.02, 1133.32], "text": " This can also be called creative destruction, where it's basically an entire sector is just"}, {"timestamp": [1133.32, 1135.8], "text": " invalidated by a new technology."}, {"timestamp": [1135.8, 1139.16], "text": " Either way, there's going to be a lot of companies that collapse."}, {"timestamp": [1139.16, 1144.24], "text": " Then investing in AI, both in terms of products and services, and developing AI talent, which"}, {"timestamp": [1144.24, 1145.28], "text": " we'll unpack more"}, {"timestamp": [1145.28, 1149.44], "text": " right now. So the first thing that you need to know as a business is adapt or die."}, {"timestamp": [1151.36, 1156.56], "text": " This is the same as companies that you know that were late to adopt electrification and the"}, {"timestamp": [1156.56, 1161.6], "text": " internet. Many of them went out of business and those that were able to pivot and adapt,"}, {"timestamp": [1161.6, 1169.9], "text": " some of them are still around like IBM. What you might not realize about IBM is that they started as mechanical time clocks."}, {"timestamp": [1169.9, 1174.76], "text": " And so, obviously, IBM now working on quantum computing, they have pivoted several times,"}, {"timestamp": [1174.76, 1178.36], "text": " which is why they've been around for more than 100 years."}, {"timestamp": [1178.36, 1181.4], "text": " Many of their competitors no longer exist."}, {"timestamp": [1181.4, 1183.4], "text": " Another example is borders."}, {"timestamp": [1183.4, 1185.72], "text": " Borders failed to pivot to adapt to the"}, {"timestamp": [1185.72, 1190.76], "text": " internet and so what were they replaced by? Barnes & Noble and Amazon. Again, we do"}, {"timestamp": [1190.76, 1195.52], "text": " have living memory of companies failing to adapt to the internet and therefore"}, {"timestamp": [1195.52, 1201.16], "text": " collapsing. So I'm here to tell you AI is not hype. It will change everything and"}, {"timestamp": [1201.16, 1205.12], "text": " even if you look at like, well, it's not capable of stuff today,"}, {"timestamp": [1205.12, 1210.04], "text": " look at what it was capable of last year, which in comparison, AI was not capable of"}, {"timestamp": [1210.04, 1214.56], "text": " hardly anything this time last year. And now it's like, well, a lot of us use AI every"}, {"timestamp": [1214.56, 1219.68], "text": " day all day to do our work. And so this time next year, you're not going to be able to"}, {"timestamp": [1219.68, 1247.5], "text": " get away without using AI. So you, you will adapt or you will die. It's that simple. And I'm also here to tell you that this is kind of bad news, but AI is going to destroy a lot of jobs and a lot of businesses, and there's not much we can do about it. So the beginning of my career back in 2007 was as the tech industry was recovering from the dot-com revolution and crash"}, {"timestamp": [1247.5, 1253.64], "text": " And so, you know, there was I remember growing up hearing like there are 50,000 unfilled IT jobs"}, {"timestamp": [1253.64, 1258.76], "text": " I was like, okay, I guess I'll get an IT job and it was really easy because there's such a huge vacuum"}, {"timestamp": [1258.76, 1264.38], "text": " There was a huge need for IT people. It's like oh, hey, you can program a home router. Great. You've got a job"}, {"timestamp": [1264.38, 1266.4], "text": " It wasn't quite that easy, but it was close"}, {"timestamp": [1267.0, 1273.7], "text": " And so we're seeing the same thing with AI talent right now AI is the new IT AI is the new software engineering"}, {"timestamp": [1273.7, 1276.7], "text": " I remember my mom's boyfriend back in the"}, {"timestamp": [1277.7, 1283.86], "text": " early 2000s like he came back from the army got a Microsoft certification and immediately had it like"}, {"timestamp": [1284.16, 1286.0], "text": " Back then man, it was easy., got a Microsoft certification, and immediately had it. Like, back then, man, it was easy."}, {"timestamp": [1286.0, 1288.08], "text": " You get one Microsoft certification,"}, {"timestamp": [1288.08, 1290.64], "text": " instant job that pays 50,000 a year."}, {"timestamp": [1290.64, 1294.52], "text": " You get a handful of certifications, 80,000 a year."}, {"timestamp": [1294.52, 1296.96], "text": " And your companies would pay for it, too."}, {"timestamp": [1296.96, 1299.8], "text": " Most of my training at the beginning of my career"}, {"timestamp": [1299.8, 1303.6], "text": " paid for by my company because there was so little talent."}, {"timestamp": [1304.48, 1308.58], "text": " Now, one thing that is not necessarily possible"}, {"timestamp": [1308.58, 1311.72], "text": " because a lot of the training programs don't even exist yet"}, {"timestamp": [1311.72, 1315.08], "text": " is you need to focus on your internal talent development."}, {"timestamp": [1315.08, 1320.08], "text": " So for the last 10 to 15 years, we've had this glut"}, {"timestamp": [1320.14, 1322.76], "text": " of in the labor market, in the technology space"}, {"timestamp": [1322.76, 1327.28], "text": " where pretty much anything you need, if you need a database administrator, you need"}, {"timestamp": [1327.28, 1331.84], "text": " a C sharp developer, there was someone out there. And so companies have gotten really"}, {"timestamp": [1331.84, 1336.4], "text": " lazy about talent development. Like I said, 15 years ago, at the beginning of my career,"}, {"timestamp": [1336.4, 1341.36], "text": " all of all of my talent development was paid for by my company because it wasn't there"}, {"timestamp": [1341.36, 1349.6], "text": " in the last 10 years, companies have gotten really lazy. And so what I've had to do with some of my clients is say, hey, the thing, the skills and experience that"}, {"timestamp": [1349.6, 1354.48], "text": " you want to hire for isn't out there. You need to develop it. So like one of my clients was"}, {"timestamp": [1354.48, 1359.2], "text": " basically saying like, hey, how do we find someone who is a director who understands like cognitive"}, {"timestamp": [1359.2, 1364.16], "text": " architecture? I'm like, you don't because the only people who understand cognitive architecture"}, {"timestamp": [1364.16, 1365.28], "text": " are a few of us"}, {"timestamp": [1371.04, 1373.04], "text": " Lunatics out here and then like PhDs that have been studying it since the 80s, but they're not looking for a you know Director of technology job"}, {"timestamp": [1373.16, 1375.6], "text": " So I was like what you do what you need to do"}, {"timestamp": [1375.6, 1381.34], "text": " Then is you hire for personality and the two primary traits that I recommend that people hire for is hunger"}, {"timestamp": [1381.34, 1388.0], "text": " I don't mean like physical hunger. I mean people that are hungry for AI and and and hungry for the job and then"}, {"timestamp": [1388.0, 1391.6], "text": " curiosity because those are two inborn traits"}, {"timestamp": [1391.6, 1395.3], "text": " and then then you backfill in with the talent and"}, {"timestamp": [1395.3, 1397.6], "text": " skills and other things that can be trained in"}, {"timestamp": [1397.6, 1399.9], "text": " because you can't train someone to be hungry for"}, {"timestamp": [1399.9, 1401.8], "text": " their for their job. You can't train someone to be"}, {"timestamp": [1401.8, 1410.5], "text": " curious. Those are just fixed personality traits. So you focus on those two things and develop your own internal talent. Companies"}, {"timestamp": [1410.5, 1417.18], "text": " that go all in on AI, companies that focus on the AI talent, people that develop their"}, {"timestamp": [1417.18, 1422.52], "text": " own internal AI talent, they're going to have a much better chance at surviving this coming"}, {"timestamp": [1422.52, 1425.04], "text": " AI wave than those that don't."}, {"timestamp": [1434.08, 1434.02], "text": " And mark my word there are plenty of companies out there that are basically sticking their head in the sand and ignoring the stuff so if you"}, {"timestamp": [1448.96, 1454.68], "text": " if you're watching this i know that there's a lot of c-suite people and senior vice presidents and other folks that watch like if you're watching this you are ahead of of the curve. Now I'm not saying that it's going to be easy because like I said, there are macroscopic economic macroeconomic forces at play here that could just cut out your legs from underneath"}, {"timestamp": [1454.68, 1455.68], "text": " you."}, {"timestamp": [1455.68, 1459.04], "text": " So I know that's a really grim outlook, but like that's how it is and that is how every"}, {"timestamp": [1459.04, 1462.5], "text": " industrial revolution has happened up until this point."}, {"timestamp": [1462.5, 1464.96], "text": " And this one's going to be no different in that respect."}, {"timestamp": [1464.96, 1468.88], "text": " Okay. has happened up until this point and this one's going to be no different in that respect. Okay, so finally on a personal level how can you brace for"}, {"timestamp": [1468.88, 1475.32], "text": " impact? First and foremost is emotional adaptation. It is perfectly natural to"}, {"timestamp": [1475.32, 1480.24], "text": " have a very wide range of emotions as you contemplate these changes. Just last"}, {"timestamp": [1480.24, 1483.48], "text": " night it took me like an hour and a half to get to sleep because I didn't know"}, {"timestamp": [1483.48, 1486.98], "text": " what I was feeling. I was like, am I angry about this?"}, {"timestamp": [1486.98, 1487.98], "text": " Am I hopeful?"}, {"timestamp": [1487.98, 1488.98], "text": " Am I worried?"}, {"timestamp": [1488.98, 1493.86], "text": " Like, it was just like, just this potpourri of random nebulous emotions."}, {"timestamp": [1493.86, 1498.28], "text": " Cause I'm like, man, like, cause I was making the slide deck last night and so I'm like,"}, {"timestamp": [1498.28, 1500.7], "text": " you know, I need to take my own advice here."}, {"timestamp": [1500.7, 1503.26], "text": " Anyways, this is all natural."}, {"timestamp": [1503.26, 1505.78], "text": " When you're facing a huge paradigm shift,"}, {"timestamp": [1505.78, 1510.1], "text": " it is natural to have the occasional existential crisis like this dude at the"}, {"timestamp": [1510.1, 1513.42], "text": " bar being served by a robot bartender. Uh,"}, {"timestamp": [1513.78, 1516.14], "text": " the best analogy that I have is it's like,"}, {"timestamp": [1516.42, 1519.78], "text": " you know that there's a big storm coming. You can prepare for the storm,"}, {"timestamp": [1519.78, 1520.82], "text": " you can brace for the storm,"}, {"timestamp": [1520.82, 1524.84], "text": " but eventually the storm is going to get here and all you can do is ride it out."}, {"timestamp": [1525.0, 1530.0], "text": " Um, and so, yeah, like that's that. And you have to acknowledge these emotions."}, {"timestamp": [1530.0, 1535.0], "text": " You have to accept them, work with them, talk about them. And so back when I was still hosting"}, {"timestamp": [1535.0, 1540.0], "text": " AI meetups, like a lot of people were like giddy. Like it was really validating to have a bunch of"}, {"timestamp": [1540.0, 1546.4], "text": " people like 20 and 30 people like at the bar together like talking about like yeah, this is so exciting and so like it was actually very"}, {"timestamp": [1546.4, 1549.3], "text": " normalizing for us to like feel saying like"}, {"timestamp": [1549.3, 1551.9], "text": " yeah, we're not making this up right like"}, {"timestamp": [1551.9, 1553.6], "text": " so many of the conversations were like we're"}, {"timestamp": [1553.6, 1555.5], "text": " checking in with each other like are we crazy"}, {"timestamp": [1555.5, 1557.8], "text": " or are we just like have the lunatics taken over"}, {"timestamp": [1557.8, 1559.8], "text": " the assignment it could be a little bit of both"}, {"timestamp": [1559.8, 1561.9], "text": " but it was really validating to get together with"}, {"timestamp": [1561.9, 1566.26], "text": " a bunch of other people and say like, hey, this is happening, right?"}, {"timestamp": [1566.26, 1567.26], "text": " Yes, cool."}, {"timestamp": [1567.26, 1569.2], "text": " Okay, now what?"}, {"timestamp": [1569.2, 1574.86], "text": " So and that's why I have an existential coping channel in my discord server."}, {"timestamp": [1574.86, 1578.98], "text": " Another thing you can do to prepare is start moving towards a forever job."}, {"timestamp": [1578.98, 1583.12], "text": " And so a forever job, this is the other side of post labor economics, which is there will"}, {"timestamp": [1583.12, 1586.92], "text": " always be some jobs that people just want other people to do now"}, {"timestamp": [1586.92, 1591.24], "text": " I'm not saying go start an only fans go start. You know your YouTube career"}, {"timestamp": [1591.6, 1594.9], "text": " I don't know what kind of jobs are gonna be forever jobs"}, {"timestamp": [1594.9, 1598.92], "text": " But this is why I'm here on YouTube is because as long as there are humans"}, {"timestamp": [1598.92, 1604.32], "text": " I suspect there are gonna be humans that want to see my dumb face talking about AI or whatever it is that I ultimately talk about"}, {"timestamp": [1603.26, 1605.86], "text": " are going to be humans that want to see my dumb face talking about AI or whatever it is that I ultimately talk about."}, {"timestamp": [1605.86, 1611.04], "text": " So but yeah, so be thinking about and talking about like, okay, what are some things that"}, {"timestamp": [1611.04, 1612.52], "text": " will stick around forever?"}, {"timestamp": [1612.52, 1614.28], "text": " And these are the demand side jobs."}, {"timestamp": [1614.28, 1617.96], "text": " Now, obviously, not everyone can become a content creator."}, {"timestamp": [1617.96, 1620.62], "text": " Not everyone wants to get into into childcare."}, {"timestamp": [1620.62, 1625.64], "text": " And so that leads to another part, which is redefining how you achieve social"}, {"timestamp": [1625.64, 1629.44], "text": " status. So I've been reading this book it was recommended to me by a good friend"}, {"timestamp": [1629.44, 1633.96], "text": " and mentor called The Status Game by William Storr and this book is the"}, {"timestamp": [1633.96, 1640.84], "text": " single most profound book on human psychology I have ever read. It explains"}, {"timestamp": [1640.84, 1647.0], "text": " so much about the human condition, it blows sapiens out of the water."}, {"timestamp": [1647.0, 1650.0], "text": " And I know that that's like heretical to say, but like"}, {"timestamp": [1650.0, 1653.0], "text": " this book is so well researched and it is so practical"}, {"timestamp": [1653.0, 1654.0], "text": " and it is so useful."}, {"timestamp": [1654.0, 1658.0], "text": " So, basically the TLDR is that all humans"}, {"timestamp": [1658.0, 1660.0], "text": " across the entire planet"}, {"timestamp": [1660.0, 1664.0], "text": " all care about social status above all else."}, {"timestamp": [1664.0, 1665.92], "text": " Everything else that we care about social status above all else. Everything else that we"}, {"timestamp": [1665.92, 1670.88], "text": " care about flows from this central foundational desire and it makes sense."}, {"timestamp": [1670.88, 1676.32], "text": " We are a social species. Your survival is predicated on your social status and"}, {"timestamp": [1676.32, 1682.16], "text": " your success and happiness in life is predicated on your social status. So I"}, {"timestamp": [1682.16, 1686.88], "text": " strongly recommend you read this game, this book. But basically,"}, {"timestamp": [1686.88, 1692.48], "text": " there are three kinds of status games that we all play. And these status games are also rooted in"}, {"timestamp": [1692.48, 1697.04], "text": " our ancient evolution, because we see them in bonobos, we see it in chimps, we even see it in"}, {"timestamp": [1698.72, 1707.76], "text": " lions and other social mammals. So there's the success game, which is often material success or financial success."}, {"timestamp": [1707.76, 1711.98], "text": " And so this is associated with career and conspicuous consumption. And one piece of"}, {"timestamp": [1711.98, 1716.48], "text": " evidence for this, and everyone has seen this, is that even toddlers are possessive. So our"}, {"timestamp": [1716.48, 1722.12], "text": " instinct for private property is inborn. Why? Because if you possess the neat things, you"}, {"timestamp": [1722.12, 1728.2], "text": " have higher social status. And this goes way, way, way before capitalism, way before neoliberalism."}, {"timestamp": [1728.2, 1730.82], "text": " This is deeply embedded in our DNA."}, {"timestamp": [1730.82, 1737.36], "text": " So material success, the possession of cool things, the nicer house, the cool shells,"}, {"timestamp": [1737.36, 1742.7], "text": " you know, the fancy car, this is an evolutionary artifact that is deeply embedded in us."}, {"timestamp": [1742.7, 1745.28], "text": " Now obviously, if careers go away, like,"}, {"timestamp": [1745.28, 1748.44], "text": " okay, you're not going to have financial success through your career, but there"}, {"timestamp": [1748.44, 1752.76], "text": " will still be ways to have that kind of material success. Next up is the"}, {"timestamp": [1752.76, 1757.32], "text": " dominance game. So, dominance game is, you know, showing your muscles,"}, {"timestamp": [1757.32, 1762.6], "text": " intimidation, fear, physical prowess, sexual prowess, that sort of stuff. Part"}, {"timestamp": [1762.6, 1771.04], "text": " of the dominance game, you see this more often with militaries, sports, and you know people that like to pump iron and"}, {"timestamp": [1771.04, 1774.48], "text": " get on the beach and you know winning right you know dominance is all about"}, {"timestamp": [1774.48, 1778.56], "text": " winning it's about conquering your enemies. And then there the the third"}, {"timestamp": [1778.56, 1783.84], "text": " game is the virtue or prestige game which this is more about like people"}, {"timestamp": [1783.84, 1786.0], "text": " that are either spiritual or"}, {"timestamp": [1786.0, 1791.8], "text": " intellectual or emotional and so there's depending on which kind of virtues you"}, {"timestamp": [1791.8, 1797.36], "text": " prefer this is something that like I guess what I'm trying to say is like say"}, {"timestamp": [1797.36, 1801.56], "text": " for instance you are a very religious person part of your virtue is how well"}, {"timestamp": [1801.56, 1805.8], "text": " you adhere to your religious doctrine that's another way to get social status or if you're an academic if you're a researcher part of your virtue is how well you adhere to your religious doctrine. That's another way to get social status."}, {"timestamp": [1805.8, 1808.44], "text": " Or, if you're an academic, if you're a researcher,"}, {"timestamp": [1808.44, 1812.54], "text": " part of the virtue or prestige is about intellectual contribution."}, {"timestamp": [1812.54, 1815.58], "text": " So, that's another example of the status game."}, {"timestamp": [1815.58, 1819.82], "text": " By recognizing that your social standing comes from multiple dimensions,"}, {"timestamp": [1819.82, 1823.12], "text": " because everyone plays a little bit of all three of these games,"}, {"timestamp": [1823.12, 1827.96], "text": " everyone cares about some material success."}, {"timestamp": [1827.96, 1832.2], "text": " Everyone cares about some dominance and everyone cares about some virtue or prestige."}, {"timestamp": [1832.2, 1836.6], "text": " It's just a matter of which one you prefer and what your particular social tribe prefers"}, {"timestamp": [1836.6, 1837.6], "text": " as well."}, {"timestamp": [1837.6, 1838.8], "text": " But everyone does all three."}, {"timestamp": [1838.8, 1845.52], "text": " And so recognizing and learning about social status is one of the number one ways to prepare for and adapt for"}, {"timestamp": [1845.52, 1850.12], "text": " the possibility of post-labor economics and no longer having a career. After"}, {"timestamp": [1850.12, 1853.48], "text": " reading this book I'm like, oh man, nobody needs a career. There are so many other"}, {"timestamp": [1853.48, 1858.54], "text": " ways to establish your social rank and to make sure that you have social"}, {"timestamp": [1858.54, 1864.0], "text": " standing in your tribe. Yeah, no, we're gonna be fine there. Another thing you"}, {"timestamp": [1864.0, 1868.48], "text": " can do is, as you have more time, because either you lose your job, and"}, {"timestamp": [1868.48, 1872.04], "text": " there's plenty of people that I talk to, some of the folks that have volunteered for some"}, {"timestamp": [1872.04, 1877.2], "text": " of the open source projects that I'm running, they lost their job six months ago, and they"}, {"timestamp": [1877.2, 1879.76], "text": " don't know if they're ever going to have a job again, and they're trying to find their"}, {"timestamp": [1879.76, 1881.6], "text": " way back in."}, {"timestamp": [1881.6, 1887.92], "text": " But as we pivot to post-labor economics, as people lose their jobs or only have gig"}, {"timestamp": [1887.92, 1894.36], "text": " work or whatever, one of the most powerful frameworks for living happily on a day-to-day"}, {"timestamp": [1894.36, 1902.6], "text": " basis is Dr. Walsh's TLC, Therapeutic Lifestyle Changes. It is a framework of eight behaviors"}, {"timestamp": [1902.6, 1907.6], "text": " that you can engage in on a daily or weekly basis that really, really helps you feel better."}, {"timestamp": [1907.88, 1912.64], "text": " But basically it's like, okay, so a TLC specialist is going to say, all right, let's fix your exercise."}, {"timestamp": [1912.64, 1915.04], "text": " Like let's fix your, your diet and nutrition."}, {"timestamp": [1915.32, 1916.68], "text": " Let's fix your relationships."}, {"timestamp": [1916.68, 1918.28], "text": " Let's make sure you're spending time in nature."}, {"timestamp": [1918.28, 1922.48], "text": " Let's make sure that you're doing your recreational stuff, your fun, your hobbies."}, {"timestamp": [1922.48, 1926.36], "text": " Let's make sure that you're getting some relaxation and stress management."}, {"timestamp": [1926.36, 1931.56], "text": " Let's make sure that you're engaging with your religious or spiritual side. And then finally, let's make sure that you are"}, {"timestamp": [1932.48, 1934.98], "text": " engaging in some kind of community service or giving back."}, {"timestamp": [1935.24, 1940.96], "text": " So I learned about TLC many, many years ago, way back on the days of StumbleUpon, which doesn't even exist anymore."}, {"timestamp": [1941.76, 1945.16], "text": " But this framework is super helpful and it's just"}, {"timestamp": [1945.16, 1948.46], "text": " like a checklist. You can just go through this every day and say like, hey, can I"}, {"timestamp": [1948.46, 1953.16], "text": " invest some time in this? Cool. And you do this and you'll feel better, I promise."}, {"timestamp": [1953.16, 1958.92], "text": " Another thing, and this has been kind of a personal insight as I am acclimating"}, {"timestamp": [1958.92, 1967.4], "text": " to this change that we're facing, is forget about tomorrow. And you know, you might say like, Dave, you're always predicting like, you know, into the"}, {"timestamp": [1967.4, 1970.12], "text": " future, you're obviously not forgetting about tomorrow."}, {"timestamp": [1970.12, 1974.48], "text": " And what I mean by this is, no, I'm not forgetting about tomorrow, like not in that sense, but"}, {"timestamp": [1974.48, 1975.84], "text": " I'm not worrying about tomorrow."}, {"timestamp": [1975.84, 1979.2], "text": " It's like, okay, I see everything that everyone is doing."}, {"timestamp": [1979.2, 1981.44], "text": " Like I go on archive on a regular basis."}, {"timestamp": [1981.44, 1985.12], "text": " And I see that there are literally like thousands upon thousands of"}, {"timestamp": [1985.12, 1991.68], "text": " scientists, hundreds of labs and universities all over the world working on AI alignment"}, {"timestamp": [1991.68, 1998.44], "text": " and bias and safety. And, and I'm like, okay, the collective brainpower of those like literally"}, {"timestamp": [1998.44, 2002.72], "text": " tens of thousands of students and researchers. So I'm pretty sure we're going to figure out"}, {"timestamp": [2002.72, 2010.04], "text": " safety like this is a solvable problem and we will solve it. And then on the on the other side, there is the"}, {"timestamp": [2010.04, 2015.12], "text": " geopolitical and governmental side. There's the business side and it's like, okay, well,"}, {"timestamp": [2015.12, 2019.08], "text": " you know, as I've covered in some of my recent videos, all the halls of power are talking"}, {"timestamp": [2019.08, 2027.68], "text": " about AI, the EU, the UN, NATO, America, like ASEAN, like literally every international organization"}, {"timestamp": [2027.68, 2029.5], "text": " on the planet is aware of AI"}, {"timestamp": [2029.5, 2030.86], "text": " and they are doing something about it."}, {"timestamp": [2030.86, 2033.8], "text": " Now, I might not agree with their closed door meetings,"}, {"timestamp": [2033.8, 2037.36], "text": " I might not agree with exactly how they're conducting it,"}, {"timestamp": [2037.36, 2038.64], "text": " but that's why I'm commenting on it."}, {"timestamp": [2038.64, 2040.18], "text": " But the fact of the matter is,"}, {"timestamp": [2040.18, 2041.36], "text": " there are adults in the room"}, {"timestamp": [2041.36, 2043.0], "text": " and they are working on this stuff."}, {"timestamp": [2043.0, 2044.76], "text": " And so it's like, you know what?"}, {"timestamp": [2044.76, 2045.92], "text": " I'm doing everything that I can."}, {"timestamp": [2045.92, 2049.28], "text": " So I'm going to let go of the worry and I'm just going to forget about tomorrow"}, {"timestamp": [2049.28, 2055.92], "text": " and enjoy today. So like adopting a carpe diem mentality and just trusting that it'll work out."}, {"timestamp": [2055.92, 2061.92], "text": " And I don't mean blind trust. I'm never one to argue for blind trust. I keep my ear to the ground,"}, {"timestamp": [2061.92, 2065.16], "text": " but it's like, yeah, I think generally things are going in the right direction."}, {"timestamp": [2065.88, 2067.52], "text": " And then finally simplify your life."}, {"timestamp": [2067.8, 2070.72], "text": " This is something that I realized that I've been doing lately,"}, {"timestamp": [2070.72, 2075.44], "text": " which is just, you know, the rat race is ending. Um, you know, the, the,"}, {"timestamp": [2075.44, 2078.68], "text": " the competition for a better job and you know, the,"}, {"timestamp": [2078.68, 2082.48], "text": " the fancy house on the cul-de-sac like, yeah, we can still want those things,"}, {"timestamp": [2082.92, 2093.0], "text": " but the current American dream has like, it's, it's, it's on its deathbed and it's just circling the drain and it's going to go any minute now."}, {"timestamp": [2093.0, 2106.0], "text": " And like, yes, the status game will be forever, you know, so we're going to find new ways to compete. But this, this workaholic treadmill that we've been on, that's what's going away."}, {"timestamp": [2106.8, 2112.16], "text": " And like the question that my wife and I have been asking each other and asking ourselves for"}, {"timestamp": [2112.16, 2118.56], "text": " the last few months is how do we want to live with all this cultural baggage of middle-class"}, {"timestamp": [2118.56, 2125.2], "text": " America and all that stuff? It's going away, it's dying. And so we're like, well, how do we want to live instead?"}, {"timestamp": [2126.56, 2130.6], "text": " And so, you know, we, we have been kind of critically recalibrating our own lives."}, {"timestamp": [2130.6, 2133.72], "text": " And so one thing that I do is like when I'm done with work for the day,"}, {"timestamp": [2133.84, 2135.76], "text": " sometimes I'll go to see a movie sometime."}, {"timestamp": [2135.76, 2138.44], "text": " Like we love going to Panera after we go hiking and it's just like,"}, {"timestamp": [2138.84, 2141.44], "text": " we're engaging with life on our own terms."}, {"timestamp": [2141.88, 2144.64], "text": " And obviously like I recognize not everyone can do this yet,"}, {"timestamp": [2144.92, 2149.52], "text": " but I certainly recommend that everyone try, you know, like, whatever your dream is, like,"}, {"timestamp": [2150.24, 2156.24], "text": " why not start now if you can and look forward to that in the future. And this is why, like,"}, {"timestamp": [2156.24, 2160.48], "text": " I'm trying to thread the needle when I talk about post-labor economics and preparing for these"}, {"timestamp": [2160.48, 2168.0], "text": " changes, because if we all work together, if we work hard to make sure that AI is implemented in the"}, {"timestamp": [2168.0, 2172.0], "text": " ways that are best for everyone, if we work with the government and the"}, {"timestamp": [2172.0, 2176.0], "text": " businesses to make sure that it's not heavily skewed"}, {"timestamp": [2176.0, 2180.0], "text": " or lopsided and keeps everyone in a cyberpunk dystopian"}, {"timestamp": [2180.0, 2184.0], "text": " hellscape, then there's no reason, I don't see any reason"}, {"timestamp": [2184.0, 2186.2], "text": " no physical reason, no economic reason don't see any reason no physical reason no economic reason"}, {"timestamp": [2186.2, 2191.28], "text": " No game theory reason that we all couldn't live in a much more harmonious way"}, {"timestamp": [2191.84, 2194.72], "text": " That would be closer to our preference very soon"}, {"timestamp": [2194.72, 2201.0], "text": " And I mean like within the next two to five years I could see some of these major transitions happening which you know"}, {"timestamp": [2201.4, 2209.0], "text": " The like call that acceleration ism call it whatever you want, but like it's not a foregone conclusion that it will work out that way."}, {"timestamp": [2209.0, 2216.0], "text": " But I don't see any reason that it can't. There's no fundamental reason that this is not the natural flow of things,"}, {"timestamp": [2216.0, 2227.28], "text": " except of course as some people will say like the billionaires are greedy and they of course want to make sure that they control everything and I'm like, I think maybe some do, but I don't know."}, {"timestamp": [2227.28, 2230.88], "text": " I see it playing out really well."}, {"timestamp": [2230.88, 2233.8], "text": " Anyways, thanks for watching. I hope you got a lot out of this."}, {"timestamp": [2233.8, 2235.4], "text": " Let me know what you think in the comments."}, {"timestamp": [2235.4, 2239.16], "text": " How are you preparing? Is there anything that I missed?"}, {"timestamp": [2239.16, 2241.52], "text": " So on and so forth. Have a good one. Cheers."}, {"timestamp": [2236.71, 2238.71], "text": " Have a good one. Cheers."}]}