{"text": " Hey everybody, David Shapiro here with another video. So it's a really exciting time because research is accelerating. Just in the last couple days a whole bunch of interesting papers have come out on archive and you know, I could read them all myself, the hard way, the long way, but you know what? I'm really lazy and you know how Mr. Henry Ford he said allegedly said I don't know if he actually said this but he said give your hardest problems to the laziest engineers because they'll find an easier way to do it. That's me. That's why I became an automation engineer. Back in the day I told people like I would rather spend a week building an automation tool that I can then just push the button and for the rest of my life it makes that job easier and guess what that's how I automated a three petabyte environment. Because why? I didn't want to manage it myself. Okay, so with the volume of paper that came out, because all of these came out Monday, so we've got five interesting papers that came out on the same day and this happens pretty much every day lately and it is entirely too much to keep up with. So rather than having to read all of these papers every day I wanted a way to digest them so I could quickly just one skim and keep on top of things and then also just basically make it sustainable or make it operationalized. And so what I mean by that is something that you can just fully automate and then just maybe get an email every day or have the interns do it or use this as part of your literature review for science because one of the things that I want to do is use this technology to accelerate science as much as possible. And one of the things that I hear from some of my friends in science is that just keeping up with things is getting harder and harder, at least in these high velocity spaces. Some places like oceanography, they don't change that much, they don't change that fast. But certainly computer science, artificial intelligence, and that sort of thing, cybersecurity, quantum computing, these things are moving so incredibly fast, we need the AI to help us keep up. So let me show you what I've done. Let's see, where should I start? I guess I'll just start with some of the final reports. So basically what I do is I just copy paste the text of the thing into here. Obviously the figures help, but language models are already pretty intelligent, so they don't even really need the figures. And then what I do is I feed it a series of questions and it gives me answers. And so this basically summarizes it from, you know, maybe 20,000, 40,000, 100,000 characters down to 4,000 characters. So we get a compression ratio of at least 5 to 1, but also it's often in much simpler language. And probably what I'll do is I'll add a second step that will render this as an HTML document. Maybe I'll do that at the end. But anyways, so the idea is I plug in the text. If it's a little too long, it'll trim it, but you get the first 22,000 characters of a paper. You've got the general gist. And and in many cases you actually have the whole paper now so I say can you give me a very clear explanation of the core assertions implications and mechanics elucidated in this paper very simple prompt it comes back and says you know yada yada yada the paper explores the concept of continual learning okay cool you cool. So it asks that question. And so basically this is a standard chat GPT conversation. So this is a way to implement a chain of thinking, but it's really an automated dialogue. So imagine that you have an intern or a research assistant that read the paper, and you can ask them a couple of questions. And you can change this on your own, by the way, very easily. So in the code I have it here. You can just add whatever questions or change whatever questions you want here and it will be happy to take it and run with it for you entirely on its own. So you change these questions if you want, you add more, you know, depending on the research that you're looking for. So let's say for instance you are in a very specific domain. Maybe you're trying to do this for medical research and you're really just looking for what are the implications for, let's say, rejuvenation therapy or regenerative medicine or even something even more specific. Maybe you're trying to research a specific kind of cancer or a specific, any kind're trying to research a specific kind of cancer or a specific any kind of metabolic disorder really. So then you can say first you want it to just tell me what are the implications and then you could say okay what are the implications with respect to my particular domain? What is the impact to my area of research? So restate it for me and then you can have it automatically spider a whole bunch of documents. So one of the things that I'm going to do with this is that rather than have just one input at a time I'm going to create a folder where you give it you just download the PDFs to directly. It'll scrape the PDFs and go through all of them as part of the automated process and it'll whatever the questions that you have, it will kind of break it down. But anyways, so I have a few standard questions. Can you explain the value of this in basic terms like you're talking to a CEO? So what? What's the bottom line here? And it's really good at explaining things in simple terms. So in this case, this paper says the research is about making code generation models, which are tools that help programmers by automating some of their work more adaptable and efficient. Currently, these models need to be retrained every time there's a significant change to the programming languages or libraries they work with, which this is what some people are noticing. And I noticed this too, is that sometimes it'll program with an outdated version, which of course limits the utility of coding models. The bottom line is that this research could lead to more efficient and adaptable code generation models. This means less time and money spent on retraining these models and more up-to-date and effective tools for programmers. So the implication for this, just reading that one paragraph to me says, okay, cool, this is going to be part of the acceleration because if we come up with a way to make coding models updated or updatable you know using continuous learning great excellent and then I said can you give me an analogy or metaphor that will help me explain this to a broad audience why because I'm a youtuber right so basically what I want is to be able to explain this paper in real basic terms real fast and contrary to the belief about a year ago, language models are actually really good at analogy and metaphor. So it says, sure, let's think of the cogeneration models as chefs in a kitchen. These chefs are trained to prepare a variety of dishes using specific recipes and ingredients. However, the culinary world is always evolving, with new recipes and ingredients being introduced regularly. In the current scenario, every time a new recipe or ingredient is introduced, the chef has to go through a complete retraining process, which is time-consuming and expensive. It's as if the chef forgets all of the old recipes when they learn a new one. See, that's a good metaphor. Or I guess that's an analogy, that's not a metaphor. The researchers in this study developed a new training method for these chefs. Instead of forgetting old recipes when learning new ones, the chefs can now continually learn and adapt, adding new recipes to the repertoire while still remembering the old ones. This is like a chef who can learn to cook a new dish while still remembering to cook all the previous dishes they've ever learned. This new training method is called prompt pooling with teacher forcing. It makes chefs, or in the real case, the cogeneration models, more efficient and adaptable, yada yada yada. OK. You get the idea. So this only takes a few seconds and it takes only a few cents to run. And so actually probably what I'll do is I'll pause it and I'll go ahead and update it so that it'll just ingest everything in a folder and then I'll show you a nice cleaned up output. So actually we'll be right back. OK. So speaking of being lazy I just wanted to show you real quick, I'm using my coding chatbot to do this because I'm ultra lazy. Work smart, not hard. So basically, I took the script and I just copied it into my coding chatbot, which you can find it, it's literally just called coding underscore chatbot underscore assistant on my GitHub. So I copied the script that I had, which is all of 99 lines, and I came over to my coding chat bot and I said, Hey, can you do this for me instead? And it's like, sure. Okay, cool. So basically I said, let's get a folder. So we're using this folder. So we can just download the PDFs directly to there rather than copy and pasting the text. And we're just going to take the output folder or the input folder for the PDFs and then an output folder for the what you call it. Whoops. OK. So we come over to here and it wants us to add OS and Pi PDF. That's fine. So we add that and then we see what else it wants to do. So we add that and then we see what else it wants to do. If name equals main, yep, so it's going to do all that. PDF file replace, yep, cool. So I just I gave it really simple instructions. I said, can you modify this script so that it will one, open every PDF in the input folder one by one and perform the same operation and two, check an output folder for the report as the same PDF or blah. Check the output folder for a report as the same PDF, blah. Check the output folder for a file of the same name. This will enable us to run batches without duplicating effort. Should be pretty straightforward. Let me know if you have any questions. And okay, so let's put this over here and see if it worked. Okay, so PDF files for files in OSLister, that looks right. Open, read binary as file, PDF reader, yep, so we get that. It gets all the page numbers, that should all work. I've used this module before, pypdf2 and PDF file reader. If it's over 22,000 characters, just cut it off. It seems to work well enough and then we get the report so on and so forth. Let's see. It looks like it's not actually checking if the file exists. Yep OK so this is this is close so let's take this over to the scratch pad, and then we'll say, let's see, we'll then check the output folder for the report. Wait, am I missing something? It doesn't have a continue function. Okay. Sorry. I think we need to check if the final file name exists in the output folder first and then use a continue to skip the process. Make sense? I found that if you, obviously, like if you get frustrated with like, no, you idiot, like it'll be apologetic and it'll spend more time apologizing. So don't be mean to the machine. If you just say, sorry, I think there was a misunderstanding, it's actually much more helpful. So words matter. Be polite to your coding assistant. Because if it's, just like a human, if the human is spending mental energy trying to placate, you know, a frustrated friend or whatever, it's going to waste a little bit more time and energy. Okay, sure, here's the modified script. The script will first check if the report already exists in the output folder. If it does, it will skip the current PDF and move to the next one. Excellent, so let's check this out and see if it works, if it looks how I think it should look. So we'll come over here. All right, so for PDF file and PDF files first, all right, yep, so first we list, there we go, that's what I was expecting. If it exists, then continue, so you just skip the whole thing. Otherwise, go ahead and open it. Yep, there we go, so we set, because we set the file name first. All right, so this should be fine. Okay, I think that's, I think that's good. So let's come over here. Let's exit out of my coding chatbot assistant. So again, like I had to put very little energy into that. All I had to do was check. And honestly, what I could have done is just asked it to check its work. Like, you know, does it do the thing that I think it is? But you saw, I didn't really do any coding all I did was copy paste okay. So let's go back out of here quickly extract science papers and then we'll do Python whoops generate multiple reports no module named pie pdf too. I thought I already had it maybe that was my previous install pip install I pdf2. I thought I already had it. Maybe that was my previous install. pip install pypdf2. pypdf2. This is the boring part. Okay, now it should work. Is deprecator and res removed? Use pdf reader instead. So this is exactly, exactly the problem that this one of the papers addresses is the fact that the modules have been updated and so now it's out of date. So we gotta go switch to this thing over here. Oh, I forgot to save it. That could be a problem. All right. So if it ends with otherwise All right. Let's see if that fixed it. And also it might have yarfed anyways because I forgot to save. Reader num pages is deprecated. Use len reader pages instead. Okay. At least their documentation is good and it's helping me fix it. Okay. Okay, that should be good. Int object is not iterable. And let's see for page in so if we're doing. So that's an end. We don't need that. We just need number of pages. So we should do. Let's see list of range of zero to zero to that. I think that's how that formatting is. So I'm having to fix some of it because exactly the problem, virtual list cannot be interpreted as an integer. Hang on. Let me just come back over here and say, I don't know what I'm doing. I'm lost. Python chat. Let's see. I got shift enter. Can you help me? I'm lost. I probably have the range formatted wrong or something. Let's see. It's typically blah, blah, blah. OK. For page in list range 0 PDF reader pages. Yeah, that's the correct line. List range zero length. Okay, interesting. Okay, so it was not lying to me when it said I needed length of PDF reader pages. All right, cool. So let's see if that fixed it. So let's come over here. So four page in. It seems like it's getting kind of long. Yeah, right. Let's just open another terminal. CD quickly. Yada, yada, yada. Anyways, well, here, let me just go ahead and see if it works. I thought generate still doesn't work. It's There we go. Reader pages. So we found another bug. Page num. Almost there. Reader is not defined. Oh, right. PDF reader. There we go. Extract text is deprecated and removed. Use extract underscore text instead. Man, okay, this is like an object lesson as to why this continuous learning needs to be done. Okay, cool. Now it's thinking. All right, I think we fixed it. So, ideally, what should happen is we'll get a list of outputs here that are going to have the same name as those so then it will not duplicate the efforts in the future. We'll go ahead and delete the reports folder. We can delete the inputs delete the generate report. There we go. Okay. So here we go. The continuous learning this would have actually helped this. So this will actually this kind of thing. I've actually had some conversations with people because with chat GPT having had the cutoff date in 2021 it's already losing utility because it's increasingly out of date. Some of that I think is deliberate on the part of openAI because they didn't want it to be able to use, other people to use it to accelerate language model research or who knows what else is going on. But yeah, so there it is. So we should have our first output here. There we go. So now you can correlate it back to exactly the same thing and you will be able to just quickly grab a whole bunch of stuff. Okay. Yep. Excellent. Excellent. Excellent. Python chat. Pi. Okay. Great. Let's see. I have a folder here. Let's go ahead and grab the updated version of this and put this. No we can get rid of that. Put this in scratch pad. So we've got coding scratch pad. All right. So let's put it there and then we'll say I have a folder output that is full of text files with the file name being the name of an archive paper. I would like to render all those files to HTML. Let's use the file name as a header. Where is my there we go. Let's use the file name as a header For each section. And then there is there is a conversation of QA. within each file which I'd like to present on the page pretty simply. So let's go ahead and grab an example of the report and put it in the scratchpad so it can see. Because then in the scratchpad you just give it examples of what you're talking about you can see an example of the plain text report in your scratch pad. Okay go. The final output should be report dot html, which should be fully self-contained and pretty all right so let's see what it gives me for that. Meanwhile this should be the other one should be pretty much done. Yep so we should have we've got four we've got four papers summarized and like I said this probably cost a few cents because it was you know it it it does add up a little bit because each paper actually you you have to read the entire paper three times because the conversation is three messages long. So that's that's one of the only things to keep in mind is that the more questions you ask it you're basically reading the entire paper every time to keep asking or to keep answering those questions about it. Let's see it status get add it commit a.m. all done and get push so you guys can use this and then let's hop back over to my coding chat bot to see what it said. OK cool. Let's see from B.S. import beautiful soup. And I'm just going to fully send this to see if it works. All right. So then, not coding chatbot, quickly extract. And we're going to come up here and just save this as render report.py. So let's jump over here. Oops, wrong terminal. Python render report dot pi. No module named BS4. Import. No. Pip install. Darn it. Pip install BS4. There we go. All right, let's try that again. All right, and that ran pretty much instantly, so let's see if that worked. Hey, cool, look at that. So it could stand to be a little bit prettier, but this is definitely good enough where it's got each one with a header. And so there you have it you've now got everything rendered to a nice report you can print this to PDF if you want it's searchable right you could you can say okay prompt where else prompt listed excellent yeah so I think I'm done I'll be using this to help with my video prep I can imagine that there's a whole bunch of other AI commentators out there who might start using this. But yeah, it's a super, super simple brain dead tool. Hopefully it'll help accelerate science. And yeah, it's out there under the MIT license. So please take it, use it, let's accelerate science. Let's accelerate all science with this. All right, cheers. Let's accelerate all science with this. Alright, cheers.", "chunks": [{"timestamp": [0.0, 3.36], "text": " Hey everybody, David Shapiro here with another video."}, {"timestamp": [3.36, 8.08], "text": " So it's a really exciting time because research is accelerating."}, {"timestamp": [8.08, 13.32], "text": " Just in the last couple days a whole bunch of interesting papers have come out on archive"}, {"timestamp": [13.32, 19.62], "text": " and you know, I could read them all myself, the hard way, the long way, but you know what?"}, {"timestamp": [19.62, 25.76], "text": " I'm really lazy and you know how Mr. Henry Ford he said allegedly said I don't know if he"}, {"timestamp": [25.76, 29.56], "text": " actually said this but he said give your hardest problems to the laziest engineers because"}, {"timestamp": [29.56, 34.6], "text": " they'll find an easier way to do it. That's me. That's why I became an automation engineer."}, {"timestamp": [34.6, 38.74], "text": " Back in the day I told people like I would rather spend a week building an automation"}, {"timestamp": [38.74, 42.62], "text": " tool that I can then just push the button and for the rest of my life it makes that"}, {"timestamp": [42.62, 47.96], "text": " job easier and guess what that's how I automated a three petabyte environment."}, {"timestamp": [47.96, 48.96], "text": " Because why?"}, {"timestamp": [48.96, 49.96], "text": " I didn't want to manage it myself."}, {"timestamp": [49.96, 56.66], "text": " Okay, so with the volume of paper that came out, because all of these came out Monday,"}, {"timestamp": [56.66, 61.44], "text": " so we've got five interesting papers that came out on the same day and this happens"}, {"timestamp": [61.44, 65.56], "text": " pretty much every day lately and it is entirely too much to keep up with."}, {"timestamp": [65.92, 68.12], "text": " So rather than having"}, {"timestamp": [68.12, 70.28], "text": " to read all of these papers every day I"}, {"timestamp": [70.28, 72.64], "text": " wanted a way to digest them so I could quickly"}, {"timestamp": [72.64, 73.7], "text": " just one skim"}, {"timestamp": [73.7, 75.08], "text": " and keep on top of things"}, {"timestamp": [75.8, 77.56], "text": " and then also just"}, {"timestamp": [78.4, 79.76], "text": " basically make it sustainable"}, {"timestamp": [79.76, 81.2], "text": " or make it operationalized."}, {"timestamp": [81.56, 83.52], "text": " And so what I mean by that is something that you can"}, {"timestamp": [83.52, 84.48], "text": " just fully automate"}, {"timestamp": [84.48, 85.04], "text": " and then just"}, {"timestamp": [85.04, 91.28], "text": " maybe get an email every day or have the interns do it or use this as part of your literature"}, {"timestamp": [91.28, 96.2], "text": " review for science because one of the things that I want to do is use this technology to"}, {"timestamp": [96.2, 99.24], "text": " accelerate science as much as possible."}, {"timestamp": [99.24, 103.9], "text": " And one of the things that I hear from some of my friends in science is that just keeping"}, {"timestamp": [103.9, 109.48], "text": " up with things is getting harder and harder, at least in these high velocity spaces."}, {"timestamp": [109.48, 114.04], "text": " Some places like oceanography, they don't change that much, they don't change that fast."}, {"timestamp": [114.04, 119.8], "text": " But certainly computer science, artificial intelligence, and that sort of thing, cybersecurity,"}, {"timestamp": [119.8, 124.84], "text": " quantum computing, these things are moving so incredibly fast, we need the AI to help"}, {"timestamp": [124.84, 126.04], "text": " us keep up."}, {"timestamp": [126.04, 129.6], "text": " So let me show you what I've done."}, {"timestamp": [129.6, 130.68], "text": " Let's see, where should I start?"}, {"timestamp": [130.68, 133.44], "text": " I guess I'll just start with some of the final reports."}, {"timestamp": [133.44, 138.32], "text": " So basically what I do is I just copy paste the text of the thing into here."}, {"timestamp": [138.32, 141.86], "text": " Obviously the figures help, but language models are already pretty intelligent, so they don't"}, {"timestamp": [141.86, 151.26], "text": " even really need the figures. And then what I do is I feed it a series of questions and it gives me answers."}, {"timestamp": [151.26, 159.16], "text": " And so this basically summarizes it from, you know, maybe 20,000, 40,000, 100,000 characters"}, {"timestamp": [159.16, 161.68], "text": " down to 4,000 characters."}, {"timestamp": [161.68, 167.6], "text": " So we get a compression ratio of at least 5 to 1, but also it's often in much simpler language."}, {"timestamp": [167.6, 172.2], "text": " And probably what I'll do is I'll add a second step that will render this as an HTML document."}, {"timestamp": [172.2, 178.6], "text": " Maybe I'll do that at the end. But anyways, so the idea is I plug in the text."}, {"timestamp": [178.6, 184.4], "text": " If it's a little too long, it'll trim it, but you get the first 22,000 characters of a paper."}, {"timestamp": [184.4, 189.0], "text": " You've got the general gist. And and in many cases you actually have the whole paper"}, {"timestamp": [189.0, 192.84], "text": " now so I say can you give me a very clear explanation of the core"}, {"timestamp": [192.84, 196.92], "text": " assertions implications and mechanics elucidated in this paper very simple"}, {"timestamp": [196.92, 200.4], "text": " prompt it comes back and says you know yada yada yada the paper explores the"}, {"timestamp": [200.4, 205.44], "text": " concept of continual learning okay cool you cool. So it asks that question."}, {"timestamp": [205.44, 209.84], "text": " And so basically this is a standard chat GPT conversation."}, {"timestamp": [209.84, 213.44], "text": " So this is a way to implement a chain of thinking,"}, {"timestamp": [213.44, 216.04], "text": " but it's really an automated dialogue."}, {"timestamp": [216.04, 218.28], "text": " So imagine that you have an intern"}, {"timestamp": [218.28, 220.72], "text": " or a research assistant that read the paper,"}, {"timestamp": [220.72, 222.64], "text": " and you can ask them a couple of questions."}, {"timestamp": [222.64, 226.74], "text": " And you can change this on your own, by the way, very easily."}, {"timestamp": [226.74, 227.9], "text": " So in the code I have it here."}, {"timestamp": [227.9, 232.26], "text": " You can just add whatever questions or change whatever questions you want here and it will"}, {"timestamp": [232.26, 237.2], "text": " be happy to take it and run with it for you entirely on its own."}, {"timestamp": [237.2, 242.22], "text": " So you change these questions if you want, you add more, you know, depending on the research"}, {"timestamp": [242.22, 243.5], "text": " that you're looking for."}, {"timestamp": [243.5, 246.4], "text": " So let's say for instance you are"}, {"timestamp": [246.4, 250.68], "text": " in a very specific domain. Maybe you're trying to do this for medical research"}, {"timestamp": [250.68, 253.96], "text": " and you're really just looking for what are the implications"}, {"timestamp": [253.96, 259.36], "text": " for, let's say, rejuvenation therapy or regenerative medicine or even"}, {"timestamp": [259.36, 262.92], "text": " something even more specific. Maybe you're trying to research a specific"}, {"timestamp": [262.92, 264.0], "text": " kind of cancer"}, {"timestamp": [264.0, 266.26], "text": " or a specific, any kind're trying to research a specific kind of cancer or a specific any"}, {"timestamp": [266.26, 268.64], "text": " kind of metabolic disorder really."}, {"timestamp": [268.64, 272.62], "text": " So then you can say first you want it to just tell me what are the implications and then"}, {"timestamp": [272.62, 278.48], "text": " you could say okay what are the implications with respect to my particular domain?"}, {"timestamp": [278.48, 283.44], "text": " What is the impact to my area of research?"}, {"timestamp": [283.44, 285.0], "text": " So restate it for me"}, {"timestamp": [288.72, 294.16], "text": " and then you can have it automatically spider a whole bunch of documents. So one of the things that I'm going to do with this is that rather than have just one input at a time"}, {"timestamp": [294.36, 298.16], "text": " I'm going to create a folder where you give it you just download the PDFs to directly."}, {"timestamp": [298.4, 303.04], "text": " It'll scrape the PDFs and go through all of them as part of the automated process"}, {"timestamp": [303.24, 305.5], "text": " and it'll whatever the questions that you have,"}, {"timestamp": [305.5, 307.5], "text": " it will kind of break it down. But anyways,"}, {"timestamp": [307.5, 310.5], "text": " so I have a few standard questions."}, {"timestamp": [310.5, 312.5], "text": " Can you explain the value of this in basic terms"}, {"timestamp": [312.5, 314.0], "text": " like you're talking to a CEO?"}, {"timestamp": [314.0, 316.0], "text": " So what? What's the bottom line here?"}, {"timestamp": [316.0, 319.0], "text": " And it's really good at explaining things in simple terms."}, {"timestamp": [319.0, 321.0], "text": " So in this case, this paper says"}, {"timestamp": [321.0, 323.5], "text": " the research is about making code generation models,"}, {"timestamp": [323.5, 326.76], "text": " which are tools that help programmers by automating some of their work"}, {"timestamp": [327.14, 333.68], "text": " more adaptable and efficient. Currently, these models need to be retrained every time there's a significant change to the programming languages or"}, {"timestamp": [334.12, 336.76], "text": " libraries they work with, which this is what some people are noticing."}, {"timestamp": [336.96, 344.36], "text": " And I noticed this too, is that sometimes it'll program with an outdated version, which of course limits the utility of coding models."}, {"timestamp": [345.56, 348.52], "text": " The bottom line is that this research could lead to more efficient and adaptable code"}, {"timestamp": [348.52, 349.76], "text": " generation models."}, {"timestamp": [349.76, 353.28], "text": " This means less time and money spent on retraining these models and more up-to-date and effective"}, {"timestamp": [353.28, 354.88], "text": " tools for programmers."}, {"timestamp": [354.88, 358.64], "text": " So the implication for this, just reading that one paragraph to me says, okay, cool,"}, {"timestamp": [358.64, 363.92], "text": " this is going to be part of the acceleration because if we come up with a way to make coding"}, {"timestamp": [363.92, 366.0], "text": " models updated or"}, {"timestamp": [366.0, 370.44], "text": " updatable you know using continuous learning great excellent and then I said"}, {"timestamp": [370.44, 372.96], "text": " can you give me an analogy or metaphor that will help me explain this to a"}, {"timestamp": [372.96, 377.6], "text": " broad audience why because I'm a youtuber right so basically what I want"}, {"timestamp": [377.6, 383.96], "text": " is to be able to explain this paper in real basic terms real fast and contrary"}, {"timestamp": [383.96, 386.0], "text": " to the belief about a year ago,"}, {"timestamp": [386.0, 389.0], "text": " language models are actually really good at analogy and metaphor."}, {"timestamp": [389.0, 393.0], "text": " So it says, sure, let's think of the cogeneration models as chefs in a kitchen."}, {"timestamp": [393.0, 396.0], "text": " These chefs are trained to prepare a variety of dishes using specific recipes and ingredients."}, {"timestamp": [396.0, 399.0], "text": " However, the culinary world is always evolving,"}, {"timestamp": [399.0, 402.0], "text": " with new recipes and ingredients being introduced regularly."}, {"timestamp": [402.0, 405.08], "text": " In the current scenario, every time a new recipe"}, {"timestamp": [405.08, 407.56], "text": " or ingredient is introduced, the chef has to go through"}, {"timestamp": [407.56, 408.92], "text": " a complete retraining process,"}, {"timestamp": [408.92, 411.4], "text": " which is time-consuming and expensive."}, {"timestamp": [411.4, 413.62], "text": " It's as if the chef forgets all of the old recipes"}, {"timestamp": [413.62, 414.84], "text": " when they learn a new one."}, {"timestamp": [414.84, 416.24], "text": " See, that's a good metaphor."}, {"timestamp": [417.68, 420.48], "text": " Or I guess that's an analogy, that's not a metaphor."}, {"timestamp": [420.48, 422.68], "text": " The researchers in this study developed"}, {"timestamp": [422.68, 423.98], "text": " a new training method for these chefs."}, {"timestamp": [423.98, 426.0], "text": " Instead of forgetting old recipes when learning new ones,"}, {"timestamp": [426.0, 428.0], "text": " the chefs can now continually learn and adapt,"}, {"timestamp": [428.0, 432.0], "text": " adding new recipes to the repertoire while still remembering the old ones."}, {"timestamp": [432.0, 434.0], "text": " This is like a chef who can learn to cook a new dish"}, {"timestamp": [434.0, 437.0], "text": " while still remembering to cook all the previous dishes they've ever learned."}, {"timestamp": [437.0, 441.0], "text": " This new training method is called prompt pooling with teacher forcing."}, {"timestamp": [441.0, 443.0], "text": " It makes chefs, or in the real case, the cogeneration models,"}, {"timestamp": [443.0, 450.8], "text": " more efficient and adaptable, yada yada yada. OK. You get the idea. So this only takes a few seconds and it takes only a few cents to run."}, {"timestamp": [450.8, 455.96], "text": " And so actually probably what I'll do is I'll pause it and I'll go ahead and update it so that it'll just ingest"}, {"timestamp": [455.96, 462.96], "text": " everything in a folder and then I'll show you a nice cleaned up output. So actually we'll be right back."}, {"timestamp": [462.96, 465.54], "text": " OK. So speaking of being lazy I just wanted to show you real quick,"}, {"timestamp": [465.54, 467.2], "text": " I'm using my coding chatbot to do this"}, {"timestamp": [467.2, 468.74], "text": " because I'm ultra lazy."}, {"timestamp": [469.84, 471.62], "text": " Work smart, not hard."}, {"timestamp": [471.62, 473.32], "text": " So basically, I took the script"}, {"timestamp": [473.32, 475.64], "text": " and I just copied it into my coding chatbot,"}, {"timestamp": [475.64, 476.72], "text": " which you can find it,"}, {"timestamp": [476.72, 478.9], "text": " it's literally just called coding underscore chatbot"}, {"timestamp": [478.9, 480.68], "text": " underscore assistant on my GitHub."}, {"timestamp": [480.68, 482.72], "text": " So I copied the script that I had,"}, {"timestamp": [482.72, 484.42], "text": " which is all of 99 lines,"}, {"timestamp": [484.42, 486.64], "text": " and I came over to my coding chat bot and I said, Hey,"}, {"timestamp": [486.76, 490.52], "text": " can you do this for me instead? And it's like, sure. Okay, cool."}, {"timestamp": [490.56, 494.6], "text": " So basically I said, let's get a folder."}, {"timestamp": [494.88, 496.32], "text": " So we're using this folder."}, {"timestamp": [496.8, 500.6], "text": " So we can just download the PDFs directly to there rather than copy and pasting"}, {"timestamp": [500.62, 501.44], "text": " the text."}, {"timestamp": [501.52, 506.08], "text": " And we're just going to take the output folder or the input folder for the PDFs"}, {"timestamp": [506.08, 514.0], "text": " and then an output folder for the what you call it. Whoops. OK. So we come over to here and it"}, {"timestamp": [514.0, 523.92], "text": " wants us to add OS and Pi PDF. That's fine. So we add that and then we see what else it wants to do."}, {"timestamp": [524.76, 529.52], "text": " So we add that and then we see what else it wants to do. If name equals main, yep, so it's going to do all that."}, {"timestamp": [529.52, 530.96], "text": " PDF file replace, yep, cool."}, {"timestamp": [530.96, 532.72], "text": " So I just I gave it really simple instructions."}, {"timestamp": [532.72, 536.88], "text": " I said, can you modify this script so that it will one, open every PDF in the input folder"}, {"timestamp": [536.88, 543.32], "text": " one by one and perform the same operation and two, check an output folder for the report"}, {"timestamp": [543.32, 547.5], "text": " as the same PDF or blah. Check the output folder for a report as the same PDF, blah."}, {"timestamp": [547.5, 549.78], "text": " Check the output folder for a file of the same name."}, {"timestamp": [549.78, 551.9], "text": " This will enable us to run batches without duplicating effort."}, {"timestamp": [551.9, 552.8], "text": " Should be pretty straightforward."}, {"timestamp": [552.8, 554.38], "text": " Let me know if you have any questions."}, {"timestamp": [554.38, 560.34], "text": " And okay, so let's put this over here and see if it worked."}, {"timestamp": [561.78, 567.0], "text": " Okay, so PDF files for files in OSLister, that looks right."}, {"timestamp": [567.0, 573.88], "text": " Open, read binary as file, PDF reader, yep, so we get that."}, {"timestamp": [573.88, 577.04], "text": " It gets all the page numbers, that should all work."}, {"timestamp": [577.04, 581.08], "text": " I've used this module before, pypdf2 and PDF file reader."}, {"timestamp": [581.08, 587.84], "text": " If it's over 22,000 characters, just cut it off. It seems to work well enough"}, {"timestamp": [587.84, 596.06], "text": " and then we get the report so on and so forth. Let's see. It looks like it's not actually"}, {"timestamp": [596.06, 602.12], "text": " checking if the file exists."}, {"timestamp": [602.12, 607.0], "text": " Yep OK so this is this is close so let's take this over to the scratch pad, and then we'll"}, {"timestamp": [607.0, 613.52], "text": " say, let's see, we'll then check the output folder for the report."}, {"timestamp": [613.52, 617.2], "text": " Wait, am I missing something?"}, {"timestamp": [617.2, 632.96], "text": " It doesn't have a continue function. Okay. Sorry. I think we need to check if the final file name exists in the output folder first and"}, {"timestamp": [632.96, 642.72], "text": " then use a continue to skip the process. Make sense? I found that if you, obviously, like if"}, {"timestamp": [642.72, 646.2], "text": " you get frustrated with like, no, you idiot, like it'll be apologetic"}, {"timestamp": [646.2, 648.6], "text": " and it'll spend more time apologizing."}, {"timestamp": [648.6, 649.78], "text": " So don't be mean to the machine."}, {"timestamp": [649.78, 651.84], "text": " If you just say, sorry, I think there was a misunderstanding,"}, {"timestamp": [651.84, 653.24], "text": " it's actually much more helpful."}, {"timestamp": [653.24, 654.8], "text": " So words matter."}, {"timestamp": [654.8, 657.6], "text": " Be polite to your coding assistant."}, {"timestamp": [657.6, 659.54], "text": " Because if it's, just like a human,"}, {"timestamp": [659.54, 662.52], "text": " if the human is spending mental energy trying to placate,"}, {"timestamp": [662.52, 665.22], "text": " you know, a frustrated friend or whatever, it's going"}, {"timestamp": [665.22, 668.02], "text": " to waste a little bit more time and energy."}, {"timestamp": [668.02, 671.3], "text": " Okay, sure, here's the modified script."}, {"timestamp": [671.3, 673.86], "text": " The script will first check if the report already exists in the output folder."}, {"timestamp": [673.86, 676.7], "text": " If it does, it will skip the current PDF and move to the next one."}, {"timestamp": [676.7, 684.7], "text": " Excellent, so let's check this out and see if it works, if it looks how I think it should"}, {"timestamp": [684.7, 685.0], "text": " look."}, {"timestamp": [686.96, 688.76], "text": " So we'll come over here."}, {"timestamp": [688.76, 692.36], "text": " All right, so for PDF file and PDF files first,"}, {"timestamp": [692.36, 694.52], "text": " all right, yep, so first we list, there we go,"}, {"timestamp": [694.52, 695.92], "text": " that's what I was expecting."}, {"timestamp": [695.92, 698.08], "text": " If it exists, then continue,"}, {"timestamp": [698.08, 699.68], "text": " so you just skip the whole thing."}, {"timestamp": [699.68, 701.54], "text": " Otherwise, go ahead and open it."}, {"timestamp": [701.54, 702.96], "text": " Yep, there we go, so we set,"}, {"timestamp": [702.96, 704.64], "text": " because we set the file name first."}, {"timestamp": [704.64, 706.36], "text": " All right, so this should be fine."}, {"timestamp": [706.36, 710.28], "text": " Okay, I think that's, I think that's good."}, {"timestamp": [710.28, 711.56], "text": " So let's come over here."}, {"timestamp": [711.56, 714.4], "text": " Let's exit out of my coding chatbot assistant."}, {"timestamp": [714.4, 716.68], "text": " So again, like I had to put very little energy into that."}, {"timestamp": [716.68, 717.68], "text": " All I had to do was check."}, {"timestamp": [717.68, 721.16], "text": " And honestly, what I could have done is just asked it to check its work."}, {"timestamp": [721.16, 724.02], "text": " Like, you know, does it do the thing that I think it is?"}, {"timestamp": [724.02, 728.08], "text": " But you saw, I didn't really do any coding all I did was copy paste"}, {"timestamp": [728.1, 731.64], "text": " okay. So let's go back out of here quickly"}, {"timestamp": [731.66, 734.76], "text": " extract science papers and then we'll do Python"}, {"timestamp": [734.78, 738.52], "text": " whoops generate multiple reports"}, {"timestamp": [738.54, 741.96], "text": " no module named pie pdf too."}, {"timestamp": [741.98, 746.88], "text": " I thought I already had it maybe that was my previous install pip install I pdf2. I thought I already had it. Maybe that was my previous install. pip install pypdf2."}, {"timestamp": [748.24, 750.16], "text": " pypdf2."}, {"timestamp": [752.8, 760.48], "text": " This is the boring part. Okay, now it should work. Is deprecator and res removed? Use pdf reader"}, {"timestamp": [760.48, 773.0], "text": " instead. So this is exactly, exactly the problem that this one of the papers addresses is the fact that the modules have been updated and so now it's out of date."}, {"timestamp": [773.0, 777.0], "text": " So we gotta go switch to this thing over here."}, {"timestamp": [777.0, 786.0], "text": " Oh, I forgot to save it. That could be a problem. All right. So if it"}, {"timestamp": [786.0, 788.0], "text": " ends with otherwise"}, {"timestamp": [788.0, 790.0], "text": " All right. Let's see if that fixed it."}, {"timestamp": [790.0, 792.0], "text": " And also it might have"}, {"timestamp": [792.0, 794.0], "text": " yarfed anyways because I forgot to save."}, {"timestamp": [794.0, 796.0], "text": " Reader num pages is deprecated."}, {"timestamp": [796.0, 798.0], "text": " Use len reader pages instead."}, {"timestamp": [798.0, 800.0], "text": " Okay. At least their"}, {"timestamp": [800.0, 802.0], "text": " documentation is good and it's helping me fix it."}, {"timestamp": [802.0, 805.6], "text": " Okay."}, {"timestamp": [811.94, 818.74], "text": " Okay, that should be good. Int object is not iterable."}, {"timestamp": [819.64, 827.6], "text": " And let's see for page in so if we're doing. So that's an end. We don't need that."}, {"timestamp": [827.6, 838.4], "text": " We just need number of pages. So we should do. Let's see list of range of zero to zero to that."}, {"timestamp": [838.4, 846.44], "text": " I think that's how that formatting is. So I'm having to fix some of it because exactly the problem, virtual list cannot be interpreted as an integer."}, {"timestamp": [846.44, 848.44], "text": " Hang on."}, {"timestamp": [848.44, 854.16], "text": " Let me just come back over here and say, I don't know what I'm doing."}, {"timestamp": [854.16, 855.16], "text": " I'm lost."}, {"timestamp": [855.16, 859.16], "text": " Python chat."}, {"timestamp": [859.16, 870.56], "text": " Let's see. I got shift enter."}, {"timestamp": [870.56, 871.56], "text": " Can you help me?"}, {"timestamp": [871.56, 872.56], "text": " I'm lost."}, {"timestamp": [872.56, 885.64], "text": " I probably have the range formatted wrong or something."}, {"timestamp": [886.64, 889.24], "text": " Let's see. It's typically blah, blah, blah."}, {"timestamp": [889.24, 889.96], "text": " OK."}, {"timestamp": [889.96, 892.64], "text": " For page in list range 0 PDF reader pages."}, {"timestamp": [896.12, 897.68], "text": " Yeah, that's the correct line."}, {"timestamp": [904.4, 906.0], "text": " List range zero length."}, {"timestamp": [906.0, 907.5], "text": " Okay, interesting."}, {"timestamp": [907.5, 912.0], "text": " Okay, so it was not lying to me when it said I needed length of PDF reader pages."}, {"timestamp": [912.0, 913.0], "text": " All right, cool."}, {"timestamp": [913.0, 914.5], "text": " So let's see if that fixed it."}, {"timestamp": [914.5, 916.0], "text": " So let's come over here."}, {"timestamp": [916.0, 918.0], "text": " So four page in."}, {"timestamp": [918.0, 921.0], "text": " It seems like it's getting kind of long."}, {"timestamp": [921.0, 922.0], "text": " Yeah, right."}, {"timestamp": [922.0, 929.48], "text": " Let's just open another terminal. CD quickly. Yada, yada, yada. Anyways, well,"}, {"timestamp": [929.48, 951.94], "text": " here, let me just go ahead and see if it works. I thought generate still doesn't work. It's There we go. Reader pages. So we found another bug."}, {"timestamp": [951.94, 954.66], "text": " Page num."}, {"timestamp": [954.66, 958.28], "text": " Almost there."}, {"timestamp": [958.28, 959.68], "text": " Reader is not defined."}, {"timestamp": [959.68, 961.68], "text": " Oh, right."}, {"timestamp": [961.68, 963.6], "text": " PDF reader."}, {"timestamp": [963.6, 968.36], "text": " There we go."}, {"timestamp": [968.36, 970.84], "text": " Extract text is deprecated and removed."}, {"timestamp": [970.84, 973.4], "text": " Use extract underscore text instead."}, {"timestamp": [973.4, 980.28], "text": " Man, okay, this is like an object lesson as to why this continuous learning needs to be"}, {"timestamp": [980.28, 981.28], "text": " done."}, {"timestamp": [981.28, 982.28], "text": " Okay, cool."}, {"timestamp": [982.28, 983.28], "text": " Now it's thinking."}, {"timestamp": [983.28, 984.28], "text": " All right, I think we fixed it."}, {"timestamp": [984.28, 990.72], "text": " So, ideally, what should happen is we'll get a list of outputs here that are going to have the same name as"}, {"timestamp": [990.72, 996.6], "text": " those so then it will not duplicate the efforts in the future. We'll go ahead and delete the reports folder."}, {"timestamp": [996.6, 1006.72], "text": " We can delete the inputs delete the generate report. There we go. Okay. So here we go. The continuous learning this would have actually helped this."}, {"timestamp": [1006.72, 1013.04], "text": " So this will actually this kind of thing. I've actually had some conversations with people because with chat"}, {"timestamp": [1013.04, 1021.08], "text": " GPT having had the cutoff date in 2021 it's already losing utility because it's increasingly out of date."}, {"timestamp": [1021.08, 1030.08], "text": " Some of that I think is deliberate on the part of openAI because they didn't want it to be able to use, other people to use it to accelerate language model research"}, {"timestamp": [1030.08, 1036.92], "text": " or who knows what else is going on. But yeah, so there it is. So we should have our first"}, {"timestamp": [1036.92, 1046.44], "text": " output here. There we go. So now you can correlate it back to exactly the same thing and you will be able to just quickly grab a whole bunch of stuff."}, {"timestamp": [1046.44, 1052.44], "text": " Okay. Yep. Excellent. Excellent. Excellent."}, {"timestamp": [1052.44, 1056.96], "text": " Python chat."}, {"timestamp": [1056.96, 1060.48], "text": " Pi. Okay. Great."}, {"timestamp": [1062.0, 1067.62], "text": " Let's see. I have a folder here."}, {"timestamp": [1067.62, 1072.5], "text": " Let's go ahead and grab the updated version of this and put this."}, {"timestamp": [1072.5, 1074.82], "text": " No we can get rid of that."}, {"timestamp": [1074.82, 1077.84], "text": " Put this in scratch pad."}, {"timestamp": [1077.84, 1082.1], "text": " So we've got coding scratch pad."}, {"timestamp": [1082.1, 1083.22], "text": " All right."}, {"timestamp": [1083.22, 1111.76], "text": " So let's put it there and then we'll say I have a folder output that is full of text files with the file name being the name of an archive paper. I would like to render all those files to"}, {"timestamp": [1111.76, 1121.92], "text": " HTML. Let's use the file name as a header. Where is my there"}, {"timestamp": [1121.92, 1126.0], "text": " we go. Let's use the file name as a header"}, {"timestamp": [1128.4, 1132.1], "text": " For each section."}, {"timestamp": [1132.5, 1148.0], "text": " And then there is there is a conversation of QA. within each file which I'd like to present on the page"}, {"timestamp": [1148.0, 1152.0], "text": " pretty simply. So let's go ahead and grab"}, {"timestamp": [1152.0, 1156.0], "text": " an example of the report and put it in the scratchpad"}, {"timestamp": [1156.0, 1160.0], "text": " so it can see. Because then in the scratchpad"}, {"timestamp": [1160.0, 1164.0], "text": " you just give it examples of what you're talking about"}, {"timestamp": [1164.0, 1171.1], "text": " you can see an example of the plain text report in your scratch"}, {"timestamp": [1171.1, 1181.98], "text": " pad. Okay go. The final output should be report dot html,"}, {"timestamp": [1181.98, 1187.6], "text": " which should be fully self-contained"}, {"timestamp": [1187.64, 1191.0], "text": " and pretty all right so let's see what it gives me for that."}, {"timestamp": [1191.04, 1194.36], "text": " Meanwhile this should be the other one should be pretty much"}, {"timestamp": [1194.36, 1198.52], "text": " done. Yep so we should have we've got four we've got four"}, {"timestamp": [1198.52, 1202.08], "text": " papers summarized and like I said this probably cost a few"}, {"timestamp": [1202.08, 1208.06], "text": " cents because it was you know it it it does add up a little"}, {"timestamp": [1208.06, 1212.76], "text": " bit because each paper actually you you have to read the entire paper three times because"}, {"timestamp": [1212.76, 1216.76], "text": " the conversation is three messages long. So that's that's one of the only things to keep"}, {"timestamp": [1216.76, 1221.76], "text": " in mind is that the more questions you ask it you're basically reading the entire paper"}, {"timestamp": [1221.76, 1225.52], "text": " every time to keep asking or to keep answering those questions about it."}, {"timestamp": [1226.08, 1228.52], "text": " Let's see it status get"}, {"timestamp": [1228.76, 1231.2], "text": " add it commit"}, {"timestamp": [1231.2, 1233.2], "text": " a.m. all done"}, {"timestamp": [1234.16, 1235.98], "text": " and get push so you guys can"}, {"timestamp": [1236.0, 1237.74], "text": " use this and then let's hop back over"}, {"timestamp": [1237.76, 1239.48], "text": " to my coding chat"}, {"timestamp": [1239.48, 1241.32], "text": " bot to see what it said."}, {"timestamp": [1242.32, 1243.68], "text": " OK cool."}, {"timestamp": [1244.76, 1247.82], "text": " Let's see from B.S. import beautiful soup. And I'm just going"}, {"timestamp": [1247.82, 1256.78], "text": " to fully send this to see if it works. All right. So then, not coding chatbot, quickly"}, {"timestamp": [1256.78, 1265.0], "text": " extract. And we're going to come up here and just save this as render report.py. So let's jump over here."}, {"timestamp": [1265.0, 1267.0], "text": " Oops, wrong terminal."}, {"timestamp": [1267.0, 1270.0], "text": " Python render report dot pi."}, {"timestamp": [1270.0, 1274.0], "text": " No module named BS4."}, {"timestamp": [1274.0, 1276.0], "text": " Import."}, {"timestamp": [1276.0, 1278.0], "text": " No."}, {"timestamp": [1278.0, 1279.0], "text": " Pip install."}, {"timestamp": [1279.0, 1280.0], "text": " Darn it."}, {"timestamp": [1280.0, 1283.0], "text": " Pip install BS4."}, {"timestamp": [1283.0, 1286.0], "text": " There we go. All right, let's try that again."}, {"timestamp": [1286.0, 1293.0], "text": " All right, and that ran pretty much instantly, so let's see if that worked."}, {"timestamp": [1293.0, 1295.08], "text": " Hey, cool, look at that."}, {"timestamp": [1295.08, 1302.08], "text": " So it could stand to be a little bit prettier, but this is definitely good enough where it's"}, {"timestamp": [1302.08, 1303.84], "text": " got each one with a header."}, {"timestamp": [1303.84, 1305.3], "text": " And so there you have it you've"}, {"timestamp": [1305.3, 1309.48], "text": " now got everything rendered to a nice report you can print this to PDF if you"}, {"timestamp": [1309.48, 1315.76], "text": " want it's searchable right you could you can say okay prompt where else prompt"}, {"timestamp": [1315.76, 1322.32], "text": " listed excellent yeah so I think I'm done I'll be using this to help with my"}, {"timestamp": [1322.32, 1325.12], "text": " video prep I can imagine that there's a whole bunch of other"}, {"timestamp": [1325.12, 1331.44], "text": " AI commentators out there who might start using this. But yeah, it's a super, super"}, {"timestamp": [1331.44, 1336.74], "text": " simple brain dead tool. Hopefully it'll help accelerate science. And yeah, it's out there"}, {"timestamp": [1336.74, 1341.36], "text": " under the MIT license. So please take it, use it, let's accelerate science. Let's accelerate"}, {"timestamp": [1341.36, 1343.16], "text": " all science with this. All right, cheers."}, {"timestamp": [1340.54, 1342.54], "text": " Let's accelerate all science with this."}, {"timestamp": [1342.54, 1344.54], "text": " Alright, cheers."}]}