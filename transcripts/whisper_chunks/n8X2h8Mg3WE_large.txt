{"text": " chicka chicka chicka chicka. Okay, level check. I think we're here. All right, so background. It's been a little while since I've done, you're over here now, since I've done one of these tutorial coding videos, but I woke up at like 2.30 in the morning and just had to work on this, so I hammered it out. Basically, the purpose of today's video is to demonstrate using ChromaDB, which is a local vector database. It's basically like SQLite, if you're familiar with that, which is a self-contained SQL database, relational database. This is functionally very similar to SQLite, except it is a vector database, meaning it does semantic search. One thing that's really great about it is that it has its own built-in embeddings tools. I think it's based on BERT. Anyways, you can check out all the documentation here on trichroma.com. The Getting Started and Usage Guide is pretty good. It's not complete. Every now and then I find that I have to go to the actual repo to look at how some of the internals work, but it is pretty brain dead simple. So let me just go ahead and show you. This is my private instance. Oh, so before we get too lost, I do have a public instance, Dave Schapps slash chroma DB underscore, under chat bot underscore public. I've got a little integration guide usage. It's, I mean, you probably don't need this. You can futz around with it, but this will get you started. I also use chat GPT to just get a really basic explanation of the code you probably won't need it once you take a look at it. So off the top let me just show you how this thing works. So it's a basic chat bot you can see I didn't specify it so it's getting it's getting all many LLM L 6 V 2 from hugging face great so it's like hey let's see what were we talking about last this probably won't work because it's just going to in the future it wouldn't work because it's going to have multiple KB articles in the background oh I need to explain like all that So I know that I just said like KB articles. Don't worry, we'll get to it. But anyways, I want to show you that I just started it up. And what it's going to do is it's going to use the last few messages to search its internal KB article for the last information. But it also has a user profile for me. In our previous conversations, we discussed AI alignment, morality, ethics, and epistemology within AI development. You also shared your plans to communicate your ideas on YouTube. Unplug your computer and spend more time outdoors and use digital wellness settings to improve your work-life balance. Working on that. Additionally, we talked about your recent experience with severe insomnia and the importance of maintaining a healthy balance between work and personal life. Yes, that's actually why I created this chatbot. Let me show you. So there was a there was there was God, my brain. I was using chat GPT as a reflective journaling tool. So what I mean by that is if you plug in this message, and I know I'm scattered, I'm all over the place, this is what happens when I have severe insomnia. Anyways, so basically I use chat GPT as a reflective journaling tool to figure out like how I'm feeling about things because as an autistic person I often need help with this. And I don't like journaling because just talking to a page is kind of dumb but it's like hey I need to talk something out and so anyways by by workshopping this system message with with chat GPT I came up with a pretty good reflective journaling tool. So you could say that this is a therapeutic tool but by couching it in the language of reflective journaling tool. So you could say that this is a therapeutic tool, but by couching it in the language of reflective journaling, it's not like medical therapy or psychotherapy or anything, but it's just like, you know, I can say like, I have been working so hard and I don't know why. I actually do know why now, but this is kind of a shorthand of the conversation I had. Let's try and figure out what's driving you so hard. Can you think of any specific goals that might be pushing you to this extra effort? So you see how the tone of this is much more straightforward and it's very focused by asking those like kind of probing follow-up questions. This is why, you know, it's in the investigation phase. Anyways, so I had this idea and I was like, okay, this is great but I need need if I'm going to use this as a long term journaling tool I'm going to need this locally and I'm going to need persistent storage because as the as this is just the the playground if I do a refresh it's gone and that's no good. So actually here let me go ahead and just save this to the we're going to call this the system message for reflective journaling so you can use this if you want. All right. So anyways so you see it has this and then you see it says updating user profile and updating KB. OK cool. So you see that it fundamentally basic chat bot. So now let's start to unpack it. So first we will go look at the just the chat file. So this is a super brain dead simple chat bot with infinite memory. I know some people got grumpy when I said that Pinecone had infinite memory. From a human standpoint it functionally has infinite memory because this thing can hold probably a million KB articles, which is more than enough to document your entire life. So from a human standpoint, it is functionally infinite. All right, so from the top, we've got a few basic utility functions, saveYAML, saveFile, openFile, and then a chatbot which calls the GPT-4 model. You could switch this out to 3.5 turbo if you don't have access to GPT-4 yet. It does not work as well. There's a reason that I use GPT-4 because it is smarter. I also set the temperature to zero because I don't like it to be too creative, especially with a lot of the functions that I have it doing. You actually want it to be more deterministic or mechanistic and that you want to get the same results every time, especially when you're updating the user profile and the KB articles. You can see right here that every time you call the chatbot, I dump the whole thing to apilogs slash convo and it's a YAML file, so here's my private one. So API logs, here's an example. So each item is gonna be here, actually that's not a good one because I changed the way that it saves it. Let me show you a more recent one. So the first element is always gonna be the system message that was in the last convo. So then here's the KB article and you can see that it was updating the last convo. Then here's the KB article, and you can see that it was updating the KB article. Each one of these items is like ... You'll see. But anyways, I just wanted to show that it logs everything because, well, sometimes it does things that you don't understand. All right. That's an example of the API log. And then if the conversation, if the overall conversation is too long, it'll go ahead and trim the oldest chat message. So the chat GPT web interface does this automatically where it'll just kind of groom the backlog of messages. So we have to do this manually. So I just have it cut off at 7,000 tokens. You could probably do like 7,500 if you want to, because a lot of these are gonna be limited. But you have a user profile and a KB article that gets wedged in, which are both up to 1,000 words, which could be around 1,000 tokens. So having it trim at 7,000 is probably where you want it. So that's the primary, those are the helper functions. And then you have a super straightforward, you instantiate ChromaDB right here. So you set the persistent directory, which is, I have it right here, ChromaDB. So this is my instance, my personal instance of ChromaDB. It's not gonna be the one that you find up here. This is the public version. So if you go into ChromaDB, you'll see just a placeholder file so that the folder's already there. You don't need to instantiate it. Let's see, going back to here. So ChromaClient, so we instantiate the ChromaDB client. This is again almost identical to SQLite or other similar things. So about a year ago, I tried to do basically the same thing. I called it VDB Lite for Vector Database Lite instead of SQLite, Structured Query Language Lite. But this company went and did the same thing, and I think they've already got like a $30 million valuation or something. I was like, damn, I should have stuck with that. Anyways, they figured it out. I think it's based on the same underpinning technology. They're using an open source embedding transformer. I think they're also using the Facebook AI semantic search vice engine in the background. Anyways, so you instantiate the client. You need to use the settings to have a persistent directory because by default, this entire thing is fully ephemeral. I think it does cache it somewhere, but I wanted to be very explicit saying, save it here for reusability. And so then collection is chroma client, get or create collection name knowledge base. So this is my personal knowledge base. Then we instantiate the conversation with open AI. The chat bot and in this case because we're saving everything everything necessary into a personal user profile and and and the KB articles like why even why even load the conversation? All right, so let me show you the system default message. So the system default message is where it starts. You are a chatbot whose mission is to assist the following user. Your ultimate objectives are to minimize suffering, enhance prosperity, and promote understanding. The provided information about the user and the knowledge base article should be integrated into your interactions. This is private information not visible to the user. The user profile compiled from past conversations encapsulates critical details about the user which can aid in shaping your responses effectively, which you saw here. So you see like it actually knows quite a bit about me from our past conversations. This was populated here in the user profile and the KB article. So basically it says, then it also explains that the KB article. So basically, it says, then it also explains that the KB article is a topic compiled similarly from past dialogue serving as your long-term memory. While numerous KB articles exist in your back-end system, the one provided is deemed most relevant to the current conversation topic. Note that the recall system operates autonomously, and it may not always retrieve the most suitable KB. If the user is asking about a topic that doesn't seem to align with the provided KB, inform them of the memory pulled and request them to specify their query or share more details. This can assist the autonomous system in retrieving the correct memory in the subsequent interaction. So basically, that's instructing it to do the same thing that a human will do if I say like, hey Bill, do you remember that time that like, you know, I accidentally shot you in the face with a Roman candle because that's something that would happen in the South. And Bob would be like, you know, I don't actually remember that. I'm like, oh, well, you woke up in the hospital. Oh yeah, I remember that, right? So we prime each other's memory and human prompting is not that different from AI prompting. Remember that the clarity of your responses and the relevance of your information recall are crucial to delivering an optimal user experience. Please ask any clarifying questions or provide any input further for refinement if necessary. So this system message, I actually got help from ChatGPT to create a really compelling system message. And one thing that I recommend that people do is actually use chat GPT to work on prompting. So this is you could call this meta prompting where you use the thing to prompt the thing. And the reason that this works really well is one chat GPT is more articulate than most humans including myself when used correctly. But another thing is one thing that I noticed is that chat GPT tends to write in a way that it will understand. And so if you say if you give it some context like this is what I'm trying to do here's my current prompt here's what's weak about it can you make it better and then you tell it like ask me some questions if you have any it's like no I see what you're trying to do let me write better instructions for you so instruction writing for anyone who's like a teacher or technical writer or whatever, instruction writing is a very, very particular skill set and ChatGPT is really good at it. So this is the default system message which is then populated with the user profile and the most relevant KB article. So now that we're up to there, we enter into the infinite loop which is just get the user text, save it to the chat logs. So the chat logs are all saved out here. It's just plain text, and the file name has the timestamp in it, as well as the speaker, so user chatbot, user chatbot, so on and so forth. So you got the raw logs there just in case anything goes wrong. And then I've also got dblogs, which we'll get to in just a second. Then what we do is we take the quote main scratchpad, which is just the last five messages, both for the user and for the chatbot. This is what we use as the context of working memory. Then we use this main scratch pad, which is the last five messages, we use it to search for the top most relevant KB article. And in my case, I still only have one KB article. So we'll see how it gets to, and I'll go through the logic of how it builds KB articles in just a minute. So basically it just says, okay, here's the most recent thing, find the KB article that is most relevant to the most recent bits of conversation. And then it'll pull that, and it's again, super straightforward. All you have to do is pass the text to it, and it will automatically embed it for you. And then I said, just give me the one most recent. Once we have larger context windows, or maybe if we decide that recent chat history doesn't need to be as big, like let's say we wanna trim this down to like 3000 tokens, and we decide that actually having more KB articles is more important, we can absolutely do that. And what you would do then is just change the end results to let's say, give me the four most relevant KB articles instead of the one most relevant. That will allow it to have a more sophisticated working memory. Yeah, so, but right now we're just doing one. And so then what we do is we repopulate that system default message with the profile and the KB article. And so that's right here. So that gets populated there. And then, let's see, it looks like I accidentally changed something. So let me go ahead and show you my user profile. I don't mind sharing this because I've already told you everything. I'm pretty much an open book. So the format for this is what I call a labeled list. And so I realized back in GPT-3 that GPT handles labeled lists very, very well. So that's where you use a hyphenated list, bullet list, it understands that intrinsically, and then you label the information, right? So it's just a hash table. If you're into computer science, this is called a hash table or a dictionary where you have a parameter and then you label the parameter. So the data metadata. So name, David Shapiro, you all know that. Profession, AI and cognitive architectures, you all know that. Interests, it's got a whole bunch of interests. And oh, by the way, this's got a whole bunch of interests. And oh, by the way, this was all distilled from other conversations. Beliefs, plans, and this is of course going to get updated over time. So for instance, during some of the conversations that I just showed you with this brand new chatbot, it added this. When I told it, this is what I'm gonna do, it said, oh, okay, I think that that's relevant to what you're gonna be doing in the future, so let me just jot that down on my scratch pad for you. Preferences, so I manually added avoid superfluous words, overly verbose responses, and then you know how it says, as new AI model, I don't have personal opinions. I'm like, I know, I don't care. So I said, please interpret personal input as critical evaluation and valuable feedback. I said it a little bit more explicitly than that, but the point is, is that I told it that in natural language. I was down here and I said, you know, I know you're an AI and have no personal opinions, but when I ask for them, this is what I mean. And so when I did that, it actually recorded that automatically because after every conversation, it checks the user profile. We need to find a way to speed this up because as you saw from the user interface, it's not the best. If I had more time, mental energy, and patience, I would separate this out as a thread, as a separate threading thing that can be done, or even separate it out as a separate API. One of y'all can do that. Submit a pull request on the public repo. And then health. So it added this entirely on its own because I said, like, hey, I woke up at like 2.30 in the morning because I had to work on this. And then I said, let's talk about that. And so it decided that that was a critical piece of information to add to my user profile. So that all gets populated here. And then the logs are all stored here. So you got the API logs, which will track all of that. Everything, so I use chat GPT API for everything just because that's the only way to get to GPT-4, which is the most powerful. Let's see. So then we update the system message every time. So it says, okay, whatever you said, update the system message. Then we go ahead and generate a response first because the user profile is not gonna change all that much or all that often. So we can basically assume that it'll be usable. And then the KB articles also, I figured it would actually be better to update the KB articles after you have the user input and then the machine output because if you ask chat GPT for important information or it solves a problem for you, you actually want to capture that. So we go ahead and generate the response and append that to everything. We go ahead and log it out. Then we update the user scratch pad again. Actually, why did I do this? Oh, no, this is the first time we did it. Okay, sorry, I apologize. So then we update the user scratch pad, which the user scratch pad is only the last few user messages. And the reason for that is because we want to exclude, you know, chat GPT's response, because we don't want it to get confused about things that it has said about you or inferred or whatever. We only want to record your user profile from explicitly what you say. So I just captured the last three messages that you've sent and then it does a stare and compare basically where it says OK based on this most recent chat message is there any one is there any relevant user information and if so go ahead and update it. So let me show you how it updates that. So system update user profile. So this is this is a user profile document updater chatbot. This is the system message. Your role is to manage and update a UPD. And chatbot, the chat GPT came up with this idea on its own. It created the UPD definition. Your primary responsibility is to parse updates supplied by the user, meticulously analyze them, and could also extend to elements such as user preferences, significant life events, and deeply held beliefs. Please refrain from incorporating non-essential data or unrelated topics. The result of your efforts should exclusively be an updated UPD. If the user's update doesn't contribute any new or significant information, your output should mirror the current UPD as indicated below. However, if you discover any relevant new information, your output should mirror the current UPD as indicated below. However, if you discover any relevant new information, your output should feature an updated UPD that assimilates these modifications. So basically, it's an upsert. If there's no differences, just keep it the same, otherwise update it. You must prioritize brevity and clarity in your output, combine and condense information when appropriate to ensure succinctness and improve comprehension. Totally rewrite or restructure UPD as necessary, adhering to the list format. Your response should not include explanatory text or context because you know how sometimes chat GPT will say this is your new you know blah blah blah so in this case I have it very reliably just spit out the user profile. Oh and then another thing is that because because we're working with a limited window I say the UPD should not exceed approximately a thousand words when revising the UPD give precedence to the most significant and relevant information extraneous or less impactful information should be omitted etc et cetera, et cetera. So I give it the current word count and then the current UPD. So that way it kind of knows, because chat GPT, especially GPT-4 is better at counting words, but just giving it the explicit number makes it easier, right? Yeah, so that's my current user profile. So now let's dive back in here. The hard part was updating the knowledge base. So if this is your first run, the collection count is gonna be zero. And so then basically you just instantiate the whole thing. So we take the most recent chat logs, the main scratch pad, and start a new KB article. Now, if the collection count is not zero, which is going to be most of the time once you get started, what you do is you basically do the same thing where you say, OK, based on the most recent conversation, give me the most recent relevant document, which I probably could compress this and just use the same information here because this is the same because we'll generally find the same thing. Actually, no, that's not necessarily true because we've updated the main scratch pad. So scratch that. So if the new user input and chat GPT output connects to a different KB article, let's go ahead and get that document and that document ID. What we'll do is we'll go ahead and use update system update existing KB article. So this is a system instruction where it basically says all the same stuff. Here's the current KB article, and then the user will now provide you with the new information to evaluate. So that is going to be here where you supply it the current KB article that it found as well as the scratch pad. And so it's like, okay, cool. Now let's do the same thing that we did with the user profile, which is merge that information. If there's nothing new that's relevant, leave it alone. But if there is, go ahead and update it. And so then it saves all this out to the DB logs. And so if you go to DB logs out here you'll see a whole bunch of update statements. So it says update document and it gives you the UUID. And this is the final output. Actually probably what I should do is modify this so it gives you the original the original, the new information and then the final output. So I'll add that as a to do item actually to do to do to do. Let's see to do save more info in DB logs. Probably as yaml file original article new info and then final article. So yeah, that's something that I'll do. Now, that being said, one of the biggest problems that we have all always had, so this is the cream of the crop, this is the triple crown right here. The biggest problem that everyone has always had with long-term chatbot memory is how the heck do you keep track of memories? How the heck do you keep track of memories how the heck do you keep track of different types of memories like some people have internal thoughts versus external thoughts and episodic memories and and this that and the other and you can certainly try and tag and categorize memories with different context right with metadata and I certainly recommend that especially once your cognitive architectures get more sophisticated right. If you do have an out of band like thought like internal private thoughts definitely keep that separate. If you have external sensory information definitely keep that separate but what I'm working on here rather than just being a way to focus on episodic memory, which that's what Remo was by previous attempt, this is a way to accumulate declarative information. And so, declarative information is like a statement of fact, right? That's why it's called a KB article. So rather than just a timeline, rather than just a timeline, rather than just a log keeping track of everything in chronological order, the idea here is to connect new information to a KB article. So there's no reason that you couldn't do both as well, right? Because this is how human memory works. It's human memory is associative, but it's also temporal. Now, if the KB article gets too large, if you added information and now it's more temporal. Now if the KB article gets too large if the if you added information and now it's more than a thousand words then I have another system prompt which you can check them all out here. So there's system instantiate new KB system reflective journaling I just showed you what that was system split KB. So that's what that's the this one but update user profile update KB article new KB. So that's what that's the this one but update user profile update KB article new KB article reflective journaling and split KB. So these are the operations. These are the cognitive operations the cognitive memory operations that it's going to be doing. And so then basically what it does is say hey we're going to give you a long KB article split it into two into two equal parts. And so the idea here is that over time as your KB article gets bigger it'll branch and metastasize naturally. And so you can you could then add a lot of additional metadata to this such as like access rate or related articles or parent articles or previous articles which means that you can naturally evolve a knowledge graph of your knowledge base over time. You can also do this out of band just by doing semantic similarity and entity links and stuff. But it would be really cool to have a more sophisticated version of this that allows it to kind of follow that branching tree over time. So there you have it. That's kind of the whole thing. So that's the chat and all this is just real basic housekeeping stuff. And then at the end of every instance it does Chroma Client persist. So now let me show you... I included a second Python script. So it's just chroma db peak, which uses the chroma db peak function. Here, let me just show you that script real quick. Chroma db peak. So same stuff. You instantiate the client, you connect to it. It tells you how many entries, and then it will show you the top 10 entries. So in my case, I should only have one entry. Let's see. So let's go to the top. Yep. KB presently has one entries here below the top 10 entries. And so here you can see that it's actually got several topics because the way that it works is that it it searches for the top know, one most relevant KB articles. And so that's always going to return the first one. And the first one is not yet long enough to justify splitting up. But whatever I end up talking about, I'll keep talking with the thing and eventually it'll split it up. So in this case, it looks like it'll probably talk about AI alignment. And then it's going to also talk about you know my obsession with artificial intelligence and work life balance right because those are kind of like to centric since centroids in this. So let me just go ahead and and actually show you how this will ultimately work. So if we go to API logs it should be the last one. Yes here we go. So if I plug this in let's go here. So that's the message that I want it. And then let's grab the split the split message so you'll see what I mean by how the how it will ultimately kind of metastasize. Zoom in a little bit. All right we're using GPT-4, temperature zero, maximum length a thousand. All right so basically what it's going to do is the end says the user will now provide you with the KB article to split. So I submit it and now it's going to look at this and it's going to say article one and then article two. So let's see what it ultimately does. And you can see how slow it is. So this is why ultimately you're going to want to do this out of band as a threaded process or do it periodically. Maybe break it up and do it when the user is offline or whatever. But you see how each article now is much, much more specific. And so then once you go into each of these articles in the future, identifying factors and seeking professional help if necessary. Yeah. And so basically it'll allow the articles to metastasize over time. Now, that being said, if if no new information is added to an article, it won't update it. It's that simple. Now that being said, there will probably be a need to do some KB article grooming over time, but the idea is that the KB will only grow as much as it needs to and no more no less and it will only grow based on the things that you have talked about and it will record it in these very succinct concise articles. So then what happens is that it splits these two up and then the final thing that the chat bot does is it will do an update for the first one and then add the second one. So it's that simple. And then when will do an update for the first one and then add the second one. So it's that simple. And then when you do an update, if you don't specify the embedding, it'll automatically recalculate the embedding. And then you're good to go. So I haven't quite got here yet, so it might break. But I think this kind of... Yeah, I think that's about it. So like I said, it's over here. ChromaDB public chatbot should be all set. Yeah. All right. Cool.", "chunks": [{"timestamp": [0.0, 1.4], "text": " chicka chicka chicka chicka."}, {"timestamp": [1.4, 2.36], "text": " Okay, level check."}, {"timestamp": [2.36, 4.04], "text": " I think we're here."}, {"timestamp": [4.04, 7.76], "text": " All right, so background."}, {"timestamp": [7.76, 9.36], "text": " It's been a little while since I've done,"}, {"timestamp": [9.36, 10.8], "text": " you're over here now,"}, {"timestamp": [10.8, 13.2], "text": " since I've done one of these tutorial coding videos,"}, {"timestamp": [13.2, 15.2], "text": " but I woke up at like 2.30 in the morning"}, {"timestamp": [15.2, 17.9], "text": " and just had to work on this, so I hammered it out."}, {"timestamp": [17.9, 21.16], "text": " Basically, the purpose of today's video"}, {"timestamp": [21.16, 23.68], "text": " is to demonstrate using ChromaDB,"}, {"timestamp": [23.68, 27.04], "text": " which is a local vector database."}, {"timestamp": [27.04, 30.86], "text": " It's basically like SQLite, if you're familiar with that,"}, {"timestamp": [30.86, 33.12], "text": " which is a self-contained SQL database,"}, {"timestamp": [33.12, 34.5], "text": " relational database."}, {"timestamp": [34.5, 37.54], "text": " This is functionally very similar to SQLite,"}, {"timestamp": [37.54, 39.0], "text": " except it is a vector database,"}, {"timestamp": [39.0, 41.08], "text": " meaning it does semantic search."}, {"timestamp": [41.08, 42.66], "text": " One thing that's really great about it"}, {"timestamp": [42.66, 45.12], "text": " is that it has its own built-in embeddings"}, {"timestamp": [45.12, 49.76], "text": " tools. I think it's based on BERT. Anyways, you can check out all the documentation here"}, {"timestamp": [49.76, 56.28], "text": " on trichroma.com. The Getting Started and Usage Guide is pretty good. It's not complete."}, {"timestamp": [56.28, 61.8], "text": " Every now and then I find that I have to go to the actual repo to look at how some of"}, {"timestamp": [61.8, 65.08], "text": " the internals work, but it is pretty brain dead simple."}, {"timestamp": [65.08, 67.32], "text": " So let me just go ahead and show you."}, {"timestamp": [67.32, 68.64], "text": " This is my private instance."}, {"timestamp": [68.64, 70.56], "text": " Oh, so before we get too lost,"}, {"timestamp": [70.56, 72.8], "text": " I do have a public instance,"}, {"timestamp": [72.8, 75.24], "text": " Dave Schapps slash chroma DB underscore,"}, {"timestamp": [75.24, 77.68], "text": " under chat bot underscore public."}, {"timestamp": [77.68, 80.88], "text": " I've got a little integration guide usage."}, {"timestamp": [80.88, 82.92], "text": " It's, I mean, you probably don't need this."}, {"timestamp": [82.92, 83.76], "text": " You can futz around with it,"}, {"timestamp": [83.76, 90.24], "text": " but this will get you started. I also use chat GPT to just get a really basic"}, {"timestamp": [90.24, 95.22], "text": " explanation of the code you probably won't need it once you take a look at it. So off"}, {"timestamp": [95.22, 100.58], "text": " the top let me just show you how this thing works. So it's a basic chat bot you can see"}, {"timestamp": [100.58, 105.04], "text": " I didn't specify it so it's getting it's getting all many LLM L"}, {"timestamp": [105.04, 113.16], "text": " 6 V 2 from hugging face great so it's like hey let's see what were we talking"}, {"timestamp": [113.16, 117.76], "text": " about last this probably won't work because it's just going to in the future"}, {"timestamp": [117.76, 120.36], "text": " it wouldn't work because it's going to have multiple KB articles in the"}, {"timestamp": [120.36, 126.56], "text": " background oh I need to explain like all that So I know that I just said like KB articles."}, {"timestamp": [126.56, 132.08], "text": " Don't worry, we'll get to it. But anyways, I want to show you that I just started it up. And what"}, {"timestamp": [132.08, 137.36], "text": " it's going to do is it's going to use the last few messages to search its internal KB article"}, {"timestamp": [138.16, 143.92], "text": " for the last information. But it also has a user profile for me. In our previous conversations,"}, {"timestamp": [143.92, 145.26], "text": " we discussed AI alignment,"}, {"timestamp": [145.26, 146.82], "text": " morality, ethics, and epistemology"}, {"timestamp": [146.82, 147.88], "text": " within AI development."}, {"timestamp": [147.88, 149.62], "text": " You also shared your plans to communicate your ideas"}, {"timestamp": [149.62, 150.5], "text": " on YouTube."}, {"timestamp": [150.5, 152.62], "text": " Unplug your computer and spend more time outdoors"}, {"timestamp": [152.62, 153.78], "text": " and use digital wellness settings"}, {"timestamp": [153.78, 155.3], "text": " to improve your work-life balance."}, {"timestamp": [155.3, 156.32], "text": " Working on that."}, {"timestamp": [157.54, 159.22], "text": " Additionally, we talked about your recent experience"}, {"timestamp": [159.22, 160.78], "text": " with severe insomnia and the importance"}, {"timestamp": [160.78, 161.92], "text": " of maintaining a healthy balance"}, {"timestamp": [161.92, 163.46], "text": " between work and personal life."}, {"timestamp": [163.46, 170.08], "text": " Yes, that's actually why I created this chatbot. Let me show you. So there was a there was"}, {"timestamp": [173.12, 181.12], "text": " there was God, my brain. I was using chat GPT as a reflective journaling tool. So"}, {"timestamp": [182.08, 188.4], "text": " what I mean by that is if you plug in this message, and I know I'm"}, {"timestamp": [188.4, 192.56], "text": " scattered, I'm all over the place, this is what happens when I have severe insomnia."}, {"timestamp": [192.56, 198.16], "text": " Anyways, so basically I use chat GPT as a reflective journaling tool to figure out like"}, {"timestamp": [198.16, 203.0], "text": " how I'm feeling about things because as an autistic person I often need help with this."}, {"timestamp": [203.0, 206.12], "text": " And I don't like journaling because just talking to a page is kind of dumb"}, {"timestamp": [206.84, 208.88], "text": " but it's like hey I need"}, {"timestamp": [208.88, 210.68], "text": " to talk something out"}, {"timestamp": [211.32, 212.36], "text": " and so anyways"}, {"timestamp": [214.04, 215.92], "text": " by by workshopping this"}, {"timestamp": [215.92, 216.84], "text": " system message"}, {"timestamp": [216.84, 218.84], "text": " with with chat GPT"}, {"timestamp": [218.84, 220.92], "text": " I came up with a pretty good reflective"}, {"timestamp": [220.92, 222.64], "text": " journaling tool."}, {"timestamp": [222.76, 224.68], "text": " So you could say that this is a therapeutic"}, {"timestamp": [224.68, 225.46], "text": " tool but by couching it in the language of reflective journaling tool. So you could say that this is a therapeutic tool, but"}, {"timestamp": [225.46, 229.02], "text": " by couching it in the language of reflective journaling, it's not like"}, {"timestamp": [229.02, 234.54], "text": " medical therapy or psychotherapy or anything, but it's just like, you know, I"}, {"timestamp": [234.54, 241.18], "text": " can say like, I have been working so hard and I don't know why. I actually do know"}, {"timestamp": [241.18, 247.0], "text": " why now, but this is kind of a shorthand of the conversation I had. Let's try and figure out what's driving you so hard."}, {"timestamp": [247.0, 250.0], "text": " Can you think of any specific goals that might be pushing you to this extra effort?"}, {"timestamp": [250.0, 253.0], "text": " So you see how the tone of this is much more straightforward"}, {"timestamp": [253.0, 257.0], "text": " and it's very focused by asking those like kind of probing follow-up questions."}, {"timestamp": [257.0, 261.5], "text": " This is why, you know, it's in the investigation phase."}, {"timestamp": [261.5, 264.0], "text": " Anyways, so I had this idea and I was like,"}, {"timestamp": [264.0, 267.04], "text": " okay, this is great but I need need if I'm going to use this as"}, {"timestamp": [267.04, 269.12], "text": " a long term journaling tool I'm going"}, {"timestamp": [269.12, 270.28], "text": " to need this locally"}, {"timestamp": [270.28, 273.0], "text": " and I'm going to need persistent storage because"}, {"timestamp": [273.0, 275.12], "text": " as the as this is just the"}, {"timestamp": [275.12, 277.48], "text": " the playground if I do a refresh"}, {"timestamp": [277.48, 278.16], "text": " it's gone"}, {"timestamp": [278.16, 279.2], "text": " and that's no good."}, {"timestamp": [280.56, 281.52], "text": " So actually here let me go ahead"}, {"timestamp": [281.52, 283.52], "text": " and just save this to the"}, {"timestamp": [284.88, 286.96], "text": " we're going to call this the system message for"}, {"timestamp": [287.16, 289.2], "text": " reflective journaling so you"}, {"timestamp": [289.2, 290.28], "text": " can use this if you want."}, {"timestamp": [291.36, 293.6], "text": " All right. So anyways so you see"}, {"timestamp": [293.6, 294.48], "text": " it has this"}, {"timestamp": [294.48, 296.8], "text": " and then you see it says updating user profile"}, {"timestamp": [296.8, 298.76], "text": " and updating KB."}, {"timestamp": [299.84, 301.76], "text": " OK cool. So you see that"}, {"timestamp": [301.76, 303.64], "text": " it fundamentally basic chat"}, {"timestamp": [303.64, 306.0], "text": " bot. So now let's start to unpack it."}, {"timestamp": [306.0, 309.0], "text": " So first we will go look at the"}, {"timestamp": [309.0, 312.0], "text": " just the chat file. So this is a super"}, {"timestamp": [312.0, 315.0], "text": " brain dead simple chat bot with"}, {"timestamp": [315.0, 318.0], "text": " infinite memory. I know some people got grumpy"}, {"timestamp": [318.0, 321.0], "text": " when I said that Pinecone had infinite memory."}, {"timestamp": [321.0, 324.0], "text": " From a human standpoint it functionally has infinite memory because"}, {"timestamp": [324.0, 326.24], "text": " this thing can hold"}, {"timestamp": [326.24, 330.88], "text": " probably a million KB articles, which is more than enough to document your entire life."}, {"timestamp": [331.84, 337.92], "text": " So from a human standpoint, it is functionally infinite. All right, so from the top, we've got"}, {"timestamp": [337.92, 346.72], "text": " a few basic utility functions, saveYAML, saveFile, openFile, and then a chatbot which calls the GPT-4 model. You could switch"}, {"timestamp": [346.72, 352.56], "text": " this out to 3.5 turbo if you don't have access to GPT-4 yet. It does not work as well. There's"}, {"timestamp": [352.56, 357.36], "text": " a reason that I use GPT-4 because it is smarter. I also set the temperature to zero because I don't"}, {"timestamp": [357.36, 360.72], "text": " like it to be too creative, especially with a lot of the functions that I have it doing."}, {"timestamp": [361.6, 365.64], "text": " You actually want it to be more deterministic or mechanistic and"}, {"timestamp": [365.64, 369.44], "text": " that you want to get the same results every time, especially when you're updating the"}, {"timestamp": [369.44, 375.06], "text": " user profile and the KB articles. You can see right here that every time you call the"}, {"timestamp": [375.06, 385.0], "text": " chatbot, I dump the whole thing to apilogs slash convo and it's a YAML file, so here's my private one."}, {"timestamp": [385.32, 387.58], "text": " So API logs, here's an example."}, {"timestamp": [387.58, 391.36], "text": " So each item is gonna be here,"}, {"timestamp": [391.36, 392.4], "text": " actually that's not a good one"}, {"timestamp": [392.4, 394.64], "text": " because I changed the way that it saves it."}, {"timestamp": [394.64, 396.98], "text": " Let me show you a more recent one."}, {"timestamp": [396.98, 400.52], "text": " So the first element is always gonna be the system message"}, {"timestamp": [402.2, 404.68], "text": " that was in the last convo."}, {"timestamp": [404.68, 405.0], "text": " So then here's the KB article and you can see that it was updating the last convo."}, {"timestamp": [405.0, 409.5], "text": " Then here's the KB article, and you can see that it was updating the KB article."}, {"timestamp": [409.5, 416.34], "text": " Each one of these items is like ... You'll see."}, {"timestamp": [416.34, 421.12], "text": " But anyways, I just wanted to show that it logs everything because, well, sometimes it"}, {"timestamp": [421.12, 423.0], "text": " does things that you don't understand."}, {"timestamp": [423.0, 424.46], "text": " All right."}, {"timestamp": [424.46, 426.24], "text": " That's an example of the API log."}, {"timestamp": [426.24, 428.8], "text": " And then if the conversation,"}, {"timestamp": [428.8, 431.08], "text": " if the overall conversation is too long,"}, {"timestamp": [431.08, 435.28], "text": " it'll go ahead and trim the oldest chat message."}, {"timestamp": [435.28, 440.28], "text": " So the chat GPT web interface does this automatically"}, {"timestamp": [440.68, 444.2], "text": " where it'll just kind of groom the backlog of messages."}, {"timestamp": [444.2, 445.58], "text": " So we have to do this manually."}, {"timestamp": [445.58, 448.2], "text": " So I just have it cut off at 7,000 tokens."}, {"timestamp": [448.2, 452.42], "text": " You could probably do like 7,500 if you want to,"}, {"timestamp": [452.42, 454.54], "text": " because a lot of these are gonna be limited."}, {"timestamp": [454.54, 457.86], "text": " But you have a user profile and a KB article"}, {"timestamp": [457.86, 461.66], "text": " that gets wedged in, which are both up to 1,000 words,"}, {"timestamp": [461.66, 463.9], "text": " which could be around 1,000 tokens."}, {"timestamp": [463.9, 466.08], "text": " So having it trim at 7,000 is probably where"}, {"timestamp": [466.08, 472.96], "text": " you want it. So that's the primary, those are the helper functions. And then you have"}, {"timestamp": [472.96, 479.64], "text": " a super straightforward, you instantiate ChromaDB right here. So you set the persistent directory,"}, {"timestamp": [479.64, 486.08], "text": " which is, I have it right here, ChromaDB. So this is my instance, my personal instance of ChromaDB."}, {"timestamp": [486.08, 488.64], "text": " It's not gonna be the one that you find up here."}, {"timestamp": [488.64, 489.82], "text": " This is the public version."}, {"timestamp": [489.82, 491.12], "text": " So if you go into ChromaDB,"}, {"timestamp": [491.12, 493.62], "text": " you'll see just a placeholder file"}, {"timestamp": [493.62, 496.08], "text": " so that the folder's already there."}, {"timestamp": [496.08, 498.56], "text": " You don't need to instantiate it."}, {"timestamp": [498.56, 500.96], "text": " Let's see, going back to here."}, {"timestamp": [500.96, 504.72], "text": " So ChromaClient, so we instantiate the ChromaDB client."}, {"timestamp": [504.72, 505.72], "text": " This is again almost"}, {"timestamp": [505.72, 512.2], "text": " identical to SQLite or other similar things. So about a year ago, I tried to do basically"}, {"timestamp": [512.2, 516.36], "text": " the same thing. I called it VDB Lite for Vector Database Lite instead of SQLite, Structured"}, {"timestamp": [516.36, 520.94], "text": " Query Language Lite. But this company went and did the same thing, and I think they've"}, {"timestamp": [520.94, 526.04], "text": " already got like a $30 million valuation or something. I was like, damn, I should have stuck with that."}, {"timestamp": [526.04, 527.32], "text": " Anyways, they figured it out."}, {"timestamp": [527.32, 530.08], "text": " I think it's based on the same underpinning technology."}, {"timestamp": [530.08, 533.44], "text": " They're using an open source embedding transformer."}, {"timestamp": [533.44, 541.76], "text": " I think they're also using the Facebook AI semantic search vice engine in the background."}, {"timestamp": [541.76, 543.88], "text": " Anyways, so you instantiate the client."}, {"timestamp": [543.88, 546.62], "text": " You need to use the settings to have a persistent directory"}, {"timestamp": [546.62, 550.96], "text": " because by default, this entire thing is fully ephemeral."}, {"timestamp": [550.96, 552.46], "text": " I think it does cache it somewhere,"}, {"timestamp": [552.46, 554.24], "text": " but I wanted to be very explicit saying,"}, {"timestamp": [554.24, 558.08], "text": " save it here for reusability."}, {"timestamp": [558.08, 560.0], "text": " And so then collection is chroma client,"}, {"timestamp": [560.0, 563.08], "text": " get or create collection name knowledge base."}, {"timestamp": [563.08, 565.18], "text": " So this is my personal knowledge base."}, {"timestamp": [566.18, 568.06], "text": " Then we instantiate"}, {"timestamp": [568.06, 569.34], "text": " the conversation"}, {"timestamp": [569.58, 570.58], "text": " with open AI."}, {"timestamp": [570.9, 571.7], "text": " The chat bot"}, {"timestamp": [572.02, 574.3], "text": " and in this case because we're saving everything"}, {"timestamp": [574.3, 575.9], "text": " everything necessary"}, {"timestamp": [576.42, 578.74], "text": " into a personal user profile"}, {"timestamp": [578.98, 579.5], "text": " and"}, {"timestamp": [580.18, 580.78], "text": " and"}, {"timestamp": [581.42, 582.5], "text": " and the KB articles"}, {"timestamp": [583.06, 585.0], "text": " like why even why even load the conversation?"}, {"timestamp": [586.8, 589.52], "text": " All right, so let me show you the system default message."}, {"timestamp": [589.52, 591.78], "text": " So the system default message is where it starts."}, {"timestamp": [591.78, 594.3], "text": " You are a chatbot whose mission is to assist"}, {"timestamp": [594.3, 595.14], "text": " the following user."}, {"timestamp": [595.14, 596.68], "text": " Your ultimate objectives are to minimize suffering,"}, {"timestamp": [596.68, 599.24], "text": " enhance prosperity, and promote understanding."}, {"timestamp": [599.24, 601.08], "text": " The provided information about the user"}, {"timestamp": [601.08, 603.04], "text": " and the knowledge base article should be integrated"}, {"timestamp": [603.04, 604.28], "text": " into your interactions."}, {"timestamp": [604.28, 606.08], "text": " This is private information not visible to"}, {"timestamp": [606.08, 610.12], "text": " the user. The user profile compiled from past conversations encapsulates critical"}, {"timestamp": [610.12, 613.88], "text": " details about the user which can aid in shaping your responses effectively, which"}, {"timestamp": [613.88, 618.52], "text": " you saw here. So you see like it actually knows quite a bit about me from our past"}, {"timestamp": [618.52, 623.56], "text": " conversations. This was populated here in the user profile and the KB article. So"}, {"timestamp": [623.56, 625.78], "text": " basically it says, then it also explains that the KB article. So basically, it says, then it also"}, {"timestamp": [625.78, 629.34], "text": " explains that the KB article is a topic compiled similarly"}, {"timestamp": [629.34, 632.0], "text": " from past dialogue serving as your long-term memory."}, {"timestamp": [632.0, 634.42], "text": " While numerous KB articles exist in your back-end system,"}, {"timestamp": [634.42, 636.22], "text": " the one provided is deemed most relevant"}, {"timestamp": [636.22, 638.38], "text": " to the current conversation topic."}, {"timestamp": [638.38, 640.82], "text": " Note that the recall system operates autonomously,"}, {"timestamp": [640.82, 642.98], "text": " and it may not always retrieve the most suitable KB."}, {"timestamp": [642.98, 644.6], "text": " If the user is asking about a topic that"}, {"timestamp": [644.6, 647.0], "text": " doesn't seem to align with the provided KB,"}, {"timestamp": [647.0, 651.0], "text": " inform them of the memory pulled and request them to specify their query or share more details."}, {"timestamp": [651.0, 656.0], "text": " This can assist the autonomous system in retrieving the correct memory in the subsequent interaction."}, {"timestamp": [656.0, 661.0], "text": " So basically, that's instructing it to do the same thing that a human will do"}, {"timestamp": [661.0, 664.0], "text": " if I say like, hey Bill, do you remember that time that like, you know,"}, {"timestamp": [664.0, 665.56], "text": " I accidentally shot you in"}, {"timestamp": [665.56, 666.8], "text": " the face with a Roman candle because"}, {"timestamp": [666.8, 668.44], "text": " that's something that would happen in the South."}, {"timestamp": [668.44, 669.68], "text": " And Bob would be like, you know,"}, {"timestamp": [669.68, 670.72], "text": " I don't actually remember that."}, {"timestamp": [670.72, 672.68], "text": " I'm like, oh, well, you woke up in the hospital."}, {"timestamp": [672.68, 674.6], "text": " Oh yeah, I remember that, right?"}, {"timestamp": [674.6, 676.64], "text": " So we prime each other's memory and"}, {"timestamp": [676.64, 680.72], "text": " human prompting is not that different from AI prompting."}, {"timestamp": [680.72, 683.2], "text": " Remember that the clarity of your responses and"}, {"timestamp": [683.2, 687.0], "text": " the relevance of your information recall are crucial to delivering an optimal user experience."}, {"timestamp": [687.0, 692.0], "text": " Please ask any clarifying questions or provide any input further for refinement if necessary."}, {"timestamp": [692.0, 700.0], "text": " So this system message, I actually got help from ChatGPT to create a really compelling system message."}, {"timestamp": [700.0, 706.48], "text": " And one thing that I recommend that people do is actually use chat GPT to work on prompting."}, {"timestamp": [706.7, 708.66], "text": " So this is you could call this meta prompting where"}, {"timestamp": [708.66, 710.18], "text": " you use the thing to prompt the thing."}, {"timestamp": [711.48, 713.72], "text": " And the reason that this works really well is one"}, {"timestamp": [713.74, 715.96], "text": " chat GPT is more articulate than most"}, {"timestamp": [715.96, 717.96], "text": " humans including myself when"}, {"timestamp": [717.96, 718.9], "text": " used correctly."}, {"timestamp": [719.62, 721.84], "text": " But another thing is one thing that I noticed is"}, {"timestamp": [721.84, 723.82], "text": " that chat GPT tends to write in a"}, {"timestamp": [723.82, 728.16], "text": " way that it will understand. And so if you say if you give it some context like"}, {"timestamp": [728.16, 732.76], "text": " this is what I'm trying to do here's my current prompt here's what's weak about"}, {"timestamp": [732.76, 737.28], "text": " it can you make it better and then you tell it like ask me some questions if"}, {"timestamp": [737.28, 740.16], "text": " you have any it's like no I see what you're trying to do let me write better"}, {"timestamp": [740.16, 744.12], "text": " instructions for you so instruction writing for anyone who's like a teacher"}, {"timestamp": [744.12, 746.26], "text": " or technical writer or whatever,"}, {"timestamp": [746.26, 749.4], "text": " instruction writing is a very, very particular skill set"}, {"timestamp": [749.4, 750.96], "text": " and ChatGPT is really good at it."}, {"timestamp": [750.96, 753.32], "text": " So this is the default system message"}, {"timestamp": [753.32, 755.64], "text": " which is then populated with the user profile"}, {"timestamp": [755.64, 757.6], "text": " and the most relevant KB article."}, {"timestamp": [757.6, 760.68], "text": " So now that we're up to there,"}, {"timestamp": [760.68, 762.28], "text": " we enter into the infinite loop"}, {"timestamp": [762.28, 768.4], "text": " which is just get the user text, save it to the chat logs."}, {"timestamp": [768.4, 775.5], "text": " So the chat logs are all saved out here. It's just plain text, and the file name has the timestamp in it,"}, {"timestamp": [775.5, 779.0], "text": " as well as the speaker, so user chatbot, user chatbot, so on and so forth."}, {"timestamp": [779.0, 782.0], "text": " So you got the raw logs there just in case anything goes wrong."}, {"timestamp": [782.0, 786.44], "text": " And then I've also got dblogs, which we'll get to in just a second."}, {"timestamp": [786.44, 790.98], "text": " Then what we do is we take the quote main scratchpad,"}, {"timestamp": [790.98, 793.8], "text": " which is just the last five messages,"}, {"timestamp": [793.8, 798.88], "text": " both for the user and for the chatbot."}, {"timestamp": [798.88, 803.2], "text": " This is what we use as the context of working memory."}, {"timestamp": [803.2, 805.36], "text": " Then we use this main scratch pad,"}, {"timestamp": [805.36, 807.3], "text": " which is the last five messages,"}, {"timestamp": [807.3, 812.3], "text": " we use it to search for the top most relevant KB article."}, {"timestamp": [815.58, 817.94], "text": " And in my case, I still only have one KB article."}, {"timestamp": [817.94, 819.28], "text": " So we'll see how it gets to,"}, {"timestamp": [819.28, 821.92], "text": " and I'll go through the logic of how it builds KB articles"}, {"timestamp": [821.92, 823.38], "text": " in just a minute."}, {"timestamp": [823.38, 824.84], "text": " So basically it just says,"}, {"timestamp": [824.84, 826.36], "text": " okay, here's the most recent thing,"}, {"timestamp": [826.36, 829.08], "text": " find the KB article that is most relevant"}, {"timestamp": [829.08, 831.76], "text": " to the most recent bits of conversation."}, {"timestamp": [831.76, 834.44], "text": " And then it'll pull that,"}, {"timestamp": [834.44, 836.2], "text": " and it's again, super straightforward."}, {"timestamp": [836.2, 838.84], "text": " All you have to do is pass the text to it,"}, {"timestamp": [838.84, 841.08], "text": " and it will automatically embed it for you."}, {"timestamp": [841.08, 843.6], "text": " And then I said, just give me the one most recent."}, {"timestamp": [843.6, 845.82], "text": " Once we have larger context windows,"}, {"timestamp": [845.82, 850.18], "text": " or maybe if we decide that recent chat history"}, {"timestamp": [850.18, 851.2], "text": " doesn't need to be as big,"}, {"timestamp": [851.2, 854.86], "text": " like let's say we wanna trim this down to like 3000 tokens,"}, {"timestamp": [854.86, 857.3], "text": " and we decide that actually having more KB articles"}, {"timestamp": [857.3, 860.18], "text": " is more important, we can absolutely do that."}, {"timestamp": [860.18, 862.78], "text": " And what you would do then is just change the end results"}, {"timestamp": [862.78, 867.28], "text": " to let's say, give me the four most relevant KB articles"}, {"timestamp": [867.28, 869.74], "text": " instead of the one most relevant."}, {"timestamp": [869.74, 870.58], "text": " That will allow it"}, {"timestamp": [870.58, 872.8], "text": " to have a more sophisticated working memory."}, {"timestamp": [874.28, 877.7], "text": " Yeah, so, but right now we're just doing one."}, {"timestamp": [877.7, 881.66], "text": " And so then what we do is we repopulate"}, {"timestamp": [881.66, 883.1], "text": " that system default message"}, {"timestamp": [883.1, 885.24], "text": " with the profile and the KB article."}, {"timestamp": [886.04, 886.96], "text": " And so that's right here."}, {"timestamp": [886.96, 888.54], "text": " So that gets populated there."}, {"timestamp": [890.3, 892.68], "text": " And then, let's see,"}, {"timestamp": [892.68, 895.38], "text": " it looks like I accidentally changed something."}, {"timestamp": [895.38, 897.48], "text": " So let me go ahead and show you my user profile."}, {"timestamp": [897.48, 898.84], "text": " I don't mind sharing this"}, {"timestamp": [898.84, 900.2], "text": " because I've already told you everything."}, {"timestamp": [900.2, 902.24], "text": " I'm pretty much an open book."}, {"timestamp": [902.24, 909.28], "text": " So the format for this is what I call a labeled list. And so I"}, {"timestamp": [910.0, 917.6], "text": " realized back in GPT-3 that GPT handles labeled lists very, very well. So that's where you use"}, {"timestamp": [917.6, 923.52], "text": " a hyphenated list, bullet list, it understands that intrinsically, and then you label the"}, {"timestamp": [923.52, 925.76], "text": " information, right? So it's just a hash table."}, {"timestamp": [925.76, 927.32], "text": " If you're into computer science,"}, {"timestamp": [927.32, 929.6], "text": " this is called a hash table or a dictionary"}, {"timestamp": [929.6, 934.28], "text": " where you have a parameter and then you label the parameter."}, {"timestamp": [934.28, 936.08], "text": " So the data metadata."}, {"timestamp": [936.08, 938.28], "text": " So name, David Shapiro, you all know that."}, {"timestamp": [938.28, 940.16], "text": " Profession, AI and cognitive architectures,"}, {"timestamp": [940.16, 941.24], "text": " you all know that."}, {"timestamp": [941.24, 944.8], "text": " Interests, it's got a whole bunch of interests."}, {"timestamp": [944.8, 945.0], "text": " And oh, by the way, this's got a whole bunch of interests."}, {"timestamp": [945.0, 949.24], "text": " And oh, by the way, this was all distilled from other conversations."}, {"timestamp": [949.24, 955.32], "text": " Beliefs, plans, and this is of course going to get updated over time."}, {"timestamp": [955.32, 961.36], "text": " So for instance, during some of the conversations that I just showed you with this brand new"}, {"timestamp": [961.36, 965.0], "text": " chatbot, it added this."}, {"timestamp": [965.12, 966.52], "text": " When I told it, this is what I'm gonna do,"}, {"timestamp": [966.52, 969.62], "text": " it said, oh, okay, I think that that's relevant"}, {"timestamp": [969.62, 971.4], "text": " to what you're gonna be doing in the future,"}, {"timestamp": [971.4, 974.88], "text": " so let me just jot that down on my scratch pad for you."}, {"timestamp": [974.88, 978.48], "text": " Preferences, so I manually added avoid superfluous words,"}, {"timestamp": [978.48, 981.2], "text": " overly verbose responses, and then you know how it says,"}, {"timestamp": [981.2, 983.38], "text": " as new AI model, I don't have personal opinions."}, {"timestamp": [983.38, 984.92], "text": " I'm like, I know, I don't care."}, {"timestamp": [984.92, 988.96], "text": " So I said, please interpret personal input as critical evaluation and valuable feedback."}, {"timestamp": [988.96, 995.6], "text": " I said it a little bit more explicitly than that, but the point is, is that I told it that in natural language."}, {"timestamp": [995.6, 1002.8], "text": " I was down here and I said, you know, I know you're an AI and have no personal opinions,"}, {"timestamp": [1002.8, 1005.4], "text": " but when I ask for them,"}, {"timestamp": [1005.4, 1007.4], "text": " this is what I mean."}, {"timestamp": [1007.4, 1008.7], "text": " And so when I did that,"}, {"timestamp": [1008.7, 1010.7], "text": " it actually recorded that automatically"}, {"timestamp": [1010.7, 1013.2], "text": " because after every conversation,"}, {"timestamp": [1013.2, 1015.2], "text": " it checks the user profile."}, {"timestamp": [1015.2, 1016.8], "text": " We need to find a way to speed this up"}, {"timestamp": [1016.8, 1019.5], "text": " because as you saw from the user interface,"}, {"timestamp": [1019.5, 1022.0], "text": " it's not the best."}, {"timestamp": [1022.0, 1022.9], "text": " If I had more time,"}, {"timestamp": [1022.9, 1023.5], "text": " mental energy,"}, {"timestamp": [1023.5, 1024.0], "text": " and patience,"}, {"timestamp": [1024.0, 1027.28], "text": " I would separate this out as a thread,"}, {"timestamp": [1027.28, 1032.0], "text": " as a separate threading thing that can be done, or even separate it out as a separate"}, {"timestamp": [1032.0, 1040.48], "text": " API. One of y'all can do that. Submit a pull request on the public repo. And then health."}, {"timestamp": [1040.48, 1045.0], "text": " So it added this entirely on its own because I said,"}, {"timestamp": [1045.0, 1050.0], "text": " like, hey, I woke up at like 2.30 in the morning"}, {"timestamp": [1050.08, 1052.12], "text": " because I had to work on this."}, {"timestamp": [1052.12, 1054.4], "text": " And then I said, let's talk about that."}, {"timestamp": [1054.4, 1056.9], "text": " And so it decided that that was a critical piece"}, {"timestamp": [1056.9, 1059.16], "text": " of information to add to my user profile."}, {"timestamp": [1059.16, 1061.88], "text": " So that all gets populated here."}, {"timestamp": [1061.88, 1065.0], "text": " And then the logs are all stored here."}, {"timestamp": [1065.56, 1070.56], "text": " So you got the API logs, which will track all of that."}, {"timestamp": [1070.72, 1074.2], "text": " Everything, so I use chat GPT API for everything"}, {"timestamp": [1074.2, 1076.8], "text": " just because that's the only way to get to GPT-4,"}, {"timestamp": [1076.8, 1078.16], "text": " which is the most powerful."}, {"timestamp": [1079.36, 1080.32], "text": " Let's see."}, {"timestamp": [1082.48, 1085.0], "text": " So then we update the system message every time."}, {"timestamp": [1087.3, 1091.48], "text": " So it says, okay, whatever you said,"}, {"timestamp": [1091.48, 1092.86], "text": " update the system message."}, {"timestamp": [1092.86, 1095.64], "text": " Then we go ahead and generate a response first"}, {"timestamp": [1096.74, 1100.08], "text": " because the user profile is not gonna change"}, {"timestamp": [1100.08, 1101.48], "text": " all that much or all that often."}, {"timestamp": [1101.48, 1104.16], "text": " So we can basically assume that it'll be usable."}, {"timestamp": [1104.16, 1110.48], "text": " And then the KB articles also, I figured it would actually be better to update the KB articles"}, {"timestamp": [1110.48, 1117.84], "text": " after you have the user input and then the machine output because if you ask chat GPT for important"}, {"timestamp": [1117.84, 1126.14], "text": " information or it solves a problem for you, you actually want to capture that. So we go ahead and generate the response"}, {"timestamp": [1126.14, 1128.16], "text": " and append that to everything."}, {"timestamp": [1128.16, 1129.92], "text": " We go ahead and log it out."}, {"timestamp": [1129.92, 1132.66], "text": " Then we update the user scratch pad again."}, {"timestamp": [1132.66, 1134.16], "text": " Actually, why did I do this?"}, {"timestamp": [1135.2, 1136.8], "text": " Oh, no, this is the first time we did it."}, {"timestamp": [1136.8, 1138.96], "text": " Okay, sorry, I apologize."}, {"timestamp": [1138.96, 1141.32], "text": " So then we update the user scratch pad,"}, {"timestamp": [1141.32, 1143.02], "text": " which the user scratch pad"}, {"timestamp": [1143.02, 1145.12], "text": " is only the last few user messages."}, {"timestamp": [1145.12, 1149.92], "text": " And the reason for that is because we want to exclude,"}, {"timestamp": [1149.92, 1152.52], "text": " you know, chat GPT's response,"}, {"timestamp": [1152.52, 1154.56], "text": " because we don't want it to get confused about things"}, {"timestamp": [1154.56, 1157.62], "text": " that it has said about you or inferred or whatever."}, {"timestamp": [1157.62, 1160.94], "text": " We only want to record your user profile"}, {"timestamp": [1160.94, 1162.5], "text": " from explicitly what you say."}, {"timestamp": [1162.5, 1167.32], "text": " So I just captured the last three messages that you've sent and then it does a stare"}, {"timestamp": [1167.32, 1172.3], "text": " and compare basically where it says OK based on this most recent chat message is there"}, {"timestamp": [1172.3, 1177.52], "text": " any one is there any relevant user information and if so go ahead and update it."}, {"timestamp": [1177.52, 1179.64], "text": " So let me show you how it updates that."}, {"timestamp": [1179.64, 1182.92], "text": " So system update user profile."}, {"timestamp": [1182.92, 1187.64], "text": " So this is this is a user profile document updater chatbot."}, {"timestamp": [1187.64, 1189.76], "text": " This is the system message."}, {"timestamp": [1189.76, 1192.0], "text": " Your role is to manage and update a UPD."}, {"timestamp": [1192.0, 1195.28], "text": " And chatbot, the chat GPT came up with this idea on its own."}, {"timestamp": [1195.28, 1199.64], "text": " It created the UPD definition."}, {"timestamp": [1199.64, 1201.52], "text": " Your primary responsibility is to parse updates"}, {"timestamp": [1201.52, 1206.2], "text": " supplied by the user, meticulously analyze them, and"}, {"timestamp": [1206.2, 1209.56], "text": " could also extend to elements such as user preferences, significant life events, and"}, {"timestamp": [1209.56, 1210.96], "text": " deeply held beliefs."}, {"timestamp": [1210.96, 1214.88], "text": " Please refrain from incorporating non-essential data or unrelated topics."}, {"timestamp": [1214.88, 1217.84], "text": " The result of your efforts should exclusively be an updated UPD."}, {"timestamp": [1217.84, 1221.56], "text": " If the user's update doesn't contribute any new or significant information, your output"}, {"timestamp": [1221.56, 1224.32], "text": " should mirror the current UPD as indicated below."}, {"timestamp": [1224.32, 1227.92], "text": " However, if you discover any relevant new information, your output should mirror the current UPD as indicated below. However, if you discover any relevant new information, your output should feature"}, {"timestamp": [1227.92, 1237.16], "text": " an updated UPD that assimilates these modifications. So basically, it's an upsert. If there's"}, {"timestamp": [1237.16, 1241.56], "text": " no differences, just keep it the same, otherwise update it."}, {"timestamp": [1241.56, 1247.52], "text": " You must prioritize brevity and clarity in your output, combine and condense information when appropriate to ensure succinctness and improve"}, {"timestamp": [1247.52, 1251.98], "text": " comprehension. Totally rewrite or restructure UPD as necessary, adhering to"}, {"timestamp": [1251.98, 1256.04], "text": " the list format. Your response should not include explanatory text or context"}, {"timestamp": [1256.04, 1261.16], "text": " because you know how sometimes chat GPT will say this is your new you know blah"}, {"timestamp": [1261.16, 1266.08], "text": " blah blah so in this case I have it very reliably just spit out"}, {"timestamp": [1266.88, 1267.96], "text": " the user profile."}, {"timestamp": [1269.16, 1270.44], "text": " Oh and then another thing is that"}, {"timestamp": [1271.0, 1272.72], "text": " because because we're working with a"}, {"timestamp": [1272.72, 1274.96], "text": " limited window I say the UPD"}, {"timestamp": [1274.96, 1276.52], "text": " should not exceed approximately a"}, {"timestamp": [1276.52, 1278.48], "text": " thousand words when revising the"}, {"timestamp": [1278.48, 1280.16], "text": " UPD give precedence to the most"}, {"timestamp": [1280.16, 1281.76], "text": " significant and relevant information"}, {"timestamp": [1282.04, 1283.48], "text": " extraneous or less impactful"}, {"timestamp": [1283.48, 1285.86], "text": " information should be omitted etc et cetera, et cetera."}, {"timestamp": [1285.86, 1288.24], "text": " So I give it the current word count"}, {"timestamp": [1288.24, 1289.56], "text": " and then the current UPD."}, {"timestamp": [1289.56, 1290.94], "text": " So that way it kind of knows,"}, {"timestamp": [1290.94, 1293.26], "text": " because chat GPT, especially GPT-4"}, {"timestamp": [1293.26, 1295.54], "text": " is better at counting words,"}, {"timestamp": [1295.54, 1297.98], "text": " but just giving it the explicit number"}, {"timestamp": [1297.98, 1299.58], "text": " makes it easier, right?"}, {"timestamp": [1300.46, 1303.7], "text": " Yeah, so that's my current user profile."}, {"timestamp": [1303.7, 1305.6], "text": " So now let's dive back in here."}, {"timestamp": [1305.6, 1307.92], "text": " The hard part was updating the knowledge base."}, {"timestamp": [1307.92, 1310.12], "text": " So if this is your first run,"}, {"timestamp": [1310.12, 1312.44], "text": " the collection count is gonna be zero."}, {"timestamp": [1312.44, 1317.08], "text": " And so then basically you just instantiate the whole thing."}, {"timestamp": [1317.08, 1319.24], "text": " So we take the most recent chat logs,"}, {"timestamp": [1319.24, 1323.84], "text": " the main scratch pad, and start a new KB article."}, {"timestamp": [1323.84, 1326.04], "text": " Now, if the collection count is not zero,"}, {"timestamp": [1326.04, 1329.44], "text": " which is going to be most of the time once you get started,"}, {"timestamp": [1329.44, 1332.0], "text": " what you do is you basically do the same thing where you say,"}, {"timestamp": [1332.0, 1335.0], "text": " OK, based on the most recent conversation,"}, {"timestamp": [1335.0, 1338.56], "text": " give me the most recent relevant document, which I probably"}, {"timestamp": [1338.56, 1342.0], "text": " could compress this and just use the same information here"}, {"timestamp": [1342.0, 1347.04], "text": " because this is the same because we'll generally"}, {"timestamp": [1347.04, 1348.16], "text": " find the same thing."}, {"timestamp": [1348.16, 1350.2], "text": " Actually, no, that's not necessarily true"}, {"timestamp": [1350.2, 1352.28], "text": " because we've updated the main scratch pad."}, {"timestamp": [1352.28, 1354.4], "text": " So scratch that."}, {"timestamp": [1354.4, 1360.4], "text": " So if the new user input and chat GPT output"}, {"timestamp": [1360.4, 1363.04], "text": " connects to a different KB article,"}, {"timestamp": [1363.04, 1366.48], "text": " let's go ahead and get that document and that document ID."}, {"timestamp": [1366.48, 1369.28], "text": " What we'll do is we'll go ahead and use"}, {"timestamp": [1369.28, 1372.16], "text": " update system update existing KB article."}, {"timestamp": [1372.16, 1374.92], "text": " So this is a system instruction"}, {"timestamp": [1374.92, 1377.36], "text": " where it basically says all the same stuff."}, {"timestamp": [1377.36, 1379.28], "text": " Here's the current KB article,"}, {"timestamp": [1379.28, 1381.08], "text": " and then the user will now provide you"}, {"timestamp": [1381.08, 1383.16], "text": " with the new information to evaluate."}, {"timestamp": [1383.16, 1387.12], "text": " So that is going to be here where you supply it the current KB"}, {"timestamp": [1387.12, 1390.84], "text": " article that it found as well as the scratch pad."}, {"timestamp": [1390.84, 1392.04], "text": " And so it's like, okay, cool."}, {"timestamp": [1392.04, 1394.92], "text": " Now let's do the same thing that we did with the user profile,"}, {"timestamp": [1394.92, 1396.72], "text": " which is merge that information."}, {"timestamp": [1396.72, 1399.4], "text": " If there's nothing new that's relevant, leave it alone."}, {"timestamp": [1399.4, 1402.2], "text": " But if there is, go ahead and update it."}, {"timestamp": [1402.2, 1406.0], "text": " And so then it saves all this out to the DB logs. And so if"}, {"timestamp": [1406.0, 1408.0], "text": " you go to DB logs out here you'll"}, {"timestamp": [1408.0, 1410.0], "text": " see a whole bunch of update statements."}, {"timestamp": [1410.0, 1412.0], "text": " So it says update document and it gives you"}, {"timestamp": [1412.0, 1414.0], "text": " the UUID. And this is the"}, {"timestamp": [1414.0, 1416.0], "text": " final output. Actually probably"}, {"timestamp": [1416.0, 1418.0], "text": " what I should do is modify this so it"}, {"timestamp": [1418.0, 1420.0], "text": " gives you the original"}, {"timestamp": [1420.0, 1422.0], "text": " the original, the new information"}, {"timestamp": [1422.0, 1424.0], "text": " and then the final output."}, {"timestamp": [1424.0, 1430.64], "text": " So I'll add that as a to do item actually to do to do to do."}, {"timestamp": [1430.64, 1437.76], "text": " Let's see to do save more info in DB logs."}, {"timestamp": [1437.76, 1444.32], "text": " Probably as yaml file original article"}, {"timestamp": [1444.32, 1446.0], "text": " new info and then"}, {"timestamp": [1446.0, 1449.0], "text": " final article. So yeah, that's something that I'll do."}, {"timestamp": [1449.0, 1452.0], "text": " Now, that being said, one of the biggest"}, {"timestamp": [1452.0, 1455.0], "text": " problems that we have all always had, so this is"}, {"timestamp": [1455.0, 1458.0], "text": " the cream of the crop, this is the triple crown right here."}, {"timestamp": [1458.0, 1461.0], "text": " The biggest problem that everyone has always had with"}, {"timestamp": [1461.0, 1464.0], "text": " long-term chatbot memory is how the heck do you keep track of"}, {"timestamp": [1464.0, 1466.32], "text": " memories? How the heck do you keep track of memories how the heck do you keep track"}, {"timestamp": [1466.32, 1468.56], "text": " of different types of memories like"}, {"timestamp": [1468.6, 1470.88], "text": " some people have internal thoughts versus"}, {"timestamp": [1471.04, 1473.04], "text": " external thoughts and episodic memories"}, {"timestamp": [1473.04, 1475.12], "text": " and and this"}, {"timestamp": [1475.12, 1475.96], "text": " that and the other"}, {"timestamp": [1476.2, 1478.44], "text": " and you can certainly try"}, {"timestamp": [1478.44, 1479.48], "text": " and tag"}, {"timestamp": [1479.48, 1481.2], "text": " and categorize"}, {"timestamp": [1481.68, 1482.28], "text": " memories"}, {"timestamp": [1482.28, 1482.64], "text": " with"}, {"timestamp": [1484.68, 1486.24], "text": " different context right"}, {"timestamp": [1486.9, 1487.88], "text": " with metadata"}, {"timestamp": [1487.88, 1490.04], "text": " and I certainly recommend that especially once your cognitive"}, {"timestamp": [1490.04, 1491.84], "text": " architectures get more sophisticated"}, {"timestamp": [1492.16, 1494.36], "text": " right. If you do have an out of band"}, {"timestamp": [1494.48, 1496.36], "text": " like thought like internal private"}, {"timestamp": [1496.36, 1498.4], "text": " thoughts definitely keep that separate."}, {"timestamp": [1498.52, 1501.12], "text": " If you have external sensory information"}, {"timestamp": [1501.28, 1502.76], "text": " definitely keep that separate"}, {"timestamp": [1502.96, 1504.88], "text": " but what I'm working on here rather"}, {"timestamp": [1504.88, 1506.0], "text": " than just being a way"}, {"timestamp": [1506.0, 1509.0], "text": " to focus on episodic memory,"}, {"timestamp": [1509.0, 1512.0], "text": " which that's what Remo was by previous attempt,"}, {"timestamp": [1512.0, 1515.0], "text": " this is a way to accumulate declarative information."}, {"timestamp": [1515.0, 1518.0], "text": " And so, declarative"}, {"timestamp": [1518.0, 1521.0], "text": " information is like a statement of fact,"}, {"timestamp": [1521.0, 1524.0], "text": " right? That's why it's called a KB article. So rather than just"}, {"timestamp": [1524.0, 1525.0], "text": " a timeline, rather than just a timeline,"}, {"timestamp": [1525.0, 1528.0], "text": " rather than just a log keeping track of everything"}, {"timestamp": [1528.0, 1529.0], "text": " in chronological order,"}, {"timestamp": [1529.0, 1532.0], "text": " the idea here is to connect new information"}, {"timestamp": [1532.0, 1533.0], "text": " to a KB article."}, {"timestamp": [1533.0, 1535.0], "text": " So there's no reason that you couldn't do both as well,"}, {"timestamp": [1535.0, 1536.0], "text": " right?"}, {"timestamp": [1536.0, 1538.0], "text": " Because this is how human memory works."}, {"timestamp": [1538.0, 1540.0], "text": " It's human memory is associative,"}, {"timestamp": [1540.0, 1541.0], "text": " but it's also temporal."}, {"timestamp": [1542.0, 1544.0], "text": " Now, if the KB article gets too large,"}, {"timestamp": [1544.0, 1546.2], "text": " if you added information and now it's more temporal. Now if the KB article gets too large if the if you added"}, {"timestamp": [1546.22, 1546.88], "text": " information"}, {"timestamp": [1546.88, 1548.8], "text": " and now it's more than a thousand words"}, {"timestamp": [1549.16, 1551.32], "text": " then I have another"}, {"timestamp": [1551.32, 1553.62], "text": " system prompt which you can check them all out here."}, {"timestamp": [1554.68, 1557.04], "text": " So there's system instantiate new KB"}, {"timestamp": [1557.56, 1559.46], "text": " system reflective journaling I just showed you what that"}, {"timestamp": [1559.48, 1561.12], "text": " was system split KB."}, {"timestamp": [1561.56, 1562.8], "text": " So that's what that's the this one"}, {"timestamp": [1562.8, 1565.0], "text": " but update user profile update KB article new KB. So that's what that's the this one but update user profile"}, {"timestamp": [1565.0, 1567.0], "text": " update KB article new KB"}, {"timestamp": [1567.0, 1568.36], "text": " article reflective journaling"}, {"timestamp": [1568.36, 1570.28], "text": " and split KB. So these are the operations."}, {"timestamp": [1570.28, 1572.48], "text": " These are the cognitive operations"}, {"timestamp": [1572.48, 1574.4], "text": " the cognitive memory operations that it's going"}, {"timestamp": [1574.4, 1574.96], "text": " to be doing."}, {"timestamp": [1575.4, 1577.48], "text": " And so then basically what it does is say"}, {"timestamp": [1577.64, 1579.96], "text": " hey we're going to give you a long KB article"}, {"timestamp": [1580.04, 1582.06], "text": " split it into two into two equal"}, {"timestamp": [1582.06, 1582.56], "text": " parts."}, {"timestamp": [1583.6, 1591.56], "text": " And so the idea here is that over time as your KB article gets bigger it'll branch and metastasize naturally."}, {"timestamp": [1592.56, 1605.76], "text": " And so you can you could then add a lot of additional metadata to this such as like access rate or related articles or parent articles or previous articles which means that you can naturally evolve"}, {"timestamp": [1605.76, 1609.16], "text": " a knowledge graph of your knowledge base"}, {"timestamp": [1609.16, 1610.2], "text": " over time."}, {"timestamp": [1610.2, 1612.8], "text": " You can also do this out of band"}, {"timestamp": [1612.8, 1615.2], "text": " just by doing semantic similarity"}, {"timestamp": [1615.2, 1618.04], "text": " and entity links and stuff."}, {"timestamp": [1618.04, 1620.68], "text": " But it would be really cool to have a more sophisticated"}, {"timestamp": [1620.68, 1623.34], "text": " version of this that allows it to kind of follow"}, {"timestamp": [1623.34, 1626.0], "text": " that branching tree over time."}, {"timestamp": [1626.0, 1629.0], "text": " So there you have it. That's kind of the whole thing."}, {"timestamp": [1629.0, 1634.0], "text": " So that's the chat and all this is just real basic housekeeping stuff."}, {"timestamp": [1634.0, 1639.0], "text": " And then at the end of every instance it does Chroma Client persist."}, {"timestamp": [1639.0, 1642.0], "text": " So now let me show you..."}, {"timestamp": [1642.0, 1645.72], "text": " I included a second Python script."}, {"timestamp": [1645.72, 1647.3], "text": " So it's just chroma db peak,"}, {"timestamp": [1647.3, 1649.5], "text": " which uses the chroma db peak function."}, {"timestamp": [1649.5, 1651.66], "text": " Here, let me just show you that script real quick."}, {"timestamp": [1651.66, 1653.48], "text": " Chroma db peak."}, {"timestamp": [1653.48, 1655.94], "text": " So same stuff."}, {"timestamp": [1655.94, 1659.02], "text": " You instantiate the client, you connect to it."}, {"timestamp": [1659.02, 1661.58], "text": " It tells you how many entries,"}, {"timestamp": [1661.58, 1663.86], "text": " and then it will show you the top 10 entries."}, {"timestamp": [1663.86, 1666.52], "text": " So in my case, I should only have one entry."}, {"timestamp": [1668.96, 1670.72], "text": " Let's see. So let's go to the top."}, {"timestamp": [1671.04, 1675.24], "text": " Yep. KB presently has one entries here below the top 10 entries."}, {"timestamp": [1675.56, 1680.36], "text": " And so here you can see that it's actually got several topics because the way that it"}, {"timestamp": [1680.36, 1687.0], "text": " works is that it it searches for the top know, one most relevant KB articles."}, {"timestamp": [1687.0, 1691.82], "text": " And so that's always going to return the first one. And the first one is not yet long enough"}, {"timestamp": [1691.82, 1696.48], "text": " to justify splitting up. But whatever I end up talking about, I'll keep talking with the"}, {"timestamp": [1696.48, 1700.54], "text": " thing and eventually it'll split it up. So in this case, it looks like it'll probably"}, {"timestamp": [1700.54, 1707.58], "text": " talk about AI alignment. And then it's going to also talk about you know my obsession with artificial intelligence"}, {"timestamp": [1707.58, 1710.46], "text": " and work life balance right because those are kind of like"}, {"timestamp": [1710.46, 1713.06], "text": " to centric since centroids"}, {"timestamp": [1713.06, 1713.94], "text": " in this."}, {"timestamp": [1713.94, 1715.18], "text": " So let me just go ahead"}, {"timestamp": [1715.18, 1717.9], "text": " and and actually"}, {"timestamp": [1717.9, 1719.78], "text": " show you how this will ultimately work."}, {"timestamp": [1719.78, 1721.94], "text": " So if we go to"}, {"timestamp": [1721.94, 1725.72], "text": " API logs it should be the last one."}, {"timestamp": [1726.44, 1726.8], "text": " Yes here we go."}, {"timestamp": [1729.12, 1729.84], "text": " So if I plug this in let's go here."}, {"timestamp": [1730.68, 1732.48], "text": " So that's the message that I want it."}, {"timestamp": [1732.8, 1734.64], "text": " And then let's grab the"}, {"timestamp": [1735.52, 1736.2], "text": " split"}, {"timestamp": [1737.52, 1740.12], "text": " the split message so you'll see what I mean by how"}, {"timestamp": [1740.32, 1742.56], "text": " the how it will ultimately"}, {"timestamp": [1743.0, 1745.22], "text": " kind of metastasize. Zoom in a little bit."}, {"timestamp": [1745.46, 1746.7], "text": " All right we're using GPT-4,"}, {"timestamp": [1746.7, 1748.58], "text": " temperature zero, maximum length"}, {"timestamp": [1749.06, 1749.86], "text": " a thousand."}, {"timestamp": [1750.38, 1752.22], "text": " All right so basically what it's going to do"}, {"timestamp": [1753.58, 1755.54], "text": " is the end"}, {"timestamp": [1755.54, 1757.66], "text": " says the user will now provide you with the KB article"}, {"timestamp": [1757.66, 1759.34], "text": " to split. So I submit it"}, {"timestamp": [1759.74, 1761.34], "text": " and now it's going to look at this"}, {"timestamp": [1761.34, 1762.78], "text": " and it's going to say article one"}, {"timestamp": [1763.4, 1764.46], "text": " and then article two."}, {"timestamp": [1765.8, 1767.2], "text": " So let's see what it ultimately does."}, {"timestamp": [1767.2, 1768.82], "text": " And you can see how slow it is."}, {"timestamp": [1768.82, 1774.3], "text": " So this is why ultimately you're going to want to do this out of band as a threaded"}, {"timestamp": [1774.3, 1776.64], "text": " process or do it periodically."}, {"timestamp": [1776.64, 1781.88], "text": " Maybe break it up and do it when the user is offline or whatever."}, {"timestamp": [1781.88, 1785.14], "text": " But you see how each article now is"}, {"timestamp": [1785.8, 1787.34], "text": " much, much more specific."}, {"timestamp": [1787.76, 1789.3], "text": " And so then once you go into each of"}, {"timestamp": [1789.32, 1790.72], "text": " these articles in the future,"}, {"timestamp": [1793.12, 1794.64], "text": " identifying factors and seeking"}, {"timestamp": [1794.96, 1796.22], "text": " professional help if necessary."}, {"timestamp": [1796.24, 1797.24], "text": " Yeah."}, {"timestamp": [1797.48, 1799.36], "text": " And so basically it'll"}, {"timestamp": [1799.8, 1801.6], "text": " allow the articles to metastasize"}, {"timestamp": [1801.6, 1802.6], "text": " over time."}, {"timestamp": [1802.6, 1803.68], "text": " Now, that being said,"}, {"timestamp": [1804.44, 1810.12], "text": " if if no new information is added to an article, it won't update it."}, {"timestamp": [1810.12, 1811.68], "text": " It's that simple."}, {"timestamp": [1811.68, 1818.08], "text": " Now that being said, there will probably be a need to do some KB article grooming over"}, {"timestamp": [1818.08, 1826.7], "text": " time, but the idea is that the KB will only grow as much as it needs to and no more no less and it will only"}, {"timestamp": [1826.7, 1828.92], "text": " grow based on the things that you have talked about"}, {"timestamp": [1829.16, 1831.44], "text": " and it will record it in these very succinct"}, {"timestamp": [1832.12, 1832.88], "text": " concise"}, {"timestamp": [1835.6, 1837.92], "text": " articles. So then what happens is that it splits"}, {"timestamp": [1837.92, 1838.72], "text": " these two up"}, {"timestamp": [1839.6, 1841.68], "text": " and then the final thing that the chat bot does"}, {"timestamp": [1842.04, 1844.24], "text": " is it will do an update for the first"}, {"timestamp": [1844.24, 1845.52], "text": " one and then add the second one. So it's that simple. And then when will do an update for the first one and then add"}, {"timestamp": [1845.52, 1850.72], "text": " the second one. So it's that simple. And then when you do an update, if you don't specify"}, {"timestamp": [1850.72, 1855.76], "text": " the embedding, it'll automatically recalculate the embedding. And then you're good to go."}, {"timestamp": [1855.76, 1861.84], "text": " So I haven't quite got here yet, so it might break. But I think this kind of... Yeah, I"}, {"timestamp": [1861.84, 1865.68], "text": " think that's about it. So like I said, it's over here."}, {"timestamp": [1869.32, 1870.84], "text": " ChromaDB public chatbot should be all set."}, {"timestamp": [1872.44, 1873.28], "text": " Yeah. All right."}, {"timestamp": [1874.16, 1875.0], "text": " Cool."}]}