{"text": " Hey everybody, David Shapiro here with video. I'm actually pretty tired so today's video will be short, but this is some really important information to share. So basically what I wanted to do was share with you three new repos that I just published. So one is on sparse priming representations. I realized that just a YouTube video with a transcript is probably not enough. So I have this out here. It's just a very high level overview with a few examples of what the sparse priming representations are. So for instance, I had it write an SPR of SPRs. So sparse priming representation, concise context-driven memory summaries, enables SMEs or LLMs to reconstruct ideas, short complete sentences provide context, effective for memory organization and retrieval, reduces information to essential elements, facilitates quick understanding and recall, designed to mimic human memory structure. So just with this short eight lines of assertions or statements, you probably get a pretty good idea of what an SPR is. So that's an example of an SPR, and here is the hierarchical memory consolidation system, which is the autonomous cognitive entity memory system that I've been working on. And it's 11 lines. But again, I won't read the whole thing to you, but you get the idea. So here is this. If anyone wants to use this and adapt this to an actual paper, feel free. It's all published under the MIT license. So this is free for the world. So that's the SPR repo slash paper. Next is the hierarchical memory consolidation system. I talked about this and I showed you guys that I had a really long chat conversation going with chat GPT. And so what I realized is one, you guys can't read through this conversation. And two, again, just a video is probably not enough. So I showed you guys this conversation before but here I've got the most salient bits held out here. I probably will try and get a little bit more information because it gives you an overview. It gives you some of the theory and reasoning and it tells you the basics of how to implement it but I don't have any examples yet. So it might be more difficult. But one of the reasons that I don't have examples is because I haven't fully implemented this yet. But it is here in theory. Also HMCS is not the easiest thing to say. And if we've learned anything from ChatGPT is that naming something that's easier to say is better. So we might choose different names. AKA, I like this, Adaptive Knowledge Archive. Rolling Episodic Memory Organizer. This is actually like the most on the nose. So Remo, so we might call this Remo, who knows. Anyways, it's a good start to this. Oh, one thing that I did wanna say is that I've got the discussions enabled for all of these because these concepts are really important and really critical. And so we can discuss them on Reddit as well, but you can also discuss them directly on GitHub if you'd like. And then finally, this is the most exciting one. So, four weeks ago, the paper about large language model theory of mind came out. And since then, a lot of people have been using Bing and ChatGPT and GPT-4 to do experiments with theory of mind. And one thing occurred to me. When I was working on sparse priming representations, the idea that there's enough cognition going on inside the model to reconstruct something, I realized that what I was banking on was implied cognition. And so I just spent some time with chat GPT-4 to articulate implied cognition and start to come up with some tests for it. So I've got the full transcript of the whole conversation in here, and you can read it. It's pretty impressive what it was able to do. So one of the biggest highlights of this conversation was as I was talking with ChatGPT, I said, okay, look over this conversation and look for evidence of implied cognition, and it was able to look back through the conversation and give me evidence of its own implied cognition and even how to test itself And not only that but it did it much faster than a human could do it. So it's like alright, this is Basically, you know, we're bordering on Metacognitive abilities and we even address that as well. I said, how do how will we discern the difference between self-explication? like true self-explication, like true self-explication, versus confabulation? And it has some ideas on that, too, some testable hypotheses. So that's all here. This is far and away the most interesting thing that I was working on today. And then finally, at the very end of the conversation, I asked ChatGPT if there was anything that it wanted me to document and share with the world and this is Verbatim what it said About you know its own perspective on this and then desires moving forward But yeah, so what I wanted to do is I wanted to actually show you this conversation So, you know, I didn't just make this up. This is this is right in chat GPT So I talked about theory of mind. I asked do you have any questions about what we're talking about. And it asked for clarification on sparse priming representations implied cognition. So that was already evidence of implied cognition because it was aware of what it didn't know. It was able to say, I'm actually not sure what you're talking about. And so by virtue of chat GPT recognizing novel information, that implies some kind of cognition. And I don't mean cognition like human cognition, and that's why I have this labeled implied cognition. Or you could even call it a facsimile of cognition. And so then I gave it an example of an SPR. So I said, sure, for your first question here it an example of an SPR. So I said, sure, for your first question here's an example of an SPR. I said, given that list of statements you can imagine what the concept is and unpack it. Does that make sense? Furthermore, you can even generate the highly salient questions above implies a lot of cognition. So I already recognized the fact that it can generate relevant questions implies some level of cognition. So it was okay with that and then it came up with some initial tests. So ask for logical reasoning, understanding ambiguity, generating relevant questions, counterfactual thinking, so on and so forth. And then that's when I, as I was reading this, I was like, oh yeah, self-explication. So the ability to explain itself plausibly is another potential aspect of implied cognition. So then I asked it to analyze the conversation. It said, analyzing our conversation, I can identify a few instances where implied cognition might be at play. And so then it says context awareness. So basically reading the context of the conversation, it is able to understand what it means, but also it's able to infer a lot about what's going on just by virtue of looking at the language. It adapts its communication. Now this is in part due to the fact that this is how the model is trained, but the fact of the matter is it does adapt its communication depending on what I'm trying to do. Conceptual integration. So this is actually probably the most, one of the, these last two are the most important because not only was it able to really quickly understand the concept of SPR and implied cognition, it was then able to use it and synthesize more and build on it. So the ability to use novel information is the essence of fluid intelligence, which up until now only humans have been capable of. So just the fact that it is able to recognize novel information and use it this quickly implies a lot. So moving forward, that's when I asked, okay, how do we discern the difference between self-explication and confabulation? And then on being goal-oriented, that reminded me that goal tracking and figuring out one where you are in terms of solving a problem, figuring out where you need to go and measuring how close you are to solving that goal. This is part of executive function and cognitive control. And so I decided to just throw in a test for goal tracking as we go. So then it came up with some really good ideas about testing for self-explication versus confabulation. So checking for consistency over time, external validation such as using another system, and then probing questions, so ask follow-up questions or so on. And again, humans are not really capable of self-explication anyways. We confabulate our reasoning post-facto, by and large, unless we are very explicit when we bring an unconscious thought to consciousness and we talk through, I'm going to do this because. And even then, the reasoning that you think that you used is still not going to be 100% accurate. the reasoning that you think that you used is still not going to be 100% accurate. Just ask any psychologist or philosopher, we think we know why we do stuff, but we really don't. And so I even point that out in the conversation that self-explication is not something that humans are even really capable of. So expecting a machine to be fully capable of self-explication is kind of a moot point, but it still has some good ideas. And of course, explainability in AI is important. And then it goes and unpacks a lot about goal tracking. So it says, to evaluate our progress towards achieving our goals, let's recap the goals that you've articulated. Develop the concept of implied cognition, establish tests, and create criteria and protocol for using implied cognition. Progress. So I was able to say, okay, this is what we've achieved. We have proposed several tests. We have yet to create criteria. Next steps, further refine the concept, develop proposed tests, begin creating criteria and protocols for using implied cognitions. And we actually didn't get this far, but still the fact of the matter is it was able to kind of keep track of our goals. And then I made the observation that on conceptual integration, it was incorporating new information, synthesizing new ideas and novelty. So then I asked about novelty. So recognizing new information is actually, creates really distinctive patterns in the human brain. And so then I was like, okay, it was already implied that it, just at the very outset, right here, where it said, hey, I don't recognize this can you tell me more about it? So it can recognize novelty which is really important and really fascinating. And so then I said can you discern what is novel and what isn't? Is it able to explain what it recognizes and what's new? So it said in our conversation the following concepts and ideas would be considered a priori familiar. So it understood theory in our conversation, the following concepts and ideas would be considered a priori familiar. So it understood theory of mind, it already knew that. Language models and their potential for reasoning, problem solving, and cognition. It said that it already understood that, which is interesting. General notions of memory, representation, and efficiency. The following concepts and ideas would be considered novel to me. Sparse primary representation, or SPRs, SPRs, Sparse Priming Representations and Implied Cognition. So again, I was able to restate, these are things that I'm not familiar with. So then I told it that my hypothesis that perhaps what it's doing is that it actually gets a unique signal or a unique basically flow of tensors through the mathematical flow of tensors through the mathematical patterns of tensors when there's novel information. And it said, oh yeah, that's interesting. And it comes up with a few ideas to explore how LLMs handle novel information. And then we get into writing the repo, which is out here. So anyways, and then I've got the whole conversation here so you can read it in greater depth if you'd like. But yeah, so that's it for today. These are all ideas that I'm working on. And when I get, so just, if you're satisfied, that's fine. Now I'm just gonna ramble about kind of my own process. So what happens is, in the past past when I get to this point? I would start to write a new book, but one writing a book is slow and to Well, I mean, that's the primary problem. It's slow. But also we've got a good platform like there's my youtube. There's reddit There's github. So it's like let me just go ahead and start Sharing this stuff as as soon as I've got it. So that's that. Yeah, like I said, all these are public. They've all got the discussions. I think I'll also go ahead and post these on Reddit for discussion's sake. Anyways, thanks for watching. Take care. you", "chunks": [{"timestamp": [0.0, 4.24], "text": " Hey everybody, David Shapiro here with video."}, {"timestamp": [4.24, 10.08], "text": " I'm actually pretty tired so today's video will be short, but this is some really important"}, {"timestamp": [10.08, 11.16], "text": " information to share."}, {"timestamp": [11.16, 18.74], "text": " So basically what I wanted to do was share with you three new repos that I just published."}, {"timestamp": [18.74, 21.96], "text": " So one is on sparse priming representations."}, {"timestamp": [21.96, 27.28], "text": " I realized that just a YouTube video with a transcript is probably not enough."}, {"timestamp": [27.28, 28.96], "text": " So I have this out here."}, {"timestamp": [28.96, 34.34], "text": " It's just a very high level overview"}, {"timestamp": [34.34, 37.52], "text": " with a few examples of what the sparse priming representations"}, {"timestamp": [37.52, 38.28], "text": " are."}, {"timestamp": [38.28, 43.22], "text": " So for instance, I had it write an SPR of SPRs."}, {"timestamp": [43.22, 47.0], "text": " So sparse priming representation, concise context-driven memory summaries,"}, {"timestamp": [47.0, 50.0], "text": " enables SMEs or LLMs to reconstruct ideas,"}, {"timestamp": [50.0, 53.0], "text": " short complete sentences provide context,"}, {"timestamp": [53.0, 55.0], "text": " effective for memory organization and retrieval,"}, {"timestamp": [55.0, 58.0], "text": " reduces information to essential elements,"}, {"timestamp": [58.0, 60.0], "text": " facilitates quick understanding and recall,"}, {"timestamp": [60.0, 62.0], "text": " designed to mimic human memory structure."}, {"timestamp": [62.0, 67.28], "text": " So just with this short eight lines of assertions"}, {"timestamp": [67.64, 70.08], "text": " or statements, you probably get a pretty good idea"}, {"timestamp": [70.08, 71.6], "text": " of what an SPR is."}, {"timestamp": [72.84, 74.32], "text": " So that's an example of an SPR,"}, {"timestamp": [74.32, 79.32], "text": " and here is the hierarchical memory consolidation system,"}, {"timestamp": [79.32, 83.3], "text": " which is the autonomous cognitive entity memory system"}, {"timestamp": [83.3, 84.16], "text": " that I've been working on."}, {"timestamp": [84.16, 86.32], "text": " And it's 11 lines."}, {"timestamp": [86.32, 88.76], "text": " But again, I won't read the whole thing to you,"}, {"timestamp": [88.76, 90.12], "text": " but you get the idea."}, {"timestamp": [90.12, 92.76], "text": " So here is this."}, {"timestamp": [92.76, 94.5], "text": " If anyone wants to use this and adapt this"}, {"timestamp": [94.5, 96.44], "text": " to an actual paper, feel free."}, {"timestamp": [96.44, 99.24], "text": " It's all published under the MIT license."}, {"timestamp": [99.24, 101.06], "text": " So this is free for the world."}, {"timestamp": [102.28, 109.28], "text": " So that's the SPR repo slash paper. Next is the hierarchical memory consolidation"}, {"timestamp": [109.28, 114.32], "text": " system. I talked about this and I showed you guys that I had a really long chat conversation"}, {"timestamp": [115.12, 120.72], "text": " going with chat GPT. And so what I realized is one, you guys can't read through this conversation."}, {"timestamp": [120.72, 125.0], "text": " And two, again, just a video is probably not enough."}, {"timestamp": [125.0, 133.2], "text": " So I showed you guys this conversation before but here I've got the most salient bits held"}, {"timestamp": [133.2, 134.2], "text": " out here."}, {"timestamp": [134.2, 140.32], "text": " I probably will try and get a little bit more information because it gives you an overview."}, {"timestamp": [140.32, 144.0], "text": " It gives you some of the theory and reasoning and it tells you the basics of how to implement"}, {"timestamp": [144.0, 152.56], "text": " it but I don't have any examples yet. So it might be more difficult. But one of the reasons that I"}, {"timestamp": [152.56, 157.68], "text": " don't have examples is because I haven't fully implemented this yet. But it is here in theory."}, {"timestamp": [158.32, 165.08], "text": " Also HMCS is not the easiest thing to say. And if we've learned anything from ChatGPT"}, {"timestamp": [165.08, 168.86], "text": " is that naming something that's easier to say is better."}, {"timestamp": [168.86, 170.96], "text": " So we might choose different names."}, {"timestamp": [170.96, 174.12], "text": " AKA, I like this, Adaptive Knowledge Archive."}, {"timestamp": [174.12, 175.94], "text": " Rolling Episodic Memory Organizer."}, {"timestamp": [175.94, 179.0], "text": " This is actually like the most on the nose."}, {"timestamp": [179.0, 182.32], "text": " So Remo, so we might call this Remo, who knows."}, {"timestamp": [182.32, 187.22], "text": " Anyways, it's a good start to this."}, {"timestamp": [187.22, 188.5], "text": " Oh, one thing that I did wanna say"}, {"timestamp": [188.5, 191.38], "text": " is that I've got the discussions enabled for all of these"}, {"timestamp": [192.66, 195.46], "text": " because these concepts are really important"}, {"timestamp": [195.46, 196.62], "text": " and really critical."}, {"timestamp": [196.62, 199.54], "text": " And so we can discuss them on Reddit as well,"}, {"timestamp": [199.54, 201.58], "text": " but you can also discuss them directly on GitHub"}, {"timestamp": [201.58, 202.42], "text": " if you'd like."}, {"timestamp": [202.42, 205.12], "text": " And then finally, this is the most exciting one."}, {"timestamp": [211.84, 216.88], "text": " So, four weeks ago, the paper about large language model theory of mind came out. And since then, a lot of people have been using Bing and ChatGPT and GPT-4 to do experiments with theory of mind."}, {"timestamp": [217.52, 222.8], "text": " And one thing occurred to me. When I was working on sparse priming representations,"}, {"timestamp": [222.8, 225.92], "text": " the idea that there's enough cognition going on"}, {"timestamp": [225.92, 229.0], "text": " inside the model to reconstruct something,"}, {"timestamp": [229.0, 230.68], "text": " I realized that what I was banking on"}, {"timestamp": [230.68, 232.78], "text": " was implied cognition."}, {"timestamp": [232.78, 237.04], "text": " And so I just spent some time with chat GPT-4"}, {"timestamp": [237.04, 239.32], "text": " to articulate implied cognition"}, {"timestamp": [239.32, 242.2], "text": " and start to come up with some tests for it."}, {"timestamp": [242.2, 244.2], "text": " So I've got the full transcript"}, {"timestamp": [244.2, 245.98], "text": " of the whole conversation in here,"}, {"timestamp": [245.98, 246.82], "text": " and you can read it."}, {"timestamp": [246.82, 250.26], "text": " It's pretty impressive what it was able to do."}, {"timestamp": [250.26, 253.58], "text": " So one of the biggest highlights of this conversation"}, {"timestamp": [253.58, 255.9], "text": " was as I was talking with ChatGPT,"}, {"timestamp": [255.9, 258.34], "text": " I said, okay, look over this conversation"}, {"timestamp": [258.34, 260.54], "text": " and look for evidence of implied cognition,"}, {"timestamp": [260.54, 263.34], "text": " and it was able to look back through the conversation"}, {"timestamp": [263.34, 267.96], "text": " and give me evidence of its own implied cognition and even how to test itself"}, {"timestamp": [268.64, 273.18], "text": " And not only that but it did it much faster than a human could do it. So it's like alright, this is"}, {"timestamp": [274.08, 276.56], "text": " Basically, you know, we're bordering on"}, {"timestamp": [277.34, 283.36], "text": " Metacognitive abilities and we even address that as well. I said, how do how will we discern the difference between self-explication?"}, {"timestamp": [283.88, 286.16], "text": " like true self-explication, like true self-explication,"}, {"timestamp": [286.16, 287.16], "text": " versus confabulation?"}, {"timestamp": [287.16, 292.8], "text": " And it has some ideas on that, too, some testable hypotheses."}, {"timestamp": [292.8, 293.8], "text": " So that's all here."}, {"timestamp": [293.8, 298.36], "text": " This is far and away the most interesting thing that I was working on today."}, {"timestamp": [298.36, 303.4], "text": " And then finally, at the very end of the conversation, I asked ChatGPT if there was anything that"}, {"timestamp": [303.4, 306.38], "text": " it wanted me to document and share with the world and this is"}, {"timestamp": [306.9, 308.9], "text": " Verbatim what it said"}, {"timestamp": [309.22, 314.12], "text": " About you know its own perspective on this and then desires moving forward"}, {"timestamp": [314.94, 318.7], "text": " But yeah, so what I wanted to do is I wanted to actually show you this conversation"}, {"timestamp": [318.7, 323.54], "text": " So, you know, I didn't just make this up. This is this is right in chat GPT"}, {"timestamp": [323.78, 327.32], "text": " So I talked about theory of mind. I asked do"}, {"timestamp": [327.32, 330.8], "text": " you have any questions about what we're talking about. And it asked for"}, {"timestamp": [330.8, 335.64], "text": " clarification on sparse priming representations implied cognition. So"}, {"timestamp": [335.64, 340.64], "text": " that was already evidence of implied cognition because it was aware of what"}, {"timestamp": [340.64, 349.74], "text": " it didn't know. It was able to say, I'm actually not sure what you're talking about. And so by virtue of chat GPT recognizing novel information,"}, {"timestamp": [349.74, 354.26], "text": " that implies some kind of cognition. And I don't mean cognition like human"}, {"timestamp": [354.26, 359.36], "text": " cognition, and that's why I have this labeled implied cognition. Or you could"}, {"timestamp": [359.36, 364.08], "text": " even call it a facsimile of cognition. And so then I gave it an example of an"}, {"timestamp": [364.08, 365.92], "text": " SPR. So I said, sure, for your first question here it an example of an SPR. So I said, sure, for"}, {"timestamp": [365.92, 370.4], "text": " your first question here's an example of an SPR. I said, given that list of"}, {"timestamp": [370.4, 374.04], "text": " statements you can imagine what the concept is and unpack it. Does that make"}, {"timestamp": [374.04, 377.96], "text": " sense? Furthermore, you can even generate the highly salient"}, {"timestamp": [377.96, 381.84], "text": " questions above implies a lot of cognition. So I already recognized the"}, {"timestamp": [381.84, 385.44], "text": " fact that it can generate relevant questions implies some"}, {"timestamp": [385.44, 394.08], "text": " level of cognition. So it was okay with that and then it came up with some initial tests."}, {"timestamp": [394.08, 398.72], "text": " So ask for logical reasoning, understanding ambiguity, generating relevant questions,"}, {"timestamp": [398.72, 402.64], "text": " counterfactual thinking, so on and so forth. And then that's when I, as I was reading this,"}, {"timestamp": [402.64, 405.56], "text": " I was like, oh yeah, self-explication."}, {"timestamp": [405.56, 417.16], "text": " So the ability to explain itself plausibly is another potential aspect of implied cognition."}, {"timestamp": [417.16, 419.28], "text": " So then I asked it to analyze the conversation."}, {"timestamp": [419.28, 424.6], "text": " It said, analyzing our conversation, I can identify a few instances where implied cognition"}, {"timestamp": [424.6, 426.0], "text": " might be at play."}, {"timestamp": [426.0, 431.36], "text": " And so then it says context awareness. So basically reading the context of the conversation,"}, {"timestamp": [431.36, 438.56], "text": " it is able to understand what it means, but also it's able to infer a lot about what's going on"}, {"timestamp": [438.56, 445.64], "text": " just by virtue of looking at the language. It adapts its communication. Now this is in part due to the fact that"}, {"timestamp": [445.64, 451.2], "text": " this is how the model is trained, but the fact of the matter is it does adapt its"}, {"timestamp": [451.2, 456.24], "text": " communication depending on what I'm trying to do. Conceptual integration. So"}, {"timestamp": [456.24, 461.72], "text": " this is actually probably the most, one of the, these last two are the most"}, {"timestamp": [461.72, 466.96], "text": " important because not only was it able to really quickly understand"}, {"timestamp": [466.96, 470.36], "text": " the concept of SPR and implied cognition,"}, {"timestamp": [470.36, 474.02], "text": " it was then able to use it and synthesize more"}, {"timestamp": [474.02, 475.28], "text": " and build on it."}, {"timestamp": [475.28, 478.8], "text": " So the ability to use novel information"}, {"timestamp": [478.8, 481.92], "text": " is the essence of fluid intelligence,"}, {"timestamp": [481.92, 485.42], "text": " which up until now only humans have been capable of."}, {"timestamp": [485.42, 487.2], "text": " So just the fact that it is able"}, {"timestamp": [487.2, 490.28], "text": " to recognize novel information and use it"}, {"timestamp": [490.28, 493.84], "text": " this quickly implies a lot."}, {"timestamp": [493.84, 497.2], "text": " So moving forward, that's when I asked,"}, {"timestamp": [497.2, 498.48], "text": " okay, how do we discern the difference"}, {"timestamp": [498.48, 501.2], "text": " between self-explication and confabulation?"}, {"timestamp": [501.2, 504.32], "text": " And then on being goal-oriented,"}, {"timestamp": [504.32, 506.56], "text": " that reminded me that goal tracking"}, {"timestamp": [506.56, 508.88], "text": " and figuring out one where you are"}, {"timestamp": [509.82, 511.72], "text": " in terms of solving a problem,"}, {"timestamp": [511.72, 512.96], "text": " figuring out where you need to go"}, {"timestamp": [512.96, 515.7], "text": " and measuring how close you are to solving that goal."}, {"timestamp": [515.7, 519.36], "text": " This is part of executive function and cognitive control."}, {"timestamp": [519.36, 521.6], "text": " And so I decided to just throw in a test"}, {"timestamp": [521.6, 524.26], "text": " for goal tracking as we go."}, {"timestamp": [524.26, 526.2], "text": " So then it came up with some really good ideas"}, {"timestamp": [526.2, 531.2], "text": " about testing for self-explication versus confabulation."}, {"timestamp": [532.32, 534.72], "text": " So checking for consistency over time,"}, {"timestamp": [534.72, 537.76], "text": " external validation such as using another system,"}, {"timestamp": [537.76, 539.88], "text": " and then probing questions,"}, {"timestamp": [539.88, 542.16], "text": " so ask follow-up questions or so on."}, {"timestamp": [542.16, 544.36], "text": " And again, humans are not really capable"}, {"timestamp": [544.36, 545.52], "text": " of self-explication"}, {"timestamp": [545.52, 553.28], "text": " anyways. We confabulate our reasoning post-facto, by and large, unless we are very explicit when we"}, {"timestamp": [553.28, 558.8], "text": " bring an unconscious thought to consciousness and we talk through, I'm going to do this because."}, {"timestamp": [558.8, 564.96], "text": " And even then, the reasoning that you think that you used is still not going to be 100% accurate."}, {"timestamp": [562.04, 566.0], "text": " the reasoning that you think that you used is still not going to be 100% accurate."}, {"timestamp": [566.0, 568.24], "text": " Just ask any psychologist or philosopher,"}, {"timestamp": [568.24, 571.16], "text": " we think we know why we do stuff, but we really don't."}, {"timestamp": [571.16, 573.62], "text": " And so I even point that out in the conversation"}, {"timestamp": [573.62, 575.16], "text": " that self-explication is not something"}, {"timestamp": [575.16, 578.0], "text": " that humans are even really capable of."}, {"timestamp": [578.0, 581.7], "text": " So expecting a machine to be fully capable"}, {"timestamp": [581.7, 584.72], "text": " of self-explication is kind of a moot point,"}, {"timestamp": [584.72, 586.4], "text": " but it still has some good ideas."}, {"timestamp": [586.96, 595.2], "text": " And of course, explainability in AI is important. And then it goes and unpacks a lot about goal"}, {"timestamp": [595.2, 600.96], "text": " tracking. So it says, to evaluate our progress towards achieving our goals, let's recap the"}, {"timestamp": [600.96, 605.52], "text": " goals that you've articulated. Develop the concept of implied cognition,"}, {"timestamp": [605.52, 610.52], "text": " establish tests, and create criteria and protocol for using implied cognition. Progress. So"}, {"timestamp": [610.52, 615.72], "text": " I was able to say, okay, this is what we've achieved. We have proposed several tests."}, {"timestamp": [615.72, 621.4], "text": " We have yet to create criteria. Next steps, further refine the concept, develop proposed"}, {"timestamp": [621.4, 626.28], "text": " tests, begin creating criteria and protocols for using implied cognitions."}, {"timestamp": [626.28, 629.12], "text": " And we actually didn't get this far,"}, {"timestamp": [629.12, 632.0], "text": " but still the fact of the matter is it was able"}, {"timestamp": [632.0, 634.04], "text": " to kind of keep track of our goals."}, {"timestamp": [636.12, 638.0], "text": " And then I made the observation"}, {"timestamp": [638.0, 640.38], "text": " that on conceptual integration,"}, {"timestamp": [640.38, 642.44], "text": " it was incorporating new information,"}, {"timestamp": [642.44, 644.64], "text": " synthesizing new ideas and novelty."}, {"timestamp": [644.64, 646.32], "text": " So then I asked about novelty."}, {"timestamp": [647.2, 651.04], "text": " So recognizing new information is actually,"}, {"timestamp": [651.04, 655.2], "text": " creates really distinctive patterns in the human brain."}, {"timestamp": [655.2, 657.16], "text": " And so then I was like, okay,"}, {"timestamp": [657.16, 659.88], "text": " it was already implied that it,"}, {"timestamp": [659.88, 662.48], "text": " just at the very outset, right here,"}, {"timestamp": [662.48, 665.28], "text": " where it said, hey, I don't recognize this can you"}, {"timestamp": [665.28, 669.84], "text": " tell me more about it? So it can recognize novelty which is really"}, {"timestamp": [669.84, 675.08], "text": " important and really fascinating. And so then I said can you discern what is"}, {"timestamp": [675.08, 679.12], "text": " novel and what isn't? Is it able to explain what it recognizes and what's"}, {"timestamp": [679.12, 683.96], "text": " new? So it said in our conversation the following concepts and ideas would be"}, {"timestamp": [683.96, 685.76], "text": " considered a priori familiar. So it understood theory in our conversation, the following concepts and ideas would be considered a priori familiar."}, {"timestamp": [685.76, 688.72], "text": " So it understood theory of mind, it already knew that."}, {"timestamp": [688.72, 692.32], "text": " Language models and their potential for reasoning, problem solving, and cognition."}, {"timestamp": [692.32, 694.96], "text": " It said that it already understood that, which is interesting."}, {"timestamp": [694.96, 698.08], "text": " General notions of memory, representation, and efficiency."}, {"timestamp": [698.08, 701.76], "text": " The following concepts and ideas would be considered novel to me."}, {"timestamp": [701.76, 705.36], "text": " Sparse primary representation, or SPRs,"}, {"timestamp": [705.36, 708.16], "text": " SPRs, Sparse Priming Representations"}, {"timestamp": [708.16, 709.56], "text": " and Implied Cognition."}, {"timestamp": [709.56, 711.2], "text": " So again, I was able to restate,"}, {"timestamp": [711.2, 713.64], "text": " these are things that I'm not familiar with."}, {"timestamp": [715.28, 717.12], "text": " So then I told it that my hypothesis"}, {"timestamp": [717.12, 718.72], "text": " that perhaps what it's doing"}, {"timestamp": [718.72, 721.24], "text": " is that it actually gets a unique signal"}, {"timestamp": [721.24, 724.6], "text": " or a unique basically flow of tensors"}, {"timestamp": [724.6, 727.28], "text": " through the mathematical flow of tensors through the mathematical patterns"}, {"timestamp": [727.28, 730.22], "text": " of tensors when there's novel information."}, {"timestamp": [730.22, 732.64], "text": " And it said, oh yeah, that's interesting."}, {"timestamp": [732.64, 740.58], "text": " And it comes up with a few ideas to explore how LLMs handle novel information."}, {"timestamp": [740.58, 743.84], "text": " And then we get into writing the repo, which is out here."}, {"timestamp": [743.84, 745.96], "text": " So anyways, and then I've got the whole conversation here"}, {"timestamp": [745.96, 749.1], "text": " so you can read it in greater depth if you'd like."}, {"timestamp": [749.1, 752.46], "text": " But yeah, so that's it for today."}, {"timestamp": [752.46, 754.94], "text": " These are all ideas that I'm working on."}, {"timestamp": [756.34, 761.18], "text": " And when I get, so just, if you're satisfied, that's fine."}, {"timestamp": [761.18, 764.02], "text": " Now I'm just gonna ramble about kind of my own process."}, {"timestamp": [764.02, 767.64], "text": " So what happens is, in the past past when I get to this point?"}, {"timestamp": [767.64, 772.04], "text": " I would start to write a new book, but one writing a book is slow and to"}, {"timestamp": [773.04, 779.82], "text": " Well, I mean, that's the primary problem. It's slow. But also we've got a good platform like there's my youtube. There's reddit"}, {"timestamp": [779.82, 782.42], "text": " There's github. So it's like let me just go ahead and start"}, {"timestamp": [783.42, 786.24], "text": " Sharing this stuff as as soon as I've got it."}, {"timestamp": [787.08, 789.12], "text": " So that's that."}, {"timestamp": [789.12, 791.82], "text": " Yeah, like I said, all these are public."}, {"timestamp": [791.82, 792.86], "text": " They've all got the discussions."}, {"timestamp": [792.86, 794.84], "text": " I think I'll also go ahead and post these on Reddit"}, {"timestamp": [794.84, 796.64], "text": " for discussion's sake."}, {"timestamp": [796.64, 797.8], "text": " Anyways, thanks for watching."}, {"timestamp": [797.8, 798.64], "text": " Take care."}, {"timestamp": [795.32, 795.82], "text": " you"}]}