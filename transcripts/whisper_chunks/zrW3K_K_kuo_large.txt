{"text": " Morning everybody, David Shapiro here with a video. So my video about AGI was super popular. I suppose I should have anticipated that, you know, making a bold declaration like AGI within 18 months. So with that being said, the ramp up to AGI, ASI, or super intelligence, and then singularity seems like it's accelerating, especially if you go superintelligence, and then singularity seems like it's accelerating, especially if you go by Reddit comments on r slash singularity and a few other places, people are like, is this happening? Are we actually approaching the wall of exponential takeoff? So, assuming that that is the case and that we are ramping up to the singularity within the coming months or years or whatever, let's explore how the singularity will actually unfold. First, we need to define singularity. So what do we mean when we say singularity? There's obviously a lot of ways to define this thing and the simplest way that I could come up with to define it is just we say that the singularity is when AI becomes orders of magnitude more intelligent than all humans combined. So basically if current trends continue in terms of AI research and the power of AI, GPT-4 is just as intelligent as many people, more intelligent than some, and GPT-5 is being trained and there's open source versions, etc. So basically if you haven't been living under a rock you are probably aware of the rapid ramp up of A.I. and it's not showing any signs of slowing down. If anything it's accelerating because now we're not looking at A.I. advancements on a monthly basis we're looking at it on a weekly basis. I was actually at a meet up recently and someone pointed that out there like I think we're actually already in the singularity because we're measuring advancements on a week to week basis. And soon we might be measuring it on a day to day basis. Okay, so let's break this down. What are some of the macroeconomic changes that we can expect to see with the singularity? First we have to talk about what remains scarce, because it's very easy to get caught up in this magical thinking of AI is going to change everything, but there's going to be some things that don't change with AI, no matter how smart it gets. So if the singularity happens, there's a few things that are not really going to change that much. So first is desirable and arable land. Some places will remain deserts, hence this AI generated image of a woman in a desert. We'll get to that later when we talk about fusion. But fresh potable water, most of the water on the planet is also saltwater. Again, we might be able to change that if we solve nuclear fusion and other energy sources. But then there's other physical resources, such as minerals and mined natural resources, that will also probably remain scarce no matter how intelligent AI becomes. So this will be a really critical constraint, which could really drive up the value of some of these resources. But, and as I mentioned, if we solve nuclear fusion we could desalinate water, we could irrigate deserts, and so on and so forth, but that could have unintended consequences. Because if suddenly you irrigate every desert on the planet, maybe those deserts actually form a really critical component of our ecosystem. Lastly, if we solve space flight, we could probably start harvesting asteroids and even other planets for rare minerals because there are trillions and trillions and trillions of dollars worth of rare minerals out there on the solar system. So it's entirely possible that all of these will actually be solved at some point in the future with the singularity, but at least in the short term, these will remain scarce resources. Now, on the flip side, from a macroeconomic perspective, what becomes abundant with the singularity? The primary thing that becomes abundant with the singularity is knowledge, information, and cognitive labor. So what I mean by cognitive labor is thinking, knowledge work, service industry jobs. So basically what happens if AI becomes orders of magnitude smarter than humans and we remain in control of it, this is all assuming the good ending, right, that we don't get wiped out, basically what that means is that human cognitive effort becomes irrelevant. Now that sounds really awful but one thing that I realized while I was working on this is that on an individual basis most people's cognitive effort is already irrelevant, right? We're on a planet of eight billion people, chances are someone has already solved the problem that you are working on. Whether or not you realize it is a different story, but you know, doing science and solving problems, it can be really difficult and it's mostly a matter of right place, right time, but you know, there are, well with that being said, there are still unsolved problems out there. And the singularity with, you know, hyper-advanced AI will probably just result in kind of the same behavior that we're already seeing, because the collective wisdom of humanity solves problems pretty quickly, right? But the velocity of that problem-solving will probably go up, you know, maybe a few degrees maybe an order of magnitude not sure yet, but a hyper abundance of cognitive labor is is actually probably not going to be as immediately and dramatically impactful as you might think Because they like look at reddit and Twitter and other social media platforms that allow you to solve problems get answers and other social media platforms that allow you to solve problems, get answers, and move on very quickly. So basically, instead of having, you know, lazy Twitter or Reddit where you ask a problem, ask the machines for a problem, or, you know, people are collectively, now the machines are going to be doing it. And actually, some of the people that I'm working with on these autonomous AI projects, one of the key things that we're working on is figuring out how to get AI to talk to each other in an autonomous manner that is safe and transparent, and this is where natural language comes in because you don't want AI using their own coded language to talk to each other, you want AI using human-readable natural language to talk to each other. Anyways, that's a topic for another video. So let's move forward from those macroeconomic changes to technological breakthroughs. If suddenly we have a hyperabundance of cognitive effort or cognitive labor, what kind of technology solutions can we imagine being solved? So first is high-energy physics. High-energy physics, the stuff that they're working on at the CERN, at LHC, this includes nuclear fusion. It could include even antimatter research. Who knows, maybe time travel, maybe faster than light travel. Not really sure, but at least the first problem that will likely be solved in high-energy physics is probably going to be nuclear fusion. It's really difficult to anticipate what solving nuclear fusion will do because nuclear fusion is a thousand times more powerful and efficient than any form of energy we have today. So when you have a hyperabundance of energy suddenly a lot of other things become possible. For instance you can then afford to desalinate as much water as you need. You can then afford to run underground farms, you know, that are completely unbounded from arable land. There's all kinds of stuff that you can do once you unlock nuclear fusion. The knock-on effects of solving nuclear fusion are impossible to say. Not only just like in the short term, we can come up with a couple ideas, but certainly in the long term solving nuclear fusion solves so many other problems. It solves recycling because then suddenly you can afford to just melt down any material no matter how expensive it is, so you can reclaim all the lithium, all the cobalt, all the nickel from everything. Platinum, gold, pretty much every mineral becomes accessible no matter how difficult it is to isolate because suddenly if you have many many many gigajoules of energy available at all times for practically free it doesn't matter how much energy it costs to recycle a material. That's just another example. Another set of solved problems that you can expect with a hyperabundance of cognitive labor is basically disease genetics and aging. That, you know, the human body, our genetics, our metabolism, one of the most complex systems in existence. There's more than a hundred thousand metabolic pathways that we know of in the human body alone, and they all interact. Not only that, they interact with your genes, your epigenetics, your microflora, all kinds of stuff. Super complex system. But, if you have a hyperabundance of intellect, then you can create new tools, you can create new processes, you can manage vast amounts of information and so then we might end up curing all disease, all aging and untangling all genetics within a relatively short period of time after achieving the singularity or AGI or however you want to call it. And then finally material science. So material science, we're already seeing the beginning of this with alpha fold. And so basically imagine that you have alpha fold, which if you're not familiar with alpha fold, that is a way of using deep neural networks, using transformers to model protein folding, which was an unsolved problem. But now that it's a solved problem, we can model any protein folding. Now take that to the next level. What if not only you can model all protein folding, you can model all protein interactions, all genetic interactions. Then take that one step further, you can measure or model nanoparticles, carbon. You can predict how to build very, very advanced materials which could revolutionize, for instance, batteries and computer technology. I predict that the material science breakthroughs that will result from AI means that basically in five to ten years, your phone could be more powerful than all computers on earth today. And I'm not really exaggerating when I say that because the amount of computational power just in the atoms of a phone, like if you have a membrane or whatever, or a three-dimensional wafer, the amount of potential computational power in matter is inconceivable, basically. Inconceivable, basically. Inconceivable! So anyways, it would not surprise me if we move up a Kardashev scale or two post-singularity. Now, that being said, there are still some unsolved problems that pretty much no amount of intellectual labor on Earth could solve. So for instance, some people in the comments have asked about the hard problem of consciousness. That may or may not be solvable by machines, period. That might be something that we humans have to figure out for ourselves, which extends to fundamental questions of existence, of cosmology. Some of these things are not necessarily a matter of, you know, mathematically proving it and measuring it in the lab. Some of these things are a matter of interpretation. Some of these things are a matter of subjective values such as the meaning of life, so on and so forth. Now, one thing that people imagine when we talk about transhumanism or post-humanism is that we will have some sort of transcendence event. I Personally don't think the singularity will result in some kind of transcendent event where we all become like Q from Star Trek or you know some final solution where we become Beings of energy. I also don't think that mind uploading is a good idea I know a lot of people think that that's great. but like we don't understand why we are conscious, you know, and basically I predict that, you know, if you try and upload your mind, you're just going to upload a copy of yourself and then your body will be dead. And so subjectively you will have died, but a copy of you will continue on forever. So I don't think that mind uploading is a good idea, which if that's the case, then like we will forever be locked in our organic bodies Even if there are digital copies of us frolicking out in cyberspace they're not going to be us and they're gonna have an entirely different set of constraints because then if There if you become or a copy of you becomes a digital entity You suddenly don't have the same biological constraints. And so we have this like grand divergence of Digital post humans and then us organic meat bags. That to me sounds like an unsolved problem that I don't think AI is going to fix for us. Alright moving on to social changes. Jobs and occupations. So as machines get more intelligent, the TLDR is that most jobs are going to become irrelevant. I've talked with people about this. There's a lot of BS jobs out there that nobody really wants to do, but you do it because you need to eat and you need to pay for your house and whatever. And so what we're going to have to do is then recalibrate how we think of meaning and purpose and success. And this includes maybe shifting and having a greater emphasis on creativity exploration and self-improvement. And then one idea that came from discussing this with ChatGPT was that as a society, we might instead of focusing on conformance to one standard of education, we might instead really focus on what makes everyone unique, which was a really interesting new model of education. So imagine that you go to school and instead of like everyone has the same classes, you have a broad variety of projects and experiments and things to figure out what it is that one, you really care about, and two, what really makes you stand out. And so then everyone can have a very different focus on education. My first year of school was at Montessori School, and so I can imagine taking that to the next level. Anyways, I know that there's a lot of people that say, oh well without a job we have no meaning. That is your neoliberal programming speaking. I and other people that have made a transition to a different kind of occupation, you know, my occupation is now YouTube and Patreon, which I find much more interesting and rewarding, is much closer to lifestyles that have existed in the past. So for instance, in ancient Greece, particularly in Sparta, Spartan citizens were not allowed to have a job. Their job was to be soldiers, to be hunters, to be politicians, to participate in culture and society, not to be leather workers or anything else. And so obviously ancient Sparta didn't, ultimately didn't do so well. Ancient Athens, they did much better. Very similar model with the citizen class, the leisure class. Ditto for ancient Rome. So humans have adapted to kind of these, effectively a post-scarcity world before, but instead of working on the backs of subjugated classes of people, we will all enter into a post-scarcity leisure class on the backs of AI. That's kind of what I predict is gonna happen. Because honestly, most people want that anyways, and if we have a collective willpower to want that, who cares? And I can hear some of you already complaining, corporations are never going to allow that to happen. I'm going to get to that in just a second. Glad you asked. Okay, so if we if nobody's job really matters, what do we do then? One of the conversations that I had at a meetup was like, well, what if everyone just plays video games? There's actually a reason that video games are so popular. Because video games can foster social connection, right? A lot of games are very, very social today. And they're also challenging, which means that they give you a sense of competence, a sense of mastery. which means that they give you a sense of competence, a sense of mastery. And finally, video games give you a lot more autonomy, like you can be anyone that you want in a video game world, and those three things satisfy the three pillars of self-determination theory, autonomy, human connection, and competence, which is why so many people play video games. So if you look at SDT, self-determination theory, and then you say, okay, well, take away the need for a job, and suddenly AI gives us all a lot more autonomy, gives us an opportunity for more human connection, the only remaining thing is challenge. And what happens for a lot of people who retire or step away from conventional work is that we realize, like, oh wait, I can challenge myself in new ways. All of you that watch my YouTube channel, I don't actually need to do all the coding experiments that I do, but I find it deeply satisfying to challenge myself to try and solve the problems out there. And I'm not saying everyone is gonna engage in this kind of problem-solving. Some people are gonna go to do martial arts or go climb mountains or whatever, but we humans love, love challenges. We need to feel competent and we need to have a sense of mastery. And the Sam Altman interview, he pointed out that yes, AI has solved Go and chess and other things, but we still play chess. We just don't play against computers because there's no point. There's no sense of mastery against something that you're never going to win against. So anyways, the long-term effect of this is that we're probably going to see new social structures emerge or maybe even older social structures re-emerge. I particularly predict that we're going to see more multi-generational homes, more kind of tribal or village lifestyle things re-emerge. Because suddenly it's like, okay, well, here's a dozen people that I really like and none of us have a job, so let's go form an eco-village out in the countryside. Or maybe an urban co-living situation in the city. Who knows? Just some speculation there. Okay, so I promised that we would address some of the elephants in the room. So let's unpack all the risks and factors that will go into this rosy post-singularity result that I have outlined. So the first one is the development and control of AI. Obviously many of you are probably aware that there's been a the letter circulating that's signed by a whole bunch of people including Elon Musk and Max Tegmark all calling for a moratorium on the advancement of AI for at least six months while we take a breath and reassess. So it is possible that if we continue at a breakneck pace and things do it and people do it wrong then we're gonna end up in some kind of dystopian or cataclysmic outcome. So there's basically two primary failure modes for this. One is we lose control of the AI and it decides to kill us all. The other major failure mode is that we don't lose control of AI, but the wrong people get the powerful AI, and they use it to kill everyone else or subjugate everyone else. So those are the two primary failure modes that have to do with AI development and control. And this has been explored in a lot of fiction. And so I'm kind of tired of it. So I'm not going to really talk about it that much more. But point being is that 99 percent of people don't really want an AI apocalypse. Some people seem to really wish for it. But I think that's a sense of nihilism leaking through. Some people think it's inevitable and there's a sort of fatalism about it. And that, again, you know, I empathize with people like that. I echo Sam Altman's sentiment that like, yeah, there are a lot of people afraid and I'm not going to tell them that they're wrong or that they're stupid or that it's magical thinking. Like we are playing with fire. I just happen to be very sanguine about it because I feel like, one, all the problems that exist are solvable. And two, I think that they are solvable in the very near term. Okay, another big risk is distribution of benefits. This is one of the biggest things that people are worried about, which is, okay, do you, like, one of the most common pushbacks is, like, do you honestly think that corporations are gonna allow everyone to live a luxurious lifestyle lifestyle or that the rich and powerful are going to allow everyone else to live like they do? Well, first, I don't know that they'll have that much of a choice in it. But two, I think the fact that the masses, like you and I, the proletariat, we don't want to live in a cyberpunk hell, right? And we have seen what happens repeatedly through history as people get hungrier and more desperate. The most recent incident was the Arab Spring, in which case much of the Middle East, the Arab world, rose up and the primary driving factor was economic conditions. And then, of course, you go back even further, the French Revolution. This kind of thing has happened time and time again. So I'm not too particularly worried about that because push comes to shove, people are going to stand up and redistribute forcefully. Now I'm not advocating for, you know, civil war or anything. I don't even think it's going to come to that because, you know, I follow Davos and World Economic Forum and UN and, and all the, you know, halls of power, IMF, the World Bank, um, the halls of power really are paying attention to this. And I think that they're preparing for it, honestly. So for instance, I suspect that the, uh, the, the stimulus checks that America did during the pandemic, I think that that was a pilot program to demonstrate that redistribution works, that it is fast, efficient, and fair, because what they did was they did these stimulus checks alongside the paycheck protection program, the PPP loans, and they basically did a side-by-side test showing, showing look the PPP loans are expensive and rife with corruption and the stimulus checks went directly to people who needed it and it all got spent by individuals who needed it. So I kind of think that the stimulus checks were a pilot program or a prototype for UBI and when you look at the landscape right now where there's been over 300,000 tech layoffs and more other kinds of people are already starting to get laid off and notified of layoffs due to technologies like chat GPT. My fiancee who's a writer and is in a lot of writing discords, there are copywriters out there who are already getting laid off and losing work to AI. So like the AI layoffs are coming so I think that we're also gonna see a lot of stimulus checks coming and it's just a matter of okay are these stimulus checks permanent and I think that they will be. The regulatory environment. So this is where that letter that just came out is is asking for regulation. Sam Altman has asked for regulation, Elon Musk has asked for regulation, all kinds of people are asking for more regulation. Now the big problem here though is one, there's no agreement on how to regulate these things and in the conversations I've had at meetups, the question rapidly comes up, how do you even enforce it? If all these models are getting faster and more efficient and you can run them on laptops now, you can't put that genie back in the model, so does regulation even matter? Or if it does, how? So the big concern here with the regulatory environment at the federal and international level is existing power structures and the status quo. So the wealthy and powerful are going to want to remain the wealthiest and most powerful on the planet. That's just how it is and how it has always been. There have been reset events like, you know, the French Revolution, American Revolution, so on and so forth. There have been reset events in history, but they're generally violent and we want to avoid that. So do the powers that be also want to avoid that. But the biggest problem in these conversations that I've had is that things are advancing so fast and the gerontocracy, which is ruled by the elderly, old folks generally don't get AI. They don't understand how much is changing and why and what its impact is going to be. And that honestly could be one of the biggest risks, is us younger people, we get it, we see it coming. Even some of the people at the meetups that I talk to, their children are already acclimating to an AI world and they're gonna trust the AI more than people because it's like, well, politicians lie and yeah, chat GPT might get it wrong sometimes, but it's not gonna lie to you, not like a politician will. So we're in for some very interesting advancements on the regulatory front. Public perception and adaptation. So there's a lot of FUD, fear, uncertainty, and doubt, denialism, doomerism, and then also lots of people saying, oh, that's still decades away. It's not, it's months and years away, not decades. So another big problem is a lot of this uncertainty, a lot of this denialism. There's various aspects of the denialism. For instance, some people think, oh well AI is never going to be as smart as us or it's never going to be smarter than us, and it's like, yeah, I kind of think that it's already smarter than most people. It just lacks autonomy. But you know, that's my opinion and I know some of you disagree with it. Anyways, this is another big risk is because a lot of people are sticking their head in the sand. And then there's also comments around the world, like someone was saying that I think in France, like they don't even, people aren't even talking about it. Right. And so like all of this is happening so quickly and most people aren't even talking about it, right? So like all of this is happening so quickly and most people aren't even aware of it. Of course, chat GPT made it the news, but then people just kind of, you know, the world by and large collectively shrugged without understanding how fast this is ramping up. So public perception and acclimating to this could also be a big barrier. Global cooperation and collaboration. The big thing here is what I call trauma politics. So basically you look at people like Putin and Xi Jinping, both of whom suffered a tremendous amount of trauma at the hands of their dystopian governments. And they basically are seeking power for the purpose of self-soothing. That's pretty much all there is to it. But when people who have a tremendous amount of trauma come into power, they tend to have a more nihilistic worldview, which then results in things like genocide, mass incarceration, surveillance states, because they want control. They want as much control and power as they can get, and it's never enough. And so this nihilism also creates a self-fulfilling prophecy because they project their pain onto the world, which causes more trauma. Look at the war in Ukraine. Look at China's treatment of the Uyghurs, and then that creates a self-perpetuating loop of more trauma, intergenerational trauma, and so forth. So on and so forth. And so in my opinion, this unaddressed, basically intergenerational PTSD or nihilism is the greatest threat to humanity because these are the kinds of people who will look at these things, AI, and say, oh that's the perfect weapon for control, that's the perfect weapon for subjugation. Whereas healthy individuals look at AI and say, maybe we don't do that. Singularity facts. So there's a lot of kind of gotcha questions that come up. I tried to capture some of the best ones. What will happen to money post-singularity? Some people think like, oh, cryptocurrency is the future or maybe we get to do away with money altogether. Well, I've got some good news and some bad news. The good news is that it is entirely possible that money will change, monetary systems will change, and financial policies will change. However, the concept of currency, the concept of money, is too useful and too helpful because it is an abstract reserve of value, and it is also a really good medium of exchange. And so, you know, whether that means that Bitcoin or other cryptocurrencies are gonna, you know, replace fiat currency, I'm not really gonna say one way or another, but basically currency is here to stay in some form. Personally, I think that there's too many problems with cryptocurrency, namely that it is subject to manipulation because its value can change a lot, right? Like the wild swings of value of Bitcoin and stuff basically proves that it is not a stable reserve of value. And people have lost fortunes on it. People have made fortunes on it too. Usually people with not the best intentions, I don't want to say usually, but sometimes, basically organized crime loves cryptocurrency. What will happen to the human population? Now this one really kind of is interesting because there's a lot of debate over what is the actual carrying capacity of the planet. Some people say, oh it's easily 50 billion, and it's no it's not. Simply enough enough, no the carrying capacity of the planet is nowhere near 50 billion. There is technically enough room, physical room, for 50 billion humans, but when you look at the the constraints of thermodynamics, hydrological cycles, the amount of arable land, no. Now it is possible that the singularity with you know its results in nuclear fusion and stuff you could probably tip that a little bit further right especially if you can synthesize more arable land or grow food underground or desalinate water you could probably boost the carrying capacity of the planet quite a bit. 50 billion still seems way out there for me but the biggest thing is not gonna be those things. Like, okay, we overcome those energetic constraints. It's still gonna come down to mostly management, right? Sustainable management of the population. Because the thing is, if know, you if logistics breaks down today, we all starve pretty quickly, right? Because we don't have locally sourced food, our food and water requires a very stable infrastructure in order to provide that. And that only gets worse when you have like 50 billion people on the planet. So, you know, sustainable and responsible management of necessary resources, primarily food and water, are going to be the key to what happens with the human population. Now, in some of the discussions that I've had, there's a few confounding factors here. One thing that isn't mentioned on this slide is what happens if we solve aging? Because what happens with populations is as they become more gender equal, women choose to have fewer children. And so what if people are living longer but having fewer children? I kind of predict that the population is going to stabilize. There's always going to be some people who want children, but at the same time, right, like if you don't actually really deeply want children, you're probably not going to have them. And then in a post-scarcity life, like, maybe you choose never to have children. And again, some people will choose to have children, and even if you solve aging, people will still die. There's still going to be accidents, right? There's still going to be maybe a few, a handful of unsolved medical issues, but primarily you're going to see accidents. And also one of the conversations that came up was, okay, well, if you can hypothetically live forever, do you want to? And many people suspect that you won't actually want to live forever. You might choose to live for a few hundred years, but then you might get tired of life and then you know quit taking the life-extending medicine and allow yourself to die naturally. Who knows? But personally I kind of predict a population stabilization. Food. So food has been a big thing. So on top of you know vertical farming or underground farming powered by nuclear fusion, okay, great, we can eat whatever we want, wherever we want. I also suspect that biotechnology is going to really change our diet. And what I mean by that is synthetic foods, engineered foods, and even hyper-personalized diets. So, for instance, by and large you might believe that dairy is bad for you because it's you know got you know saturated fat in it, but when I started when I added more dairy to my diet all my numbers got better because it's just in my genes it's in whatever and so but I had to figure that out through trial and error. Dairy raises some people's cholesterol in my case it lowered it. So the combination of engineered foods, better bioinformatics and biotech and and things like mobile farms. Oh there's actually I actually saw an ad for it the first like portable farms are actually the the container shipping container farms are are coming. So that only that only ramps up and gets better over time so that means you go to the grocery store and everything that you could possibly want is there and it's fresh and it's local so that so you know some people are worried like oh well they're gonna take our steaks they're gonna take our burgers I don't think so I think think you're actually going to have much more options and they're going to be healthier options in a post-singularity world. War. So I did mention trauma politics and geopolitics earlier. Obviously the biggest, the absolute biggest risk here is an AI arms race. Even nations, liberal democracies that are not run by deeply traumatized tyrants are still going to be engaged in some kind of AI arms race, which is an unfortunate reality. I'm not saying that that's a good thing. I'm not passing moral judgment on it. It's just an observation. Every time there's new technology, it is integrated into the military apparatus. I also don't think that we're going to end up with a one world government, at least not any time soon, and there's numerous reasons for this, not the least of which is language barriers, cultural differences, past grievances between cultures. You know, it could take many, many generations to heal those intercultural wounds before people even want to collaborate. You look at the animosity between China and Japan, between Israel and Palestine, between Iran and a bunch of other nations, and so on and so forth. It takes a lot of work to heal those wounds. And there's a lot of resistance to healing those wounds. And those wounds could continue to fester. What I'm hoping is that AI actually helps us break the cycle of intergenerational trauma. And so then within maybe two or three generations, we're ready for a more peaceful global community. And again, I still don't think that a global government is going to happen just because, like, geographically speaking, like, it kind of makes sense to have the nations, the nation states, and then the union model. That makes the most sense right now. Like, you know, France is still France, Great Britain is still Great Britain, but they're part of the European Union, right? And over time, I do suspect that those continental-sized unions will get stronger, but not that they'll replace the local governments. Just like, you know, we have municipal, we have local city governments, we have county, we have state governments, and we have federal governments. I think that we're just going to add a few tiers on top of that, and eventually we will end up with a global governance. But again, I think that it's probably at least two or three generations away minimum. And then finally, corporations. So I did promise that I would address this. So some people, and this includes myself, I hope that corporations as we know them go away. Because corporations are intrinsically amoral, and I don't mean immoral, amoral. In corporations, their morality is only beholden to the investor, right, to the Corporations are intrinsically amoral, and I don't mean immoral, amoral. Corporations, their morality is only beholden to the investor, to the shareholders. And the shareholders just want more value, whatever it costs. Corporations will always explore every little nook and cranny of what they can legally get away with, and that often results in bad things things such as mistreatment of people, environmental abuse and so on. So because corporations are intrinsically amoral, I hope that they go away, but I don't think that they will. I tried to figure out how the singularity could result in this, but the more I explored it, the more I realized, like, no, basically what's going to happen is that AI is going to allow corporations to produce more with less. So productivity will continue to go up while headcount goes down. And I talked about this in my AI jobpocalypse video a couple months ago. Basically what's going to happen is that you're going to see corporations replace as many of their workers as they can. And so then you have the owner, the ownership class, whether it's shareholders, CEOs, whoever, is going to have basically unmitigated stock price growth. Because suddenly the greatest constraint and the most expensive aspect of running a corporation, human labor is no longer a factor. So I think that we are at risk of seeing like the megacorp things that you see in like dystopian sci-fi. I think that we probably are at risk of seeing, you know, multi-trillion dollar, quadrillion dollar companies out there that have almost no employees, that are all entirely run by shareholders and then AI. So that is an interesting thing. Now as to whether or not they will allow the rest of us to live in certain ways, I kind of think that they don't care, right? Because as obscenely wealthy as corporations are going to be, like, there's just, it doesn't make sense for them to expend any energy depriving everyone else. And so, like, let's just imagine that, like, Elon Musk takes SpaceX and uses it to start harvesting asteroids, and SpaceX becomes a 20 trillion dollar company by harvesting iridium and cobalt and platinum from asteroids. Great. Is Elon Musk going to personally say, actually I don't think that I think that everyone should live in slums and favelas around the world? No he's not gonna care. He doesn't give a crap how everyone else lives as long as he's a trillionaire, right? And so when I think it through it that way it's like it would take a lot of deliberate effort on corporate to on behalf of corporations to deliberately deprive the rest of us of a better life. So I don't think that's going to happen. Certainly it's something to be aware of because again, corporations are intrinsically amoral, which is one of the biggest risks to our standard of living in the future. Okay, that's that. Thanks for watching. I hope you found this video enlightening and thought-provoking Yeah, I know that uh There there will probably be some disagreements in the comments. Um, keep it civil or you get banned. Thanks. Bye", "chunks": [{"timestamp": [0.0, 4.0], "text": " Morning everybody, David Shapiro here with a video."}, {"timestamp": [4.0, 8.36], "text": " So my video about AGI was super popular."}, {"timestamp": [8.36, 14.76], "text": " I suppose I should have anticipated that, you know, making a bold declaration like AGI"}, {"timestamp": [14.76, 15.96], "text": " within 18 months."}, {"timestamp": [15.96, 24.96], "text": " So with that being said, the ramp up to AGI, ASI, or super intelligence, and then singularity"}, {"timestamp": [24.96, 26.32], "text": " seems like it's accelerating, especially if you go superintelligence, and then singularity seems like it's accelerating,"}, {"timestamp": [26.32, 28.32], "text": " especially if you go by Reddit comments"}, {"timestamp": [28.32, 30.72], "text": " on r slash singularity and a few other places,"}, {"timestamp": [30.72, 32.08], "text": " people are like, is this happening?"}, {"timestamp": [32.08, 33.92], "text": " Are we actually approaching the wall"}, {"timestamp": [33.92, 35.84], "text": " of exponential takeoff?"}, {"timestamp": [35.84, 38.32], "text": " So, assuming that that is the case"}, {"timestamp": [38.32, 40.04], "text": " and that we are ramping up to the singularity"}, {"timestamp": [40.04, 43.44], "text": " within the coming months or years or whatever,"}, {"timestamp": [43.44, 47.82], "text": " let's explore how the singularity will actually unfold."}, {"timestamp": [47.82, 51.24], "text": " First, we need to define singularity."}, {"timestamp": [51.24, 53.72], "text": " So what do we mean when we say singularity?"}, {"timestamp": [53.72, 57.06], "text": " There's obviously a lot of ways to define this thing"}, {"timestamp": [57.06, 59.04], "text": " and the simplest way that I could come up with"}, {"timestamp": [59.04, 61.88], "text": " to define it is just we say that the singularity"}, {"timestamp": [61.88, 65.1], "text": " is when AI becomes orders of magnitude more intelligent than"}, {"timestamp": [65.1, 67.06], "text": " all humans combined."}, {"timestamp": [67.06, 72.38], "text": " So basically if current trends continue in terms of AI research and the power of AI,"}, {"timestamp": [72.38, 80.48], "text": " GPT-4 is just as intelligent as many people, more intelligent than some, and GPT-5 is being"}, {"timestamp": [80.48, 84.26], "text": " trained and there's open source versions, etc."}, {"timestamp": [84.26, 86.16], "text": " So basically if you haven't been living"}, {"timestamp": [86.16, 88.08], "text": " under a rock you are probably"}, {"timestamp": [88.08, 89.96], "text": " aware of the rapid ramp up"}, {"timestamp": [90.16, 91.08], "text": " of A.I."}, {"timestamp": [91.2, 92.96], "text": " and it's not showing any signs of slowing down."}, {"timestamp": [92.96, 94.92], "text": " If anything it's accelerating because"}, {"timestamp": [94.92, 96.78], "text": " now we're not looking at A.I."}, {"timestamp": [96.8, 98.78], "text": " advancements on a monthly basis we're looking"}, {"timestamp": [98.8, 100.48], "text": " at it on a weekly basis."}, {"timestamp": [100.8, 102.76], "text": " I was actually at a meet up recently"}, {"timestamp": [102.76, 104.68], "text": " and someone pointed that out there like I think"}, {"timestamp": [104.68, 107.28], "text": " we're actually already in the singularity because we're measuring"}, {"timestamp": [107.28, 110.4], "text": " advancements on a week to week basis."}, {"timestamp": [110.4, 113.84], "text": " And soon we might be measuring it on a day to day basis."}, {"timestamp": [113.84, 117.32], "text": " Okay, so let's break this down."}, {"timestamp": [117.32, 123.92], "text": " What are some of the macroeconomic changes that we can expect to see with the singularity?"}, {"timestamp": [123.92, 126.68], "text": " First we have to talk about what remains scarce,"}, {"timestamp": [126.68, 128.56], "text": " because it's very easy to get caught up"}, {"timestamp": [128.56, 132.84], "text": " in this magical thinking of AI is going to change everything,"}, {"timestamp": [132.84, 135.04], "text": " but there's going to be some things that don't change"}, {"timestamp": [135.04, 137.96], "text": " with AI, no matter how smart it gets."}, {"timestamp": [137.96, 141.12], "text": " So if the singularity happens, there's a few things"}, {"timestamp": [141.12, 142.84], "text": " that are not really going to change that much."}, {"timestamp": [142.84, 145.04], "text": " So first is desirable and"}, {"timestamp": [145.04, 151.76], "text": " arable land. Some places will remain deserts, hence this AI generated image of a woman in a desert."}, {"timestamp": [152.72, 159.44], "text": " We'll get to that later when we talk about fusion. But fresh potable water, most of the water on the"}, {"timestamp": [159.44, 169.46], "text": " planet is also saltwater. Again, we might be able to change that if we solve nuclear fusion and other energy sources."}, {"timestamp": [169.46, 171.52], "text": " But then there's other physical resources,"}, {"timestamp": [171.52, 176.26], "text": " such as minerals and mined natural resources,"}, {"timestamp": [176.26, 179.5], "text": " that will also probably remain scarce no matter"}, {"timestamp": [179.5, 181.74], "text": " how intelligent AI becomes."}, {"timestamp": [181.74, 189.0], "text": " So this will be a really critical constraint, which could really drive up the value of some of these resources."}, {"timestamp": [189.0, 197.0], "text": " But, and as I mentioned, if we solve nuclear fusion we could desalinate water, we could irrigate deserts, and so on and so forth,"}, {"timestamp": [197.0, 205.08], "text": " but that could have unintended consequences. Because if suddenly you irrigate every desert on the planet, maybe those deserts actually form"}, {"timestamp": [205.08, 207.92], "text": " a really critical component of our ecosystem."}, {"timestamp": [207.92, 214.6], "text": " Lastly, if we solve space flight, we could probably start harvesting asteroids and even"}, {"timestamp": [214.6, 220.52], "text": " other planets for rare minerals because there are trillions and trillions and trillions"}, {"timestamp": [220.52, 224.64], "text": " of dollars worth of rare minerals out there on the solar system."}, {"timestamp": [224.64, 229.04], "text": " So it's entirely possible that all of these will actually be solved at some point in the"}, {"timestamp": [229.04, 233.48], "text": " future with the singularity, but at least in the short term, these will remain scarce"}, {"timestamp": [233.48, 234.48], "text": " resources."}, {"timestamp": [234.48, 240.28], "text": " Now, on the flip side, from a macroeconomic perspective, what becomes abundant with the"}, {"timestamp": [240.28, 241.28], "text": " singularity?"}, {"timestamp": [241.28, 246.88], "text": " The primary thing that becomes abundant with the singularity is knowledge, information, and cognitive labor."}, {"timestamp": [246.88, 248.24], "text": " So what I mean by cognitive labor"}, {"timestamp": [248.24, 252.3], "text": " is thinking, knowledge work, service industry jobs."}, {"timestamp": [252.3, 256.24], "text": " So basically what happens if AI becomes orders of magnitude"}, {"timestamp": [256.24, 258.8], "text": " smarter than humans and we remain in control of it,"}, {"timestamp": [258.8, 262.16], "text": " this is all assuming the good ending, right,"}, {"timestamp": [262.16, 263.6], "text": " that we don't get wiped out,"}, {"timestamp": [264.52, 265.88], "text": " basically what that means is"}, {"timestamp": [265.88, 271.68], "text": " that human cognitive effort becomes irrelevant. Now that sounds really awful"}, {"timestamp": [271.68, 276.08], "text": " but one thing that I realized while I was working on this is that on an"}, {"timestamp": [276.08, 282.52], "text": " individual basis most people's cognitive effort is already irrelevant, right? We're"}, {"timestamp": [282.52, 287.52], "text": " on a planet of eight billion people, chances are someone has already solved the problem that you are working on."}, {"timestamp": [287.52, 293.56], "text": " Whether or not you realize it is a different story, but you know, doing"}, {"timestamp": [293.56, 298.16], "text": " science and solving problems, it can be really difficult and it's mostly"}, {"timestamp": [298.16, 304.0], "text": " a matter of right place, right time, but you know, there are, well with that"}, {"timestamp": [304.0, 307.0], "text": " being said, there are still unsolved problems out there."}, {"timestamp": [307.0, 316.0], "text": " And the singularity with, you know, hyper-advanced AI will probably just result in kind of the same behavior that we're already seeing,"}, {"timestamp": [316.0, 320.0], "text": " because the collective wisdom of humanity solves problems pretty quickly, right?"}, {"timestamp": [320.0, 326.32], "text": " But the velocity of that problem-solving will probably go up, you know, maybe a few degrees maybe an order of magnitude"}, {"timestamp": [326.42, 328.42], "text": " not sure yet, but a"}, {"timestamp": [329.24, 334.06], "text": " hyper abundance of cognitive labor is is actually probably not going to be as"}, {"timestamp": [334.7, 337.16], "text": " immediately and dramatically impactful as you might think"}, {"timestamp": [337.56, 344.48], "text": " Because they like look at reddit and Twitter and other social media platforms that allow you to solve problems get answers"}, {"timestamp": [347.5, 351.9], "text": " and other social media platforms that allow you to solve problems, get answers, and move on very quickly. So basically, instead of having, you know, lazy Twitter or Reddit where you ask a problem,"}, {"timestamp": [351.9, 357.3], "text": " ask the machines for a problem, or, you know, people are collectively, now the machines are going to be doing it."}, {"timestamp": [357.3, 361.3], "text": " And actually, some of the people that I'm working with on these autonomous AI projects,"}, {"timestamp": [361.3, 369.64], "text": " one of the key things that we're working on is figuring out how to get AI to talk to each other in an autonomous manner that is safe and"}, {"timestamp": [369.64, 373.8], "text": " transparent, and this is where natural language comes in because you don't want"}, {"timestamp": [373.8, 378.04], "text": " AI using their own coded language to talk to each other, you want AI using"}, {"timestamp": [378.04, 386.36], "text": " human-readable natural language to talk to each other. Anyways, that's a topic for another video. So"}, {"timestamp": [386.36, 390.92], "text": " let's move forward from those macroeconomic changes to technological"}, {"timestamp": [390.92, 396.34], "text": " breakthroughs. If suddenly we have a hyperabundance of cognitive effort or"}, {"timestamp": [396.34, 401.64], "text": " cognitive labor, what kind of technology solutions can we imagine being solved? So"}, {"timestamp": [401.64, 406.32], "text": " first is high-energy physics. High-energy physics, the stuff"}, {"timestamp": [406.32, 411.44], "text": " that they're working on at the CERN, at LHC, this includes nuclear fusion. It"}, {"timestamp": [411.44, 416.46], "text": " could include even antimatter research. Who knows, maybe time travel, maybe faster"}, {"timestamp": [416.46, 420.2], "text": " than light travel. Not really sure, but at least the first problem that will likely"}, {"timestamp": [420.2, 429.5], "text": " be solved in high-energy physics is probably going to be nuclear fusion. It's really difficult to anticipate what solving nuclear fusion will do because"}, {"timestamp": [429.5, 434.64], "text": " nuclear fusion is a thousand times more powerful and efficient than any form of"}, {"timestamp": [434.64, 439.56], "text": " energy we have today. So when you have a hyperabundance of energy suddenly a lot"}, {"timestamp": [439.56, 443.4], "text": " of other things become possible. For instance you can then afford to"}, {"timestamp": [443.4, 451.32], "text": " desalinate as much water as you need. You can then afford to run underground farms, you know, that are completely unbounded"}, {"timestamp": [451.32, 457.14], "text": " from arable land. There's all kinds of stuff that you can do once you unlock nuclear fusion."}, {"timestamp": [457.14, 463.28], "text": " The knock-on effects of solving nuclear fusion are impossible to say. Not only just like"}, {"timestamp": [463.28, 469.32], "text": " in the short term, we can come up with a couple ideas, but certainly in the long term solving nuclear fusion solves so"}, {"timestamp": [469.32, 474.2], "text": " many other problems. It solves recycling because then suddenly you can afford to"}, {"timestamp": [474.2, 478.12], "text": " just melt down any material no matter how expensive it is, so you can reclaim"}, {"timestamp": [478.12, 483.4], "text": " all the lithium, all the cobalt, all the nickel from everything. Platinum, gold,"}, {"timestamp": [483.4, 485.64], "text": " pretty much every mineral becomes"}, {"timestamp": [485.64, 491.16], "text": " accessible no matter how difficult it is to isolate because suddenly if you have"}, {"timestamp": [491.16, 496.56], "text": " many many many gigajoules of energy available at all times for practically"}, {"timestamp": [496.56, 500.34], "text": " free it doesn't matter how much energy it costs to recycle a material. That's"}, {"timestamp": [500.34, 507.04], "text": " just another example. Another set of solved problems that you can expect with a hyperabundance"}, {"timestamp": [507.04, 514.88], "text": " of cognitive labor is basically disease genetics and aging. That, you know, the human body,"}, {"timestamp": [514.88, 521.68], "text": " our genetics, our metabolism, one of the most complex systems in existence. There's more than"}, {"timestamp": [521.68, 525.8], "text": " a hundred thousand metabolic pathways that we know of in the human body alone,"}, {"timestamp": [525.8, 530.5], "text": " and they all interact. Not only that, they interact with your genes, your epigenetics,"}, {"timestamp": [530.5, 535.0], "text": " your microflora, all kinds of stuff. Super complex system."}, {"timestamp": [535.0, 539.3], "text": " But, if you have a hyperabundance of intellect,"}, {"timestamp": [539.3, 551.76], "text": " then you can create new tools, you can create new processes, you can manage vast amounts of information and so then we might end up curing all disease, all aging and untangling all"}, {"timestamp": [551.76, 558.08], "text": " genetics within a relatively short period of time after achieving the singularity or"}, {"timestamp": [558.08, 561.2], "text": " AGI or however you want to call it."}, {"timestamp": [561.2, 563.24], "text": " And then finally material science."}, {"timestamp": [563.24, 567.8], "text": " So material science, we're already seeing the beginning of this with alpha fold."}, {"timestamp": [567.8, 571.88], "text": " And so basically imagine that you have alpha fold, which if you're not familiar with alpha"}, {"timestamp": [571.88, 579.8], "text": " fold, that is a way of using deep neural networks, using transformers to model protein folding,"}, {"timestamp": [579.8, 581.62], "text": " which was an unsolved problem."}, {"timestamp": [581.62, 585.2], "text": " But now that it's a solved problem, we can model any protein folding."}, {"timestamp": [585.2, 586.5], "text": " Now take that to the next level."}, {"timestamp": [586.5, 592.88], "text": " What if not only you can model all protein folding, you can model all protein interactions,"}, {"timestamp": [592.88, 594.52], "text": " all genetic interactions."}, {"timestamp": [594.52, 600.88], "text": " Then take that one step further, you can measure or model nanoparticles, carbon."}, {"timestamp": [600.88, 607.68], "text": " You can predict how to build very, very advanced materials which could revolutionize,"}, {"timestamp": [607.68, 610.68], "text": " for instance, batteries and computer technology."}, {"timestamp": [610.68, 617.9], "text": " I predict that the material science breakthroughs that will result from AI means that basically"}, {"timestamp": [617.9, 623.2], "text": " in five to ten years, your phone could be more powerful than all computers on earth"}, {"timestamp": [623.2, 624.2], "text": " today."}, {"timestamp": [624.2, 629.52], "text": " And I'm not really exaggerating when I say that because the amount of computational power"}, {"timestamp": [629.52, 634.08], "text": " just in the atoms of a phone, like if you have a membrane or whatever, or a three-dimensional"}, {"timestamp": [634.08, 642.52], "text": " wafer, the amount of potential computational power in matter is inconceivable, basically."}, {"timestamp": [642.52, 652.0], "text": " Inconceivable, basically. Inconceivable! So anyways, it would not surprise me if we move up a Kardashev scale or two post-singularity."}, {"timestamp": [652.0, 664.0], "text": " Now, that being said, there are still some unsolved problems that pretty much no amount of intellectual labor on Earth could solve."}, {"timestamp": [664.0, 666.72], "text": " So for instance, some people in the comments"}, {"timestamp": [666.72, 669.8], "text": " have asked about the hard problem of consciousness."}, {"timestamp": [669.8, 672.68], "text": " That may or may not be solvable by machines, period."}, {"timestamp": [672.68, 674.44], "text": " That might be something that we humans have"}, {"timestamp": [674.44, 677.52], "text": " to figure out for ourselves, which"}, {"timestamp": [677.52, 681.44], "text": " extends to fundamental questions of existence, of cosmology."}, {"timestamp": [681.44, 683.44], "text": " Some of these things are not necessarily"}, {"timestamp": [683.44, 685.16], "text": " a matter of, you know,"}, {"timestamp": [685.16, 689.12], "text": " mathematically proving it and measuring it in the lab. Some of these things are a"}, {"timestamp": [689.12, 693.36], "text": " matter of interpretation. Some of these things are a matter of subjective values"}, {"timestamp": [693.36, 699.04], "text": " such as the meaning of life, so on and so forth. Now, one thing that people imagine"}, {"timestamp": [699.04, 703.52], "text": " when we talk about transhumanism or post-humanism is that we will have some"}, {"timestamp": [703.52, 705.12], "text": " sort of transcendence event. I"}, {"timestamp": [706.0, 712.44], "text": " Personally don't think the singularity will result in some kind of transcendent event where we all become like Q from"}, {"timestamp": [712.76, 716.34], "text": " Star Trek or you know some final solution where we become"}, {"timestamp": [717.04, 720.52], "text": " Beings of energy. I also don't think that mind uploading is a good idea"}, {"timestamp": [720.52, 729.88], "text": " I know a lot of people think that that's great. but like we don't understand why we are conscious, you know, and basically I predict that, you know, if you try and upload"}, {"timestamp": [729.88, 733.8], "text": " your mind, you're just going to upload a copy of yourself and then your body will be dead."}, {"timestamp": [733.8, 737.84], "text": " And so subjectively you will have died, but a copy of you will continue on forever. So"}, {"timestamp": [737.84, 742.44], "text": " I don't think that mind uploading is a good idea, which if that's the case, then like"}, {"timestamp": [742.44, 745.04], "text": " we will forever be locked in our organic bodies"}, {"timestamp": [745.76, 747.76], "text": " Even if there are digital copies of us"}, {"timestamp": [748.2, 750.04], "text": " frolicking out in cyberspace"}, {"timestamp": [750.04, 754.4], "text": " they're not going to be us and they're gonna have an entirely different set of constraints because then if"}, {"timestamp": [754.48, 757.88], "text": " There if you become or a copy of you becomes a digital entity"}, {"timestamp": [757.88, 763.48], "text": " You suddenly don't have the same biological constraints. And so we have this like grand divergence of"}, {"timestamp": [764.04, 765.36], "text": " Digital post humans"}, {"timestamp": [765.36, 771.04], "text": " and then us organic meat bags. That to me sounds like an unsolved problem"}, {"timestamp": [771.04, 776.48], "text": " that I don't think AI is going to fix for us. Alright moving on to social"}, {"timestamp": [776.48, 790.08], "text": " changes. Jobs and occupations. So as machines get more intelligent, the TLDR is that most jobs are going to become irrelevant."}, {"timestamp": [790.08, 791.68], "text": " I've talked with people about this."}, {"timestamp": [791.68, 796.76], "text": " There's a lot of BS jobs out there that nobody really wants to do, but you do it because"}, {"timestamp": [796.76, 802.0], "text": " you need to eat and you need to pay for your house and whatever."}, {"timestamp": [802.0, 808.88], "text": " And so what we're going to have to do is then recalibrate how we think of meaning and purpose"}, {"timestamp": [808.88, 810.84], "text": " and success."}, {"timestamp": [810.84, 817.48], "text": " And this includes maybe shifting and having a greater emphasis on creativity exploration"}, {"timestamp": [817.48, 819.52], "text": " and self-improvement."}, {"timestamp": [819.52, 828.04], "text": " And then one idea that came from discussing this with ChatGPT was that as a society, we might instead of focusing"}, {"timestamp": [828.04, 831.64], "text": " on conformance to one standard of education,"}, {"timestamp": [831.64, 835.88], "text": " we might instead really focus on what makes everyone unique,"}, {"timestamp": [835.88, 839.76], "text": " which was a really interesting new model of education."}, {"timestamp": [839.76, 841.72], "text": " So imagine that you go to school"}, {"timestamp": [841.72, 844.64], "text": " and instead of like everyone has the same classes,"}, {"timestamp": [844.64, 850.36], "text": " you have a broad variety of projects and experiments and things to figure out what it is that one,"}, {"timestamp": [850.36, 853.76], "text": " you really care about, and two, what really makes you stand out."}, {"timestamp": [853.76, 859.92], "text": " And so then everyone can have a very different focus on education."}, {"timestamp": [859.92, 864.84], "text": " My first year of school was at Montessori School, and so I can imagine taking that to"}, {"timestamp": [864.84, 869.28], "text": " the next level. Anyways, I know that there's a lot of people that say, oh"}, {"timestamp": [869.28, 874.18], "text": " well without a job we have no meaning. That is your neoliberal programming"}, {"timestamp": [874.18, 879.76], "text": " speaking. I and other people that have made a transition to a different"}, {"timestamp": [879.76, 885.04], "text": " kind of occupation, you know, my occupation is now YouTube and Patreon, which I find much more"}, {"timestamp": [885.04, 893.6], "text": " interesting and rewarding, is much closer to lifestyles that have existed in the past."}, {"timestamp": [893.6, 899.52], "text": " So for instance, in ancient Greece, particularly in Sparta, Spartan citizens were not allowed to"}, {"timestamp": [899.52, 905.68], "text": " have a job. Their job was to be soldiers, to be hunters, to be politicians, to participate"}, {"timestamp": [905.68, 912.48], "text": " in culture and society, not to be leather workers or anything else. And so obviously"}, {"timestamp": [912.48, 917.24], "text": " ancient Sparta didn't, ultimately didn't do so well. Ancient Athens, they did much"}, {"timestamp": [917.24, 922.4], "text": " better. Very similar model with the citizen class, the leisure class."}, {"timestamp": [922.4, 927.36], "text": " Ditto for ancient Rome. So humans have adapted to kind of these,"}, {"timestamp": [927.36, 930.92], "text": " effectively a post-scarcity world before,"}, {"timestamp": [930.92, 932.6], "text": " but instead of working on the backs"}, {"timestamp": [932.6, 935.3], "text": " of subjugated classes of people,"}, {"timestamp": [935.3, 940.3], "text": " we will all enter into a post-scarcity leisure class"}, {"timestamp": [940.58, 941.88], "text": " on the backs of AI."}, {"timestamp": [941.88, 944.12], "text": " That's kind of what I predict is gonna happen."}, {"timestamp": [944.12, 946.0], "text": " Because honestly, most people want that anyways,"}, {"timestamp": [946.0, 949.0], "text": " and if we have a collective willpower to want that, who cares?"}, {"timestamp": [949.0, 952.0], "text": " And I can hear some of you already complaining,"}, {"timestamp": [952.0, 955.0], "text": " corporations are never going to allow that to happen. I'm going to get to that in just a second."}, {"timestamp": [955.0, 958.0], "text": " Glad you asked. Okay, so if we"}, {"timestamp": [958.0, 961.0], "text": " if nobody's job"}, {"timestamp": [961.0, 964.0], "text": " really matters, what do we do then?"}, {"timestamp": [964.0, 968.34], "text": " One of the conversations that I had at a meetup was like, well, what if everyone just plays video games?"}, {"timestamp": [968.46, 971.02], "text": " There's actually a reason that video games are so popular."}, {"timestamp": [971.7, 978.14], "text": " Because video games can foster social connection, right? A lot of games are very, very social today."}, {"timestamp": [978.14, 984.62], "text": " And they're also challenging, which means that they give you a sense of competence, a sense of mastery."}, {"timestamp": [984.6, 988.6], "text": " which means that they give you a sense of competence, a sense of mastery. And finally, video games give you a lot more autonomy,"}, {"timestamp": [988.6, 991.8], "text": " like you can be anyone that you want in a video game world,"}, {"timestamp": [991.8, 996.3], "text": " and those three things satisfy the three pillars of self-determination theory,"}, {"timestamp": [996.3, 998.4], "text": " autonomy, human connection, and competence,"}, {"timestamp": [998.4, 1001.0], "text": " which is why so many people play video games."}, {"timestamp": [1001.0, 1004.6], "text": " So if you look at SDT, self-determination theory,"}, {"timestamp": [1004.6, 1005.22], "text": " and then you"}, {"timestamp": [1005.22, 1011.0], "text": " say, okay, well, take away the need for a job, and suddenly AI gives us all a lot"}, {"timestamp": [1011.0, 1015.42], "text": " more autonomy, gives us an opportunity for more human connection, the only"}, {"timestamp": [1015.42, 1019.62], "text": " remaining thing is challenge. And what happens for a lot of people who retire"}, {"timestamp": [1019.62, 1028.84], "text": " or step away from conventional work is that we realize, like, oh wait, I can challenge myself in new ways. All of you that watch my YouTube"}, {"timestamp": [1028.84, 1029.36], "text": " channel,"}, {"timestamp": [1029.36, 1032.84], "text": " I don't actually need to do all the coding experiments that I do, but I find"}, {"timestamp": [1032.84, 1034.4], "text": " it deeply satisfying"}, {"timestamp": [1034.4, 1037.48], "text": " to challenge myself to try and solve the problems out there."}, {"timestamp": [1037.48, 1041.64], "text": " And I'm not saying everyone is gonna engage in this kind of problem-solving."}, {"timestamp": [1041.64, 1044.96], "text": " Some people are gonna go to do martial arts or"}, {"timestamp": [1044.96, 1045.44], "text": " go climb"}, {"timestamp": [1045.44, 1051.76], "text": " mountains or whatever, but we humans love, love challenges. We need to feel competent"}, {"timestamp": [1051.76, 1058.56], "text": " and we need to have a sense of mastery. And the Sam Altman interview, he pointed out that yes,"}, {"timestamp": [1058.56, 1063.44], "text": " AI has solved Go and chess and other things, but we still play chess. We just don't play against"}, {"timestamp": [1063.44, 1065.16], "text": " computers because there's no point."}, {"timestamp": [1065.16, 1069.26], "text": " There's no sense of mastery against something that you're never going to win against."}, {"timestamp": [1069.26, 1073.8], "text": " So anyways, the long-term effect of this is that we're probably going to see new social"}, {"timestamp": [1073.8, 1080.16], "text": " structures emerge or maybe even older social structures re-emerge."}, {"timestamp": [1080.16, 1090.0], "text": " I particularly predict that we're going to see more multi-generational homes, more kind of tribal or village lifestyle things re-emerge."}, {"timestamp": [1090.0, 1100.0], "text": " Because suddenly it's like, okay, well, here's a dozen people that I really like and none of us have a job, so let's go form an eco-village out in the countryside."}, {"timestamp": [1100.0, 1105.64], "text": " Or maybe an urban co-living situation in the city. Who knows?"}, {"timestamp": [1105.64, 1107.92], "text": " Just some speculation there."}, {"timestamp": [1107.92, 1111.04], "text": " Okay, so I promised that we would address"}, {"timestamp": [1111.04, 1112.12], "text": " some of the elephants in the room."}, {"timestamp": [1112.12, 1114.94], "text": " So let's unpack all the risks and factors"}, {"timestamp": [1114.94, 1119.32], "text": " that will go into this rosy post-singularity result"}, {"timestamp": [1119.32, 1121.04], "text": " that I have outlined."}, {"timestamp": [1121.04, 1126.4], "text": " So the first one is the development and control of AI. Obviously many of you are"}, {"timestamp": [1126.4, 1131.4], "text": " probably aware that there's been a the letter circulating that's signed by a"}, {"timestamp": [1131.4, 1137.44], "text": " whole bunch of people including Elon Musk and Max Tegmark all calling for a"}, {"timestamp": [1137.44, 1141.8], "text": " moratorium on the advancement of AI for at least six months while we take a"}, {"timestamp": [1141.8, 1146.24], "text": " breath and reassess. So it is possible that if"}, {"timestamp": [1146.24, 1151.96], "text": " we continue at a breakneck pace and things do it and people do it wrong then"}, {"timestamp": [1151.96, 1157.2], "text": " we're gonna end up in some kind of dystopian or cataclysmic outcome. So"}, {"timestamp": [1157.2, 1162.96], "text": " there's basically two primary failure modes for this. One is we lose control of"}, {"timestamp": [1162.96, 1165.6], "text": " the AI and it decides to kill us all."}, {"timestamp": [1165.6, 1168.8], "text": " The other major failure mode is that we"}, {"timestamp": [1168.8, 1170.96], "text": " don't lose control of AI, but the wrong people"}, {"timestamp": [1170.96, 1174.0], "text": " get the powerful AI, and they use it to kill everyone else"}, {"timestamp": [1174.0, 1175.68], "text": " or subjugate everyone else."}, {"timestamp": [1175.68, 1178.0], "text": " So those are the two primary failure modes"}, {"timestamp": [1178.0, 1181.08], "text": " that have to do with AI development and control."}, {"timestamp": [1181.08, 1184.18], "text": " And this has been explored in a lot of fiction."}, {"timestamp": [1184.18, 1185.0], "text": " And so I'm kind of tired of it."}, {"timestamp": [1185.0, 1188.0], "text": " So I'm not going to really talk about it that much more."}, {"timestamp": [1188.0, 1193.0], "text": " But point being is that 99 percent of people don't really want an AI apocalypse."}, {"timestamp": [1193.0, 1196.0], "text": " Some people seem to really wish for it."}, {"timestamp": [1196.0, 1199.0], "text": " But I think that's a sense of nihilism leaking through."}, {"timestamp": [1199.0, 1202.0], "text": " Some people think it's inevitable and there's a sort of fatalism about it."}, {"timestamp": [1202.0, 1207.0], "text": " And that, again, you know, I empathize with people like that."}, {"timestamp": [1207.0, 1210.84], "text": " I echo Sam Altman's sentiment that like, yeah, there are a lot of people afraid and I'm not"}, {"timestamp": [1210.84, 1215.56], "text": " going to tell them that they're wrong or that they're stupid or that it's magical thinking."}, {"timestamp": [1215.56, 1218.0], "text": " Like we are playing with fire."}, {"timestamp": [1218.0, 1222.68], "text": " I just happen to be very sanguine about it because I feel like, one, all the problems"}, {"timestamp": [1222.68, 1224.54], "text": " that exist are solvable."}, {"timestamp": [1224.54, 1226.6], "text": " And two, I think that they are solvable"}, {"timestamp": [1226.6, 1229.0], "text": " in the very near term."}, {"timestamp": [1229.0, 1232.8], "text": " Okay, another big risk is distribution of benefits."}, {"timestamp": [1232.8, 1234.7], "text": " This is one of the biggest things"}, {"timestamp": [1234.7, 1237.04], "text": " that people are worried about, which is, okay,"}, {"timestamp": [1238.12, 1241.16], "text": " do you, like, one of the most common pushbacks is,"}, {"timestamp": [1241.16, 1243.28], "text": " like, do you honestly think that corporations"}, {"timestamp": [1243.28, 1249.8], "text": " are gonna allow everyone to live a luxurious lifestyle lifestyle or that the rich and powerful are going to allow"}, {"timestamp": [1249.8, 1252.56], "text": " everyone else to live like they do?"}, {"timestamp": [1252.56, 1256.24], "text": " Well, first, I don't know that they'll have that much of a choice in it."}, {"timestamp": [1256.24, 1262.04], "text": " But two, I think the fact that the masses, like you and I, the proletariat, we don't"}, {"timestamp": [1262.04, 1264.58], "text": " want to live in a cyberpunk hell, right?"}, {"timestamp": [1264.58, 1270.72], "text": " And we have seen what happens repeatedly through history as people get hungrier and more desperate."}, {"timestamp": [1270.72, 1275.48], "text": " The most recent incident was the Arab Spring, in which case much of the Middle East, the"}, {"timestamp": [1275.48, 1282.46], "text": " Arab world, rose up and the primary driving factor was economic conditions."}, {"timestamp": [1282.46, 1285.7], "text": " And then, of course, you go back even further, the French Revolution."}, {"timestamp": [1285.7, 1288.56], "text": " This kind of thing has happened time and time again."}, {"timestamp": [1288.56, 1292.78], "text": " So I'm not too particularly worried about that because push comes to shove, people are"}, {"timestamp": [1292.78, 1296.4], "text": " going to stand up and redistribute forcefully."}, {"timestamp": [1296.4, 1300.4], "text": " Now I'm not advocating for, you know, civil war or anything."}, {"timestamp": [1300.4, 1308.84], "text": " I don't even think it's going to come to that because, you know, I follow Davos and World Economic Forum and UN and, and all the, you know,"}, {"timestamp": [1308.84, 1312.36], "text": " halls of power, IMF, the World Bank, um,"}, {"timestamp": [1312.68, 1315.8], "text": " the halls of power really are paying attention to this."}, {"timestamp": [1315.8, 1319.36], "text": " And I think that they're preparing for it, honestly. So for instance,"}, {"timestamp": [1319.36, 1322.48], "text": " I suspect that the, uh, the,"}, {"timestamp": [1322.48, 1326.58], "text": " the stimulus checks that America did during the pandemic, I think that"}, {"timestamp": [1326.58, 1331.04], "text": " that was a pilot program to demonstrate that redistribution works, that it is"}, {"timestamp": [1331.04, 1334.84], "text": " fast, efficient, and fair, because what they did was they did these stimulus"}, {"timestamp": [1334.84, 1341.08], "text": " checks alongside the paycheck protection program, the PPP loans, and they"}, {"timestamp": [1341.08, 1346.0], "text": " basically did a side-by-side test showing, showing look the PPP loans are expensive and rife"}, {"timestamp": [1346.0, 1350.48], "text": " with corruption and the stimulus checks went directly to people who needed it and it all got"}, {"timestamp": [1350.48, 1357.52], "text": " spent by individuals who needed it. So I kind of think that the stimulus checks were a pilot"}, {"timestamp": [1357.52, 1365.5], "text": " program or a prototype for UBI and when you look at the landscape right now where there's been over 300,000 tech layoffs"}, {"timestamp": [1365.5, 1371.7], "text": " and more other kinds of people are already starting to get laid off and notified of layoffs"}, {"timestamp": [1371.7, 1374.2], "text": " due to technologies like chat GPT."}, {"timestamp": [1374.2, 1378.0], "text": " My fiancee who's a writer and is in a lot of writing discords,"}, {"timestamp": [1378.0, 1383.2], "text": " there are copywriters out there who are already getting laid off and losing work to AI."}, {"timestamp": [1383.2, 1386.7], "text": " So like the AI layoffs are coming so I"}, {"timestamp": [1386.7, 1391.46], "text": " think that we're also gonna see a lot of stimulus checks coming and it's just a"}, {"timestamp": [1391.46, 1395.56], "text": " matter of okay are these stimulus checks permanent and I think that they will be."}, {"timestamp": [1395.56, 1401.36], "text": " The regulatory environment. So this is where that letter that just came out is"}, {"timestamp": [1401.36, 1407.94], "text": " is asking for regulation. Sam Altman has asked for regulation, Elon Musk has asked for regulation, all kinds of"}, {"timestamp": [1407.94, 1410.34], "text": " people are asking for more regulation."}, {"timestamp": [1410.34, 1415.76], "text": " Now the big problem here though is one, there's no agreement on how to regulate these things"}, {"timestamp": [1415.76, 1420.8], "text": " and in the conversations I've had at meetups, the question rapidly comes up, how do you"}, {"timestamp": [1420.8, 1422.52], "text": " even enforce it?"}, {"timestamp": [1422.52, 1428.76], "text": " If all these models are getting faster and more efficient and you can run them on laptops now, you can't put"}, {"timestamp": [1428.76, 1434.04], "text": " that genie back in the model, so does regulation even matter? Or if it does, how?"}, {"timestamp": [1434.04, 1439.72], "text": " So the big concern here with the regulatory environment at the federal"}, {"timestamp": [1439.72, 1444.3], "text": " and international level is existing power structures and the status quo. So"}, {"timestamp": [1444.3, 1448.06], "text": " the wealthy and powerful are going to want to remain the wealthiest and most powerful"}, {"timestamp": [1448.06, 1449.06], "text": " on the planet."}, {"timestamp": [1449.06, 1451.8], "text": " That's just how it is and how it has always been."}, {"timestamp": [1451.8, 1456.44], "text": " There have been reset events like, you know, the French Revolution, American Revolution,"}, {"timestamp": [1456.44, 1457.44], "text": " so on and so forth."}, {"timestamp": [1457.44, 1460.78], "text": " There have been reset events in history, but they're generally violent and we want to"}, {"timestamp": [1460.78, 1461.98], "text": " avoid that."}, {"timestamp": [1461.98, 1465.44], "text": " So do the powers that be also want to avoid that."}, {"timestamp": [1465.44, 1469.66], "text": " But the biggest problem in these conversations that I've had is that things are advancing"}, {"timestamp": [1469.66, 1476.04], "text": " so fast and the gerontocracy, which is ruled by the elderly, old folks generally don't"}, {"timestamp": [1476.04, 1477.04], "text": " get AI."}, {"timestamp": [1477.04, 1482.04], "text": " They don't understand how much is changing and why and what its impact is going to be."}, {"timestamp": [1482.04, 1489.48], "text": " And that honestly could be one of the biggest risks, is us younger people, we get it, we see it coming."}, {"timestamp": [1489.48, 1491.7], "text": " Even some of the people at the meetups that I talk to,"}, {"timestamp": [1491.7, 1496.7], "text": " their children are already acclimating to an AI world"}, {"timestamp": [1496.7, 1498.6], "text": " and they're gonna trust the AI more than people"}, {"timestamp": [1498.6, 1500.04], "text": " because it's like, well, politicians lie"}, {"timestamp": [1500.04, 1502.38], "text": " and yeah, chat GPT might get it wrong sometimes,"}, {"timestamp": [1502.38, 1503.56], "text": " but it's not gonna lie to you,"}, {"timestamp": [1503.56, 1505.0], "text": " not like a politician will."}, {"timestamp": [1505.0, 1508.32], "text": " So we're in for some very interesting advancements"}, {"timestamp": [1508.32, 1509.66], "text": " on the regulatory front."}, {"timestamp": [1511.12, 1513.44], "text": " Public perception and adaptation."}, {"timestamp": [1513.44, 1517.08], "text": " So there's a lot of FUD, fear, uncertainty, and doubt,"}, {"timestamp": [1517.08, 1519.96], "text": " denialism, doomerism, and then also lots of people saying,"}, {"timestamp": [1519.96, 1521.28], "text": " oh, that's still decades away."}, {"timestamp": [1521.28, 1525.32], "text": " It's not, it's months and years away, not decades. So"}, {"timestamp": [1525.32, 1530.44], "text": " another big problem is a lot of this uncertainty, a lot of this denialism."}, {"timestamp": [1530.44, 1535.12], "text": " There's various aspects of the denialism. For instance, some"}, {"timestamp": [1535.12, 1538.32], "text": " people think, oh well AI is never going to be as smart as us or it's never going"}, {"timestamp": [1538.32, 1540.96], "text": " to be smarter than us, and it's like, yeah, I kind of think that it's already"}, {"timestamp": [1540.96, 1545.4], "text": " smarter than most people. It just lacks autonomy."}, {"timestamp": [1545.4, 1549.68], "text": " But you know, that's my opinion and I know some of you disagree with it."}, {"timestamp": [1549.68, 1553.44], "text": " Anyways, this is another big risk is because a lot of people are sticking their head in"}, {"timestamp": [1553.44, 1554.44], "text": " the sand."}, {"timestamp": [1554.44, 1557.76], "text": " And then there's also comments around the world, like someone was saying that I think"}, {"timestamp": [1557.76, 1561.72], "text": " in France, like they don't even, people aren't even talking about it."}, {"timestamp": [1561.72, 1562.72], "text": " Right."}, {"timestamp": [1562.72, 1565.36], "text": " And so like all of this is happening so quickly and most people aren't even talking about it, right? So like all of this is happening so quickly"}, {"timestamp": [1570.08, 1574.32], "text": " and most people aren't even aware of it. Of course, chat GPT made it the news, but then people just kind of, you know, the world by and large collectively shrugged without understanding"}, {"timestamp": [1574.32, 1580.56], "text": " how fast this is ramping up. So public perception and acclimating to this could also be a big barrier."}, {"timestamp": [1582.0, 1591.16], "text": " Global cooperation and collaboration. The big thing here is what I call trauma politics."}, {"timestamp": [1591.16, 1597.12], "text": " So basically you look at people like Putin and Xi Jinping, both of whom suffered a tremendous"}, {"timestamp": [1597.12, 1605.2], "text": " amount of trauma at the hands of their dystopian governments. And they basically are seeking power"}, {"timestamp": [1605.2, 1609.08], "text": " for the purpose of self-soothing."}, {"timestamp": [1609.08, 1611.12], "text": " That's pretty much all there is to it."}, {"timestamp": [1611.12, 1614.64], "text": " But when people who have a tremendous amount of trauma"}, {"timestamp": [1614.64, 1617.52], "text": " come into power, they tend to have"}, {"timestamp": [1617.52, 1620.96], "text": " a more nihilistic worldview, which then results"}, {"timestamp": [1620.96, 1624.96], "text": " in things like genocide, mass incarceration, surveillance"}, {"timestamp": [1624.96, 1625.56], "text": " states,"}, {"timestamp": [1625.56, 1626.86], "text": " because they want control."}, {"timestamp": [1626.86, 1629.3], "text": " They want as much control and power as they can get,"}, {"timestamp": [1629.3, 1631.02], "text": " and it's never enough."}, {"timestamp": [1632.56, 1637.56], "text": " And so this nihilism also creates a self-fulfilling prophecy"}, {"timestamp": [1637.9, 1641.28], "text": " because they project their pain onto the world,"}, {"timestamp": [1641.28, 1642.56], "text": " which causes more trauma."}, {"timestamp": [1642.56, 1644.36], "text": " Look at the war in Ukraine."}, {"timestamp": [1644.36, 1646.92], "text": " Look at China's treatment of the Uyghurs, and then"}, {"timestamp": [1646.92, 1651.44], "text": " that creates a self-perpetuating loop of more trauma, intergenerational trauma, and"}, {"timestamp": [1651.44, 1652.16], "text": " so forth."}, {"timestamp": [1652.16, 1655.24], "text": " So on and so forth. And so in my opinion,"}, {"timestamp": [1655.24, 1660.44], "text": " this unaddressed, basically intergenerational PTSD or nihilism"}, {"timestamp": [1660.44, 1663.84], "text": " is the greatest threat to humanity because these are the kinds of people"}, {"timestamp": [1663.84, 1667.72], "text": " who will look at these things, AI, and say, oh that's the perfect weapon for"}, {"timestamp": [1667.72, 1672.24], "text": " control, that's the perfect weapon for subjugation. Whereas healthy individuals"}, {"timestamp": [1672.24, 1679.92], "text": " look at AI and say, maybe we don't do that. Singularity facts. So there's a lot"}, {"timestamp": [1679.92, 1685.08], "text": " of kind of gotcha questions that come up. I tried to capture some of the best ones."}, {"timestamp": [1685.08, 1690.42], "text": " What will happen to money post-singularity? Some people think like, oh, cryptocurrency"}, {"timestamp": [1690.42, 1695.42], "text": " is the future or maybe we get to do away with money altogether. Well, I've got some good"}, {"timestamp": [1695.42, 1702.62], "text": " news and some bad news. The good news is that it is entirely possible that money will change,"}, {"timestamp": [1702.62, 1705.32], "text": " monetary systems will change, and financial policies will change."}, {"timestamp": [1705.72, 1711.72], "text": " However, the concept of currency, the concept of money, is too useful and too helpful because"}, {"timestamp": [1712.48, 1714.48], "text": " it is an abstract"}, {"timestamp": [1714.64, 1718.2], "text": " reserve of value, and it is also a really good medium of exchange."}, {"timestamp": [1718.2, 1725.76], "text": " And so, you know, whether that means that Bitcoin or other cryptocurrencies are gonna, you know, replace"}, {"timestamp": [1725.76, 1732.32], "text": " fiat currency, I'm not really gonna say one way or another, but basically currency is here to stay in some form."}, {"timestamp": [1732.32, 1736.32], "text": " Personally, I think that there's too many problems with cryptocurrency,"}, {"timestamp": [1736.32, 1742.0], "text": " namely that it is subject to manipulation because its value can change"}, {"timestamp": [1742.0, 1748.56], "text": " a lot, right? Like the wild swings of value of Bitcoin and stuff"}, {"timestamp": [1748.56, 1751.92], "text": " basically proves that it is not a stable reserve of value."}, {"timestamp": [1751.92, 1754.64], "text": " And people have lost fortunes on it."}, {"timestamp": [1754.64, 1756.4], "text": " People have made fortunes on it too."}, {"timestamp": [1756.4, 1760.88], "text": " Usually people with not the best intentions,"}, {"timestamp": [1760.88, 1762.72], "text": " I don't want to say usually, but sometimes,"}, {"timestamp": [1762.72, 1771.7], "text": " basically organized crime loves cryptocurrency. What will happen to the human population? Now this one really"}, {"timestamp": [1771.7, 1776.98], "text": " kind of is interesting because there's a lot of debate over what is the actual"}, {"timestamp": [1776.98, 1781.84], "text": " carrying capacity of the planet. Some people say, oh it's easily 50 billion, and"}, {"timestamp": [1781.84, 1787.04], "text": " it's no it's not. Simply enough enough, no the carrying capacity of the planet is nowhere"}, {"timestamp": [1787.04, 1793.44], "text": " near 50 billion. There is technically enough room, physical room, for 50 billion humans,"}, {"timestamp": [1793.44, 1798.8], "text": " but when you look at the the constraints of thermodynamics, hydrological cycles,"}, {"timestamp": [1798.8, 1806.54], "text": " the amount of arable land, no. Now it is possible that the singularity with you know its results in"}, {"timestamp": [1806.54, 1810.14], "text": " nuclear fusion and stuff you could probably tip that a little bit further"}, {"timestamp": [1810.14, 1814.94], "text": " right especially if you can synthesize more arable land or grow food"}, {"timestamp": [1814.94, 1819.62], "text": " underground or desalinate water you could probably boost the carrying"}, {"timestamp": [1819.62, 1823.82], "text": " capacity of the planet quite a bit. 50 billion still seems way out there for me"}, {"timestamp": [1823.82, 1827.16], "text": " but the biggest thing is not gonna be those things."}, {"timestamp": [1827.16, 1832.16], "text": " Like, okay, we overcome those energetic constraints."}, {"timestamp": [1832.24, 1837.24], "text": " It's still gonna come down to mostly management, right?"}, {"timestamp": [1837.64, 1840.76], "text": " Sustainable management of the population."}, {"timestamp": [1840.76, 1846.12], "text": " Because the thing is, if know, you if logistics breaks down"}, {"timestamp": [1846.12, 1848.08], "text": " today, we all starve pretty quickly,"}, {"timestamp": [1848.16, 1850.16], "text": " right? Because we don't have locally"}, {"timestamp": [1850.16, 1851.72], "text": " sourced food, our food"}, {"timestamp": [1852.68, 1854.76], "text": " and water requires"}, {"timestamp": [1855.08, 1857.6], "text": " a very stable infrastructure"}, {"timestamp": [1857.84, 1859.04], "text": " in order to provide that."}, {"timestamp": [1859.68, 1860.8], "text": " And that only gets worse when you"}, {"timestamp": [1860.8, 1862.16], "text": " have like 50 billion people on the"}, {"timestamp": [1862.16, 1863.04], "text": " planet."}, {"timestamp": [1863.04, 1864.96], "text": " So, you know, sustainable and"}, {"timestamp": [1864.96, 1872.24], "text": " responsible management of necessary resources, primarily food and water, are going to be the key"}, {"timestamp": [1872.24, 1877.28], "text": " to what happens with the human population. Now, in some of the discussions that I've had, there's a"}, {"timestamp": [1877.28, 1890.8], "text": " few confounding factors here. One thing that isn't mentioned on this slide is what happens if we solve aging? Because what happens with populations is as they become more gender equal, women choose to have fewer"}, {"timestamp": [1890.8, 1895.56], "text": " children. And so what if people are living longer but having fewer children?"}, {"timestamp": [1895.56, 1899.56], "text": " I kind of predict that the population is going to stabilize. There's always going"}, {"timestamp": [1899.56, 1905.92], "text": " to be some people who want children, but at the same time, right, like if you don't"}, {"timestamp": [1905.92, 1909.32], "text": " actually really deeply want children, you're probably not going to have them."}, {"timestamp": [1909.32, 1914.72], "text": " And then in a post-scarcity life, like, maybe you choose never to have children."}, {"timestamp": [1914.72, 1918.84], "text": " And again, some people will choose to have children, and even if you solve"}, {"timestamp": [1918.84, 1922.02], "text": " aging, people will still die. There's still going to be accidents, right?"}, {"timestamp": [1922.02, 1929.68], "text": " There's still going to be maybe a few, a handful of unsolved medical issues, but primarily you're going to see accidents."}, {"timestamp": [1929.68, 1935.76], "text": " And also one of the conversations that came up was, okay, well, if you can hypothetically"}, {"timestamp": [1935.76, 1941.52], "text": " live forever, do you want to? And many people suspect that you won't actually want to live"}, {"timestamp": [1941.52, 1946.28], "text": " forever. You might choose to live for a few hundred years, but then you might get tired of life and then you know quit"}, {"timestamp": [1946.28, 1950.64], "text": " taking the life-extending medicine and allow yourself to die naturally. Who"}, {"timestamp": [1950.64, 1958.64], "text": " knows? But personally I kind of predict a population stabilization. Food. So food"}, {"timestamp": [1958.64, 1964.56], "text": " has been a big thing. So on top of you know vertical farming or underground"}, {"timestamp": [1964.56, 1966.88], "text": " farming powered by nuclear fusion, okay, great,"}, {"timestamp": [1966.88, 1969.36], "text": " we can eat whatever we want, wherever we want."}, {"timestamp": [1969.36, 1975.48], "text": " I also suspect that biotechnology is going to really change our diet."}, {"timestamp": [1975.48, 1981.88], "text": " And what I mean by that is synthetic foods, engineered foods, and even hyper-personalized"}, {"timestamp": [1981.88, 1982.88], "text": " diets."}, {"timestamp": [1982.88, 1986.3], "text": " So, for instance, by and large you might believe"}, {"timestamp": [1986.3, 1991.64], "text": " that dairy is bad for you because it's you know got you know saturated fat in"}, {"timestamp": [1991.64, 1997.68], "text": " it, but when I started when I added more dairy to my diet all my numbers got"}, {"timestamp": [1997.68, 2002.12], "text": " better because it's just in my genes it's in whatever and so but I had to"}, {"timestamp": [2002.12, 2009.36], "text": " figure that out through trial and error. Dairy raises some people's cholesterol in my case it lowered it. So the"}, {"timestamp": [2009.36, 2015.12], "text": " combination of engineered foods, better bioinformatics and biotech and and"}, {"timestamp": [2015.12, 2018.96], "text": " things like mobile farms. Oh there's actually I actually saw an ad for it"}, {"timestamp": [2018.96, 2023.56], "text": " the first like portable farms are actually the the container shipping"}, {"timestamp": [2023.56, 2029.48], "text": " container farms are are coming. So that only that only ramps up and gets better over time so that"}, {"timestamp": [2029.48, 2034.04], "text": " means you go to the grocery store and everything that you could possibly want"}, {"timestamp": [2034.04, 2038.36], "text": " is there and it's fresh and it's local so that so you know some people are"}, {"timestamp": [2038.36, 2040.88], "text": " worried like oh well they're gonna take our steaks they're gonna take our"}, {"timestamp": [2040.88, 2046.04], "text": " burgers I don't think so I think think you're actually going to have much more options and they're going to be healthier"}, {"timestamp": [2046.04, 2049.32], "text": " options in a post-singularity world."}, {"timestamp": [2049.32, 2050.68], "text": " War."}, {"timestamp": [2050.68, 2055.68], "text": " So I did mention trauma politics and geopolitics earlier."}, {"timestamp": [2055.68, 2061.16], "text": " Obviously the biggest, the absolute biggest risk here is an AI arms race."}, {"timestamp": [2061.16, 2073.0], "text": " Even nations, liberal democracies that are not run by deeply traumatized tyrants are still going to be engaged in some kind of AI arms race, which is an unfortunate reality."}, {"timestamp": [2073.0, 2077.0], "text": " I'm not saying that that's a good thing. I'm not passing moral judgment on it. It's just an observation."}, {"timestamp": [2077.0, 2087.94], "text": " Every time there's new technology, it is integrated into the military apparatus. I also don't think that we're going to end up with a one world government, at least not"}, {"timestamp": [2087.94, 2093.7], "text": " any time soon, and there's numerous reasons for this, not the least of which is language"}, {"timestamp": [2093.7, 2101.22], "text": " barriers, cultural differences, past grievances between cultures."}, {"timestamp": [2101.22, 2108.26], "text": " You know, it could take many, many generations to heal those intercultural wounds before people even"}, {"timestamp": [2108.26, 2110.94], "text": " want to collaborate."}, {"timestamp": [2110.94, 2117.1], "text": " You look at the animosity between China and Japan, between Israel and Palestine, between"}, {"timestamp": [2117.1, 2121.42], "text": " Iran and a bunch of other nations, and so on and so forth."}, {"timestamp": [2121.42, 2127.2], "text": " It takes a lot of work to heal those wounds. And there's a lot of resistance to healing those wounds."}, {"timestamp": [2127.2, 2130.56], "text": " And those wounds could continue to fester."}, {"timestamp": [2130.56, 2132.9], "text": " What I'm hoping is that AI actually"}, {"timestamp": [2132.9, 2136.88], "text": " helps us break the cycle of intergenerational trauma."}, {"timestamp": [2136.88, 2140.08], "text": " And so then within maybe two or three generations,"}, {"timestamp": [2140.08, 2143.72], "text": " we're ready for a more peaceful global community."}, {"timestamp": [2143.72, 2146.8], "text": " And again, I still don't think that a global government is going to happen"}, {"timestamp": [2146.8, 2151.28], "text": " just because, like, geographically speaking, like, it kind of makes sense to"}, {"timestamp": [2151.28, 2154.0], "text": " have the nations, the nation states, and then the"}, {"timestamp": [2154.0, 2156.72], "text": " union model. That makes the most sense right now."}, {"timestamp": [2156.72, 2159.68], "text": " Like, you know, France is still France, Great Britain is still Great Britain, but"}, {"timestamp": [2159.68, 2164.56], "text": " they're part of the European Union, right? And over time, I do suspect that those"}, {"timestamp": [2164.56, 2166.24], "text": " continental-sized unions will"}, {"timestamp": [2166.24, 2171.52], "text": " get stronger, but not that they'll replace the local governments. Just like, you know, we have"}, {"timestamp": [2171.52, 2176.08], "text": " municipal, we have local city governments, we have county, we have state governments, and we have"}, {"timestamp": [2176.08, 2180.96], "text": " federal governments. I think that we're just going to add a few tiers on top of that, and eventually"}, {"timestamp": [2180.96, 2188.34], "text": " we will end up with a global governance. But again, I think that it's probably at least two or three generations away minimum. And then"}, {"timestamp": [2188.34, 2194.2], "text": " finally, corporations. So I did promise that I would address this. So some people,"}, {"timestamp": [2194.2, 2198.44], "text": " and this includes myself, I hope that corporations as we know them go away."}, {"timestamp": [2198.44, 2203.92], "text": " Because corporations are intrinsically amoral, and I don't mean immoral, amoral."}, {"timestamp": [2203.92, 2205.04], "text": " In corporations, their morality is only beholden to the investor, right, to the Corporations are intrinsically amoral, and I don't mean immoral, amoral."}, {"timestamp": [2205.04, 2210.4], "text": " Corporations, their morality is only beholden to the investor, to the shareholders."}, {"timestamp": [2210.4, 2216.36], "text": " And the shareholders just want more value, whatever it costs."}, {"timestamp": [2216.36, 2220.24], "text": " Corporations will always explore every little nook and cranny of what they can legally get"}, {"timestamp": [2220.24, 2228.28], "text": " away with, and that often results in bad things things such as mistreatment of people, environmental"}, {"timestamp": [2228.28, 2230.38], "text": " abuse and so on."}, {"timestamp": [2230.38, 2234.74], "text": " So because corporations are intrinsically amoral, I hope that they go away, but I don't"}, {"timestamp": [2234.74, 2236.48], "text": " think that they will."}, {"timestamp": [2236.48, 2241.62], "text": " I tried to figure out how the singularity could result in this, but the more I explored"}, {"timestamp": [2241.62, 2249.84], "text": " it, the more I realized, like, no, basically what's going to happen is that AI is going to allow corporations to produce more with less."}, {"timestamp": [2249.84, 2253.3], "text": " So productivity will continue to go up while headcount goes down."}, {"timestamp": [2253.3, 2258.16], "text": " And I talked about this in my AI jobpocalypse video a couple months ago."}, {"timestamp": [2258.16, 2263.2], "text": " Basically what's going to happen is that you're going to see corporations replace as many"}, {"timestamp": [2263.2, 2271.2], "text": " of their workers as they can. And so then you have the owner, the ownership class, whether it's shareholders, CEOs, whoever,"}, {"timestamp": [2271.84, 2278.4], "text": " is going to have basically unmitigated stock price growth. Because suddenly the greatest"}, {"timestamp": [2278.4, 2290.8], "text": " constraint and the most expensive aspect of running a corporation, human labor is no longer a factor. So I think that we are at risk of seeing like the megacorp things that you see in like dystopian"}, {"timestamp": [2290.8, 2292.24], "text": " sci-fi."}, {"timestamp": [2292.24, 2297.32], "text": " I think that we probably are at risk of seeing, you know, multi-trillion dollar, quadrillion"}, {"timestamp": [2297.32, 2302.12], "text": " dollar companies out there that have almost no employees, that are all entirely run by"}, {"timestamp": [2302.12, 2304.76], "text": " shareholders and then AI."}, {"timestamp": [2304.76, 2307.52], "text": " So that is an interesting thing."}, {"timestamp": [2307.52, 2312.0], "text": " Now as to whether or not they will allow the rest of us to live in certain ways, I kind"}, {"timestamp": [2312.0, 2314.16], "text": " of think that they don't care, right?"}, {"timestamp": [2314.16, 2321.52], "text": " Because as obscenely wealthy as corporations are going to be, like, there's just, it doesn't"}, {"timestamp": [2321.52, 2325.0], "text": " make sense for them to expend any energy depriving everyone else."}, {"timestamp": [2325.0, 2333.0], "text": " And so, like, let's just imagine that, like, Elon Musk takes SpaceX and uses it to start harvesting asteroids,"}, {"timestamp": [2333.0, 2341.0], "text": " and SpaceX becomes a 20 trillion dollar company by harvesting iridium and cobalt and platinum from asteroids."}, {"timestamp": [2341.0, 2345.44], "text": " Great. Is Elon Musk going to personally say, actually I don't think"}, {"timestamp": [2345.44, 2349.8], "text": " that I think that everyone should live in slums and favelas around the world? No"}, {"timestamp": [2349.8, 2353.92], "text": " he's not gonna care. He doesn't give a crap how everyone else lives as long as"}, {"timestamp": [2353.92, 2357.24], "text": " he's a trillionaire, right? And so when I think it through it that way it's like"}, {"timestamp": [2357.24, 2363.0], "text": " it would take a lot of deliberate effort on corporate to on behalf of"}, {"timestamp": [2363.0, 2367.46], "text": " corporations to deliberately deprive the rest of us of a better life."}, {"timestamp": [2367.46, 2369.48], "text": " So I don't think that's going to happen."}, {"timestamp": [2369.48, 2374.3], "text": " Certainly it's something to be aware of because again, corporations are intrinsically amoral,"}, {"timestamp": [2374.3, 2379.46], "text": " which is one of the biggest risks to our standard of living in the future."}, {"timestamp": [2379.46, 2381.08], "text": " Okay, that's that."}, {"timestamp": [2381.08, 2382.08], "text": " Thanks for watching."}, {"timestamp": [2382.08, 2385.24], "text": " I hope you found this video enlightening and thought-provoking"}, {"timestamp": [2387.12, 2389.12], "text": " Yeah, I know that uh"}, {"timestamp": [2389.24, 2394.94], "text": " There there will probably be some disagreements in the comments. Um, keep it civil or you get banned. Thanks. Bye"}]}